{
  "version": 3,
  "sources": ["../../../common/lib/backend-impl.ts", "../../../common/lib/backend.ts", "../../../common/lib/version.ts", "../../../common/lib/env-impl.ts", "../../../common/lib/env.ts", "../../../common/lib/tensor-conversion-impl.ts", "../../../common/lib/tensor-factory-impl.ts", "../../../common/lib/tensor-impl-type-mapping.ts", "../../../common/lib/tensor-utils-impl.ts", "../../../common/lib/tensor-impl.ts", "../../../common/lib/tensor.ts", "../../../common/lib/inference-session-impl.ts", "../../../common/lib/inference-session.ts", "../../../common/lib/onnx-value.ts", "../../../common/lib/training-session-impl.ts", "../../../common/lib/training-session.ts", "../../../common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../../lib/wasm/binding/ort-wasm-threaded.worker.js", "../../lib/wasm/wasm-factory.ts", "../../lib/wasm/wasm-utils.ts", "../../lib/wasm/run-options.ts", "../../lib/wasm/session-options.ts", "../../lib/wasm/wasm-common.ts", "../../lib/wasm/jsep/log.ts", "../../lib/wasm/jsep/tensor-view.ts", "../../lib/wasm/jsep/webgpu/types.ts", "../../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../../lib/wasm/jsep/util.ts", "../../lib/wasm/jsep/webgpu/ops/common.ts", "../../lib/wasm/jsep/webgpu/ops/reduce.ts", "../../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../../lib/wasm/jsep/webgpu/ops/concat.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../../lib/wasm/jsep/webgpu/ops/transpose.ts", "../../lib/wasm/jsep/webgpu/ops/conv.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../../lib/wasm/jsep/webgpu/ops/einsum.ts", "../../lib/wasm/jsep/webgpu/ops/expand.ts", "../../lib/wasm/jsep/webgpu/ops/gather.ts", "../../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../../lib/wasm/jsep/webgpu/ops/gemm.ts", "../../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/matmul.ts", "../../lib/wasm/jsep/webgpu/ops/pad.ts", "../../lib/wasm/jsep/webgpu/ops/pool.ts", "../../lib/wasm/jsep/webgpu/ops/range.ts", "../../lib/wasm/jsep/webgpu/ops/resize.ts", "../../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/slice.ts", "../../lib/wasm/jsep/webgpu/ops/softmax.ts", "../../lib/wasm/jsep/webgpu/ops/split.ts", "../../lib/wasm/jsep/webgpu/ops/tile.ts", "../../lib/wasm/jsep/webgpu/ops/where.ts", "../../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../../lib/wasm/jsep/webgpu/program-manager.ts", "../../lib/wasm/jsep/backend-webgpu.ts", "../../lib/wasm/jsep/init.ts", "../../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../../lib/wasm/proxy-wrapper.ts", "../../lib/wasm/session-handler.ts", "../../lib/backend-wasm.ts", "../../lib/backend-wasm-inference.ts", "../../lib/index.ts", "../../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    numThreads?: number;\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(_trainingOptions: TrainingSessionCreateOptions, _sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    throw new Error('Method not implemented');\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  runTrainStep(feeds: InferenceSession.OnnxValueMapType, options?: InferenceSession.RunOptions|undefined):\n      Promise<InferenceSession.OnnxValueMapType>;\n  runTrainStep(\n      feeds: InferenceSession.OnnxValueMapType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions|undefined): Promise<InferenceSession.OnnxValueMapType>;\n  async runTrainStep(_feeds: unknown, _fetches?: unknown, _options?: unknown):\n      Promise<InferenceSession.OnnxValueMapType> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\nvar ortWasm = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nvar d=moduleArg,aa,k;d.ready=new Promise((a,b)=>{aa=a;k=b});\"use strict\";\nd.jsepInit=(a,b,c,e,f,h,l,q)=>{d.Za=a;d.Oa=b;d.Qa=c;d.Ja=e;d.Pa=f;d.ra=h;d.Ra=l;d.Sa=q;b=(m,n,p)=>(...u)=>{const v=t,g=n?.();u=m(...u);const r=n?.();g!==r&&(m=r,p(g),n=p=null);return t!=v?ba():u};c=m=>async(...n)=>{try{if(d.Da)throw Error(\"Session already started\");const p=d.Da={Ta:n[0],errors:[]},u=await m(...n);if(d.Da!==p)throw Error(\"Session mismatch\");a.flush();const v=p.errors;if(0<v.length){let g=await Promise.all(v);g=g.filter(r=>r);if(0<g.length)throw Error(g.join(\"\\n\"));}return u}finally{d.Da=\nnull}};d._OrtRun=c(b(d._OrtRun,()=>d._OrtRun,m=>d._OrtRun=m));d._OrtRunWithBinding=c(b(d._OrtRunWithBinding,()=>d._OrtRunWithBinding,m=>d._OrtRunWithBinding=m));d._OrtBindInput=b(d._OrtBindInput,()=>d._OrtBindInput,m=>d._OrtBindInput=m);d.jsepRegisterBuffer=(m,n,p,u)=>a.registerBuffer(m,n,p,u);d.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};d.jsepGetBuffer=m=>a.getBuffer(m);d.jsepCreateDownloader=(m,n,p)=>a.createDownloader(m,n,p)};\nvar ca=Object.assign({},d),x=\"./this.program\",y=(a,b)=>{throw b;},da=\"object\"==typeof window,z=\"function\"==typeof importScripts,ea=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,A=\"\",B,C,D;\nif(ea){var fs=require(\"fs\"),fa=require(\"path\");A=z?fa.dirname(A)+\"/\":__dirname+\"/\";B=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};D=a=>{a=B(a,!0);a.buffer||(a=new Uint8Array(a));return a};C=(a,b,c,e=!0)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);fs.readFile(a,e?void 0:\"utf8\",(f,h)=>{f?c(f):b(e?h.buffer:h)})};!d.thisProgram&&1<process.argv.length&&(x=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);y=(a,b)=>{process.exitCode=\na;throw b;};d.inspect=()=>\"[Emscripten Module object]\"}else if(da||z)z?A=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),0!==A.indexOf(\"blob:\")?A=A.substr(0,A.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):A=\"\",B=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},z&&(D=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\nC=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)};var ha=d.print||console.log.bind(console),E=d.printErr||console.error.bind(console);Object.assign(d,ca);ca=null;d.thisProgram&&(x=d.thisProgram);d.quit&&(y=d.quit);var F;d.wasmBinary&&(F=d.wasmBinary);var noExitRuntime=d.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&H(\"no native wasm support detected\");\nvar I,J,K=!1,L,M,N,O,P,ia;function ja(){var a=I.buffer;d.HEAP8=M=new Int8Array(a);d.HEAP16=new Int16Array(a);d.HEAP32=O=new Int32Array(a);d.HEAPU8=N=new Uint8Array(a);d.HEAPU16=new Uint16Array(a);d.HEAPU32=P=new Uint32Array(a);d.HEAPF32=new Float32Array(a);d.HEAPF64=ia=new Float64Array(a)}var ka=[],la=[],ma=[];function na(){var a=d.preRun.shift();ka.unshift(a)}var Q=0,oa=null,R=null;\nfunction H(a){if(d.onAbort)d.onAbort(a);a=\"Aborted(\"+a+\")\";E(a);K=!0;L=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");k(a);throw a;}function pa(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var S;S=\"ort-wasm-simd.wasm\";if(!pa(S)){var qa=S;S=d.locateFile?d.locateFile(qa,A):A+qa}function ra(a){if(a==S&&F)return new Uint8Array(F);if(D)return D(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction sa(a){if(!F&&(da||z)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>ra(a));if(C)return new Promise((b,c)=>{C(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>ra(a))}function ta(a,b,c){return sa(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{E(\"failed to asynchronously prepare wasm: \"+e);H(e)})}\nfunction ua(a,b){var c=S;return F||\"function\"!=typeof WebAssembly.instantiateStreaming||pa(c)||c.startsWith(\"file://\")||ea||\"function\"!=typeof fetch?ta(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){E(\"wasm streaming compile failed: \"+f);E(\"falling back to ArrayBuffer instantiation\");return ta(c,a,b)}))}\nvar T,va={910336:a=>{d.ra(\"Abs\",a,void 0)},910387:a=>{d.ra(\"Neg\",a,void 0)},910438:a=>{d.ra(\"Floor\",a,void 0)},910491:a=>{d.ra(\"Ceil\",a,void 0)},910543:a=>{d.ra(\"Reciprocal\",a,void 0)},910601:a=>{d.ra(\"Sqrt\",a,void 0)},910653:a=>{d.ra(\"Exp\",a,void 0)},910704:a=>{d.ra(\"Erf\",a,void 0)},910755:a=>{d.ra(\"Sigmoid\",a,void 0)},910810:a=>{d.ra(\"Log\",a,void 0)},910861:a=>{d.ra(\"Sin\",a,void 0)},910912:a=>{d.ra(\"Cos\",a,void 0)},910963:a=>{d.ra(\"Tan\",a,void 0)},911014:a=>{d.ra(\"Asin\",a,void 0)},911066:a=>{d.ra(\"Acos\",\na,void 0)},911118:a=>{d.ra(\"Atan\",a,void 0)},911170:a=>{d.ra(\"Sinh\",a,void 0)},911222:a=>{d.ra(\"Cosh\",a,void 0)},911274:a=>{d.ra(\"Asinh\",a,void 0)},911327:a=>{d.ra(\"Acosh\",a,void 0)},911380:a=>{d.ra(\"Atanh\",a,void 0)},911433:a=>{d.ra(\"Tanh\",a,void 0)},911485:a=>{d.ra(\"Not\",a,void 0)},911536:(a,b,c)=>{d.ra(\"ClipV10\",a,{min:b,max:c})},911608:a=>{d.ra(\"Clip\",a,void 0)},911660:(a,b)=>{d.ra(\"Elu\",a,{alpha:b})},911718:a=>{d.ra(\"Relu\",a,void 0)},911770:(a,b)=>{d.ra(\"LeakyRelu\",a,{alpha:b})},911834:(a,b)=>\n{d.ra(\"ThresholdedRelu\",a,{alpha:b})},911904:(a,b)=>{d.ra(\"Cast\",a,{to:b})},911962:a=>{d.ra(\"Add\",a,void 0)},912013:a=>{d.ra(\"Sub\",a,void 0)},912064:a=>{d.ra(\"Mul\",a,void 0)},912115:a=>{d.ra(\"Div\",a,void 0)},912166:a=>{d.ra(\"Pow\",a,void 0)},912217:a=>{d.ra(\"Equal\",a,void 0)},912270:a=>{d.ra(\"Greater\",a,void 0)},912325:a=>{d.ra(\"GreaterOrEqual\",a,void 0)},912387:a=>{d.ra(\"Less\",a,void 0)},912439:a=>{d.ra(\"LessOrEqual\",a,void 0)},912498:(a,b,c,e,f)=>{d.ra(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},912662:(a,b,c,e,f)=>{d.ra(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},912825:(a,b,c,e,f)=>{d.ra(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},912988:(a,b,c,e,f)=>{d.ra(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913152:(a,b,c,e,f)=>{d.ra(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913315:(a,b,c,e,f)=>{d.ra(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913477:(a,b,c,e,f)=>{d.ra(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913639:(a,b,c,e,f)=>{d.ra(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913805:(a,b,c,e,f)=>{d.ra(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913974:(a,b,c,e,f)=>{d.ra(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},914143:a=>{d.ra(\"Where\",a,void 0)},914196:(a,b,c)=>{d.ra(\"Transpose\",a,{perm:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[]})},914309:(a,b,c,e,f,h,l,q,m,n)=>{d.ra(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[q],w_is_const:()=>!!M[n>>>0]})},914537:(a,b,c,e,f,h,l,q,\nm,n,p,u,v,g,r)=>{d.ra(\"Conv\",a,{format:g?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,l],pads:[q,m,n,p],strides:[u,v],w_is_const:()=>!!M[r>>>0]})},914796:(a,b,c,e,f,h,l,q,m,n)=>{d.ra(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[q],w_is_const:()=>!!M[n>>>0]})},915024:(a,b,c,e,f,h,l,q,m,n,p,u,v,g,r)=>{d.ra(\"Conv\",a,{format:g?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,l],pads:[q,m,n,p],strides:[u,v],w_is_const:()=>\n!!M[r>>>0]})},915283:(a,b,c,e,f,h,l,q,m,n,p,u,v,g)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[q],wIsConst:()=>!!M[n>>>0],outputPadding:p?Array.from(O.subarray(u>>>0,u+p>>>0)):[],outputShape:v?Array.from(O.subarray(g>>>0,g+v>>>0)):[]})},915663:(a,b,c,e,f,h,l,q,m,n,p,u,v)=>{d.ra(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(f>>>0,\nf+2>>>0)),pads:Array.from(O.subarray(h>>>0,h+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<n?Array.from(O.subarray(p>>>0,p+n>>>0)):[],outputShape:0<u?Array.from(O.subarray(v>>>0,v+u>>>0)):[]})},916186:(a,b,c,e,f,h,l,q,m,n,p,u,v,g)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[q],wIsConst:()=>!!M[n>>>0],outputPadding:p?Array.from(O.subarray(u>>>0,u+p>>>0)):[],outputShape:v?Array.from(O.subarray(g>>>\n0,g+v>>>0)):[]})},916566:(a,b,c,e,f,h,l,q,m,n,p,u,v)=>{d.ra(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(f>>>0,f+2>>>0)),pads:Array.from(O.subarray(h>>>0,h+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<n?Array.from(O.subarray(p>>>0,p+n>>>0)):[],outputShape:0<u?Array.from(O.subarray(v>>>0,v+u>>>0)):[]})},917089:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\n\"NHWC\":\"NCHW\"})},917180:(a,b,c,e,f,h,l,q,m,n,p,u,v,g,r,w)=>{d.ra(\"AveragePool\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[q,m],pads:[n,p,u,v],strides:[g,r]})},917464:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},917555:(a,b,c,e,f,h,l,q,m,n,p,u,v,g,r,w)=>{d.ra(\"AveragePool\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[q,m],pads:[n,p,u,v],strides:[g,\nr]})},917839:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},917926:(a,b,c,e,f,h,l,q,m,n,p,u,v,g,r,w)=>{d.ra(\"MaxPool\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[q,m],pads:[n,p,u,v],strides:[g,r]})},918206:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},918293:(a,b,c,e,f,h,l,q,m,n,p,u,v,g,r,w)=>{d.ra(\"MaxPool\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,\nl],kernel_shape:[q,m],pads:[n,p,u,v],strides:[g,r]})},918573:(a,b,c,e,f)=>{d.ra(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},918677:a=>{d.ra(\"MatMul\",a,void 0)},918731:(a,b,c,e)=>{d.ra(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},918839:(a,b,c,e)=>{d.ra(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},918947:(a,b)=>{d.ra(\"Softmax\",a,{axis:b})},919010:(a,b)=>{d.ra(\"Concat\",a,{axis:b})},919070:(a,b,c,e,f)=>{d.ra(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},919215:a=>{d.ra(\"Expand\",a,void 0)},919269:(a,b)=>{d.ra(\"Gather\",a,{axis:Number(b)})},919340:(a,b)=>{d.ra(\"GatherElements\",a,{axis:Number(b)})},919419:(a,b,c,e,f,h,l,q,m,n,p)=>{d.ra(\"Resize\",a,{antialias:b,axes:c?Array.from(O.subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:U(f),cubicCoeffA:h,excludeOutside:l,extrapolationValue:q,keepAspectRatioPolicy:U(m),mode:U(n),nearestMode:U(p)})},919770:(a,b,c,e,f,h,l)=>{d.ra(\"Slice\",a,{starts:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[],\nends:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(O.subarray(l>>>0,l+h>>>0)):[]})},920001:a=>{d.ra(\"Tile\",a,void 0)},920053:(a,b,c)=>{d.ra(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},920160:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},920274:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},920388:a=>{d.ra(\"Range\",a,void 0)},920441:(a,b)=>{d.ra(\"Einsum\",a,{equation:U(b)})},920522:(a,b,c,e,f)=>{d.ra(\"Pad\",\na,{mode:b,value:c,pads:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},920654:a=>{d.ra(\"Gelu\",a,void 0)},920706:a=>{d.ra(\"BiasAdd\",a,void 0)},920761:a=>{d.ra(\"BiasSplitGelu\",a,void 0)},920822:(a,b)=>{d.ra(\"SkipLayerNormalization\",a,{epsilon:b})},920903:a=>{d.Ra(a)},920937:(a,b)=>d.Sa(a,b,d.Da.Ta,d.Da.errors),921049:a=>d.Oa(a),921082:a=>d.Qa(a),921114:(a,b,c)=>{d.Ja(a,b,c,!0)},921153:(a,b,c)=>{d.Ja(a,b,c)}};\nfunction wa(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var xa=a=>{for(;0<a.length;)a.shift()(d)};function ya(a){this.Ha=a-24;this.Ma=function(b){P[this.Ha+4>>2>>>0]=b};this.La=function(b){P[this.Ha+8>>2>>>0]=b};this.Ya=function(b,c){this.Ka();this.Ma(b);this.La(c)};this.Ka=function(){P[this.Ha+16>>2>>>0]=0}}\nvar za=0,Aa=0,Ba=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Ca=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ba)return Ba.decode(a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var l=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|l:(f&7)<<18|h<<12|l<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},\nU=(a,b)=>(a>>>=0)?Ca(N,a,b):\"\",Da=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},Ea=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var l=a.charCodeAt(h);if(55296<=l&&57343>=l){var q=a.charCodeAt(++h);l=65536+((l&1023)<<10)|q&1023}if(127>=l){if(c>=e)break;b[c++>>>0]=l}else{if(2047>=l){if(c+1>=e)break;b[c++>>>0]=192|l>>6}else{if(65535>=l){if(c+2>=e)break;b[c++>>>0]=224|l>>12}else{if(c+\n3>=e)break;b[c++>>>0]=240|l>>18;b[c++>>>0]=128|l>>12&63}b[c++>>>0]=128|l>>6&63}b[c++>>>0]=128|l&63}}b[c>>>0]=0;return c-f},V=a=>0===a%4&&(0!==a%100||0===a%400),Fa=[0,31,60,91,121,152,182,213,244,274,305,335],Ga=[0,31,59,90,120,151,181,212,243,273,304,334],Ia=a=>{var b=Da(a)+1,c=Ha(b);c&&Ea(a,N,c,b);return c},Ja=[],Ka=(a,b)=>{Ja.length=0;var c;for(b>>=2;c=N[a++>>>0];)b+=105!=c&b,Ja.push(105==c?O[b>>>0]:ia[b++>>>1]),++b;return Ja},Ma={},Oa=()=>{if(!Na){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",\nPWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:x||\"./this.program\"},b;for(b in Ma)void 0===Ma[b]?delete a[b]:a[b]=Ma[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Na=c}return Na},Na,Pa=[null,[],[]],Qa=[31,29,31,30,31,30,31,31,30,31,30,31],Ra=[31,28,31,30,31,30,31,31,30,31,30,31];function Sa(a){var b=Array(Da(a)+1);Ea(a,b,0,b.length);return b}\nfunction Ta(a,b,c,e){function f(g,r,w){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<r;)g=w[0]+g;return g}function h(g,r){return f(g,r,\"0\")}function l(g,r){function w(La){return 0>La?-1:0<La?1:0}var G;0===(G=w(g.getFullYear()-r.getFullYear()))&&0===(G=w(g.getMonth()-r.getMonth()))&&(G=w(g.getDate()-r.getDate()));return G}function q(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var r=g.Ba;for(g=new Date((new Date(g.Ca+1900,0,1)).getTime());0<r;){var w=g.getMonth(),G=(V(g.getFullYear())?Qa:Ra)[w];if(r>G-g.getDate())r-=G-g.getDate()+1,g.setDate(1),11>w?g.setMonth(w+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+r);break}}w=new Date(g.getFullYear()+1,0,4);r=q(new Date(g.getFullYear(),\n0,4));w=q(w);return 0>=l(r,g)?0>=l(w,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var n=O[e+40>>2>>>0];e={Wa:O[e>>2>>>0],Va:O[e+4>>2>>>0],Ea:O[e+8>>2>>>0],Ia:O[e+12>>2>>>0],Fa:O[e+16>>2>>>0],Ca:O[e+20>>2>>>0],wa:O[e+24>>2>>>0],Ba:O[e+28>>2>>>0],$a:O[e+32>>2>>>0],Ua:O[e+36>>2>>>0],Xa:n?U(n):\"\"};c=U(c);n={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var p in n)c=c.replace(new RegExp(p,\"g\"),n[p]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),v=\"January February March April May June July August September October November December\".split(\" \");n={\"%a\":g=>u[g.wa].substring(0,3),\"%A\":g=>u[g.wa],\"%b\":g=>v[g.Fa].substring(0,\n3),\"%B\":g=>v[g.Fa],\"%C\":g=>h((g.Ca+1900)/100|0,2),\"%d\":g=>h(g.Ia,2),\"%e\":g=>f(g.Ia,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.Ea,2),\"%I\":g=>{g=g.Ea;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var r=0,w=0;w<=g.Fa-1;r+=(V(g.Ca+1900)?Qa:Ra)[w++]);return h(g.Ia+r,3)},\"%m\":g=>h(g.Fa+1,2),\"%M\":g=>h(g.Va,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.Ea&&12>g.Ea?\"AM\":\"PM\",\"%S\":g=>h(g.Wa,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.wa||7,\"%U\":g=>h(Math.floor((g.Ba+7-g.wa)/7),2),\"%V\":g=>{var r=Math.floor((g.Ba+\n7-(g.wa+6)%7)/7);2>=(g.wa+371-g.Ba-2)%7&&r++;if(r)53==r&&(w=(g.wa+371-g.Ba)%7,4==w||3==w&&V(g.Ca)||(r=1));else{r=52;var w=(g.wa+7-g.Ba-1)%7;(4==w||5==w&&V(g.Ca%400-1))&&r++}return h(r,2)},\"%w\":g=>g.wa,\"%W\":g=>h(Math.floor((g.Ba+7-(g.wa+6)%7)/7),2),\"%y\":g=>(g.Ca+1900).toString().substring(2),\"%Y\":g=>g.Ca+1900,\"%z\":g=>{g=g.Ua;var r=0<=g;g=Math.abs(g)/60;return(r?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Xa,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(p in n)c.includes(p)&&(c=c.replace(new RegExp(p,\n\"g\"),n[p](e)));c=c.replace(/\\0\\0/g,\"%\");p=Sa(c);if(p.length>b)return 0;M.set(p,a>>>0);return p.length-1}function W(a){try{a()}catch(b){H(b)}}function Ua(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){X.push(e);try{return f.apply(null,arguments)}finally{K||(X.pop()===e||H(),t&&1===Y&&0===X.length&&(Y=0,W(Va),\"undefined\"!=typeof Fibers&&Fibers.ab()))}}:f})(c);return b}var Y=0,t=null,Wa=0,X=[],Xa={},Ya={},Za=0,$a=null,ab=[];\nfunction ba(){return new Promise((a,b)=>{$a={resolve:a,reject:b}})}function bb(){var a=Ha(65548),b=a+12;P[a>>2>>>0]=b;P[a+4>>2>>>0]=b+65536;b=X[0];var c=Xa[b];void 0===c&&(c=Za++,Xa[b]=c,Ya[c]=b);O[a+8>>2>>>0]=c;return a}\nfunction cb(a){if(!K){if(0===Y){var b=!1,c=!1;a((e=0)=>{if(!K&&(Wa=e,b=!0,c)){Y=2;W(()=>db(t));\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.resume();e=!1;try{var f=(0,J[Ya[O[t+8>>2>>>0]]])()}catch(q){f=q,e=!0}var h=!1;if(!t){var l=$a;l&&($a=null,(e?l.reject:l.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Y=1,t=bb(),\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.pause(),W(()=>eb(t)))}else 2===Y?(Y=0,W(fb),gb(t),t=null,ab.forEach(e=>{if(!K)try{if(e(),!noExitRuntime)try{L=L=e=L;if(!noExitRuntime){if(d.onExit)d.onExit(e);\nK=!0}y(e,new wa(e))}catch(f){f instanceof wa||\"unwind\"==f||y(1,f)}}catch(f){f instanceof wa||\"unwind\"==f||y(1,f)}})):H(`invalid state: ${Y}`);return Wa}}function hb(a){return cb(b=>{a().then(b)})}\nvar jb={n:function(a,b,c){return hb(async()=>{await d.Pa(a,b,c)})},a:function(a,b,c){a>>>=0;(new ya(a)).Ya(b>>>0,c>>>0);za=a;Aa++;throw za;},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getUTCSeconds();O[c+4>>2>>>0]=\na.getUTCMinutes();O[c+8>>2>>>0]=a.getUTCHours();O[c+12>>2>>>0]=a.getUTCDate();O[c+16>>2>>>0]=a.getUTCMonth();O[c+20>>2>>>0]=a.getUTCFullYear()-1900;O[c+24>>2>>>0]=a.getUTCDay();O[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},r:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getSeconds();O[c+4>>2>>>0]=a.getMinutes();O[c+8>>2>>>0]=a.getHours();O[c+12>>2>>>0]=a.getDate();O[c+16>>2>>>0]=a.getMonth();O[c+20>>2>>>\n0]=a.getFullYear()-1900;O[c+24>>2>>>0]=a.getDay();O[c+28>>2>>>0]=(V(a.getFullYear())?Fa:Ga)[a.getMonth()]+a.getDate()-1|0;O[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();O[c+32>>2>>>0]=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0},s:function(a){a>>>=0;var b=new Date(O[a+20>>2>>>0]+1900,O[a+16>>2>>>0],O[a+12>>2>>>0],O[a+8>>2>>>0],O[a+4>>2>>>0],O[a>>2>>>0],0),c=O[a+32>>2>>>0],e=b.getTimezoneOffset(),\nf=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),l=Math.min(h,f);0>c?O[a+32>>2>>>0]=Number(f!=h&&l==e):0<c!=(l==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?l:f)-e)));O[a+24>>2>>>0]=b.getDay();O[a+28>>2>>>0]=(V(b.getFullYear())?Fa:Ga)[b.getMonth()]+b.getDate()-1|0;O[a>>2>>>0]=b.getSeconds();O[a+4>>2>>>0]=b.getMinutes();O[a+8>>2>>>0]=b.getHours();O[a+12>>2>>>0]=b.getDate();O[a+16>>2>>>0]=b.getMonth();O[a+20>>2>>>0]=b.getYear();a=b.getTime()/\n1E3;return ib((T=a,1<=+Math.abs(T)?0<T?+Math.floor(T/4294967296)>>>0:~~+Math.ceil((T-+(~~T>>>0))/4294967296)>>>0:0)),a>>>0},o:function(){return-52},p:function(){},v:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),l=new Date(f,6,1);f=h.getTimezoneOffset();var q=l.getTimezoneOffset();P[a>>>0>>2>>>0]=60*Math.max(f,q);O[b>>>0>>2>>>0]=Number(f!=q);a=e(h);b=e(l);a=Ia(a);b=Ia(b);q<f?(P[c>>2>>>0]=a,P[c+\n4>>2>>>0]=b):(P[c>>2>>>0]=b,P[c+4>>2>>>0]=a)},e:()=>{H(\"\")},b:function(a,b,c){a>>>=0;b=Ka(b>>>0,c>>>0);return va[a].apply(null,b)},i:function(a,b,c){a>>>=0;b=Ka(b>>>0,c>>>0);return va[a].apply(null,b)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(a,b,c){b>>>=0;return N.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},u:function(a){a>>>=0;var b=N.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;\ne=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-I.buffer.byteLength+65535>>>16;try{I.grow(f);ja();var h=1;break a}catch(l){}h=void 0}if(h)return!0}return!1},D:function(a,b){a>>>=0;b>>>=0;var c=0;Oa().forEach(function(e,f){var h=b+c;f=P[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)M[f++>>0>>>0]=e.charCodeAt(h);M[f>>0>>>0]=0;c+=e.length+1});return 0},E:function(a,b){a>>>=0;b>>>=0;var c=Oa();P[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});P[b>>2>>>0]=e;return 0},f:()=>\n52,k:function(){return 52},t:function(){return 70},j:function(a,b,c,e){b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var l=P[b>>2>>>0],q=P[b+4>>2>>>0];b+=8;for(var m=0;m<q;m++){var n=N[l+m>>>0],p=Pa[a];0===n||10===n?((1===a?ha:E)(Ca(p,0)),p.length=0):p.push(n)}f+=q}P[e>>2>>>0]=f;return 0},F:Ta,d:function(a,b,c,e){return Ta(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c){c=c.exports;c=Ua(c);J=c=kb(c);I=J.M;ja();la.unshift(J.N);Q--;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(0==Q&&(null!==oa&&(clearInterval(oa),oa=null),R)){var e=R;R=null;e()}return c}var b={a:jb};Q++;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(d.instantiateWasm)try{return d.instantiateWasm(b,a)}catch(c){E(\"Module.instantiateWasm callback failed with error: \"+c),k(c)}ua(b,function(c){a(c.instance)}).catch(k);return{}})();\nd._OrtInit=(a,b)=>(d._OrtInit=J.O)(a,b);d._OrtGetLastError=(a,b)=>(d._OrtGetLastError=J.P)(a,b);d._OrtCreateSessionOptions=(a,b,c,e,f,h,l,q,m,n)=>(d._OrtCreateSessionOptions=J.Q)(a,b,c,e,f,h,l,q,m,n);d._OrtAppendExecutionProvider=(a,b)=>(d._OrtAppendExecutionProvider=J.R)(a,b);d._OrtAddFreeDimensionOverride=(a,b,c)=>(d._OrtAddFreeDimensionOverride=J.S)(a,b,c);d._OrtAddSessionConfigEntry=(a,b,c)=>(d._OrtAddSessionConfigEntry=J.T)(a,b,c);d._OrtReleaseSessionOptions=a=>(d._OrtReleaseSessionOptions=J.U)(a);\nd._OrtCreateSession=(a,b,c)=>(d._OrtCreateSession=J.V)(a,b,c);d._OrtReleaseSession=a=>(d._OrtReleaseSession=J.W)(a);d._OrtGetInputOutputCount=(a,b,c)=>(d._OrtGetInputOutputCount=J.X)(a,b,c);d._OrtGetInputName=(a,b)=>(d._OrtGetInputName=J.Y)(a,b);d._OrtGetOutputName=(a,b)=>(d._OrtGetOutputName=J.Z)(a,b);d._OrtFree=a=>(d._OrtFree=J._)(a);d._OrtCreateTensor=(a,b,c,e,f,h)=>(d._OrtCreateTensor=J.$)(a,b,c,e,f,h);d._OrtGetTensorData=(a,b,c,e,f)=>(d._OrtGetTensorData=J.aa)(a,b,c,e,f);\nd._OrtReleaseTensor=a=>(d._OrtReleaseTensor=J.ba)(a);d._OrtCreateRunOptions=(a,b,c,e)=>(d._OrtCreateRunOptions=J.ca)(a,b,c,e);d._OrtAddRunConfigEntry=(a,b,c)=>(d._OrtAddRunConfigEntry=J.da)(a,b,c);d._OrtReleaseRunOptions=a=>(d._OrtReleaseRunOptions=J.ea)(a);d._OrtCreateBinding=a=>(d._OrtCreateBinding=J.fa)(a);d._OrtBindInput=(a,b,c)=>(d._OrtBindInput=J.ga)(a,b,c);d._OrtBindOutput=(a,b,c,e)=>(d._OrtBindOutput=J.ha)(a,b,c,e);d._OrtClearBoundOutputs=a=>(d._OrtClearBoundOutputs=J.ia)(a);\nd._OrtReleaseBinding=a=>(d._OrtReleaseBinding=J.ja)(a);d._OrtRunWithBinding=(a,b,c,e,f)=>(d._OrtRunWithBinding=J.ka)(a,b,c,e,f);d._OrtRun=(a,b,c,e,f,h,l,q)=>(d._OrtRun=J.la)(a,b,c,e,f,h,l,q);d._OrtEndProfiling=a=>(d._OrtEndProfiling=J.ma)(a);d._JsepOutput=(a,b,c)=>(d._JsepOutput=J.na)(a,b,c);d._JsepGetNodeName=a=>(d._JsepGetNodeName=J.oa)(a);\nvar Ha=d._malloc=a=>(Ha=d._malloc=J.pa)(a),gb=d._free=a=>(gb=d._free=J.qa)(a),ib=a=>(ib=J.sa)(a),lb=()=>(lb=J.ta)(),mb=a=>(mb=J.ua)(a),nb=a=>(nb=J.va)(a),eb=a=>(eb=J.xa)(a),Va=()=>(Va=J.ya)(),db=a=>(db=J.za)(a),fb=()=>(fb=J.Aa)();d.___start_em_js=921186;d.___stop_em_js=921347;function kb(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}d.stackAlloc=nb;\nd.stackSave=lb;d.stackRestore=mb;d.UTF8ToString=U;d.stringToUTF8=(a,b,c)=>Ea(a,N,b,c);d.lengthBytesUTF8=Da;var Z;R=function ob(){Z||pb();Z||(R=ob)};\nfunction pb(){function a(){if(!Z&&(Z=!0,d.calledRun=!0,!K)){xa(la);aa(d);if(d.onRuntimeInitialized)d.onRuntimeInitialized();if(d.postRun)for(\"function\"==typeof d.postRun&&(d.postRun=[d.postRun]);d.postRun.length;){var b=d.postRun.shift();ma.unshift(b)}xa(ma)}}if(!(0<Q)){if(d.preRun)for(\"function\"==typeof d.preRun&&(d.preRun=[d.preRun]);d.preRun.length;)na();xa(ka);0<Q||(d.setStatus?(d.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){d.setStatus(\"\")},1);a()},1)):a())}}\nif(d.preInit)for(\"function\"==typeof d.preInit&&(d.preInit=[d.preInit]);0<d.preInit.length;)d.preInit.pop()();pb();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasm;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasm);\n", "", "", "export const cpus = undefined;", "\nvar ortWasmThreaded = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nfunction d(){l.buffer!=p.buffer&&t();return p}function v(){l.buffer!=p.buffer&&t();return aa}function z(){l.buffer!=p.buffer&&t();return ba}function A(){l.buffer!=p.buffer&&t();return ca}function da(){l.buffer!=p.buffer&&t();return ea}var B=moduleArg,fa,C;B.ready=new Promise((a,b)=>{fa=a;C=b});\"use strict\";\nB.jsepInit=(a,b,c,e,f,h,k,q)=>{B.Qb=a;B.wb=b;B.yb=c;B.jb=e;B.xb=f;B.Ea=h;B.zb=k;B.Ab=q;b=(n,m,r)=>(...w)=>{const x=D,g=m?.();w=n(...w);const u=m?.();g!==u&&(n=u,r(g),m=r=null);return D!=x?ha():w};c=n=>async(...m)=>{try{if(B.bb)throw Error(\"Session already started\");const r=B.bb={Fb:m[0],errors:[]},w=await n(...m);if(B.bb!==r)throw Error(\"Session mismatch\");a.flush();const x=r.errors;if(0<x.length){let g=await Promise.all(x);g=g.filter(u=>u);if(0<g.length)throw Error(g.join(\"\\n\"));}return w}finally{B.bb=\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,n=>B._OrtRun=n));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,n=>B._OrtRunWithBinding=n));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,n=>B._OrtBindInput=n);B.jsepRegisterBuffer=(n,m,r,w)=>a.registerBuffer(n,m,r,w);B.jsepUnregisterBuffers=n=>{a.unregisterBuffers(n)};B.jsepGetBuffer=n=>a.getBuffer(n);B.jsepCreateDownloader=(n,m,r)=>a.createDownloader(n,m,r)};\nvar ia=Object.assign({},B),ja=\"./this.program\",E=(a,b)=>{throw b;},ka=\"object\"==typeof window,F=\"function\"==typeof importScripts,G=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,H=B.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function la(a){return B.locateFile?B.locateFile(a,I):I+a}var ma,J,na;\nif(G){var fs=require(\"fs\"),oa=require(\"path\");I=F?oa.dirname(I)+\"/\":__dirname+\"/\";ma=(b,c)=>{b=b.startsWith(\"file://\")?new URL(b):oa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};na=b=>{b=ma(b,!0);b.buffer||(b=new Uint8Array(b));return b};J=(b,c,e,f=!0)=>{b=b.startsWith(\"file://\")?new URL(b):oa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(h,k)=>{h?e(h):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(ja=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);E=(b,c)=>{process.exitCode=\nb;throw c;};B.inspect=()=>\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(ka||F)F?I=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(I=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(I=_scriptDir),0!==I.indexOf(\"blob:\")?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",G||(ma=a=>{var b=\nnew XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},F&&(na=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),J=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)});G&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);\nvar pa=console.log.bind(console),qa=console.error.bind(console);G&&(pa=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),qa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var ra=B.print||pa,K=B.printErr||qa;Object.assign(B,ia);ia=null;B.thisProgram&&(ja=B.thisProgram);B.quit&&(E=B.quit);var L;B.wasmBinary&&(L=B.wasmBinary);var noExitRuntime=B.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&M(\"no native wasm support detected\");var l,N,sa,P=!1,Q,p,aa,ba,ca,ea;\nfunction t(){var a=l.buffer;B.HEAP8=p=new Int8Array(a);B.HEAP16=new Int16Array(a);B.HEAP32=ba=new Int32Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=new Uint16Array(a);B.HEAPU32=ca=new Uint32Array(a);B.HEAPF32=new Float32Array(a);B.HEAPF64=ea=new Float64Array(a)}var ta=B.INITIAL_MEMORY||16777216;5242880<=ta||M(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+ta+\"! (STACK_SIZE=5242880)\");\nif(H)l=B.wasmMemory;else if(B.wasmMemory)l=B.wasmMemory;else if(l=new WebAssembly.Memory({initial:ta/65536,maximum:65536,shared:!0}),!(l.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),G&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),\nError(\"bad memory\");t();ta=l.buffer.byteLength;var ua=[],va=[],wa=[],xa=0;function ya(){return noExitRuntime||0<xa}var R=0,za=null,S=null;function Aa(){R++;B.monitorRunDependencies&&B.monitorRunDependencies(R)}function Ba(){R--;B.monitorRunDependencies&&B.monitorRunDependencies(R);if(0==R&&(null!==za&&(clearInterval(za),za=null),S)){var a=S;S=null;a()}}\nfunction M(a){if(B.onAbort)B.onAbort(a);a=\"Aborted(\"+a+\")\";K(a);P=!0;Q=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");C(a);throw a;}function Ca(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var T;T=\"ort-wasm-simd-threaded.wasm\";Ca(T)||(T=la(T));function Da(a){if(a==T&&L)return new Uint8Array(L);if(na)return na(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction Ea(a){if(!L&&(ka||F)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Da(a));if(J)return new Promise((b,c)=>{J(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>Da(a))}function Fa(a,b,c){return Ea(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{K(\"failed to asynchronously prepare wasm: \"+e);M(e)})}\nfunction Ga(a,b){var c=T;return L||\"function\"!=typeof WebAssembly.instantiateStreaming||Ca(c)||c.startsWith(\"file://\")||G||\"function\"!=typeof fetch?Fa(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){K(\"wasm streaming compile failed: \"+f);K(\"falling back to ArrayBuffer instantiation\");return Fa(c,a,b)}))}\nvar U,Ha={911532:a=>{B.Ea(\"Abs\",a,void 0)},911583:a=>{B.Ea(\"Neg\",a,void 0)},911634:a=>{B.Ea(\"Floor\",a,void 0)},911687:a=>{B.Ea(\"Ceil\",a,void 0)},911739:a=>{B.Ea(\"Reciprocal\",a,void 0)},911797:a=>{B.Ea(\"Sqrt\",a,void 0)},911849:a=>{B.Ea(\"Exp\",a,void 0)},911900:a=>{B.Ea(\"Erf\",a,void 0)},911951:a=>{B.Ea(\"Sigmoid\",a,void 0)},912006:a=>{B.Ea(\"Log\",a,void 0)},912057:a=>{B.Ea(\"Sin\",a,void 0)},912108:a=>{B.Ea(\"Cos\",a,void 0)},912159:a=>{B.Ea(\"Tan\",a,void 0)},912210:a=>{B.Ea(\"Asin\",a,void 0)},912262:a=>{B.Ea(\"Acos\",\na,void 0)},912314:a=>{B.Ea(\"Atan\",a,void 0)},912366:a=>{B.Ea(\"Sinh\",a,void 0)},912418:a=>{B.Ea(\"Cosh\",a,void 0)},912470:a=>{B.Ea(\"Asinh\",a,void 0)},912523:a=>{B.Ea(\"Acosh\",a,void 0)},912576:a=>{B.Ea(\"Atanh\",a,void 0)},912629:a=>{B.Ea(\"Tanh\",a,void 0)},912681:a=>{B.Ea(\"Not\",a,void 0)},912732:(a,b,c)=>{B.Ea(\"ClipV10\",a,{min:b,max:c})},912804:a=>{B.Ea(\"Clip\",a,void 0)},912856:(a,b)=>{B.Ea(\"Elu\",a,{alpha:b})},912914:a=>{B.Ea(\"Relu\",a,void 0)},912966:(a,b)=>{B.Ea(\"LeakyRelu\",a,{alpha:b})},913030:(a,b)=>\n{B.Ea(\"ThresholdedRelu\",a,{alpha:b})},913100:(a,b)=>{B.Ea(\"Cast\",a,{to:b})},913158:a=>{B.Ea(\"Add\",a,void 0)},913209:a=>{B.Ea(\"Sub\",a,void 0)},913260:a=>{B.Ea(\"Mul\",a,void 0)},913311:a=>{B.Ea(\"Div\",a,void 0)},913362:a=>{B.Ea(\"Pow\",a,void 0)},913413:a=>{B.Ea(\"Equal\",a,void 0)},913466:a=>{B.Ea(\"Greater\",a,void 0)},913521:a=>{B.Ea(\"GreaterOrEqual\",a,void 0)},913583:a=>{B.Ea(\"Less\",a,void 0)},913635:a=>{B.Ea(\"LessOrEqual\",a,void 0)},913694:(a,b,c,e,f)=>{B.Ea(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},913858:(a,b,c,e,f)=>{B.Ea(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914021:(a,b,c,e,f)=>{B.Ea(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914184:(a,b,c,e,f)=>{B.Ea(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914348:(a,b,c,e,f)=>{B.Ea(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914511:(a,b,c,e,f)=>{B.Ea(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914673:(a,b,c,e,f)=>{B.Ea(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},914835:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},915001:(a,b,c,e,f)=>{B.Ea(\"ReduceSumSquare\",a,{keepDims:!!b,\nnoopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},915170:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},915339:a=>{B.Ea(\"Where\",a,void 0)},915392:(a,b,c)=>{B.Ea(\"Transpose\",a,{perm:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[]})},915505:(a,b,c,e,f,h,k,q,n,m)=>{B.Ea(\"Conv\",a,{format:n?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],w_is_const:()=>!!d()[m>>>\n0]})},915733:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u)=>{B.Ea(\"Conv\",a,{format:g?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,k],pads:[q,n,m,r],strides:[w,x],w_is_const:()=>!!d()[u>>>0]})},915992:(a,b,c,e,f,h,k,q,n,m)=>{B.Ea(\"Conv\",a,{format:n?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],w_is_const:()=>!!d()[m>>>0]})},916220:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u)=>{B.Ea(\"Conv\",a,{format:g?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,\nk],pads:[q,n,m,r],strides:[w,x],w_is_const:()=>!!d()[u>>>0]})},916479:(a,b,c,e,f,h,k,q,n,m,r,w,x,g)=>{B.Ea(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[m>>>0],outputPadding:r?Array.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:x?Array.from(z().subarray(g>>>0,g+x>>>0)):[]})},916859:(a,b,c,e,f,h,k,q,n,m,r,w,x)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+\n2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[n>>>0],outputPadding:0<m?Array.from(z().subarray(r>>>0,r+m>>>0)):[],outputShape:0<w?Array.from(z().subarray(x>>>0,x+w>>>0)):[]})},917382:(a,b,c,e,f,h,k,q,n,m,r,w,x,g)=>{B.Ea(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[m>>>0],outputPadding:r?\nArray.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:x?Array.from(z().subarray(g>>>0,g+x>>>0)):[]})},917762:(a,b,c,e,f,h,k,q,n,m,r,w,x)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[n>>>0],outputPadding:0<m?Array.from(z().subarray(r>>>0,r+m>>>0)):[],outputShape:0<\nw?Array.from(z().subarray(x>>>0,x+w>>>0)):[]})},918285:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},918376:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u,y)=>{B.Ea(\"AveragePool\",a,{format:y?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,n],pads:[m,r,w,x],strides:[g,u]})},918660:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},918751:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u,y)=>{B.Ea(\"AveragePool\",a,{format:y?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,\ncount_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,n],pads:[m,r,w,x],strides:[g,u]})},919035:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},919122:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u,y)=>{B.Ea(\"MaxPool\",a,{format:y?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,n],pads:[m,r,w,x],strides:[g,u]})},919402:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},919489:(a,b,c,e,f,h,k,q,n,m,r,w,x,g,u,y)=>{B.Ea(\"MaxPool\",\na,{format:y?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,n],pads:[m,r,w,x],strides:[g,u]})},919769:(a,b,c,e,f)=>{B.Ea(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},919873:a=>{B.Ea(\"MatMul\",a,void 0)},919927:(a,b,c,e)=>{B.Ea(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},920035:(a,b,c,e)=>{B.Ea(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},920143:(a,b)=>{B.Ea(\"Softmax\",a,{axis:b})},920206:(a,b)=>{B.Ea(\"Concat\",a,{axis:b})},\n920266:(a,b,c,e,f)=>{B.Ea(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},920411:a=>{B.Ea(\"Expand\",a,void 0)},920465:(a,b)=>{B.Ea(\"Gather\",a,{axis:Number(b)})},920536:(a,b)=>{B.Ea(\"GatherElements\",a,{axis:Number(b)})},920615:(a,b,c,e,f,h,k,q,n,m,r)=>{B.Ea(\"Resize\",a,{antialias:b,axes:c?Array.from(z().subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:V(f),cubicCoeffA:h,excludeOutside:k,extrapolationValue:q,keepAspectRatioPolicy:V(n),mode:V(m),nearestMode:V(r)})},\n920966:(a,b,c,e,f,h,k)=>{B.Ea(\"Slice\",a,{starts:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[]})},921197:a=>{B.Ea(\"Tile\",a,void 0)},921249:(a,b,c)=>{B.Ea(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},921356:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},921470:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},921584:a=>{B.Ea(\"Range\",\na,void 0)},921637:(a,b)=>{B.Ea(\"Einsum\",a,{equation:V(b)})},921718:(a,b,c,e,f)=>{B.Ea(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},921850:a=>{B.Ea(\"Gelu\",a,void 0)},921902:a=>{B.Ea(\"BiasAdd\",a,void 0)},921957:a=>{B.Ea(\"BiasSplitGelu\",a,void 0)},922018:(a,b)=>{B.Ea(\"SkipLayerNormalization\",a,{epsilon:b})},922099:a=>{B.zb(a)},922133:(a,b)=>B.Ab(a,b,B.bb.Fb,B.bb.errors),922245:a=>B.wb(a),922278:a=>B.yb(a),922310:(a,b,c)=>{B.jb(a,b,c,!0)},922349:(a,b,c)=>{B.jb(a,b,c)}};\nfunction Ia(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}function Ja(a){a.terminate();a.onmessage=()=>{}}function Ka(a){(a=W.Qa[a])||M();W.Eb(a)}function La(a){var b=W.tb();if(!b)return 6;W.Ya.push(b);W.Qa[a.Xa]=b;b.Xa=a.Xa;var c={cmd:\"run\",start_routine:a.Gb,arg:a.rb,pthread_ptr:a.Xa};G&&b.unref();b.postMessage(c,a.Mb);return 0}\nvar Ma=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Na=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ma)return Ma.decode(a.buffer instanceof SharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|k:(f&7)<<18|h<<12|k<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>\n10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},V=(a,b)=>(a>>>=0)?Na(v(),a,b):\"\";function Oa(a){if(H)return X(1,1,a);Q=a;if(!ya()){W.Hb();if(B.onExit)B.onExit(a);P=!0}E(a,new Ia(a))}\nvar Qa=a=>{Q=a;if(H)throw Pa(a),\"unwind\";Oa(a)},W={ab:[],Ya:[],mb:[],Qa:{},gb:function(){H?W.vb():W.ub()},ub:function(){ua.unshift(()=>{Aa();W.Bb(()=>Ba())})},vb:function(){W.receiveObjectTransfer=W.Db;W.threadInitTLS=W.lb;W.setExitStatus=W.kb;noExitRuntime=!1},kb:function(a){Q=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of W.Ya)Ja(a);for(a of W.ab)Ja(a);W.ab=[];W.Ya=[];W.Qa=[]},Eb:function(a){var b=a.Xa;delete W.Qa[b];W.ab.push(a);W.Ya.splice(W.Ya.indexOf(a),1);a.Xa=0;Ra(b)},Db:function(){},\nlb:function(){W.mb.forEach(a=>a())},Cb:a=>new Promise(b=>{a.onmessage=h=>{h=h.data;var k=h.cmd;if(h.targetThread&&h.targetThread!=Sa()){var q=W.Qa[h.Rb];q?q.postMessage(h,h.transferList):K('Internal error! Worker sent a message \"'+k+'\" to target pthread '+h.targetThread+\", but that thread no longer exists!\")}else if(\"checkMailbox\"===k)Ta();else if(\"spawnThread\"===k)La(h);else if(\"cleanupThread\"===k)Ka(h.thread);else if(\"killThread\"===k)h=h.thread,k=W.Qa[h],delete W.Qa[h],Ja(k),Ra(h),W.Ya.splice(W.Ya.indexOf(k),\n1),k.Xa=0;else if(\"cancelThread\"===k)W.Qa[h.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,b(a);else if(\"alert\"===k)alert(\"Thread \"+h.threadId+\": \"+h.text);else if(\"setimmediate\"===h.target)a.postMessage(h);else if(\"callHandler\"===k)B[h.handler](...h.args);else k&&K(\"worker sent an unknown command \"+k)};a.onerror=h=>{K(\"worker sent an error! \"+h.filename+\":\"+h.lineno+\": \"+h.message);throw h;};G&&(a.on(\"message\",function(h){a.onmessage({data:h})}),a.on(\"error\",function(h){a.onerror(h)}));\nvar c=[],e=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],f;for(f of e)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:l,wasmModule:sa})}),Bb:function(a){a()},qb:function(){var a=la(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a);W.ab.push(a)},tb:function(){0==W.ab.length&&(W.qb(),W.Cb(W.ab[0]));return W.ab.pop()}};B.PThread=W;var Ua=a=>{for(;0<a.length;)a.shift()(B)};\nB.establishStackSpace=function(){var a=Sa(),b=z()[a+52>>2>>>0];a=z()[a+56>>2>>>0];Va(b,b-a);Wa(b)};function Pa(a){if(H)return X(2,0,a);Qa(a)}B.invokeEntryPoint=function(a,b){a=Xa.apply(null,[a,b]);ya()?W.kb(a):Ya(a)};function Za(a){this.fb=a-24;this.pb=function(b){A()[this.fb+4>>2>>>0]=b};this.ob=function(b){A()[this.fb+8>>2>>>0]=b};this.gb=function(b,c){this.nb();this.pb(b);this.ob(c)};this.nb=function(){A()[this.fb+16>>2>>>0]=0}}var $a=0,ab=0;\nfunction bb(a,b,c,e){return H?X(3,1,a,b,c,e):cb(a,b,c,e)}function cb(a,b,c,e){a>>>=0;b>>>=0;c>>>=0;e>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(H&&0===f.length)return bb(a,b,c,e);a={Gb:c,Xa:a,rb:e,Mb:f};return H?(a.Ob=\"spawnThread\",postMessage(a,f),0):La(a)}function db(a,b,c){return H?X(4,1,a,b,c):0}function eb(a,b){if(H)return X(5,1,a,b)}\nvar fb=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},gb=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var k=a.charCodeAt(h);if(55296<=k&&57343>=k){var q=a.charCodeAt(++h);k=65536+((k&1023)<<10)|q&1023}if(127>=k){if(c>=e)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=e)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=e)break;b[c++>>>0]=224|k>>12}else{if(c+3>=e)break;b[c++>>>0]=240|k>>\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},hb=(a,b,c)=>gb(a,v(),b,c);function ib(a,b){if(H)return X(6,1,a,b)}function jb(a,b,c){if(H)return X(7,1,a,b,c)}function kb(a,b,c){return H?X(8,1,a,b,c):0}function lb(a,b){if(H)return X(9,1,a,b)}function mb(a,b,c){if(H)return X(10,1,a,b,c)}function nb(a,b,c,e){if(H)return X(11,1,a,b,c,e)}function ob(a,b,c,e){if(H)return X(12,1,a,b,c,e)}function pb(a,b,c,e){if(H)return X(13,1,a,b,c,e)}\nfunction qb(a){if(H)return X(14,1,a)}function rb(a,b){if(H)return X(15,1,a,b)}function sb(a,b,c){if(H)return X(16,1,a,b,c)}var tb=a=>{if(!P)try{if(a(),!ya())try{H?Ya(Q):Qa(Q)}catch(b){b instanceof Ia||\"unwind\"==b||E(1,b)}}catch(b){b instanceof Ia||\"unwind\"==b||E(1,b)}};function ub(a){a>>>=0;\"function\"===typeof Atomics.Nb&&(Atomics.Nb(z(),a>>2,a).value.then(Ta),a+=128,Atomics.store(z(),a>>2,1))}B.__emscripten_thread_mailbox_await=ub;function Ta(){var a=Sa();a&&(ub(a),tb(()=>vb()))}B.checkMailbox=Ta;\nvar Y=a=>0===a%4&&(0!==a%100||0===a%400),wb=[0,31,60,91,121,152,182,213,244,274,305,335],xb=[0,31,59,90,120,151,181,212,243,273,304,334];function yb(a,b,c,e,f,h,k,q){return H?X(17,1,a,b,c,e,f,h,k,q):-52}function zb(a,b,c,e,f,h,k){if(H)return X(18,1,a,b,c,e,f,h,k)}var Bb=a=>{var b=fb(a)+1,c=Ab(b);c&&hb(a,c,b);return c},Cb=[],Db=(a,b)=>{Cb.length=0;var c;for(b>>=2;c=v()[a++>>>0];)b+=105!=c&b,Cb.push(105==c?z()[b>>>0]:da()[b++>>>1]),++b;return Cb},Fb=a=>{var b=Eb();a=a();Wa(b);return a};\nfunction X(a,b){var c=arguments.length-2,e=arguments;return Fb(()=>{for(var f=Gb(8*c),h=f>>3,k=0;k<c;k++){var q=e[2+k];da()[h+k>>>0]=q}return Hb(a,c,f,b)})}\nvar Ib=[],Jb={},Lb=()=>{if(!Kb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:ja||\"./this.program\"},b;for(b in Jb)void 0===Jb[b]?delete a[b]:a[b]=Jb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Kb=c}return Kb},Kb;\nfunction Mb(a,b){if(H)return X(19,1,a,b);a>>>=0;b>>>=0;var c=0;Lb().forEach(function(e,f){var h=b+c;f=A()[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)d()[f++>>0>>>0]=e.charCodeAt(h);d()[f>>0>>>0]=0;c+=e.length+1});return 0}function Nb(a,b){if(H)return X(20,1,a,b);a>>>=0;b>>>=0;var c=Lb();A()[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});A()[b>>2>>>0]=e;return 0}function Ob(a){return H?X(21,1,a):52}function Pb(a,b,c,e){return H?X(22,1,a,b,c,e):52}\nfunction Qb(a,b,c,e,f){return H?X(23,1,a,b,c,e,f):70}var Rb=[null,[],[]];function Tb(a,b,c,e){if(H)return X(24,1,a,b,c,e);b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var k=A()[b>>2>>>0],q=A()[b+4>>2>>>0];b+=8;for(var n=0;n<q;n++){var m=v()[k+n>>>0],r=Rb[a];0===m||10===m?((1===a?ra:K)(Na(r,0)),r.length=0):r.push(m)}f+=q}A()[e>>2>>>0]=f;return 0}var Ub=[31,29,31,30,31,30,31,31,30,31,30,31],Vb=[31,28,31,30,31,30,31,31,30,31,30,31];function Wb(a){var b=Array(fb(a)+1);gb(a,b,0,b.length);return b}\nvar Xb=(a,b)=>{d().set(a,b>>>0)};\nfunction Yb(a,b,c,e){function f(g,u,y){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<u;)g=y[0]+g;return g}function h(g,u){return f(g,u,\"0\")}function k(g,u){function y(Sb){return 0>Sb?-1:0<Sb?1:0}var O;0===(O=y(g.getFullYear()-u.getFullYear()))&&0===(O=y(g.getMonth()-u.getMonth()))&&(O=y(g.getDate()-u.getDate()));return O}function q(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function n(g){var u=g.Za;for(g=new Date((new Date(g.$a+1900,0,1)).getTime());0<u;){var y=g.getMonth(),O=(Y(g.getFullYear())?Ub:Vb)[y];if(u>O-g.getDate())u-=O-g.getDate()+1,g.setDate(1),11>y?g.setMonth(y+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+u);break}}y=new Date(g.getFullYear()+1,0,4);u=q(new Date(g.getFullYear(),\n0,4));y=q(y);return 0>=k(u,g)?0>=k(y,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var m=z()[e+40>>2>>>0];e={Kb:z()[e>>2>>>0],Jb:z()[e+4>>2>>>0],cb:z()[e+8>>2>>>0],ib:z()[e+12>>2>>>0],eb:z()[e+16>>2>>>0],$a:z()[e+20>>2>>>0],Wa:z()[e+24>>2>>>0],Za:z()[e+28>>2>>>0],Tb:z()[e+32>>2>>>0],Ib:z()[e+36>>2>>>0],Lb:m?V(m):\"\"};c=V(c);m={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\n\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var r in m)c=c.replace(new RegExp(r,\"g\"),m[r]);var w=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),x=\"January February March April May June July August September October November December\".split(\" \");m={\"%a\":g=>w[g.Wa].substring(0,3),\"%A\":g=>w[g.Wa],\"%b\":g=>\nx[g.eb].substring(0,3),\"%B\":g=>x[g.eb],\"%C\":g=>h((g.$a+1900)/100|0,2),\"%d\":g=>h(g.ib,2),\"%e\":g=>f(g.ib,2,\" \"),\"%g\":g=>n(g).toString().substring(2),\"%G\":g=>n(g),\"%H\":g=>h(g.cb,2),\"%I\":g=>{g=g.cb;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var u=0,y=0;y<=g.eb-1;u+=(Y(g.$a+1900)?Ub:Vb)[y++]);return h(g.ib+u,3)},\"%m\":g=>h(g.eb+1,2),\"%M\":g=>h(g.Jb,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.cb&&12>g.cb?\"AM\":\"PM\",\"%S\":g=>h(g.Kb,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Wa||7,\"%U\":g=>h(Math.floor((g.Za+7-g.Wa)/7),2),\"%V\":g=>\n{var u=Math.floor((g.Za+7-(g.Wa+6)%7)/7);2>=(g.Wa+371-g.Za-2)%7&&u++;if(u)53==u&&(y=(g.Wa+371-g.Za)%7,4==y||3==y&&Y(g.$a)||(u=1));else{u=52;var y=(g.Wa+7-g.Za-1)%7;(4==y||5==y&&Y(g.$a%400-1))&&u++}return h(u,2)},\"%w\":g=>g.Wa,\"%W\":g=>h(Math.floor((g.Za+7-(g.Wa+6)%7)/7),2),\"%y\":g=>(g.$a+1900).toString().substring(2),\"%Y\":g=>g.$a+1900,\"%z\":g=>{g=g.Ib;var u=0<=g;g=Math.abs(g)/60;return(u?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Lb,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(r in m)c.includes(r)&&\n(c=c.replace(new RegExp(r,\"g\"),m[r](e)));c=c.replace(/\\0\\0/g,\"%\");r=Wb(c);if(r.length>b)return 0;Xb(r,a);return r.length-1}function Zb(a){try{a()}catch(b){M(b)}}function $b(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){ac.push(e);try{return f.apply(null,arguments)}finally{P||(ac.pop()===e||M(),D&&1===Z&&0===ac.length&&(Z=0,xa+=1,Zb(bc),\"undefined\"!=typeof Fibers&&Fibers.Ub()))}}:f})(c);return b}var Z=0,D=null,cc=0,ac=[],dc={},ec={},fc=0,gc=null,hc=[];\nfunction ha(){return new Promise((a,b)=>{gc={resolve:a,reject:b}})}function ic(){var a=Ab(65548),b=a+12;A()[a>>2>>>0]=b;A()[a+4>>2>>>0]=b+65536;b=ac[0];var c=dc[b];void 0===c&&(c=fc++,dc[b]=c,ec[c]=b);b=c;z()[a+8>>2>>>0]=b;return a}function jc(){var a=z()[D+8>>2>>>0];a=N[ec[a]];--xa;return a()}\nfunction kc(a){if(!P){if(0===Z){var b=!1,c=!1;a((e=0)=>{if(!P&&(cc=e,b=!0,c)){Z=2;Zb(()=>lc(D));\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.resume();e=!1;try{var f=jc()}catch(q){f=q,e=!0}var h=!1;if(!D){var k=gc;k&&(gc=null,(e?k.reject:k.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Z=1,D=ic(),\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.pause(),Zb(()=>mc(D)))}else 2===Z?(Z=0,Zb(nc),oc(D),D=null,hc.forEach(e=>tb(e))):M(`invalid state: ${Z}`);return cc}}\nfunction pc(a){return kc(b=>{a().then(b)})}W.gb();\nvar qc=[null,Oa,Pa,bb,db,eb,ib,jb,kb,lb,mb,nb,ob,pb,qb,rb,sb,yb,zb,Mb,Nb,Ob,Pb,Qb,Tb],tc={r:function(a,b,c){return pc(async()=>{await B.xb(a,b,c)})},b:function(a,b,c){a>>>=0;(new Za(a)).gb(b>>>0,c>>>0);$a=a;ab++;throw $a;},O:function(a){rc(a>>>0,!F,1,!ka,131072,!1);W.lb()},l:function(a){a>>>=0;H?postMessage({cmd:\"cleanupThread\",thread:a}):Ka(a)},I:cb,i:db,U:eb,E:ib,G:jb,V:kb,S:lb,K:mb,R:nb,p:ob,F:pb,C:qb,T:rb,D:sb,q:()=>!0,A:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>Ta()):H?postMessage({targetThread:a,\ncmd:\"checkMailbox\"}):(a=W.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:ub,X:function(a){G&&W.Qa[a>>>0].ref()},u:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getUTCSeconds();z()[c+4>>2>>>0]=a.getUTCMinutes();z()[c+8>>2>>>0]=a.getUTCHours();z()[c+12>>2>>>0]=a.getUTCDate();z()[c+16>>2>>>0]=a.getUTCMonth();z()[c+20>>2>>>0]=a.getUTCFullYear()-1900;z()[c+24>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),\n0,1,0,0,0,0))/864E5|0;z()[c+28>>2>>>0]=a},v:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getSeconds();z()[c+4>>2>>>0]=a.getMinutes();z()[c+8>>2>>>0]=a.getHours();z()[c+12>>2>>>0]=a.getDate();z()[c+16>>2>>>0]=a.getMonth();z()[c+20>>2>>>0]=a.getFullYear()-1900;z()[c+24>>2>>>0]=a.getDay();b=(Y(a.getFullYear())?wb:xb)[a.getMonth()]+a.getDate()-1|0;z()[c+28>>2>>>0]=b;z()[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),\n6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0;z()[c+32>>2>>>0]=a},w:function(a){a>>>=0;var b=new Date(z()[a+20>>2>>>0]+1900,z()[a+16>>2>>>0],z()[a+12>>2>>>0],z()[a+8>>2>>>0],z()[a+4>>2>>>0],z()[a>>2>>>0],0),c=z()[a+32>>2>>>0],e=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(h,f);0>c?z()[a+32>>2>>>0]=Number(f!=h&&k==e):\n0<c!=(k==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-e)));z()[a+24>>2>>>0]=b.getDay();c=(Y(b.getFullYear())?wb:xb)[b.getMonth()]+b.getDate()-1|0;z()[a+28>>2>>>0]=c;z()[a>>2>>>0]=b.getSeconds();z()[a+4>>2>>>0]=b.getMinutes();z()[a+8>>2>>>0]=b.getHours();z()[a+12>>2>>>0]=b.getDate();z()[a+16>>2>>>0]=b.getMonth();z()[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return sc((U=a,1<=+Math.abs(U)?0<U?+Math.floor(U/4294967296)>>>0:~~+Math.ceil((U-+(~~U>>>0))/4294967296)>>>0:0)),a>>>0},s:yb,t:zb,\nz:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),k=new Date(f,6,1);f=h.getTimezoneOffset();var q=k.getTimezoneOffset(),n=Math.max(f,q);A()[a>>2>>>0]=60*n;z()[b>>2>>>0]=Number(f!=q);a=e(h);b=e(k);a=Bb(a);b=Bb(b);q<f?(A()[c>>2>>>0]=a,A()[c+4>>2>>>0]=b):(A()[c>>2>>>0]=b,A()[c+4>>2>>>0]=a)},d:()=>{M(\"\")},c:function(a,b,c){a>>>=0;b=Db(b>>>0,c>>>0);return Ha[a].apply(null,b)},k:function(a,\nb,c){a>>>=0;b=Db(b>>>0,c>>>0);return Ha[a].apply(null,b)},m:function(){},j:function(){return Date.now()},W:()=>{xa+=1;throw\"unwind\";},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return G?require(\"os\").cpus().length:navigator.hardwareConcurrency},L:function(a,b,c,e){W.Pb=b>>>0;Ib.length=c;b=e>>>0>>3;for(e=0;e<c;e++)Ib[e]=da()[b+e>>>0];return(0>a?Ha[-a-1]:qc[a]).apply(null,Ib)},y:function(a){a>>>=0;var b=v().length;if(a<=b||4294901760<a)return!1;for(var c=\n1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;e=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-l.buffer.byteLength+65535>>>16;try{l.grow(f);t();var h=1;break a}catch(k){}h=void 0}if(h)return!0}return!1},P:Mb,Q:Nb,H:Qa,h:Ob,o:Pb,x:Qb,n:Tb,a:l||B.wasmMemory,J:Yb,e:function(a,b,c,e){return Yb(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c,e){c=c.exports;c=$b(c);N=c=uc(c);W.mb.push(N.Da);va.unshift(N.Y);sa=e;Ba();return c}var b={a:tc};Aa();if(B.instantiateWasm)try{return B.instantiateWasm(b,a)}catch(c){K(\"Module.instantiateWasm callback failed with error: \"+c),C(c)}Ga(b,function(c){a(c.instance,c.module)}).catch(C);return{}})();B._OrtInit=(a,b)=>(B._OrtInit=N.Z)(a,b);B._OrtGetLastError=(a,b)=>(B._OrtGetLastError=N._)(a,b);\nB._OrtCreateSessionOptions=(a,b,c,e,f,h,k,q,n,m)=>(B._OrtCreateSessionOptions=N.$)(a,b,c,e,f,h,k,q,n,m);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=N.aa)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=N.ba)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=N.ca)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=N.da)(a);B._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=N.ea)(a,b,c);\nB._OrtReleaseSession=a=>(B._OrtReleaseSession=N.fa)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=N.ga)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=N.ha)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=N.ia)(a,b);B._OrtFree=a=>(B._OrtFree=N.ja)(a);B._OrtCreateTensor=(a,b,c,e,f,h)=>(B._OrtCreateTensor=N.ka)(a,b,c,e,f,h);B._OrtGetTensorData=(a,b,c,e,f)=>(B._OrtGetTensorData=N.la)(a,b,c,e,f);B._OrtReleaseTensor=a=>(B._OrtReleaseTensor=N.ma)(a);\nB._OrtCreateRunOptions=(a,b,c,e)=>(B._OrtCreateRunOptions=N.na)(a,b,c,e);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=N.oa)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=N.pa)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=N.qa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=N.ra)(a,b,c);B._OrtBindOutput=(a,b,c,e)=>(B._OrtBindOutput=N.sa)(a,b,c,e);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=N.ta)(a);B._OrtReleaseBinding=a=>(B._OrtReleaseBinding=N.ua)(a);\nB._OrtRunWithBinding=(a,b,c,e,f)=>(B._OrtRunWithBinding=N.va)(a,b,c,e,f);B._OrtRun=(a,b,c,e,f,h,k,q)=>(B._OrtRun=N.wa)(a,b,c,e,f,h,k,q);B._OrtEndProfiling=a=>(B._OrtEndProfiling=N.xa)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=N.ya)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=N.za)(a);var Sa=B._pthread_self=()=>(Sa=B._pthread_self=N.Aa)(),Ab=B._malloc=a=>(Ab=B._malloc=N.Ba)(a),oc=B._free=a=>(oc=B._free=N.Ca)(a);B.__emscripten_tls_init=()=>(B.__emscripten_tls_init=N.Da)();\nvar rc=B.__emscripten_thread_init=(a,b,c,e,f,h)=>(rc=B.__emscripten_thread_init=N.Fa)(a,b,c,e,f,h);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=N.Ga)();\nvar Hb=(a,b,c,e)=>(Hb=N.Ha)(a,b,c,e),Ra=a=>(Ra=N.Ia)(a),Ya=B.__emscripten_thread_exit=a=>(Ya=B.__emscripten_thread_exit=N.Ja)(a),vb=B.__emscripten_check_mailbox=()=>(vb=B.__emscripten_check_mailbox=N.Ka)(),sc=a=>(sc=N.La)(a),Va=(a,b)=>(Va=N.Ma)(a,b),Eb=()=>(Eb=N.Na)(),Wa=a=>(Wa=N.Oa)(a),Gb=a=>(Gb=N.Pa)(a),Xa=B.dynCall_ii=(a,b)=>(Xa=B.dynCall_ii=N.Ra)(a,b),mc=a=>(mc=N.Sa)(a),bc=()=>(bc=N.Ta)(),lc=a=>(lc=N.Ua)(a),nc=()=>(nc=N.Va)();B.___start_em_js=922382;B.___stop_em_js=922543;\nfunction uc(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.pthread_self=b(a.pthread_self);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}B.keepRuntimeAlive=ya;B.wasmMemory=l;B.stackAlloc=Gb;B.stackSave=Eb;B.stackRestore=Wa;B.UTF8ToString=V;B.stringToUTF8=hb;B.lengthBytesUTF8=fb;B.ExitStatus=Ia;B.PThread=W;var vc;S=function wc(){vc||xc();vc||(S=wc)};\nfunction xc(){function a(){if(!vc&&(vc=!0,B.calledRun=!0,!P)){H||Ua(va);fa(B);if(B.onRuntimeInitialized)B.onRuntimeInitialized();if(!H){if(B.postRun)for(\"function\"==typeof B.postRun&&(B.postRun=[B.postRun]);B.postRun.length;){var b=B.postRun.shift();wa.unshift(b)}Ua(wa)}}}if(!(0<R))if(H)fa(B),H||Ua(va),startWorker(B);else{if(B.preRun)for(\"function\"==typeof B.preRun&&(B.preRun=[B.preRun]);B.preRun.length;)ua.unshift(B.preRun.shift());Ua(ua);0<R||(B.setStatus?(B.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){B.setStatus(\"\")},\n1);a()},1)):a())}}if(B.preInit)for(\"function\"==typeof B.preInit&&(B.preInit=[B.preInit]);0<B.preInit.length;)B.preInit.pop()();xc();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasmThreaded;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasmThreaded);\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason||e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(Module.__embind_initialize_bindings(),initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(`worker.js received unknown command ${e.data.cmd}`),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.numThreads) {\n                let numThreads = webnnOptions.numThreads;\n                // Just ignore invalid webnnOptions.numThreads.\n                if (typeof numThreads != 'number' || !Number.isInteger(numThreads) || numThreads < 0) {\n                  numThreads = 0;\n                }\n                const keyDataOffset = allocWasmString('numThreads', allocs);\n                const valueDataOffset = allocWasmString(numThreads.toString(), allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'numThreads' - ${webnnOptions.numThreads}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private _cacheKey: string;\n  public get cacheKey(): string {\n    if (!this._cacheKey) {\n      this._cacheKey =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this._cacheKey;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input or an output) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input or an output.\n   */\n  readonly usage: 'input'|'output';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]):\n    ProgramUniform[] => [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param isInput - whether the helper is for an input or an output.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], isInput: boolean,\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${strides}[${i}];\n    let rest${i} = current % ${strides}[${i}];\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${strides}[${i}] * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${varIndices}[${idx}]`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${varIndices}[${idx}]=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        if (!useUniform) {\n          impls.push(`const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`);\n          impls.push(`const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage: isInput ? 'input' : 'output',\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, true, components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, false, components);\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   */\n  registerUniform(name: string, type: string): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x;' :\n        `let global_idx = (workgroup_id.z * ${this.normalizedDispatchGroup[0] * this.normalizedDispatchGroup[1]}u +\n          workgroup_id.y * ${this.normalizedDispatchGroup[0]}u + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_index;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    this.indicesHelpers.push(variable);\n    if (variable.shape.startsWith('uniforms.')) {\n      this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: variable.type.indices});\n    }\n    if (variable.strides.startsWith('uniforms.')) {\n      this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: variable.type.indices});\n    }\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  registerUniform(name: string, type: string): ShaderHelper {\n    this.uniforms.push({name, type});\n    return this;\n  }\n\n  private indicesHelpers: IndicesHelper[] = [];\n  private uniforms: Array<{name: string; type: string}> = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type} of this.uniforms) {\n      uniformSnippets.push(`${name}:${type}`);\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.indicesHelpers.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByOffset('inputOffset')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputs[0].dims.length);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n\n      const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n      const ops = reduceOp(input, output, axes);\n      const inputOffsetAssignment = `inputOffset = ${input.indicesToOffset('inputIndices')};`;\n      const initinputOffsetLet = `let ${inputOffsetAssignment};`;\n      const initinputOffsetVar = `var ${inputOffsetAssignment};`;\n      const initinputOffset = (ops[1] === '') ? '' : initinputOffsetVar;\n      let reduceOps = ((ops[1] === '') ? initinputOffsetLet : inputOffsetAssignment) + '\\n' + ops[2];\n\n      for (let k = 0, l = 0; k < inputs[0].dims.length; k++) {\n        // if this axis is reduced\n        if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n          if (keepDims) {\n            l++;\n          }\n          // loop over the d-th axis\n          reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputs[0].dims[k]}; j${k}++) {\n                ${ops[2].includes('lastIndex') ? `let lastIndex = j${k};` : ''}\n                ${input.indicesSet('inputIndices', k, `j${k}`)}\n                ${reduceOps}\n              }`;\n        } else {\n          idxCopy.push(`${input.indicesSet('inputIndices', k, output.indicesGet('outputIndices', l))};`);\n          l++;\n        }\n      }\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          var inputIndices: ${input.type.indices};\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${initinputOffset}\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n      };\n    };\n\nconst createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByOffset('inputOffset')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByOffset('inputOffset')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('inputIndices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = max(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByOffset('inputOffset')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = min(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nexport const parseReduceAttributes = (attributes: Record<string, unknown>): ReduceAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ReduceAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nconst createArgMinMaxAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ArgMinMaxAttributes): ArgMinMaxAttributes =>\n        createAttributeWithCacheKey(\n            {axis: attributes.axis, keepDims: attributes.keepDims, selectLastIndex: attributes.selectLastIndex});\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n  ${shaderHelper.declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)}\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nexport const clipV10 = (context: ComputeContext, attributes: ClipAttributes): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext): void => {\n  const attributes = generateClipAttributesFromInputs(context.inputs);\n  clipV10(context, attributes);\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_: f32 = f32(${attributes.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<f32>(0.0))`,\n      `const leaky_relu_alpha_: f32 = f32(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<f32>(0.0), ${a}, ${a} > vec4<f32>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<f32>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl('vec4f')}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, funcCall: BinaryFunctionCall, typeA: number, typeB: number,\n     typeOutput: number, additionalImplementation?: string) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      let broadcastImpl = '';\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', typeA, dimsA, 4);\n      const b = inputVariable('bData', typeB, dimsB, 4);\n      if (doBroadcast) {\n        const calcOffsetImpl = (dims: readonly number[]) => {\n          const strides = ShapeUtil.computeStrides(dims);\n          const offsets: string[] = [];\n          for (let i = dims.length - 1; i >= 0; i--) {\n            const idx = output.indicesGet('outputIndices', i + dimsOutput.length - dims.length);\n            offsets.push(`${strides[i]}u * (${idx} % ${dims[i]}u)`);\n          }\n          return offsets.length > 0 ? offsets.join('+') : '0u';\n        };\n\n        broadcastImpl = `\n          fn calcOffsetA(outputIndices: ${output.type.indices}) -> u32 {\n            return ${calcOffsetImpl(dimsA)};\n          }\n\n          fn calcOffsetB(outputIndices: ${output.type.indices}) -> u32 {\n            return ${calcOffsetImpl(dimsB)};\n          }\n        `;\n      }\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = calcOffsetA(outputIndices);\n            let offsetB = calcOffsetB(outputIndices);\n            ${\n                output.setByOffset(\n                    'global_idx', expressionVector(a.getByOffset('offsetA / 4u'), b.getByOffset('offsetB / 4u')))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = calcOffsetA(outputIndices${x});\n            let offsetB${x} = calcOffsetB(outputIndices${x});\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n        ${broadcastImpl}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0 || isAOneElement || isBOneElement) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n\n      return {\n        name,\n        shaderCache: {hint: cacheKey},\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, funcCall, a.dataType, b.dataType,\n            outputDataType, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)}\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n\n  const output = outputVariable('output', dataType, outputShape);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateInputIndexImpl(sizeInConcatAxis.length)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport declare type Activation = 'linear' | 'relu' | 'prelu' | 'elu' | 'relu6' | 'leakyrelu' | 'sigmoid' | 'gelu';\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const activationFnSnippet =\n    (activation?: Activation, _hasPreluActivationWeights = false, _packed = false, _coordsLength = 3): string => {\n      if (!activation) {\n        return '';\n      }\n\n      // TODO: add implementations\n      return '';\n    };\n\nexport const biasActivationSnippet = (hasBias: boolean, activation?: Activation): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      ${activation ? 'value = activation(value, coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = `\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActicationSnippet =\n    (attributes: InternalActivationAttributes): {activationFunction: string; applyActivation: string} => {\n      switch (attributes.activation) {\n        case 'Relu':\n          return {activationFunction: '', applyActivation: 'value = max(value, 0.0);'};\n        case 'Sigmoid':\n          return {activationFunction: '', applyActivation: 'value = (1.0 / (1.0 + exp(-value)));'};\n        case 'Clip':\n          return {\n            activationFunction:\n                `const clip_min_=f32(${attributes.clipMin!});const clip_max_=f32(${attributes.clipMax!});`,\n            applyActivation: 'value = clamp(value, clip_min_, clip_max_);'\n          };\n          // TODO: adding other activations that can be fused.\n        default:\n          return {activationFunction: '', applyActivation: ''};\n      }\n    };\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {getBroadcastDims, IndicesHelper, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActicationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const batchAShape = batchShapes[0];\n      const batchBShape = batchShapes[1];\n      const batchShape = batchShapes[2];\n      const batchVariable = variables[0];\n      const aVariable = variables[1];\n      const bVariable = variables[2];\n      const outputVariable = variables[3];\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const batchDims = inputVariable('batchDims', inputs[0].dataType, outerDims);\n      const variables = [batchDims];\n      const batchShapes = [outerDimsA, outerDimsB, outerDims];\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n      const {activationFunction, applyActivation} = getActicationSnippet(activationAttributes);\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n      const A = inputVariable('a', inputs[0].dataType, [...outerDimsA, dimAOuter, dimInner / components], components);\n      const B = inputVariable('b', inputs[1].dataType, [...outerDimsB, dimInner, dimBOuter / components], components);\n      const output =\n          outputVariable('result', inputs[0].dataType, [batchSize, dimAOuter, dimBOuter / components], components);\n      variables.push(A);\n      variables.push(B);\n      variables.push(output);\n      const inputVariables = [A, B];\n      const hasBias = inputs.length > 2;\n      const declareFunctions =\n          matMulReadWriteFnSource(components, hasBias, applyActivation, variables, batchShapes, isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims, biasComponents));\n      }\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dimAOuter: i32 = ${dimAOuter};\n  const dimBOuter: i32 = ${dimBOuter};\n  const dimInner: i32 = ${dimInner};\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  ${activationFunction}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   ${batchDims.impl()}`;\n      return {\n        name: 'MatMul',\n        shaderCache: {hint: activationAttributes.activationCacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\n\nimport {Activation, activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     activation?: Activation, hasPreluActivationWeights = false, innerElementSizeX = 4, innerElementSizeW = 4,\n     innerElementSize = 4, dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * wShape[3] + colIn];';\n          case 4:\n            return 'return w[row * wShape[3] / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'xShape[1]' : 'xShape[2]';\n      const xWidth = isChannelsLast ? 'xShape[2]' : 'xShape[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = wShape[2];\n    let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimAOuter && col < dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimInner && col < dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const userCode = `\n    ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasActivationSnippet(addBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : elementsPerThread[0];\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 && innerElementSize === 4 ? `vec4<${t}>` : t}>;`,\n        `@group(0) @binding(1) var<storage, read> w: array<${isVec4 ? `vec4<${t}>` : t}>;`\n      ];\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? `vec4<${t}>` : t}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${declareInputs.join('')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? `vec4<${t}>` : t}>;\n        //@group(0) @binding(${declareInputs.length + 1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias, undefined, false, elementsSize[0],\n                elementsSize[1], elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActicationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const {activationFunction, applyActivation} = getActicationSnippet(attributes);\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo =\n    (inputDataType: number, inputRank: number, permAttr: number[]): ProgramInfo => {\n      const perm = getAdjustedPerm(inputRank, permAttr);\n      const output = outputVariable('output', inputDataType, (permAttr && permAttr.length) || inputRank);\n      const input = inputVariable('a', inputDataType, inputRank);\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n      return {\n        name: 'Transpose',\n        shaderCache: {hint: `${permAttr}`, inputDependencies: ['rank']},\n        getRunData: (inputs) => {\n          const outputShape = getOutputShape(inputs[0].dims, perm);\n          const outputSize = ShapeUtil.size(outputShape);\n          return {\n            outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n            dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n            programUniforms: [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ],\n          };\n        },\n        getShaderSource,\n      };\n    };\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(\n      createTransposeProgramInfo(context.inputs[0].dataType, context.inputs[0].dims.length, attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1].dataType, inputs[1].dims.length, weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    context.compute(\n        createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n        {inputs: matmulInputs});\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1].dataType, inputs[1].dims.length, weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nimport {Activation, activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, activation?: Activation, hasPreluActivationWeights = false,\n     innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return W[getIndexFromCoords4D(coord, wShape)];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, xShape)/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < dimInner && col < dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < dimInner && col < dimBOuter' :\n                           'row < dimInner && col < dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n\n      const userCode = `\n  ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasActivationSnippet(addBias, activation)}\n      result[getIndexFromCoords4D(coords, outShape)/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`,\n        '@group(0) @binding(1) var<storage, read> W: array<f32>;'\n      ];\n      let declareFunctions = '';\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        ${declareInputs.join('\\n')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? 'vec4<f32>' : 'f32'}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${conv2dTransposeCommonSnippet(isChannelsLast, hasBias, undefined, false, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : '0.0'};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : '0.0'};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const hasBias = inputs.length === 3;\n      if (adjustedAttributes.group !== 1) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outputShape = adjustedAttributes.outputShape;\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1].dataType, inputs[1].dims.length, weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, true, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + i);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i);\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst createEinsumProgramInfo = (inputs: readonly TensorView[], einsumEquation: EinsumEquation): ProgramInfo => {\n  const dataType = inputs[0].dataType;\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  for (let i = 0; i < inputs.length; ++i) {\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n  const outputShape = einsumEquation.outputDims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', dataType, outputShape);\n  const idxCopy: string[] = [];\n  const rhsSymbols = Array.from(einsumEquation.rhs.symbolToIndices.keys());\n  const initProd = 'var prod = 1.0;';\n  const initSum = 'var sum = 0.0;';\n  const updateSum = 'sum += prod;';\n  const reduceOpsSetIndices: string[] = [];\n  const reduceOpsLoopHeaders: string[] = [];\n  const reduceOpsLoopFooters: string[] = [];\n  const reduceOpCompute: string[] = [];\n  const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === rhsSymbols.length;\n  einsumEquation.symbolToInfo.forEach((info, symbol) => {\n    if (rhsSymbols.includes(symbol)) {\n      const outputIndex = rhsSymbols.indexOf(symbol);\n      einsumEquation.lhs.forEach((term, i) => {\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            idxCopy.push(`${\n                inputVars[i].indicesSet(`input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n          });\n        }\n      });\n    } else {\n      einsumEquation.lhs.forEach((term, i) => {\n        const info = einsumEquation.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid symbol error');\n        }\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n          });\n          reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n        }\n      });\n      reduceOpsLoopHeaders.push(`for(var ${symbol}: u32 = 0; ${symbol} < ${\n          einsumEquation.symbolToInfo.get(symbol)?.dimValue}; ${symbol}++) {`);\n      reduceOpsLoopFooters.push('}');\n    }\n  });\n  const reduceOps = isReduceOpsWithoutLoop ?\n      [\n        ...idxCopy,\n        `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n      ] :\n      [\n        ...idxCopy,\n        initSum,\n        ...reduceOpsLoopHeaders,\n        ...reduceOpsSetIndices,\n        initProd,\n        ...reduceOpCompute,\n        updateSum,\n        ...reduceOpsLoopFooters,\n      ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(...inputVars, output)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        var outputIndices = ${output.offsetToIndices('global_idx')};\n        ${inputVars.map((inputVar, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n        ${reduceOps.join('\\n')};\n        ${output.setByOffset('global_idx', 'sum')};\n      }`;\n  return {\n    name: 'Einsum',\n    shaderCache: {hint: einsumEquation.equation},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  context.compute(createEinsumProgramInfo(context.inputs, einsumEquation));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const inputShape = ${input.indices(...inputShape)};\n  ${shaderHelper.declareVariables(input, output)}\n  ${shaderHelper.mainStart()}\n  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    var inputIndices: ${input.type.indices};\n    for (var i = 0; i < ${inputShape.length}; i++) {\n      if (${input.indicesGet('inputShape', 'i')} == 1) {\n        ${input.indicesSet('inputIndices', 'i', 0)}\n      } else {\n        ${\n      input.indicesSet(\n          'inputIndices', 'i', output.indicesGet('outputIndices', `i + ${outputShape.length - inputShape.length}`))}\n      }\n    }\n    ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n  }`;\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const data = inputVariable('data', inputs[0].dataType, inputs[0].dims);\n  const indices = inputVariable('inputIndices', inputs[1].dataType, inputs[1].dims);\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const calcDataIndices = (): string => {\n    const indicesRank = indicesShape.length;\n    let calcStr = `var indicesIndices  = ${indices.type.indices}(0);`;\n    for (let i = 0; i < indicesRank; i++) {\n      calcStr += `${indicesRank > 1 ? `indicesIndices[${i}]` : 'indicesIndices'} = ${\n          outputShape.length > 1 ? `outputIndices[${axis + i}]` : 'outputIndices'};`;\n    }\n    calcStr += `\n        var idx = ${indices.getByIndices('indicesIndices')};\n        if (idx < 0) {\n          idx = idx + ${axisDimLimit};\n        }\n        var dataIndices = ${data.type.indices}(0);\n      `;\n    for (let i = 0, j = 0; i < inputRank; i++) {\n      if (i === axis) {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = u32(idx);`;\n        j += indicesRank;\n      } else {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = ${\n            outputShape.length > 1 ? `outputIndices[${j}]` : 'outputIndices'};`;\n        j++;\n      }\n    }\n    return calcStr;\n  };\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        ${calcDataIndices()};\n        let value = ${data.getByIndices('dataIndices')};\n        ${output.setByOffset('global_idx', 'value')};\n      }`;\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n      const inputStrides = ShapeUtil.computeStrides(inputShape);\n      const inputSize = ShapeUtil.size(inputShape);\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const indicesSize = ShapeUtil.size(indicesShape);\n\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputShape);\n      const indices = inputVariable('indices', indicesDataType, [indicesSize]);\n      const output = outputVariable('output', inputOutputDataType, outputShape);\n\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputStrides = array<u32, ${inputStrides.length}>(${inputStrides.map(i => `${i}u`).join(',')});\n      ${shaderHelper.declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + ${axisDimLimit};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        if (i == ${axis}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${output.indicesGet('outputIndices', 'i')} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${inputSize}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst offsetC = (m: number, n: number, dims: readonly number[]): string => {\n  if (dims.length === 0) {\n    return '0u';\n  }\n\n  const broadcastM = (dims.length === 1 && m !== 1) || (dims.length === 2 && dims[0] !== m);\n  const broadcastN = dims[dims.length - 1] !== n;\n\n  let offset = '0u';\n  if (!broadcastM) {\n    offset += `+ m * ${dims[dims.length - 1]}u`;\n  }\n  if (!broadcastN) {\n    offset += '+n';\n  }\n\n  return offset;\n};\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  let line = '';\n  if (attributes.transA && attributes.transB) {\n    line = 'value += a[k * M + m] * b[n * K + k];';\n  } else if (attributes.transA && !attributes.transB) {\n    line = 'value += a[k * M + m] * b[k * N + n];';\n  } else if (!attributes.transA && attributes.transB) {\n    line = 'value += a[m * K + k] * b[n * K + k];';\n  } else if (!attributes.transA && !attributes.transB) {\n    line = 'value += a[m * K + k] * b[k * N + n];';\n  }\n\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n  const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= alpha;';\n  const calculateC = inputs.length === 3 ? `value += beta * c[${offsetC(M, N, inputs[2].dims)}];` : '';\n  const inputStorageBuffersDeclarations = [\n    `@group(0) @binding(0) var<storage, read> a : array<${dataType}>;`,\n    `@group(0) @binding(1) var<storage, read> b : array<${dataType}>;`\n  ];\n  if (inputs.length === 3) {\n    inputStorageBuffersDeclarations.push(`@group(0) @binding(2) var<storage, read> c : array<${dataType}>;`);\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha = ${dataType}(${attributes.alpha});\n  const beta = ${dataType}(${attributes.beta});\n\n  ${inputStorageBuffersDeclarations.join('\\n')}\n  @group(0) @binding(${inputs.length}) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k<${K}u; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${calculateC}\n    output[global_id.x] = value;\n\n  }`;\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<GemmAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface InstanceNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst metadata = {\n  name: 'InstanceNormalization'\n};\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const C = xShape[1];\n      const x = inputVariable('x', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n      const output = outputVariable('output', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const variables = [x, scale, bias, output];\n      const dataType = x.type.value;\n      const workgroupSize = 64;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  const C: u32 = ${C};\n  const normSize: u32 = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n  var<workgroup> meanShared : ${dataType};\n  var<workgroup> squaredNormShared : ${dataType};\n  var<workgroup> workgroupShared : array<${dataType}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${dataType} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${x.get('batch', 'channel', 'h')};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${dataType}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${x.get('batch', 'channel', 'h')} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${dataType}(normSize) + epsilon);\n    let channelScale = invStdDev * ${scale.getByOffset('channel')};\n    let channelShift = ${bias.getByOffset('channel')} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * channelScale + channelShift;\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount}\n        }),\n        getShaderSource,\n      };\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const outputSize = ShapeUtil.size(outputShape);\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const normCount = C * N;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const N: u32 = ${N};\n  const H: u32 = ${H};\n  const C: u32 = ${C};\n  const normSizeTyped: ${dataType} = ${H};\n  const imageSize: u32 = ${H * C};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  @group(0) @binding(0) var<storage, read> x : array<${dataType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${dataType}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${dataType}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    // offset is channel num * N\n    let offset = currentImageNumber * imageSize;\n    if (offset >= ${outputSize}) { return; }\n    var mean: ${dataType} = 0;\n\n    for (var i: u32 = 0u; i < H; i++) {\n        mean = mean + x[offset + i * C + currentChannelNumber];\n    }\n    mean = mean / normSizeTyped;\n\n    var squaredNorm: ${dataType} = 0;\n    for (var i: u32 = 0u; i < H; i++) {\n        let deviation: f32 = x[offset + i * C + currentChannelNumber] - mean;\n        squaredNorm = squaredNorm + deviation * deviation;\n    }\n    let invStdDev = 1 / sqrt(squaredNorm / normSizeTyped + epsilon);\n    let channelScale = invStdDev * scale[currentChannelNumber];\n    let channelShift = bias[currentChannelNumber] - mean * channelScale;\n    for (var i: u32 = 0u; i < H; i++) {\n        let currentOffset = offset + i * C + currentChannelNumber;\n        output[currentOffset] = x[currentOffset] * channelScale + channelShift;\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseInstanceNormAttributes = (attributes: InstanceNormAttributes): InstanceNormAttributes =>\n    createAttributeWithCacheKey({epsilon: attributes.epsilon, format: attributes.format});\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    context.compute(createInstanceNormNHWCProgramInfo(context.inputs, attributes));\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface LayerNormAttributes extends AttributeWithCacheKey {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float || inputs[1].dataType !== DataType.float) {\n    throw new Error('inputs should be float type');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const outputSize = ShapeUtil.size(outputShape);\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n      let bindingIndex = 0;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const normSize: u32 = ${normSize};\n  const normSizeTyped: ${dataType} = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  @group(0) @binding(${bindingIndex++}) var<storage, read> x : array<${dataType}>;\n  @group(0) @binding(${bindingIndex++}) var<storage, read> scale : array<${dataType}>;\n  ${bias ? `@group(0) @binding(${bindingIndex++}) var<storage, read> bias : array<${dataType}>;` : ''}\n  @group(0) @binding(${bindingIndex++}) var<storage, read_write> output : array<${dataType}>;\n  ${\n          hasMeanDataOutput ?\n              `@group(0) @binding(${bindingIndex++}) var<storage, read_write> meanDataOutput : array<${dataType}>` :\n              ''};\n  ${\n          hasInvStdOutput ?\n              `@group(0) @binding(${bindingIndex++}) var<storage, read_write> invStdOutput : array<${dataType}>` :\n              ''};\n\n  ${shaderHelper.mainStart()}\n    let offset = global_idx * normSize;\n    if (offset >= ${outputSize}) { return; }\n    var mean: ${dataType} = 0;\n    var meanSquare: ${dataType} = 0;\n\n    for (var h: u32 = 0u; h < normSize; h++) {\n      mean = mean + x[h + offset];\n      meanSquare = meanSquare + x[h + offset] * x[h + offset];\n    }\n    mean = mean / normSizeTyped;\n    meanSquare = sqrt(meanSquare / normSizeTyped - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSize; j++) {\n      output[j + offset] = (x[j + offset] - mean) / meanSquare * scale[j] ${bias ? '+ bias[j]' : ''};\n    }\n\n    ${hasMeanDataOutput ? 'meanDataOutput[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'invStdOutput[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push(\n            {dims: meanInvStdDevDim, dataType: inputs[0].dataType},\n        );\n      }\n      if (hasInvStdOutput) {\n        outputs.push(\n            {dims: meanInvStdDevDim, dataType: inputs[0].dataType},\n        );\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${attributes.cacheKey}|${outputCount}|${inputs.length}`},\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}}),\n        getShaderSource,\n      };\n    };\n\nexport const parseLayerNormAttributes = (attributes: LayerNormAttributes): LayerNormAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis, epsilon: attributes.epsilon});\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil} from '../../util';\nimport {ComputeContext} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface PadAttributes extends AttributeWithCacheKey {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[], dataType: string, constantValue: number): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${inputDims[i]}) {\n              break;\n            }\n            offset += k * ${inputStrides[i]};\n        `;\n      }\n\n      return `\n          value = ${dataType}(${constantValue});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n    };\n\nconst getPadReflect =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2 * (inputDims[i] - 1)};\n                  k = k % _2n_1;\n                  if(k >= ${inputDims[i]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadEdge =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${inputDims[i]}) {\n                  k = ${inputDims[i] - 1};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadWrap =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0)  {\n                  k += ${inputDims[i]};\n                }\n                if (k >= ${inputDims[i]}) {\n                  k -= ${inputDims[i]};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadSnippet =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], attributes: PadAttributes, dataType: string): string => {\n      switch (attributes.mode) {\n        case 0:\n          return getPadConstant(\n              output, outputDims, inputDims, inputStrides, attributes.pads, dataType, attributes.value);\n        case 1:\n          return getPadReflect(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 2:\n          return getPadEdge(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 3:\n          return getPadWrap(output, outputDims, inputDims, inputStrides, attributes.pads);\n        default:\n          throw new Error('Invalid mode');\n      }\n    };\n\nconst generatePadCode =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: PadAttributes, dataType: string):\n        string => {\n          const inputDims = inputs[0].dims;\n          const outputDims = ShapeUtil.padShape(inputDims.slice(), attributes.pads);\n          const outputSize = ShapeUtil.size(outputDims);\n          const inputStrides = ShapeUtil.computeStrides(inputDims);\n\n          const output = outputVariable('output', inputs[0].dataType, outputDims);\n          const input = inputVariable('x', inputs[0].dataType, inputDims);\n\n          const padSnippet = getPadSnippet(output, outputDims, inputDims, inputStrides, attributes, dataType);\n          const padCode = `\n              ${shaderHelper.declareVariables(input, output)}\n              ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(0);\n              ${padSnippet}\n              output[global_idx] = value;\n          }`;\n          return padCode;\n        };\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  return {\n    name: 'Pad',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n    }),\n    getShaderSource: shaderHelper => generatePadCode(shaderHelper, inputs, attributes, 'f32'),\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return createAttributeWithCacheKey({mode: attributes.mode, value, pads});\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parsePadAttributes = (attributes: Record<string, unknown>): PadAttributes => {\n  const mode = attributes.mode as number;\n  const value = attributes.value as number;\n  const pads = attributes.pads as number[];\n  return createAttributeWithCacheKey({mode, value, pads});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4) {\n    throw new Error('Pool ops supports 2-D inputs only for now.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst =\n      isChannelsLast ? [input.dims[0], input.dims[3], input.dims[1], input.dims[2]] : input.dims.slice();\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  return [\n    newAttributes,\n    isChannelsLast ?\n        [\n          outputShapeAsChannelFirst[0], outputShapeAsChannelFirst[2], outputShapeAsChannelFirst[3],\n          outputShapeAsChannelFirst[1]\n        ] :\n        outputShapeAsChannelFirst\n  ];\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, xShape: readonly number[], outputShape: readonly number[],\n    attributes: AttributeType, op1: string, op2: string, start: string): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputDims = xShape;\n  const dataType = x.type.value;\n  const rank = inputDims.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', x.type.tensor, outputShape);\n\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    if (pwStart + pwEnd !== 0) {\n      codeW = `\n              for (var i: u32 = 0u; i < ${kw}u; i++) {\n                xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}] >= ${inputDims[dimIdxW]}) {\n                  pad++;\n                  continue;\n                }\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      codeW = `\n              for (var i: u32 = 0u; i < ${kw}u; i++) {\n                xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      const dimH = inputDims[dimIdxH];\n      if (phStart + phEnd !== 0) {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= ${dimH}) {\n                    pad+= ${kw};\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value: ${dataType} = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelSize = ShapeUtil.size(attributes.kernelShape);\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    const stridesRank = kernelStrides.length;\n    const padsRank = attributes.pads.length;\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            const pads = array<u32, ${padsRank}>(${attributes.pads.map(i => `${i}u`).join(',')});\n            const inputDims = array<u32, ${rank}>(${inputDims.map(i => `${i}u`).join(',')});\n            const kernelStrides = array<u32, ${stridesRank}>(${kernelStrides.map(i => `${i}u`).join(',')});\n            const strides = array<u32, ${stridesRank}>(${attributes.strides.map(i => `${i}u`).join(',')});\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              let xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${output.type.value}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${kernelSize}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${rank - stridesRank}u]\n                    + offsets[j - ${rank - stridesRank}u] - pads[j - 2u];\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const kernelSize = ShapeUtil.size(adjustedAttributes.kernelShape);\n\n      const x = inputVariable('x', input.dataType, input.dims);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(${kernelSize});`;\n      } else {\n        op2 += `value /= ${dataType}(${kernelSize} - pad);`;\n      }\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '0.0'),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n\n  return createAttributeWithCacheKey({countIncludePad, ...attr});\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n  cacheKey: ''\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims);\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '-1e5'),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n\n  return createAttributeWithCacheKey({storageOrder, dilations, ...attr});\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {outputVariable, ShaderHelper} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n\n  const output = outputVariable('output', dataType, outputShape);\n  const wgslType = output.type.storage;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        output[global_idx] = ${wgslType}(${start}) + ${wgslType}(global_idx) * ${wgslType}(${delta});\n      }`;\n  return {\n    name: 'Range',\n    shaderCache: {hint: [start, limit, delta].map(x => x.toString()).join('_')},\n    getShaderSource,\n    getRunData: () => (\n        {outputs: [{dims: outputShape, dataType}],\n         dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}})\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for linear mode');\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate = (coordinateTransferMode: CoordinateTransformMode): string =>\n    'fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,\\\n    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { ' +\n    (() => {\n      switch (coordinateTransferMode) {\n        case 'asymmetric':\n          return 'return xResized / xScale;';\n        case 'pytorch_half_pixel':\n          return 'if (lengthResized > 1) { \\\n                    return (xResized + 0.5) / xScale - 0.5; \\\n                  } else { \\\n                    return 0.0; \\\n                  }';\n        case 'tf_half_pixel_for_nn':\n          return 'return (xResized + 0.5) / xScale;';\n        case 'align_corners':\n          return 'if (lengthResized == 1) { \\\n                    return 0.0; \\\n                  } else { \\\n                    return xResized * (lengthOriginal - 1) / (lengthResized - 1); \\\n                  }';\n        case 'tf_crop_and_resize':\n          return 'if (lengthResized > 1) { \\\n                    return roiStart * (lengthOriginal - 1) + \\\n                          (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1); \\\n                  } else { \\\n                    return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1); \\\n                  }';\n        case 'half_pixel_symmetric':\n          return [\n            'const outputWidth = xScale * lengthResized;', 'const adjustment = lengthResized / outputWidth;',\n            'const center = lengthOriginal / 2;', 'const offset = center * (1 - adjustment);',\n            'return offset + ((xResized + 0.5) / xScale) - 0.5;'\n          ].join('\\n');\n        case 'half_pixel':\n          return 'return ((xResized + 0.5) / xScale) - 0.5;';\n        default:\n          throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number): string =>\n    'fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {' + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape =\n    (inputShape: readonly number[], outputShape: readonly number[], scales: number[], attributes: ResizeAttributes):\n        number[] => {\n          const scaleInPolicy = (() => {\n            switch (attributes.keepAspectRatioPolicy) {\n              case 'not_larger':\n                return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                                    Math.min(...scales, Number.MAX_VALUE);\n              case 'not_smaller':\n                return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                                    Math.max(...scales, Number.MIN_VALUE);\n              default:\n                throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n            }\n          })();\n          scales.fill(1.0, 0, scales.length);\n          const adjustedOutputShape = inputShape.slice();\n          if (attributes.axes.length > 0) {\n            attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n            attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n          } else {\n            scales.fill(scaleInPolicy, 0, scales.length);\n            adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n          }\n          return adjustedOutputShape;\n        };\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scales: readonly number[],\n     roi: readonly number[]): string => `\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> array<f32, ${\n        outputShape.length}> {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n      const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n      const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n      var originalIndices: array<f32, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n        }\n      }\n      return originalIndices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n        const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n        const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n        const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n        var inputIndices: ${input.type.indices};\n        for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n          var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n            if (!${useExtrapolation} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${input.indicesSet('inputIndices', 'i', 'inputIndex')}\n        }\n        return inputIndices;\n    }`;\n\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(inputIndices: ${input.type.indices}) -> bool {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var inputIndex = ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], useExtrapolation: boolean, extrapolationValue: number): string => {\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (scales[1] === 1.0 ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${input.type.indices};\n      inputIndices[${heightIdx}] = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      inputIndices[${widthIdx}] = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      if (${inputShape.length} > 2) {\n        inputIndices[${channelIdx}] = channel;\n        inputIndices[${batchIdx}] = batch;\n      };\n      return input[${input.indicesToOffset('inputIndices')}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${heightIdx}];\n      var col:f32 = originalIndices[${widthIdx}];\n      if (${useExtrapolation} && (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > ${\n          inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${inputShape.length > 2}) {\n        channel = u32(originalIndices[${channelIdx}]);\n        batch = u32(originalIndices[${batchIdx}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const [heightIdx, widthIdx] = inputShape.length === 2 ? [0, 1] : (scales[1] === 1.0) ? [2, 3] : [1, 2];\n\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(inputIndices: ${input.type.indices}, outputIndices: ${\n            output.type.indices}) -> f32 {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : `outputIndices[${idx}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${scales[idx]},\n        f32(${outputShape[idx]}), f32(${inputShape[idx]}), ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: f32 = originalIdx + f32(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            if (${excludeOutside}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${useExtrapolation}) {\n              return ${extrapolationValue};\n            } else {\n              ${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${input.type.indices} = inputIndices;\n          inputIndicesCopy[${idx}] = u32(${direction});\n          data[i + 1] = ${idx === heightIdx ? `input[${input.indicesToOffset('inputIndicesCopy')}];` : `\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n    var inputIndices: ${input.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, outputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape);\n      const input = inputVariable('input', inputTensor.dataType, inputShape);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales, roi, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales, roi)};\n              ${\n                bilinearInterpolation(\n                    input, output, inputShape, outputShape, scales, useExtrapolation, attributes.extrapolationValue)};\n              `;\n          case 'cubic':\n            return `\n            ${\n                bicubicInterpolation(\n                    input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                    attributes.extrapolationValue, attributes.excludeOutside)};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        if (${noScale}) {\n          output[global_idx] = input[global_idx];\n        } else {\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          var inputIndices: ${input.type.indices};\n          ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                  if (checkInputIndices(inputIndices)) {\n                    output[global_idx] = input[${input.indicesToOffset('inputIndices')}];\n                  } else {\n                    output[global_idx] = ${attributes.extrapolationValue};\n                  }`;\n          case 'linear':\n            return 'output[global_idx] = bilinearInterpolation(outputIndices);';\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(outputIndices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n        }\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}`\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float || inputs[1].dataType !== DataType.float) {\n    throw new Error('inputs should be float type');\n  }\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number,\n     isTraining: boolean): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputSize = ShapeUtil.size(inputShape);\n      const outputShape = inputShape;\n      const outputSize = inputSize;\n      const hiddenSize = inputShape.slice(-1)[0];\n      const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n      const hasBetaInput = inputs.length > 3;\n      const hasBiasInput = inputs.length > 4;\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const hasMeanOutput = isTraining && outputCount > 1;\n      const hasInvStdDevOutput = isTraining && outputCount > 2;\n      const hasInputSkipBiasSumOutput = outputCount > 3;\n      let bindingNumber = 0;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: u32 = ${hiddenSize};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      @group(0) @binding(${bindingNumber++}) var<storage, read> x : array<${dataType}>;\n      @group(0) @binding(${bindingNumber++}) var<storage, read> skip : array<${dataType}>;\n      @group(0) @binding(${bindingNumber++}) var<storage, read> gamma : array<${dataType}>;\n      ${hasBetaInput ? `@group(0) @binding(${bindingNumber++}) var<storage, read> beta : array<${dataType}>;` : ''}\n      ${hasBiasInput ? `@group(0) @binding(${bindingNumber++}) var<storage, read> bias : array<${dataType}>;` : ''}\n      @group(0) @binding(${bindingNumber++}) var<storage, read_write> output : array<${dataType}>;\n      ${\n          hasMeanOutput ?\n              `@group(0) @binding(${bindingNumber++}) var<storage, read_write> meanOutput : array<${dataType}>;` :\n              ''}\n      ${\n          hasInvStdDevOutput ?\n              `@group(0) @binding(${bindingNumber++}) var<storage, read_write> invStdOutput : array<${dataType}>;` :\n              ''}\n      ${\n          hasInputSkipBiasSumOutput ?\n              `@group(0) @binding(${bindingNumber++}) var<storage, read_write> inputSkipBiasSum : array<${dataType}>;` :\n              ''}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSize;\n        var sum: f32 = 0.0;\n        var squareSum: f32 = 0.0;\n        for (var i: u32 = 0; i < hiddenSize; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          sum += value;\n          squareSum += value * value;\n        }\n        let mean: f32 = sum / f32(hiddenSize);\n        let variance: f32 = sqrt(squareSum / f32(hiddenSize) - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSize; i++) {\n          output[offset + i] = (output[offset + i] - mean) / variance * gamma[i] + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (outputCount > 1) {\n        outputs.push({dims: meanInvStdDevDim, dataType: inputs[0].dataType});\n      }\n      if (outputCount > 2) {\n        outputs.push({dims: meanInvStdDevDim, dataType: inputs[0].dataType});\n      }\n      if (outputCount > 3) {\n        outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n      }\n\n      return {\n        name: 'SkipLayerNormalization',\n        shaderCache: {hint: attributes.cacheKey},\n        getShaderSource,\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n      };\n    };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[]):\n        string => `fn calculateInputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n          var inputIndices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'} = inputIndex;\n          }\n          return inputIndices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const input = inputVariable('input', inputs[0].dataType, inputShape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(input, output)}\n        const signs = array<i32, ${signs.length}>(${signs.map(i => `${i}i`).join(',')});\n        const starts = array<u32, ${starts.length}>(${starts.map(i => `${i}u`).join(',')});\n        const ends = array<u32, ${ends.length}>(${ends.map(i => `${i}u`).join(',')});\n        const steps = array<u32, ${steps.length}>(${steps.map(i => `${i}u`).join(',')});\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n\n        ${calculateInputIndicesImpl(input, output, inputShape, outputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {hint: `${attributes.cacheKey}|${inputs[4]?.dims ?? ''}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const dataType = tensorTypeToWsglStorageType(input.dataType);\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl = dataType === 'f32' ? 'var threadMax: f32 = -3.402823e+38f;' : 'var threadMax: f16 = -65504.0h;';\n  const getShaderSource = (_shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${dataType};\n      var<workgroup> rowSumShared : ${dataType};\n      var<workgroup> threadShared : array<${dataType}, ${WG}>;\n\n      @group(0) @binding(0) var<storage, read> x : array<${dataType}>;\n      @group(0) @binding(1) var<storage, read_write> result : array<${dataType}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${dataType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${dataType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n\n      @compute @workgroup_size(${WG}, 1, 1)\n      fn main(@builtin(local_invocation_id) local_id : vec3<u32>, @builtin(global_invocation_id) global_id : vec3u) {\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = ${cols};\n        let row_stride : i32 = ${cols};\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = threadShared[0];\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum: ${dataType} = 0.0;\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = threadShared[0];\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    getRunData: () => ({outputs: [{dims: shape, dataType: input.dataType}], dispatchGroup: {x: rows}}),\n    getShaderSource,\n  };\n};\n\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (outputNumber == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (outputNumber == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(outputNumber: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const rank = inputShape.length;\n  const axis = attributes.axis;\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInConcatAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInConcatAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShapes[i]);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  const indicesAxis = rank < 2 ? 'indices' : `indices[${adjustedAxis}]`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(input, ...outputs)}\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateOutputIndexImpl(sizeInConcatAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(inputSize)}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    let outputNumber = calculateOutputIndex(${indicesAxis});\n    if (outputNumber != 0) {\n        ${indicesAxis} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      var inputIndices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let inputDimValue = ${output.indicesGet('outputIndices', 'i')}  % ${input.indicesGet('inputShape', 'i')};\n\n        ${input.indicesSet('inputIndices', 'i', 'inputDimValue')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', inputs[1].dataType, inputs[1].dims, 4);\n      const b = inputVariable('bData', inputs[2].dataType, inputs[2].dims, 4);\n      const c = inputVariable('cData', inputs[0].dataType, inputs[0].dims, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(cData[indexC${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)}\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm, parseInstanceNormAttributes} from './ops/instance-norm';\nimport {layerNorm, parseLayerNormAttributes} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {pad, parsePadAttributes} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {parseReduceAttributes, reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['ClipV10', [unaryOps.clipV10]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm, parseInstanceNormAttributes]],\n  ['LayerNormalization', [layerNorm, parseLayerNormAttributes]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad, parsePadAttributes]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin, parseReduceAttributes]],\n  ['ReduceMean', [reduceMean, parseReduceAttributes]],\n  ['ReduceMax', [reduceMax, parseReduceAttributes]],\n  ['ReduceSum', [reduceSum, parseReduceAttributes]],\n  ['ReduceProd', [reduceProd, parseReduceAttributes]],\n  ['ReduceL1', [reduceL1, parseReduceAttributes]],\n  ['ReduceL2', [reduceL2, parseReduceAttributes]],\n  ['ReduceLogSum', [reduceLogSum, parseReduceAttributes]],\n  ['ReduceLogSumExp', [reduceLogSumExp, parseReduceAttributes]],\n  ['ReduceSumSquare', [reduceSumSquare, parseReduceAttributes]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    const profilingEnabled = this.backend.supportTimestampQuery && this.backend.env.webgpu.profilingMode === 'default';\n    if (profilingEnabled) {\n      // profiling write start timestamp\n\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      (computePassEncoder as any).writeTimestamp(this.backend.profilingQuerySet, 0);\n    }\n\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (profilingEnabled) {\n      // profiling write end timestamp\n\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      (computePassEncoder as any).writeTimestamp(this.backend.profilingQuerySet, 1);\n      if (this.backend.profilingQueryData == null) {\n        this.backend.profilingQueryData =\n            // eslint-disable-next-line no-bitwise\n            this.backend.gpuDataManager.create(16, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      // eslint-disable-next-line no-bitwise\n      const syncData = this.backend.gpuDataManager.create(16, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(\n          this.backend.profilingQuerySet, 0, 2, this.backend.profilingQueryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.profilingQueryData.buffer, 0, syncData.buffer, 0, 16);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n      const kernelName = `[${kernelInfo[0]}] ${kernelInfo[1]}`;\n\n      syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const startTimeU64 = mappedData[0];\n        const endTimeU64 = mappedData[1];\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.profilingTimeBase === 'undefined') {\n          this.backend.profilingTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.profilingTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.profilingTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        let inputShapes = '';\n        inputTensorViews.forEach((value, i) => {\n          inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        let outputShapes = '';\n        outputTensorViews.forEach((value, i) => {\n          outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        // eslint-disable-next-line no-console\n        console.log(`[profiling] kernel \"${kernelId}|${kernelName}\" ${inputShapes}${outputShapes}execution time: ${\n            endTime - startTime} ns`);\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey = (programInfo: ProgramInfo, inputTensors: readonly TensorView[]): string => {\n  // final key format:\n  // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n  let key = programInfo.name;\n  if (programInfo.shaderCache?.hint) {\n    key += '[' + programInfo.shaderCache.hint + ']';\n  }\n  key += `:${\n      getProgramInputTensorInfoDependencyKey(\n          inputTensors,\n          programInfo.shaderCache?.inputDependencies ??\n              new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n  return key;\n};\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  commandEncoder: GPUCommandEncoder|null = null;\n  computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  supportTimestampQuery = false;\n  profilingQuerySet: GPUQuerySet;\n  profilingQueryData: GpuData;\n  profilingTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env): Promise<void> {\n    if (!navigator.gpu) {\n      // WebGPU is not available.\n      throw new Error('WebGpuBackend: WebGPU is not available.');\n    }\n\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error('WebGpuBackend: Failed to get GPU adapter.');\n    }\n\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n    // WebGPU Spec: Timestamp Queries Inside Passes\n    // https://github.com/gpuweb/gpuweb/blob/main/proposals/timestamp-query-inside-passes.md\n    if (adapter.features.has('timestamp-query-inside-passes')) {\n      this.supportTimestampQuery = true;\n      requiredFeatures.push('timestamp-query-inside-passes' as GPUFeatureName);\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    if (this.supportTimestampQuery) {\n      this.profilingQuerySet = this.device.createQuerySet({\n        type: 'timestamp',\n        count: 2,\n      });\n    }\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    // currently, we do not do anything in this function. In all known use cases, we don't have the requirement to\n    // actually dispose the WebGpuBackend instance, because it's always used as a singleton.\n    //\n    // revisit this place if we get real requirement to dispose the instance.\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass();\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews);\n    let artifact = this.programManager.getArtifact(key);\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      let preLength = 0;\n      const offsets: number[] = [];\n      let maxAlignmentOfField = 1;\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        // https://www.w3.org/TR/WGSL/#alignof\n        let baseAlignment: number;\n        switch (data.length) {\n          case 1:\n            baseAlignment = 4;\n            break;\n          case 2:\n            baseAlignment = 8;\n            break;\n          case 3:\n            baseAlignment = 16;\n            break;\n          case 4:\n            baseAlignment = 16;\n            break;\n          case 5:\n            baseAlignment = 16;\n            break;\n          case 6:\n            baseAlignment = 16;\n            break;\n          default:\n            throw new Error(`unsupported data length: ${data.length}`);\n        }\n\n        if (preLength === 5 || preLength === 6) {\n          baseAlignment = 16;\n        }\n        if (baseAlignment > maxAlignmentOfField) {\n          maxAlignmentOfField = baseAlignment;\n        }\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        preLength = data.length;\n        offsets.push(currentOffset);\n        currentOffset += data.length * 4;\n      });\n\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\nexport const init = async(module: OrtWasmModule, env: Env): Promise<void> => {\n  const init = module.jsepInit;\n  if (init && navigator.gpu) {\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP');\n    }\n    const backend = new WebGpuBackend();\n    await backend.initialize(env);\n\n    init(\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(size),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n            backend.memcpy(src, dst);\n          } else {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n            const data = module.HEAPU8.subarray(src, src + size);\n            backend.upload(dst, data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async(gpuDataId: number, dataOffset: number, size: number):\n            Promise<void> => {\n              LOG_DEBUG(\n                  'verbose',\n                  () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n              await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n            },\n\n        // jsepCreateKernel\n        (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n            name, kernel, attribute,\n            env.debug || env.webgpu.profilingMode === 'default' ? module.UTF8ToString(module._JsepGetNodeName(kernel)) :\n                                                                  `${kernel}`),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n          LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                  contextDataOffset}`);\n          const context = new ComputeContextImpl(module, backend, contextDataOffset);\n          return backend.computeKernel(kernel, context, errors);\n        });\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * initialize ORT environment.\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env);\n  }\n};\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\n/**\n * allocate the memory and memcpy the model bytes, preparing for creating an instance of InferenceSession.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const createSessionAllocate = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session using the prepared buffer containing the model data.\n * @param modelData a 2-elements tuple containing the pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSessionFinalize =\n    (modelData: SerializableModeldata, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const wasm = getInstance();\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelData[0], modelData[1], sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelData[0]);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\n\n/**\n * create an instance of InferenceSession.\n * @returns the metadata of InferenceSession. 0-value handle for failure.\n */\nexport const createSession =\n    (model: Uint8Array, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const modelData: SerializableModeldata = createSessionAllocate(model);\n      return createSessionFinalize(modelData, options);\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nconst prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var qr=Object.defineProperty;var tu=Object.getOwnPropertyDescriptor;var ru=Object.getOwnPropertyNames;var nu=Object.prototype.hasOwnProperty;var H=(e,t)=>()=>(e&&(t=e(e=0)),t);var Kt=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),yr=(e,t)=>{for(var r in t)qr(e,r,{get:t[r],enumerable:!0})},ou=(e,t,r,i)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let o of ru(t))!nu.call(e,o)&&o!==r&&qr(e,o,{get:()=>t[o],enumerable:!(i=tu(t,o))||i.enumerable});return e};var Tt=e=>ou(qr({},\"__esModule\",{value:!0}),e);var Yr={};yr(Yr,{readFile:()=>au});var au,Xr=H(()=>{au=void 0});var Qr={};yr(Qr,{join:()=>iu});var iu,Jr=H(()=>{iu=void 0});var Qn=Kt((Xn,Zr)=>{\"use strict\";var Yn=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){var r=t,i,o;r.ready=new Promise((u,p)=>{i=u,o=p}),r.jsepInit=(u,p,h,S,T,k,F,ne)=>{r.Za=u,r.Oa=p,r.Qa=h,r.Ja=S,r.Pa=T,r.ra=k,r.Ra=F,r.Sa=ne,p=(Y,Q,ee)=>(...ce)=>{let pe=Ne,E=Q?.();ce=Y(...ce);let ie=Q?.();return E!==ie&&(Y=ie,ee(E),Q=ee=null),Ne!=pe?ir():ce},h=Y=>async(...Q)=>{try{if(r.Da)throw Error(\"Session already started\");let ee=r.Da={Ta:Q[0],errors:[]},ce=await Y(...Q);if(r.Da!==ee)throw Error(\"Session mismatch\");u.flush();let pe=ee.errors;if(0<pe.length){let E=await Promise.all(pe);if(E=E.filter(ie=>ie),0<E.length)throw Error(E.join(`\n`))}return ce}finally{r.Da=null}},r._OrtRun=h(p(r._OrtRun,()=>r._OrtRun,Y=>r._OrtRun=Y)),r._OrtRunWithBinding=h(p(r._OrtRunWithBinding,()=>r._OrtRunWithBinding,Y=>r._OrtRunWithBinding=Y)),r._OrtBindInput=p(r._OrtBindInput,()=>r._OrtBindInput,Y=>r._OrtBindInput=Y),r.jsepRegisterBuffer=(Y,Q,ee,ce)=>u.registerBuffer(Y,Q,ee,ce),r.jsepUnregisterBuffers=Y=>{u.unregisterBuffers(Y)},r.jsepGetBuffer=Y=>u.getBuffer(Y),r.jsepCreateDownloader=(Y,Q,ee)=>u.createDownloader(Y,Q,ee)};var s=Object.assign({},r),l=\"./this.program\",n=(u,p)=>{throw p},c=typeof window==\"object\",m=typeof importScripts==\"function\",g=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",C=\"\",x,$,b;if(g){var w=(Xr(),Tt(Yr)),v=(Jr(),Tt(Qr));C=m?v.dirname(C)+\"/\":__dirname+\"/\",x=(u,p)=>(u=u.startsWith(\"file://\")?new URL(u):v.normalize(u),w.readFileSync(u,p?void 0:\"utf8\")),b=u=>(u=x(u,!0),u.buffer||(u=new Uint8Array(u)),u),$=(u,p,h,S=!0)=>{u=u.startsWith(\"file://\")?new URL(u):v.normalize(u),w.readFile(u,S?void 0:\"utf8\",(T,k)=>{T?h(T):p(S?k.buffer:k)})},!r.thisProgram&&1<process.argv.length&&(l=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),n=(u,p)=>{throw process.exitCode=u,p},r.inspect=()=>\"[Emscripten Module object]\"}else(c||m)&&(m?C=self.location.href:typeof document<\"u\"&&document.currentScript&&(C=document.currentScript.src),e&&(C=e),C.indexOf(\"blob:\")!==0?C=C.substr(0,C.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):C=\"\",x=u=>{var p=new XMLHttpRequest;return p.open(\"GET\",u,!1),p.send(null),p.responseText},m&&(b=u=>{var p=new XMLHttpRequest;return p.open(\"GET\",u,!1),p.responseType=\"arraybuffer\",p.send(null),new Uint8Array(p.response)}),$=(u,p,h)=>{var S=new XMLHttpRequest;S.open(\"GET\",u,!0),S.responseType=\"arraybuffer\",S.onload=()=>{S.status==200||S.status==0&&S.response?p(S.response):h()},S.onerror=h,S.send(null)});var I=r.print||console.log.bind(console),B=r.printErr||console.error.bind(console);Object.assign(r,s),s=null,r.thisProgram&&(l=r.thisProgram),r.quit&&(n=r.quit);var z;r.wasmBinary&&(z=r.wasmBinary);var M=r.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&We(\"no native wasm support detected\");var G,_,U=!1,V,j,le,R,X,Se;function q(){var u=G.buffer;r.HEAP8=j=new Int8Array(u),r.HEAP16=new Int16Array(u),r.HEAP32=R=new Int32Array(u),r.HEAPU8=le=new Uint8Array(u),r.HEAPU16=new Uint16Array(u),r.HEAPU32=X=new Uint32Array(u),r.HEAPF32=new Float32Array(u),r.HEAPF64=Se=new Float64Array(u)}var L=[],De=[],he=[];function Re(){var u=r.preRun.shift();L.unshift(u)}var we=0,Be=null,Ke=null;function We(u){throw r.onAbort&&r.onAbort(u),u=\"Aborted(\"+u+\")\",B(u),U=!0,V=1,u=new WebAssembly.RuntimeError(u+\". Build with -sASSERTIONS for more info.\"),o(u),u}function nt(u){return u.startsWith(\"data:application/octet-stream;base64,\")}var N;if(N=\"ort-wasm-simd.wasm\",!nt(N)){var de=N;N=r.locateFile?r.locateFile(de,C):C+de}function ge(u){if(u==N&&z)return new Uint8Array(z);if(b)return b(u);throw\"both async and sync fetching of the wasm failed\"}function ze(u){if(!z&&(c||m)){if(typeof fetch==\"function\"&&!u.startsWith(\"file://\"))return fetch(u,{credentials:\"same-origin\"}).then(p=>{if(!p.ok)throw\"failed to load wasm binary file at '\"+u+\"'\";return p.arrayBuffer()}).catch(()=>ge(u));if($)return new Promise((p,h)=>{$(u,S=>p(new Uint8Array(S)),h)})}return Promise.resolve().then(()=>ge(u))}function Ge(u,p,h){return ze(u).then(S=>WebAssembly.instantiate(S,p)).then(S=>S).then(h,S=>{B(\"failed to asynchronously prepare wasm: \"+S),We(S)})}function Te(u,p){var h=N;return z||typeof WebAssembly.instantiateStreaming!=\"function\"||nt(h)||h.startsWith(\"file://\")||g||typeof fetch!=\"function\"?Ge(h,u,p):fetch(h,{credentials:\"same-origin\"}).then(S=>WebAssembly.instantiateStreaming(S,u).then(p,function(T){return B(\"wasm streaming compile failed: \"+T),B(\"falling back to ArrayBuffer instantiation\"),Ge(h,u,p)}))}var Ae,Ue={910336:u=>{r.ra(\"Abs\",u,void 0)},910387:u=>{r.ra(\"Neg\",u,void 0)},910438:u=>{r.ra(\"Floor\",u,void 0)},910491:u=>{r.ra(\"Ceil\",u,void 0)},910543:u=>{r.ra(\"Reciprocal\",u,void 0)},910601:u=>{r.ra(\"Sqrt\",u,void 0)},910653:u=>{r.ra(\"Exp\",u,void 0)},910704:u=>{r.ra(\"Erf\",u,void 0)},910755:u=>{r.ra(\"Sigmoid\",u,void 0)},910810:u=>{r.ra(\"Log\",u,void 0)},910861:u=>{r.ra(\"Sin\",u,void 0)},910912:u=>{r.ra(\"Cos\",u,void 0)},910963:u=>{r.ra(\"Tan\",u,void 0)},911014:u=>{r.ra(\"Asin\",u,void 0)},911066:u=>{r.ra(\"Acos\",u,void 0)},911118:u=>{r.ra(\"Atan\",u,void 0)},911170:u=>{r.ra(\"Sinh\",u,void 0)},911222:u=>{r.ra(\"Cosh\",u,void 0)},911274:u=>{r.ra(\"Asinh\",u,void 0)},911327:u=>{r.ra(\"Acosh\",u,void 0)},911380:u=>{r.ra(\"Atanh\",u,void 0)},911433:u=>{r.ra(\"Tanh\",u,void 0)},911485:u=>{r.ra(\"Not\",u,void 0)},911536:(u,p,h)=>{r.ra(\"ClipV10\",u,{min:p,max:h})},911608:u=>{r.ra(\"Clip\",u,void 0)},911660:(u,p)=>{r.ra(\"Elu\",u,{alpha:p})},911718:u=>{r.ra(\"Relu\",u,void 0)},911770:(u,p)=>{r.ra(\"LeakyRelu\",u,{alpha:p})},911834:(u,p)=>{r.ra(\"ThresholdedRelu\",u,{alpha:p})},911904:(u,p)=>{r.ra(\"Cast\",u,{to:p})},911962:u=>{r.ra(\"Add\",u,void 0)},912013:u=>{r.ra(\"Sub\",u,void 0)},912064:u=>{r.ra(\"Mul\",u,void 0)},912115:u=>{r.ra(\"Div\",u,void 0)},912166:u=>{r.ra(\"Pow\",u,void 0)},912217:u=>{r.ra(\"Equal\",u,void 0)},912270:u=>{r.ra(\"Greater\",u,void 0)},912325:u=>{r.ra(\"GreaterOrEqual\",u,void 0)},912387:u=>{r.ra(\"Less\",u,void 0)},912439:u=>{r.ra(\"LessOrEqual\",u,void 0)},912498:(u,p,h,S,T)=>{r.ra(\"ReduceMean\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},912662:(u,p,h,S,T)=>{r.ra(\"ReduceMax\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},912825:(u,p,h,S,T)=>{r.ra(\"ReduceMin\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},912988:(u,p,h,S,T)=>{r.ra(\"ReduceProd\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913152:(u,p,h,S,T)=>{r.ra(\"ReduceSum\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913315:(u,p,h,S,T)=>{r.ra(\"ReduceL1\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913477:(u,p,h,S,T)=>{r.ra(\"ReduceL2\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913639:(u,p,h,S,T)=>{r.ra(\"ReduceLogSum\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913805:(u,p,h,S,T)=>{r.ra(\"ReduceSumSquare\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},913974:(u,p,h,S,T)=>{r.ra(\"ReduceLogSumExp\",u,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},914143:u=>{r.ra(\"Where\",u,void 0)},914196:(u,p,h)=>{r.ra(\"Transpose\",u,{perm:p?Array.from(R.subarray(h>>>0,h+p>>>0)):[]})},914309:(u,p,h,S,T,k,F,ne,Y,Q)=>{r.ra(\"Conv\",u,{format:Y?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h],group:S,kernel_shape:[T],pads:[k,F],strides:[ne],w_is_const:()=>!!j[Q>>>0]})},914537:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie)=>{r.ra(\"Conv\",u,{format:E?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h,S],group:T,kernel_shape:[k,F],pads:[ne,Y,Q,ee],strides:[ce,pe],w_is_const:()=>!!j[ie>>>0]})},914796:(u,p,h,S,T,k,F,ne,Y,Q)=>{r.ra(\"Conv\",u,{format:Y?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h],group:S,kernel_shape:[T],pads:[k,F],strides:[ne],w_is_const:()=>!!j[Q>>>0]})},915024:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie)=>{r.ra(\"Conv\",u,{format:E?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h,S],group:T,kernel_shape:[k,F],pads:[ne,Y,Q,ee],strides:[ce,pe],w_is_const:()=>!!j[ie>>>0]})},915283:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E)=>{r.ra(\"ConvTranspose\",u,{format:Y?\"NHWC\":\"NCHW\",autoPad:p,dilations:[h],group:S,kernel_shape:[T],pads:[k,F],strides:[ne],wIsConst:()=>!!j[Q>>>0],outputPadding:ee?Array.from(R.subarray(ce>>>0,ce+ee>>>0)):[],outputShape:pe?Array.from(R.subarray(E>>>0,E+pe>>>0)):[]})},915663:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe)=>{r.ra(\"ConvTranspose\",u,{format:ne?\"NHWC\":\"NCHW\",autoPad:p,dilations:Array.from(R.subarray(h>>>0,h+2>>>0)),group:S,kernelShape:Array.from(R.subarray(T>>>0,T+2>>>0)),pads:Array.from(R.subarray(k>>>0,k+4>>>0)),strides:Array.from(R.subarray(F>>>0,F+2>>>0)),wIsConst:()=>!!j[Y>>>0],outputPadding:0<Q?Array.from(R.subarray(ee>>>0,ee+Q>>>0)):[],outputShape:0<ce?Array.from(R.subarray(pe>>>0,pe+ce>>>0)):[]})},916186:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E)=>{r.ra(\"ConvTranspose\",u,{format:Y?\"NHWC\":\"NCHW\",autoPad:p,dilations:[h],group:S,kernel_shape:[T],pads:[k,F],strides:[ne],wIsConst:()=>!!j[Q>>>0],outputPadding:ee?Array.from(R.subarray(ce>>>0,ce+ee>>>0)):[],outputShape:pe?Array.from(R.subarray(E>>>0,E+pe>>>0)):[]})},916566:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe)=>{r.ra(\"ConvTranspose\",u,{format:ne?\"NHWC\":\"NCHW\",autoPad:p,dilations:Array.from(R.subarray(h>>>0,h+2>>>0)),group:S,kernelShape:Array.from(R.subarray(T>>>0,T+2>>>0)),pads:Array.from(R.subarray(k>>>0,k+4>>>0)),strides:Array.from(R.subarray(F>>>0,F+2>>>0)),wIsConst:()=>!!j[Y>>>0],outputPadding:0<Q?Array.from(R.subarray(ee>>>0,ee+Q>>>0)):[],outputShape:0<ce?Array.from(R.subarray(pe>>>0,pe+ce>>>0)):[]})},917089:(u,p)=>{r.ra(\"GlobalAveragePool\",u,{format:p?\"NHWC\":\"NCHW\"})},917180:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie,ye)=>{r.ra(\"AveragePool\",u,{format:ye?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:S,storage_order:T,dilations:[k,F],kernel_shape:[ne,Y],pads:[Q,ee,ce,pe],strides:[E,ie]})},917464:(u,p)=>{r.ra(\"GlobalAveragePool\",u,{format:p?\"NHWC\":\"NCHW\"})},917555:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie,ye)=>{r.ra(\"AveragePool\",u,{format:ye?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:S,storage_order:T,dilations:[k,F],kernel_shape:[ne,Y],pads:[Q,ee,ce,pe],strides:[E,ie]})},917839:(u,p)=>{r.ra(\"GlobalMaxPool\",u,{format:p?\"NHWC\":\"NCHW\"})},917926:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie,ye)=>{r.ra(\"MaxPool\",u,{format:ye?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:S,storage_order:T,dilations:[k,F],kernel_shape:[ne,Y],pads:[Q,ee,ce,pe],strides:[E,ie]})},918206:(u,p)=>{r.ra(\"GlobalMaxPool\",u,{format:p?\"NHWC\":\"NCHW\"})},918293:(u,p,h,S,T,k,F,ne,Y,Q,ee,ce,pe,E,ie,ye)=>{r.ra(\"MaxPool\",u,{format:ye?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:S,storage_order:T,dilations:[k,F],kernel_shape:[ne,Y],pads:[Q,ee,ce,pe],strides:[E,ie]})},918573:(u,p,h,S,T)=>{r.ra(\"Gemm\",u,{alpha:p,beta:h,transA:S,transB:T})},918677:u=>{r.ra(\"MatMul\",u,void 0)},918731:(u,p,h,S)=>{r.ra(\"ArgMax\",u,{keepDims:!!p,selectLastIndex:!!h,axis:S})},918839:(u,p,h,S)=>{r.ra(\"ArgMin\",u,{keepDims:!!p,selectLastIndex:!!h,axis:S})},918947:(u,p)=>{r.ra(\"Softmax\",u,{axis:p})},919010:(u,p)=>{r.ra(\"Concat\",u,{axis:p})},919070:(u,p,h,S,T)=>{r.ra(\"Split\",u,{axis:p,numOutputs:h,splitSizes:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},919215:u=>{r.ra(\"Expand\",u,void 0)},919269:(u,p)=>{r.ra(\"Gather\",u,{axis:Number(p)})},919340:(u,p)=>{r.ra(\"GatherElements\",u,{axis:Number(p)})},919419:(u,p,h,S,T,k,F,ne,Y,Q,ee)=>{r.ra(\"Resize\",u,{antialias:p,axes:h?Array.from(R.subarray(S>>>0,S+h>>>0)):[],coordinateTransformMode:Fe(T),cubicCoeffA:k,excludeOutside:F,extrapolationValue:ne,keepAspectRatioPolicy:Fe(Y),mode:Fe(Q),nearestMode:Fe(ee)})},919770:(u,p,h,S,T,k,F)=>{r.ra(\"Slice\",u,{starts:p?Array.from(R.subarray(h>>>0,h+p>>>0)):[],ends:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[],axes:k?Array.from(R.subarray(F>>>0,F+k>>>0)):[]})},920001:u=>{r.ra(\"Tile\",u,void 0)},920053:(u,p,h)=>{r.ra(\"LayerNormalization\",u,{axis:Number(p),epsilon:Number(h)})},920160:(u,p,h)=>{r.ra(\"InstanceNormalization\",u,{epsilon:p,format:h?\"NHWC\":\"NCHW\"})},920274:(u,p,h)=>{r.ra(\"InstanceNormalization\",u,{epsilon:p,format:h?\"NHWC\":\"NCHW\"})},920388:u=>{r.ra(\"Range\",u,void 0)},920441:(u,p)=>{r.ra(\"Einsum\",u,{equation:Fe(p)})},920522:(u,p,h,S,T)=>{r.ra(\"Pad\",u,{mode:p,value:h,pads:S?Array.from(R.subarray(T>>>0,T+S>>>0)):[]})},920654:u=>{r.ra(\"Gelu\",u,void 0)},920706:u=>{r.ra(\"BiasAdd\",u,void 0)},920761:u=>{r.ra(\"BiasSplitGelu\",u,void 0)},920822:(u,p)=>{r.ra(\"SkipLayerNormalization\",u,{epsilon:p})},920903:u=>{r.Ra(u)},920937:(u,p)=>r.Sa(u,p,r.Da.Ta,r.Da.errors),921049:u=>r.Oa(u),921082:u=>r.Qa(u),921114:(u,p,h)=>{r.Ja(u,p,h,!0)},921153:(u,p,h)=>{r.Ja(u,p,h)}};function qe(u){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${u})`,this.status=u}var Ve=u=>{for(;0<u.length;)u.shift()(r)};function or(u){this.Ha=u-24,this.Ma=function(p){X[this.Ha+4>>2>>>0]=p},this.La=function(p){X[this.Ha+8>>2>>>0]=p},this.Ya=function(p,h){this.Ka(),this.Ma(p),this.La(h)},this.Ka=function(){X[this.Ha+16>>2>>>0]=0}}var Ot=0,Ye=0,_t=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,ot=(u,p,h)=>{p>>>=0;var S=p+h;for(h=p;u[h]&&!(h>=S);)++h;if(16<h-p&&u.buffer&&_t)return _t.decode(u.subarray(p,h));for(S=\"\";p<h;){var T=u[p++];if(T&128){var k=u[p++]&63;if((T&224)==192)S+=String.fromCharCode((T&31)<<6|k);else{var F=u[p++]&63;T=(T&240)==224?(T&15)<<12|k<<6|F:(T&7)<<18|k<<12|F<<6|u[p++]&63,65536>T?S+=String.fromCharCode(T):(T-=65536,S+=String.fromCharCode(55296|T>>10,56320|T&1023))}}else S+=String.fromCharCode(T)}return S},Fe=(u,p)=>(u>>>=0)?ot(le,u,p):\"\",Pt=u=>{for(var p=0,h=0;h<u.length;++h){var S=u.charCodeAt(h);127>=S?p++:2047>=S?p+=2:55296<=S&&57343>=S?(p+=4,++h):p+=3}return p},wt=(u,p,h,S)=>{if(h>>>=0,!(0<S))return 0;var T=h;S=h+S-1;for(var k=0;k<u.length;++k){var F=u.charCodeAt(k);if(55296<=F&&57343>=F){var ne=u.charCodeAt(++k);F=65536+((F&1023)<<10)|ne&1023}if(127>=F){if(h>=S)break;p[h++>>>0]=F}else{if(2047>=F){if(h+1>=S)break;p[h++>>>0]=192|F>>6}else{if(65535>=F){if(h+2>=S)break;p[h++>>>0]=224|F>>12}else{if(h+3>=S)break;p[h++>>>0]=240|F>>18,p[h++>>>0]=128|F>>12&63}p[h++>>>0]=128|F>>6&63}p[h++>>>0]=128|F&63}}return p[h>>>0]=0,h-T},st=u=>u%4===0&&(u%100!==0||u%400===0),at=[0,31,60,91,121,152,182,213,244,274,305,335],vt=[0,31,59,90,120,151,181,212,243,273,304,334],dt=u=>{var p=Pt(u)+1,h=At(p);return h&&wt(u,le,h,p),h},ct=[],Rt=(u,p)=>{ct.length=0;var h;for(p>>=2;h=le[u++>>>0];)p+=h!=105&p,ct.push(h==105?R[p>>>0]:Se[p++>>>1]),++p;return ct},$t={},Bt=()=>{if(!xt){var u={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:l||\"./this.program\"},p;for(p in $t)$t[p]===void 0?delete u[p]:u[p]=$t[p];var h=[];for(p in u)h.push(`${p}=${u[p]}`);xt=h}return xt},xt,Xe=[null,[],[]],Mt=[31,29,31,30,31,30,31,31,30,31,30,31],Ct=[31,28,31,30,31,30,31,31,30,31,30,31];function oe(u){var p=Array(Pt(u)+1);return wt(u,p,0,p.length),p}function pt(u,p,h,S){function T(E,ie,ye){for(E=typeof E==\"number\"?E.toString():E||\"\";E.length<ie;)E=ye[0]+E;return E}function k(E,ie){return T(E,ie,\"0\")}function F(E,ie){function ye(jt){return 0>jt?-1:0<jt?1:0}var Qe;return(Qe=ye(E.getFullYear()-ie.getFullYear()))===0&&(Qe=ye(E.getMonth()-ie.getMonth()))===0&&(Qe=ye(E.getDate()-ie.getDate())),Qe}function ne(E){switch(E.getDay()){case 0:return new Date(E.getFullYear()-1,11,29);case 1:return E;case 2:return new Date(E.getFullYear(),0,3);case 3:return new Date(E.getFullYear(),0,2);case 4:return new Date(E.getFullYear(),0,1);case 5:return new Date(E.getFullYear()-1,11,31);case 6:return new Date(E.getFullYear()-1,11,30)}}function Y(E){var ie=E.Ba;for(E=new Date(new Date(E.Ca+1900,0,1).getTime());0<ie;){var ye=E.getMonth(),Qe=(st(E.getFullYear())?Mt:Ct)[ye];if(ie>Qe-E.getDate())ie-=Qe-E.getDate()+1,E.setDate(1),11>ye?E.setMonth(ye+1):(E.setMonth(0),E.setFullYear(E.getFullYear()+1));else{E.setDate(E.getDate()+ie);break}}return ye=new Date(E.getFullYear()+1,0,4),ie=ne(new Date(E.getFullYear(),0,4)),ye=ne(ye),0>=F(ie,E)?0>=F(ye,E)?E.getFullYear()+1:E.getFullYear():E.getFullYear()-1}u>>>=0,p>>>=0,h>>>=0,S>>>=0;var Q=R[S+40>>2>>>0];S={Wa:R[S>>2>>>0],Va:R[S+4>>2>>>0],Ea:R[S+8>>2>>>0],Ia:R[S+12>>2>>>0],Fa:R[S+16>>2>>>0],Ca:R[S+20>>2>>>0],wa:R[S+24>>2>>>0],Ba:R[S+28>>2>>>0],$a:R[S+32>>2>>>0],Ua:R[S+36>>2>>>0],Xa:Q?Fe(Q):\"\"},h=Fe(h),Q={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var ee in Q)h=h.replace(new RegExp(ee,\"g\"),Q[ee]);var ce=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),pe=\"January February March April May June July August September October November December\".split(\" \");Q={\"%a\":E=>ce[E.wa].substring(0,3),\"%A\":E=>ce[E.wa],\"%b\":E=>pe[E.Fa].substring(0,3),\"%B\":E=>pe[E.Fa],\"%C\":E=>k((E.Ca+1900)/100|0,2),\"%d\":E=>k(E.Ia,2),\"%e\":E=>T(E.Ia,2,\" \"),\"%g\":E=>Y(E).toString().substring(2),\"%G\":E=>Y(E),\"%H\":E=>k(E.Ea,2),\"%I\":E=>(E=E.Ea,E==0?E=12:12<E&&(E-=12),k(E,2)),\"%j\":E=>{for(var ie=0,ye=0;ye<=E.Fa-1;ie+=(st(E.Ca+1900)?Mt:Ct)[ye++]);return k(E.Ia+ie,3)},\"%m\":E=>k(E.Fa+1,2),\"%M\":E=>k(E.Va,2),\"%n\":()=>`\n`,\"%p\":E=>0<=E.Ea&&12>E.Ea?\"AM\":\"PM\",\"%S\":E=>k(E.Wa,2),\"%t\":()=>\"\t\",\"%u\":E=>E.wa||7,\"%U\":E=>k(Math.floor((E.Ba+7-E.wa)/7),2),\"%V\":E=>{var ie=Math.floor((E.Ba+7-(E.wa+6)%7)/7);if(2>=(E.wa+371-E.Ba-2)%7&&ie++,ie)ie==53&&(ye=(E.wa+371-E.Ba)%7,ye==4||ye==3&&st(E.Ca)||(ie=1));else{ie=52;var ye=(E.wa+7-E.Ba-1)%7;(ye==4||ye==5&&st(E.Ca%400-1))&&ie++}return k(ie,2)},\"%w\":E=>E.wa,\"%W\":E=>k(Math.floor((E.Ba+7-(E.wa+6)%7)/7),2),\"%y\":E=>(E.Ca+1900).toString().substring(2),\"%Y\":E=>E.Ca+1900,\"%z\":E=>{E=E.Ua;var ie=0<=E;return E=Math.abs(E)/60,(ie?\"+\":\"-\")+(\"0000\"+(E/60*100+E%60)).slice(-4)},\"%Z\":E=>E.Xa,\"%%\":()=>\"%\"},h=h.replace(/%%/g,\"\\0\\0\");for(ee in Q)h.includes(ee)&&(h=h.replace(new RegExp(ee,\"g\"),Q[ee](S)));return h=h.replace(/\\0\\0/g,\"%\"),ee=oe(h),ee.length>p?0:(j.set(ee,u>>>0),ee.length-1)}function ft(u){try{u()}catch(p){We(p)}}function Nr(u){var p={},h;for(h in u)(function(S){var T=u[S];p[S]=typeof T==\"function\"?function(){mt.push(S);try{return T.apply(null,arguments)}finally{U||(mt.pop()===S||We(),Ne&&He===1&&mt.length===0&&(He=0,ft(It),typeof Fibers<\"u\"&&Fibers.ab()))}}:T})(h);return p}var He=0,Ne=null,kt=0,mt=[],Dt={},Wt={},zt=0,St=null,ar=[];function ir(){return new Promise((u,p)=>{St={resolve:u,reject:p}})}function sr(){var u=At(65548),p=u+12;X[u>>2>>>0]=p,X[u+4>>2>>>0]=p+65536,p=mt[0];var h=Dt[p];return h===void 0&&(h=zt++,Dt[p]=h,Wt[h]=p),R[u+8>>2>>>0]=h,u}function ur(u){if(!U){if(He===0){var p=!1,h=!1;u((S=0)=>{if(!U&&(kt=S,p=!0,h)){He=2,ft(()=>ht(Ne)),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.resume(),S=!1;try{var T=(0,_[Wt[R[Ne+8>>2>>>0]]])()}catch(ne){T=ne,S=!0}var k=!1;if(!Ne){var F=St;F&&(St=null,(S?F.reject:F.resolve)(T),k=!0)}if(S&&!k)throw T}}),h=!0,p||(He=1,Ne=sr(),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.pause(),ft(()=>Ht(Ne)))}else He===2?(He=0,ft(it),Gt(Ne),Ne=null,ar.forEach(S=>{if(!U)try{if(S(),!M)try{V=V=S=V,M||(r.onExit&&r.onExit(S),U=!0),n(S,new qe(S))}catch(T){T instanceof qe||T==\"unwind\"||n(1,T)}}catch(T){T instanceof qe||T==\"unwind\"||n(1,T)}})):We(`invalid state: ${He}`);return kt}}function lr(u){return ur(p=>{u().then(p)})}var dr={n:function(u,p,h){return lr(async()=>{await r.Pa(u,p,h)})},a:function(u,p,h){throw u>>>=0,new or(u).Ya(p>>>0,h>>>0),Ot=u,Ye++,Ot},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(u,p,h){u=p+2097152>>>0<4194305-!!u?(u>>>0)+4294967296*p:NaN,h>>>=0,u=new Date(1e3*u),R[h>>2>>>0]=u.getUTCSeconds(),R[h+4>>2>>>0]=u.getUTCMinutes(),R[h+8>>2>>>0]=u.getUTCHours(),R[h+12>>2>>>0]=u.getUTCDate(),R[h+16>>2>>>0]=u.getUTCMonth(),R[h+20>>2>>>0]=u.getUTCFullYear()-1900,R[h+24>>2>>>0]=u.getUTCDay(),R[h+28>>2>>>0]=(u.getTime()-Date.UTC(u.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},r:function(u,p,h){u=p+2097152>>>0<4194305-!!u?(u>>>0)+4294967296*p:NaN,h>>>=0,u=new Date(1e3*u),R[h>>2>>>0]=u.getSeconds(),R[h+4>>2>>>0]=u.getMinutes(),R[h+8>>2>>>0]=u.getHours(),R[h+12>>2>>>0]=u.getDate(),R[h+16>>2>>>0]=u.getMonth(),R[h+20>>2>>>0]=u.getFullYear()-1900,R[h+24>>2>>>0]=u.getDay(),R[h+28>>2>>>0]=(st(u.getFullYear())?at:vt)[u.getMonth()]+u.getDate()-1|0,R[h+36>>2>>>0]=-(60*u.getTimezoneOffset()),p=new Date(u.getFullYear(),6,1).getTimezoneOffset();var S=new Date(u.getFullYear(),0,1).getTimezoneOffset();R[h+32>>2>>>0]=(p!=S&&u.getTimezoneOffset()==Math.min(S,p))|0},s:function(u){u>>>=0;var p=new Date(R[u+20>>2>>>0]+1900,R[u+16>>2>>>0],R[u+12>>2>>>0],R[u+8>>2>>>0],R[u+4>>2>>>0],R[u>>2>>>0],0),h=R[u+32>>2>>>0],S=p.getTimezoneOffset(),T=new Date(p.getFullYear(),6,1).getTimezoneOffset(),k=new Date(p.getFullYear(),0,1).getTimezoneOffset(),F=Math.min(k,T);return 0>h?R[u+32>>2>>>0]=+(T!=k&&F==S):0<h!=(F==S)&&(T=Math.max(k,T),p.setTime(p.getTime()+6e4*((0<h?F:T)-S))),R[u+24>>2>>>0]=p.getDay(),R[u+28>>2>>>0]=(st(p.getFullYear())?at:vt)[p.getMonth()]+p.getDate()-1|0,R[u>>2>>>0]=p.getSeconds(),R[u+4>>2>>>0]=p.getMinutes(),R[u+8>>2>>>0]=p.getHours(),R[u+12>>2>>>0]=p.getDate(),R[u+16>>2>>>0]=p.getMonth(),R[u+20>>2>>>0]=p.getYear(),u=p.getTime()/1e3,Ut((Ae=u,1<=+Math.abs(Ae)?0<Ae?+Math.floor(Ae/4294967296)>>>0:~~+Math.ceil((Ae-+(~~Ae>>>0))/4294967296)>>>0:0)),u>>>0},o:function(){return-52},p:function(){},v:function(u,p,h){function S(Y){return(Y=Y.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?Y[1]:\"GMT\"}h>>>=0;var T=new Date().getFullYear(),k=new Date(T,0,1),F=new Date(T,6,1);T=k.getTimezoneOffset();var ne=F.getTimezoneOffset();X[u>>>0>>2>>>0]=60*Math.max(T,ne),R[p>>>0>>2>>>0]=+(T!=ne),u=S(k),p=S(F),u=dt(u),p=dt(p),ne<T?(X[h>>2>>>0]=u,X[h+4>>2>>>0]=p):(X[h>>2>>>0]=p,X[h+4>>2>>>0]=u)},e:()=>{We(\"\")},b:function(u,p,h){return u>>>=0,p=Rt(p>>>0,h>>>0),Ue[u].apply(null,p)},i:function(u,p,h){return u>>>=0,p=Rt(p>>>0,h>>>0),Ue[u].apply(null,p)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(u,p,h){return p>>>=0,le.copyWithin(u>>>0>>>0,p>>>0,p+(h>>>0)>>>0)},u:function(u){u>>>=0;var p=le.length;if(4294901760<u)return!1;for(var h=1;4>=h;h*=2){var S=p*(1+.2/h);S=Math.min(S,u+100663296);var T=Math;S=Math.max(u,S);e:{T=T.min.call(T,4294901760,S+(65536-S%65536)%65536)-G.buffer.byteLength+65535>>>16;try{G.grow(T),q();var k=1;break e}catch{}k=void 0}if(k)return!0}return!1},D:function(u,p){u>>>=0,p>>>=0;var h=0;return Bt().forEach(function(S,T){var k=p+h;for(T=X[u+4*T>>2>>>0]=k,k=0;k<S.length;++k)j[T++>>0>>>0]=S.charCodeAt(k);j[T>>0>>>0]=0,h+=S.length+1}),0},E:function(u,p){u>>>=0,p>>>=0;var h=Bt();X[u>>2>>>0]=h.length;var S=0;return h.forEach(function(T){S+=T.length+1}),X[p>>2>>>0]=S,0},f:()=>52,k:function(){return 52},t:function(){return 70},j:function(u,p,h,S){p>>>=0,h>>>=0,S>>>=0;for(var T=0,k=0;k<h;k++){var F=X[p>>2>>>0],ne=X[p+4>>2>>>0];p+=8;for(var Y=0;Y<ne;Y++){var Q=le[F+Y>>>0],ee=Xe[u];Q===0||Q===10?((u===1?I:B)(ot(ee,0)),ee.length=0):ee.push(Q)}T+=ne}return X[S>>2>>>0]=T,0},F:pt,d:function(u,p,h,S){return pt(u>>>0,p>>>0,h>>>0,S>>>0)}};(function(){function u(h){if(h=h.exports,h=Nr(h),_=h=cr(h),G=_.M,q(),De.unshift(_.N),we--,r.monitorRunDependencies&&r.monitorRunDependencies(we),we==0&&(Be!==null&&(clearInterval(Be),Be=null),Ke)){var S=Ke;Ke=null,S()}return h}var p={a:dr};if(we++,r.monitorRunDependencies&&r.monitorRunDependencies(we),r.instantiateWasm)try{return r.instantiateWasm(p,u)}catch(h){B(\"Module.instantiateWasm callback failed with error: \"+h),o(h)}return Te(p,function(h){u(h.instance)}).catch(o),{}})(),r._OrtInit=(u,p)=>(r._OrtInit=_.O)(u,p),r._OrtGetLastError=(u,p)=>(r._OrtGetLastError=_.P)(u,p),r._OrtCreateSessionOptions=(u,p,h,S,T,k,F,ne,Y,Q)=>(r._OrtCreateSessionOptions=_.Q)(u,p,h,S,T,k,F,ne,Y,Q),r._OrtAppendExecutionProvider=(u,p)=>(r._OrtAppendExecutionProvider=_.R)(u,p),r._OrtAddFreeDimensionOverride=(u,p,h)=>(r._OrtAddFreeDimensionOverride=_.S)(u,p,h),r._OrtAddSessionConfigEntry=(u,p,h)=>(r._OrtAddSessionConfigEntry=_.T)(u,p,h),r._OrtReleaseSessionOptions=u=>(r._OrtReleaseSessionOptions=_.U)(u),r._OrtCreateSession=(u,p,h)=>(r._OrtCreateSession=_.V)(u,p,h),r._OrtReleaseSession=u=>(r._OrtReleaseSession=_.W)(u),r._OrtGetInputOutputCount=(u,p,h)=>(r._OrtGetInputOutputCount=_.X)(u,p,h),r._OrtGetInputName=(u,p)=>(r._OrtGetInputName=_.Y)(u,p),r._OrtGetOutputName=(u,p)=>(r._OrtGetOutputName=_.Z)(u,p),r._OrtFree=u=>(r._OrtFree=_._)(u),r._OrtCreateTensor=(u,p,h,S,T,k)=>(r._OrtCreateTensor=_.$)(u,p,h,S,T,k),r._OrtGetTensorData=(u,p,h,S,T)=>(r._OrtGetTensorData=_.aa)(u,p,h,S,T),r._OrtReleaseTensor=u=>(r._OrtReleaseTensor=_.ba)(u),r._OrtCreateRunOptions=(u,p,h,S)=>(r._OrtCreateRunOptions=_.ca)(u,p,h,S),r._OrtAddRunConfigEntry=(u,p,h)=>(r._OrtAddRunConfigEntry=_.da)(u,p,h),r._OrtReleaseRunOptions=u=>(r._OrtReleaseRunOptions=_.ea)(u),r._OrtCreateBinding=u=>(r._OrtCreateBinding=_.fa)(u),r._OrtBindInput=(u,p,h)=>(r._OrtBindInput=_.ga)(u,p,h),r._OrtBindOutput=(u,p,h,S)=>(r._OrtBindOutput=_.ha)(u,p,h,S),r._OrtClearBoundOutputs=u=>(r._OrtClearBoundOutputs=_.ia)(u),r._OrtReleaseBinding=u=>(r._OrtReleaseBinding=_.ja)(u),r._OrtRunWithBinding=(u,p,h,S,T)=>(r._OrtRunWithBinding=_.ka)(u,p,h,S,T),r._OrtRun=(u,p,h,S,T,k,F,ne)=>(r._OrtRun=_.la)(u,p,h,S,T,k,F,ne),r._OrtEndProfiling=u=>(r._OrtEndProfiling=_.ma)(u),r._JsepOutput=(u,p,h)=>(r._JsepOutput=_.na)(u,p,h),r._JsepGetNodeName=u=>(r._JsepGetNodeName=_.oa)(u);var At=r._malloc=u=>(At=r._malloc=_.pa)(u),Gt=r._free=u=>(Gt=r._free=_.qa)(u),Ut=u=>(Ut=_.sa)(u),Nt=()=>(Nt=_.ta)(),Vt=u=>(Vt=_.ua)(u),Ft=u=>(Ft=_.va)(u),Ht=u=>(Ht=_.xa)(u),It=()=>(It=_.ya)(),ht=u=>(ht=_.za)(u),it=()=>(it=_.Aa)();r.___start_em_js=921186,r.___stop_em_js=921347;function cr(u){u=Object.assign({},u);var p=S=>()=>S()>>>0,h=S=>T=>S(T)>>>0;return u.__errno_location=p(u.__errno_location),u.malloc=h(u.malloc),u.stackSave=p(u.stackSave),u.stackAlloc=h(u.stackAlloc),u}r.stackAlloc=Ft,r.stackSave=Nt,r.stackRestore=Vt,r.UTF8ToString=Fe,r.stringToUTF8=(u,p,h)=>wt(u,le,p,h),r.lengthBytesUTF8=Pt;var gt;Ke=function u(){gt||Lt(),gt||(Ke=u)};function Lt(){function u(){if(!gt&&(gt=!0,r.calledRun=!0,!U)){if(Ve(De),i(r),r.onRuntimeInitialized&&r.onRuntimeInitialized(),r.postRun)for(typeof r.postRun==\"function\"&&(r.postRun=[r.postRun]);r.postRun.length;){var p=r.postRun.shift();he.unshift(p)}Ve(he)}}if(!(0<we)){if(r.preRun)for(typeof r.preRun==\"function\"&&(r.preRun=[r.preRun]);r.preRun.length;)Re();Ve(L),0<we||(r.setStatus?(r.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){r.setStatus(\"\")},1),u()},1)):u())}}if(r.preInit)for(typeof r.preInit==\"function\"&&(r.preInit=[r.preInit]);0<r.preInit.length;)r.preInit.pop()();return Lt(),t.ready}})();typeof Xn==\"object\"&&typeof Zr==\"object\"?Zr.exports=Yn:typeof define==\"function\"&&define.amd&&define([],()=>Yn)});var Jn=Kt(()=>{});var Zn=Kt(()=>{});var eo={};yr(eo,{cpus:()=>su});var su,to=H(()=>{su=void 0});var oo=Kt((no,en)=>{\"use strict\";var ro=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){function r(){return q.buffer!=we.buffer&&N(),we}function i(){return q.buffer!=we.buffer&&N(),Be}function o(){return q.buffer!=we.buffer&&N(),Ke}function s(){return q.buffer!=we.buffer&&N(),We}function l(){return q.buffer!=we.buffer&&N(),nt}var n=t,c,m;n.ready=new Promise((a,d)=>{c=a,m=d}),n.jsepInit=(a,d,f,y,A,P,W,te)=>{n.Qb=a,n.wb=d,n.yb=f,n.jb=y,n.xb=A,n.Ea=P,n.zb=W,n.Ab=te,d=(Z,J,re)=>(...fe)=>{let be=Je,O=J?.();fe=Z(...fe);let ue=J?.();return O!==ue&&(Z=ue,re(O),J=re=null),Je!=be?Ks():fe},f=Z=>async(...J)=>{try{if(n.bb)throw Error(\"Session already started\");let re=n.bb={Fb:J[0],errors:[]},fe=await Z(...J);if(n.bb!==re)throw Error(\"Session mismatch\");a.flush();let be=re.errors;if(0<be.length){let O=await Promise.all(be);if(O=O.filter(ue=>ue),0<O.length)throw Error(O.join(`\n`))}return fe}finally{n.bb=null}},n._OrtRun=f(d(n._OrtRun,()=>n._OrtRun,Z=>n._OrtRun=Z)),n._OrtRunWithBinding=f(d(n._OrtRunWithBinding,()=>n._OrtRunWithBinding,Z=>n._OrtRunWithBinding=Z)),n._OrtBindInput=d(n._OrtBindInput,()=>n._OrtBindInput,Z=>n._OrtBindInput=Z),n.jsepRegisterBuffer=(Z,J,re,fe)=>a.registerBuffer(Z,J,re,fe),n.jsepUnregisterBuffers=Z=>{a.unregisterBuffers(Z)},n.jsepGetBuffer=Z=>a.getBuffer(Z),n.jsepCreateDownloader=(Z,J,re)=>a.createDownloader(Z,J,re)};var g=Object.assign({},n),C=\"./this.program\",x=(a,d)=>{throw d},$=typeof window==\"object\",b=typeof importScripts==\"function\",w=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",v=n.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function B(a){return n.locateFile?n.locateFile(a,I):I+a}var z,M,G;if(w){var _=(Xr(),Tt(Yr)),U=(Jr(),Tt(Qr));I=b?U.dirname(I)+\"/\":__dirname+\"/\",z=(d,f)=>(d=d.startsWith(\"file://\")?new URL(d):U.normalize(d),_.readFileSync(d,f?void 0:\"utf8\")),G=d=>(d=z(d,!0),d.buffer||(d=new Uint8Array(d)),d),M=(d,f,y,A=!0)=>{d=d.startsWith(\"file://\")?new URL(d):U.normalize(d),_.readFile(d,A?void 0:\"utf8\",(P,W)=>{P?y(P):f(A?W.buffer:W)})},!n.thisProgram&&1<process.argv.length&&(C=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),x=(d,f)=>{throw process.exitCode=d,f},n.inspect=()=>\"[Emscripten Module object]\";let a;try{a=Jn()}catch(d){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),d}global.Worker=a.Worker}else($||b)&&(b?I=self.location.href:typeof document<\"u\"&&document.currentScript&&(I=document.currentScript.src),typeof e<\"u\"&&e&&(I=e),I.indexOf(\"blob:\")!==0?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",w||(z=a=>{var d=new XMLHttpRequest;return d.open(\"GET\",a,!1),d.send(null),d.responseText},b&&(G=a=>{var d=new XMLHttpRequest;return d.open(\"GET\",a,!1),d.responseType=\"arraybuffer\",d.send(null),new Uint8Array(d.response)}),M=(a,d,f)=>{var y=new XMLHttpRequest;y.open(\"GET\",a,!0),y.responseType=\"arraybuffer\",y.onload=()=>{y.status==200||y.status==0&&y.response?d(y.response):f()},y.onerror=f,y.send(null)}));w&&typeof performance>\"u\"&&(global.performance=Zn().performance);var V=console.log.bind(console),j=console.error.bind(console);w&&(V=(...a)=>_.writeSync(1,a.join(\" \")+`\n`),j=(...a)=>_.writeSync(2,a.join(\" \")+`\n`));var le=n.print||V,R=n.printErr||j;Object.assign(n,g),g=null,n.thisProgram&&(C=n.thisProgram),n.quit&&(x=n.quit);var X;n.wasmBinary&&(X=n.wasmBinary);var Se=n.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&Ye(\"no native wasm support detected\");var q,L,De,he=!1,Re,we,Be,Ke,We,nt;function N(){var a=q.buffer;n.HEAP8=we=new Int8Array(a),n.HEAP16=new Int16Array(a),n.HEAP32=Ke=new Int32Array(a),n.HEAPU8=Be=new Uint8Array(a),n.HEAPU16=new Uint16Array(a),n.HEAPU32=We=new Uint32Array(a),n.HEAPF32=new Float32Array(a),n.HEAPF64=nt=new Float64Array(a)}var de=n.INITIAL_MEMORY||16777216;if(5242880<=de||Ye(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+de+\"! (STACK_SIZE=5242880)\"),v)q=n.wasmMemory;else if(n.wasmMemory)q=n.wasmMemory;else if(q=new WebAssembly.Memory({initial:de/65536,maximum:65536,shared:!0}),!(q.buffer instanceof SharedArrayBuffer))throw R(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),w&&R(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");N(),de=q.buffer.byteLength;var ge=[],ze=[],Ge=[],Te=0;function Ae(){return Se||0<Te}var Ue=0,qe=null,Ve=null;function or(){Ue++,n.monitorRunDependencies&&n.monitorRunDependencies(Ue)}function Ot(){if(Ue--,n.monitorRunDependencies&&n.monitorRunDependencies(Ue),Ue==0&&(qe!==null&&(clearInterval(qe),qe=null),Ve)){var a=Ve;Ve=null,a()}}function Ye(a){throw n.onAbort&&n.onAbort(a),a=\"Aborted(\"+a+\")\",R(a),he=!0,Re=1,a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\"),m(a),a}function _t(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var ot;ot=\"ort-wasm-simd-threaded.wasm\",_t(ot)||(ot=B(ot));function Fe(a){if(a==ot&&X)return new Uint8Array(X);if(G)return G(a);throw\"both async and sync fetching of the wasm failed\"}function Pt(a){if(!X&&($||b)){if(typeof fetch==\"function\"&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(d=>{if(!d.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return d.arrayBuffer()}).catch(()=>Fe(a));if(M)return new Promise((d,f)=>{M(a,y=>d(new Uint8Array(y)),f)})}return Promise.resolve().then(()=>Fe(a))}function wt(a,d,f){return Pt(a).then(y=>WebAssembly.instantiate(y,d)).then(y=>y).then(f,y=>{R(\"failed to asynchronously prepare wasm: \"+y),Ye(y)})}function st(a,d){var f=ot;return X||typeof WebAssembly.instantiateStreaming!=\"function\"||_t(f)||f.startsWith(\"file://\")||w||typeof fetch!=\"function\"?wt(f,a,d):fetch(f,{credentials:\"same-origin\"}).then(y=>WebAssembly.instantiateStreaming(y,a).then(d,function(A){return R(\"wasm streaming compile failed: \"+A),R(\"falling back to ArrayBuffer instantiation\"),wt(f,a,d)}))}var at,vt={911532:a=>{n.Ea(\"Abs\",a,void 0)},911583:a=>{n.Ea(\"Neg\",a,void 0)},911634:a=>{n.Ea(\"Floor\",a,void 0)},911687:a=>{n.Ea(\"Ceil\",a,void 0)},911739:a=>{n.Ea(\"Reciprocal\",a,void 0)},911797:a=>{n.Ea(\"Sqrt\",a,void 0)},911849:a=>{n.Ea(\"Exp\",a,void 0)},911900:a=>{n.Ea(\"Erf\",a,void 0)},911951:a=>{n.Ea(\"Sigmoid\",a,void 0)},912006:a=>{n.Ea(\"Log\",a,void 0)},912057:a=>{n.Ea(\"Sin\",a,void 0)},912108:a=>{n.Ea(\"Cos\",a,void 0)},912159:a=>{n.Ea(\"Tan\",a,void 0)},912210:a=>{n.Ea(\"Asin\",a,void 0)},912262:a=>{n.Ea(\"Acos\",a,void 0)},912314:a=>{n.Ea(\"Atan\",a,void 0)},912366:a=>{n.Ea(\"Sinh\",a,void 0)},912418:a=>{n.Ea(\"Cosh\",a,void 0)},912470:a=>{n.Ea(\"Asinh\",a,void 0)},912523:a=>{n.Ea(\"Acosh\",a,void 0)},912576:a=>{n.Ea(\"Atanh\",a,void 0)},912629:a=>{n.Ea(\"Tanh\",a,void 0)},912681:a=>{n.Ea(\"Not\",a,void 0)},912732:(a,d,f)=>{n.Ea(\"ClipV10\",a,{min:d,max:f})},912804:a=>{n.Ea(\"Clip\",a,void 0)},912856:(a,d)=>{n.Ea(\"Elu\",a,{alpha:d})},912914:a=>{n.Ea(\"Relu\",a,void 0)},912966:(a,d)=>{n.Ea(\"LeakyRelu\",a,{alpha:d})},913030:(a,d)=>{n.Ea(\"ThresholdedRelu\",a,{alpha:d})},913100:(a,d)=>{n.Ea(\"Cast\",a,{to:d})},913158:a=>{n.Ea(\"Add\",a,void 0)},913209:a=>{n.Ea(\"Sub\",a,void 0)},913260:a=>{n.Ea(\"Mul\",a,void 0)},913311:a=>{n.Ea(\"Div\",a,void 0)},913362:a=>{n.Ea(\"Pow\",a,void 0)},913413:a=>{n.Ea(\"Equal\",a,void 0)},913466:a=>{n.Ea(\"Greater\",a,void 0)},913521:a=>{n.Ea(\"GreaterOrEqual\",a,void 0)},913583:a=>{n.Ea(\"Less\",a,void 0)},913635:a=>{n.Ea(\"LessOrEqual\",a,void 0)},913694:(a,d,f,y,A)=>{n.Ea(\"ReduceMean\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},913858:(a,d,f,y,A)=>{n.Ea(\"ReduceMax\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914021:(a,d,f,y,A)=>{n.Ea(\"ReduceMin\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914184:(a,d,f,y,A)=>{n.Ea(\"ReduceProd\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914348:(a,d,f,y,A)=>{n.Ea(\"ReduceSum\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914511:(a,d,f,y,A)=>{n.Ea(\"ReduceL1\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914673:(a,d,f,y,A)=>{n.Ea(\"ReduceL2\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},914835:(a,d,f,y,A)=>{n.Ea(\"ReduceLogSum\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},915001:(a,d,f,y,A)=>{n.Ea(\"ReduceSumSquare\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},915170:(a,d,f,y,A)=>{n.Ea(\"ReduceLogSumExp\",a,{keepDims:!!d,noopWithEmptyAxes:!!f,axes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},915339:a=>{n.Ea(\"Where\",a,void 0)},915392:(a,d,f)=>{n.Ea(\"Transpose\",a,{perm:d?Array.from(o().subarray(f>>>0,f+d>>>0)):[]})},915505:(a,d,f,y,A,P,W,te,Z,J)=>{n.Ea(\"Conv\",a,{format:Z?\"NHWC\":\"NCHW\",auto_pad:d,dilations:[f],group:y,kernel_shape:[A],pads:[P,W],strides:[te],w_is_const:()=>!!r()[J>>>0]})},915733:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue)=>{n.Ea(\"Conv\",a,{format:O?\"NHWC\":\"NCHW\",auto_pad:d,dilations:[f,y],group:A,kernel_shape:[P,W],pads:[te,Z,J,re],strides:[fe,be],w_is_const:()=>!!r()[ue>>>0]})},915992:(a,d,f,y,A,P,W,te,Z,J)=>{n.Ea(\"Conv\",a,{format:Z?\"NHWC\":\"NCHW\",auto_pad:d,dilations:[f],group:y,kernel_shape:[A],pads:[P,W],strides:[te],w_is_const:()=>!!r()[J>>>0]})},916220:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue)=>{n.Ea(\"Conv\",a,{format:O?\"NHWC\":\"NCHW\",auto_pad:d,dilations:[f,y],group:A,kernel_shape:[P,W],pads:[te,Z,J,re],strides:[fe,be],w_is_const:()=>!!r()[ue>>>0]})},916479:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O)=>{n.Ea(\"ConvTranspose\",a,{format:Z?\"NHWC\":\"NCHW\",autoPad:d,dilations:[f],group:y,kernel_shape:[A],pads:[P,W],strides:[te],wIsConst:()=>!!r()[J>>>0],outputPadding:re?Array.from(o().subarray(fe>>>0,fe+re>>>0)):[],outputShape:be?Array.from(o().subarray(O>>>0,O+be>>>0)):[]})},916859:(a,d,f,y,A,P,W,te,Z,J,re,fe,be)=>{n.Ea(\"ConvTranspose\",a,{format:te?\"NHWC\":\"NCHW\",autoPad:d,dilations:Array.from(o().subarray(f>>>0,f+2>>>0)),group:y,kernelShape:Array.from(o().subarray(A>>>0,A+2>>>0)),pads:Array.from(o().subarray(P>>>0,P+4>>>0)),strides:Array.from(o().subarray(W>>>0,W+2>>>0)),wIsConst:()=>!!r()[Z>>>0],outputPadding:0<J?Array.from(o().subarray(re>>>0,re+J>>>0)):[],outputShape:0<fe?Array.from(o().subarray(be>>>0,be+fe>>>0)):[]})},917382:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O)=>{n.Ea(\"ConvTranspose\",a,{format:Z?\"NHWC\":\"NCHW\",autoPad:d,dilations:[f],group:y,kernel_shape:[A],pads:[P,W],strides:[te],wIsConst:()=>!!r()[J>>>0],outputPadding:re?Array.from(o().subarray(fe>>>0,fe+re>>>0)):[],outputShape:be?Array.from(o().subarray(O>>>0,O+be>>>0)):[]})},917762:(a,d,f,y,A,P,W,te,Z,J,re,fe,be)=>{n.Ea(\"ConvTranspose\",a,{format:te?\"NHWC\":\"NCHW\",autoPad:d,dilations:Array.from(o().subarray(f>>>0,f+2>>>0)),group:y,kernelShape:Array.from(o().subarray(A>>>0,A+2>>>0)),pads:Array.from(o().subarray(P>>>0,P+4>>>0)),strides:Array.from(o().subarray(W>>>0,W+2>>>0)),wIsConst:()=>!!r()[Z>>>0],outputPadding:0<J?Array.from(o().subarray(re>>>0,re+J>>>0)):[],outputShape:0<fe?Array.from(o().subarray(be>>>0,be+fe>>>0)):[]})},918285:(a,d)=>{n.Ea(\"GlobalAveragePool\",a,{format:d?\"NHWC\":\"NCHW\"})},918376:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue,ve)=>{n.Ea(\"AveragePool\",a,{format:ve?\"NHWC\":\"NCHW\",auto_pad:d,ceil_mode:f,count_include_pad:y,storage_order:A,dilations:[P,W],kernel_shape:[te,Z],pads:[J,re,fe,be],strides:[O,ue]})},918660:(a,d)=>{n.Ea(\"GlobalAveragePool\",a,{format:d?\"NHWC\":\"NCHW\"})},918751:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue,ve)=>{n.Ea(\"AveragePool\",a,{format:ve?\"NHWC\":\"NCHW\",auto_pad:d,ceil_mode:f,count_include_pad:y,storage_order:A,dilations:[P,W],kernel_shape:[te,Z],pads:[J,re,fe,be],strides:[O,ue]})},919035:(a,d)=>{n.Ea(\"GlobalMaxPool\",a,{format:d?\"NHWC\":\"NCHW\"})},919122:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue,ve)=>{n.Ea(\"MaxPool\",a,{format:ve?\"NHWC\":\"NCHW\",auto_pad:d,ceil_mode:f,count_include_pad:y,storage_order:A,dilations:[P,W],kernel_shape:[te,Z],pads:[J,re,fe,be],strides:[O,ue]})},919402:(a,d)=>{n.Ea(\"GlobalMaxPool\",a,{format:d?\"NHWC\":\"NCHW\"})},919489:(a,d,f,y,A,P,W,te,Z,J,re,fe,be,O,ue,ve)=>{n.Ea(\"MaxPool\",a,{format:ve?\"NHWC\":\"NCHW\",auto_pad:d,ceil_mode:f,count_include_pad:y,storage_order:A,dilations:[P,W],kernel_shape:[te,Z],pads:[J,re,fe,be],strides:[O,ue]})},919769:(a,d,f,y,A)=>{n.Ea(\"Gemm\",a,{alpha:d,beta:f,transA:y,transB:A})},919873:a=>{n.Ea(\"MatMul\",a,void 0)},919927:(a,d,f,y)=>{n.Ea(\"ArgMax\",a,{keepDims:!!d,selectLastIndex:!!f,axis:y})},920035:(a,d,f,y)=>{n.Ea(\"ArgMin\",a,{keepDims:!!d,selectLastIndex:!!f,axis:y})},920143:(a,d)=>{n.Ea(\"Softmax\",a,{axis:d})},920206:(a,d)=>{n.Ea(\"Concat\",a,{axis:d})},920266:(a,d,f,y,A)=>{n.Ea(\"Split\",a,{axis:d,numOutputs:f,splitSizes:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},920411:a=>{n.Ea(\"Expand\",a,void 0)},920465:(a,d)=>{n.Ea(\"Gather\",a,{axis:Number(d)})},920536:(a,d)=>{n.Ea(\"GatherElements\",a,{axis:Number(d)})},920615:(a,d,f,y,A,P,W,te,Z,J,re)=>{n.Ea(\"Resize\",a,{antialias:d,axes:f?Array.from(o().subarray(y>>>0,y+f>>>0)):[],coordinateTransformMode:Xe(A),cubicCoeffA:P,excludeOutside:W,extrapolationValue:te,keepAspectRatioPolicy:Xe(Z),mode:Xe(J),nearestMode:Xe(re)})},920966:(a,d,f,y,A,P,W)=>{n.Ea(\"Slice\",a,{starts:d?Array.from(o().subarray(f>>>0,f+d>>>0)):[],ends:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[],axes:P?Array.from(o().subarray(W>>>0,W+P>>>0)):[]})},921197:a=>{n.Ea(\"Tile\",a,void 0)},921249:(a,d,f)=>{n.Ea(\"LayerNormalization\",a,{axis:Number(d),epsilon:Number(f)})},921356:(a,d,f)=>{n.Ea(\"InstanceNormalization\",a,{epsilon:d,format:f?\"NHWC\":\"NCHW\"})},921470:(a,d,f)=>{n.Ea(\"InstanceNormalization\",a,{epsilon:d,format:f?\"NHWC\":\"NCHW\"})},921584:a=>{n.Ea(\"Range\",a,void 0)},921637:(a,d)=>{n.Ea(\"Einsum\",a,{equation:Xe(d)})},921718:(a,d,f,y,A)=>{n.Ea(\"Pad\",a,{mode:d,value:f,pads:y?Array.from(o().subarray(A>>>0,A+y>>>0)):[]})},921850:a=>{n.Ea(\"Gelu\",a,void 0)},921902:a=>{n.Ea(\"BiasAdd\",a,void 0)},921957:a=>{n.Ea(\"BiasSplitGelu\",a,void 0)},922018:(a,d)=>{n.Ea(\"SkipLayerNormalization\",a,{epsilon:d})},922099:a=>{n.zb(a)},922133:(a,d)=>n.Ab(a,d,n.bb.Fb,n.bb.errors),922245:a=>n.wb(a),922278:a=>n.yb(a),922310:(a,d,f)=>{n.jb(a,d,f,!0)},922349:(a,d,f)=>{n.jb(a,d,f)}};function dt(a){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${a})`,this.status=a}function ct(a){a.terminate(),a.onmessage=()=>{}}function Rt(a){(a=oe.Qa[a])||Ye(),oe.Eb(a)}function $t(a){var d=oe.tb();if(!d)return 6;oe.Ya.push(d),oe.Qa[a.Xa]=d,d.Xa=a.Xa;var f={cmd:\"run\",start_routine:a.Gb,arg:a.rb,pthread_ptr:a.Xa};return w&&d.unref(),d.postMessage(f,a.Mb),0}var Bt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,xt=(a,d,f)=>{d>>>=0;var y=d+f;for(f=d;a[f]&&!(f>=y);)++f;if(16<f-d&&a.buffer&&Bt)return Bt.decode(a.buffer instanceof SharedArrayBuffer?a.slice(d,f):a.subarray(d,f));for(y=\"\";d<f;){var A=a[d++];if(A&128){var P=a[d++]&63;if((A&224)==192)y+=String.fromCharCode((A&31)<<6|P);else{var W=a[d++]&63;A=(A&240)==224?(A&15)<<12|P<<6|W:(A&7)<<18|P<<12|W<<6|a[d++]&63,65536>A?y+=String.fromCharCode(A):(A-=65536,y+=String.fromCharCode(55296|A>>10,56320|A&1023))}}else y+=String.fromCharCode(A)}return y},Xe=(a,d)=>(a>>>=0)?xt(i(),a,d):\"\";function Mt(a){if(v)return k(1,1,a);Re=a,Ae()||(oe.Hb(),n.onExit&&n.onExit(a),he=!0),x(a,new dt(a))}var Ct=a=>{if(Re=a,v)throw ft(a),\"unwind\";Mt(a)},oe={ab:[],Ya:[],mb:[],Qa:{},gb:function(){v?oe.vb():oe.ub()},ub:function(){ge.unshift(()=>{or(),oe.Bb(()=>Ot())})},vb:function(){oe.receiveObjectTransfer=oe.Db,oe.threadInitTLS=oe.lb,oe.setExitStatus=oe.kb,Se=!1},kb:function(a){Re=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of oe.Ya)ct(a);for(a of oe.ab)ct(a);oe.ab=[],oe.Ya=[],oe.Qa=[]},Eb:function(a){var d=a.Xa;delete oe.Qa[d],oe.ab.push(a),oe.Ya.splice(oe.Ya.indexOf(a),1),a.Xa=0,Hr(d)},Db:function(){},lb:function(){oe.mb.forEach(a=>a())},Cb:a=>new Promise(d=>{a.onmessage=P=>{P=P.data;var W=P.cmd;if(P.targetThread&&P.targetThread!=mr()){var te=oe.Qa[P.Rb];te?te.postMessage(P,P.transferList):R('Internal error! Worker sent a message \"'+W+'\" to target pthread '+P.targetThread+\", but that thread no longer exists!\")}else W===\"checkMailbox\"?ht():W===\"spawnThread\"?$t(P):W===\"cleanupThread\"?Rt(P.thread):W===\"killThread\"?(P=P.thread,W=oe.Qa[P],delete oe.Qa[P],ct(W),Hr(P),oe.Ya.splice(oe.Ya.indexOf(W),1),W.Xa=0):W===\"cancelThread\"?oe.Qa[P.thread].postMessage({cmd:\"cancel\"}):W===\"loaded\"?(a.loaded=!0,d(a)):W===\"alert\"?alert(\"Thread \"+P.threadId+\": \"+P.text):P.target===\"setimmediate\"?a.postMessage(P):W===\"callHandler\"?n[P.handler](...P.args):W&&R(\"worker sent an unknown command \"+W)},a.onerror=P=>{throw R(\"worker sent an error! \"+P.filename+\":\"+P.lineno+\": \"+P.message),P},w&&(a.on(\"message\",function(P){a.onmessage({data:P})}),a.on(\"error\",function(P){a.onerror(P)}));var f=[],y=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],A;for(A of y)n.hasOwnProperty(A)&&f.push(A);a.postMessage({cmd:\"load\",handlers:f,urlOrBlob:n.mainScriptUrlOrBlob||e,wasmMemory:q,wasmModule:De})}),Bb:function(a){a()},qb:function(){var a=B(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a),oe.ab.push(a)},tb:function(){return oe.ab.length==0&&(oe.qb(),oe.Cb(oe.ab[0])),oe.ab.pop()}};n.PThread=oe;var pt=a=>{for(;0<a.length;)a.shift()(n)};n.establishStackSpace=function(){var a=mr(),d=o()[a+52>>2>>>0];a=o()[a+56>>2>>>0],Nn(d,d-a),hr(d)};function ft(a){if(v)return k(2,0,a);Ct(a)}n.invokeEntryPoint=function(a,d){a=Vn.apply(null,[a,d]),Ae()?oe.kb(a):Lr(a)};function Nr(a){this.fb=a-24,this.pb=function(d){s()[this.fb+4>>2>>>0]=d},this.ob=function(d){s()[this.fb+8>>2>>>0]=d},this.gb=function(d,f){this.nb(),this.pb(d),this.ob(f)},this.nb=function(){s()[this.fb+16>>2>>>0]=0}}var He=0,Ne=0;function kt(a,d,f,y){return v?k(3,1,a,d,f,y):mt(a,d,f,y)}function mt(a,d,f,y){if(a>>>=0,d>>>=0,f>>>=0,y>>>=0,typeof SharedArrayBuffer>\"u\")return R(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var A=[];return v&&A.length===0?kt(a,d,f,y):(a={Gb:f,Xa:a,rb:y,Mb:A},v?(a.Ob=\"spawnThread\",postMessage(a,A),0):$t(a))}function Dt(a,d,f){return v?k(4,1,a,d,f):0}function Wt(a,d){if(v)return k(5,1,a,d)}var zt=a=>{for(var d=0,f=0;f<a.length;++f){var y=a.charCodeAt(f);127>=y?d++:2047>=y?d+=2:55296<=y&&57343>=y?(d+=4,++f):d+=3}return d},St=(a,d,f,y)=>{if(f>>>=0,!(0<y))return 0;var A=f;y=f+y-1;for(var P=0;P<a.length;++P){var W=a.charCodeAt(P);if(55296<=W&&57343>=W){var te=a.charCodeAt(++P);W=65536+((W&1023)<<10)|te&1023}if(127>=W){if(f>=y)break;d[f++>>>0]=W}else{if(2047>=W){if(f+1>=y)break;d[f++>>>0]=192|W>>6}else{if(65535>=W){if(f+2>=y)break;d[f++>>>0]=224|W>>12}else{if(f+3>=y)break;d[f++>>>0]=240|W>>18,d[f++>>>0]=128|W>>12&63}d[f++>>>0]=128|W>>6&63}d[f++>>>0]=128|W&63}}return d[f>>>0]=0,f-A},ar=(a,d,f)=>St(a,i(),d,f);function ir(a,d){if(v)return k(6,1,a,d)}function sr(a,d,f){if(v)return k(7,1,a,d,f)}function ur(a,d,f){return v?k(8,1,a,d,f):0}function lr(a,d){if(v)return k(9,1,a,d)}function dr(a,d,f){if(v)return k(10,1,a,d,f)}function At(a,d,f,y){if(v)return k(11,1,a,d,f,y)}function Gt(a,d,f,y){if(v)return k(12,1,a,d,f,y)}function Ut(a,d,f,y){if(v)return k(13,1,a,d,f,y)}function Nt(a){if(v)return k(14,1,a)}function Vt(a,d){if(v)return k(15,1,a,d)}function Ft(a,d,f){if(v)return k(16,1,a,d,f)}var Ht=a=>{if(!he)try{if(a(),!Ae())try{v?Lr(Re):Ct(Re)}catch(d){d instanceof dt||d==\"unwind\"||x(1,d)}}catch(d){d instanceof dt||d==\"unwind\"||x(1,d)}};function It(a){a>>>=0,typeof Atomics.Nb==\"function\"&&(Atomics.Nb(o(),a>>2,a).value.then(ht),a+=128,Atomics.store(o(),a>>2,1))}n.__emscripten_thread_mailbox_await=It;function ht(){var a=mr();a&&(It(a),Ht(()=>Gn()))}n.checkMailbox=ht;var it=a=>a%4===0&&(a%100!==0||a%400===0),cr=[0,31,60,91,121,152,182,213,244,274,305,335],gt=[0,31,59,90,120,151,181,212,243,273,304,334];function Lt(a,d,f,y,A,P,W,te){return v?k(17,1,a,d,f,y,A,P,W,te):-52}function u(a,d,f,y,A,P,W){if(v)return k(18,1,a,d,f,y,A,P,W)}var p=a=>{var d=zt(a)+1,f=Fr(d);return f&&ar(a,f,d),f},h=[],S=(a,d)=>{h.length=0;var f;for(d>>=2;f=i()[a++>>>0];)d+=f!=105&d,h.push(f==105?o()[d>>>0]:l()[d++>>>1]),++d;return h},T=a=>{var d=jr();return a=a(),hr(d),a};function k(a,d){var f=arguments.length-2,y=arguments;return T(()=>{for(var A=Kr(8*f),P=A>>3,W=0;W<f;W++){var te=y[2+W];l()[P+W>>>0]=te}return zn(a,f,A,d)})}var F=[],ne={},Y=()=>{if(!Q){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:C||\"./this.program\"},d;for(d in ne)ne[d]===void 0?delete a[d]:a[d]=ne[d];var f=[];for(d in a)f.push(`${d}=${a[d]}`);Q=f}return Q},Q;function ee(a,d){if(v)return k(19,1,a,d);a>>>=0,d>>>=0;var f=0;return Y().forEach(function(y,A){var P=d+f;for(A=s()[a+4*A>>2>>>0]=P,P=0;P<y.length;++P)r()[A++>>0>>>0]=y.charCodeAt(P);r()[A>>0>>>0]=0,f+=y.length+1}),0}function ce(a,d){if(v)return k(20,1,a,d);a>>>=0,d>>>=0;var f=Y();s()[a>>2>>>0]=f.length;var y=0;return f.forEach(function(A){y+=A.length+1}),s()[d>>2>>>0]=y,0}function pe(a){return v?k(21,1,a):52}function E(a,d,f,y){return v?k(22,1,a,d,f,y):52}function ie(a,d,f,y,A){return v?k(23,1,a,d,f,y,A):70}var ye=[null,[],[]];function Qe(a,d,f,y){if(v)return k(24,1,a,d,f,y);d>>>=0,f>>>=0,y>>>=0;for(var A=0,P=0;P<f;P++){var W=s()[d>>2>>>0],te=s()[d+4>>2>>>0];d+=8;for(var Z=0;Z<te;Z++){var J=i()[W+Z>>>0],re=ye[a];J===0||J===10?((a===1?le:R)(xt(re,0)),re.length=0):re.push(J)}A+=te}return s()[y>>2>>>0]=A,0}var jt=[31,29,31,30,31,30,31,31,30,31,30,31],Pn=[31,28,31,30,31,30,31,31,30,31,30,31];function Vs(a){var d=Array(zt(a)+1);return St(a,d,0,d.length),d}var Fs=(a,d)=>{r().set(a,d>>>0)};function Rn(a,d,f,y){function A(O,ue,ve){for(O=typeof O==\"number\"?O.toString():O||\"\";O.length<ue;)O=ve[0]+O;return O}function P(O,ue){return A(O,ue,\"0\")}function W(O,ue){function ve(qn){return 0>qn?-1:0<qn?1:0}var yt;return(yt=ve(O.getFullYear()-ue.getFullYear()))===0&&(yt=ve(O.getMonth()-ue.getMonth()))===0&&(yt=ve(O.getDate()-ue.getDate())),yt}function te(O){switch(O.getDay()){case 0:return new Date(O.getFullYear()-1,11,29);case 1:return O;case 2:return new Date(O.getFullYear(),0,3);case 3:return new Date(O.getFullYear(),0,2);case 4:return new Date(O.getFullYear(),0,1);case 5:return new Date(O.getFullYear()-1,11,31);case 6:return new Date(O.getFullYear()-1,11,30)}}function Z(O){var ue=O.Za;for(O=new Date(new Date(O.$a+1900,0,1).getTime());0<ue;){var ve=O.getMonth(),yt=(it(O.getFullYear())?jt:Pn)[ve];if(ue>yt-O.getDate())ue-=yt-O.getDate()+1,O.setDate(1),11>ve?O.setMonth(ve+1):(O.setMonth(0),O.setFullYear(O.getFullYear()+1));else{O.setDate(O.getDate()+ue);break}}return ve=new Date(O.getFullYear()+1,0,4),ue=te(new Date(O.getFullYear(),0,4)),ve=te(ve),0>=W(ue,O)?0>=W(ve,O)?O.getFullYear()+1:O.getFullYear():O.getFullYear()-1}a>>>=0,d>>>=0,f>>>=0,y>>>=0;var J=o()[y+40>>2>>>0];y={Kb:o()[y>>2>>>0],Jb:o()[y+4>>2>>>0],cb:o()[y+8>>2>>>0],ib:o()[y+12>>2>>>0],eb:o()[y+16>>2>>>0],$a:o()[y+20>>2>>>0],Wa:o()[y+24>>2>>>0],Za:o()[y+28>>2>>>0],Tb:o()[y+32>>2>>>0],Ib:o()[y+36>>2>>>0],Lb:J?Xe(J):\"\"},f=Xe(f),J={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var re in J)f=f.replace(new RegExp(re,\"g\"),J[re]);var fe=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),be=\"January February March April May June July August September October November December\".split(\" \");J={\"%a\":O=>fe[O.Wa].substring(0,3),\"%A\":O=>fe[O.Wa],\"%b\":O=>be[O.eb].substring(0,3),\"%B\":O=>be[O.eb],\"%C\":O=>P((O.$a+1900)/100|0,2),\"%d\":O=>P(O.ib,2),\"%e\":O=>A(O.ib,2,\" \"),\"%g\":O=>Z(O).toString().substring(2),\"%G\":O=>Z(O),\"%H\":O=>P(O.cb,2),\"%I\":O=>(O=O.cb,O==0?O=12:12<O&&(O-=12),P(O,2)),\"%j\":O=>{for(var ue=0,ve=0;ve<=O.eb-1;ue+=(it(O.$a+1900)?jt:Pn)[ve++]);return P(O.ib+ue,3)},\"%m\":O=>P(O.eb+1,2),\"%M\":O=>P(O.Jb,2),\"%n\":()=>`\n`,\"%p\":O=>0<=O.cb&&12>O.cb?\"AM\":\"PM\",\"%S\":O=>P(O.Kb,2),\"%t\":()=>\"\t\",\"%u\":O=>O.Wa||7,\"%U\":O=>P(Math.floor((O.Za+7-O.Wa)/7),2),\"%V\":O=>{var ue=Math.floor((O.Za+7-(O.Wa+6)%7)/7);if(2>=(O.Wa+371-O.Za-2)%7&&ue++,ue)ue==53&&(ve=(O.Wa+371-O.Za)%7,ve==4||ve==3&&it(O.$a)||(ue=1));else{ue=52;var ve=(O.Wa+7-O.Za-1)%7;(ve==4||ve==5&&it(O.$a%400-1))&&ue++}return P(ue,2)},\"%w\":O=>O.Wa,\"%W\":O=>P(Math.floor((O.Za+7-(O.Wa+6)%7)/7),2),\"%y\":O=>(O.$a+1900).toString().substring(2),\"%Y\":O=>O.$a+1900,\"%z\":O=>{O=O.Ib;var ue=0<=O;return O=Math.abs(O)/60,(ue?\"+\":\"-\")+(\"0000\"+(O/60*100+O%60)).slice(-4)},\"%Z\":O=>O.Lb,\"%%\":()=>\"%\"},f=f.replace(/%%/g,\"\\0\\0\");for(re in J)f.includes(re)&&(f=f.replace(new RegExp(re,\"g\"),J[re](y)));return f=f.replace(/\\0\\0/g,\"%\"),re=Vs(f),re.length>d?0:(Fs(re,a),re.length-1)}function pr(a){try{a()}catch(d){Ye(d)}}function Hs(a){var d={},f;for(f in a)(function(y){var A=a[y];d[y]=typeof A==\"function\"?function(){fr.push(y);try{return A.apply(null,arguments)}finally{he||(fr.pop()===y||Ye(),Je&&ut===1&&fr.length===0&&(ut=0,Te+=1,pr(Hn),typeof Fibers<\"u\"&&Fibers.Ub()))}}:A})(f);return d}var ut=0,Je=null,Bn=0,fr=[],Mn={},kn={},Ls=0,Vr=null,js=[];function Ks(){return new Promise((a,d)=>{Vr={resolve:a,reject:d}})}function qs(){var a=Fr(65548),d=a+12;s()[a>>2>>>0]=d,s()[a+4>>2>>>0]=d+65536,d=fr[0];var f=Mn[d];return f===void 0&&(f=Ls++,Mn[d]=f,kn[f]=d),d=f,o()[a+8>>2>>>0]=d,a}function Ys(){var a=o()[Je+8>>2>>>0];return a=L[kn[a]],--Te,a()}function Xs(a){if(!he){if(ut===0){var d=!1,f=!1;a((y=0)=>{if(!he&&(Bn=y,d=!0,f)){ut=2,pr(()=>Ln(Je)),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.resume(),y=!1;try{var A=Ys()}catch(te){A=te,y=!0}var P=!1;if(!Je){var W=Vr;W&&(Vr=null,(y?W.reject:W.resolve)(A),P=!0)}if(y&&!P)throw A}}),f=!0,d||(ut=1,Je=qs(),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.pause(),pr(()=>Fn(Je)))}else ut===2?(ut=0,pr(jn),Dn(Je),Je=null,js.forEach(y=>Ht(y))):Ye(`invalid state: ${ut}`);return Bn}}function Qs(a){return Xs(d=>{a().then(d)})}oe.gb();var Js=[null,Mt,ft,kt,Dt,Wt,ir,sr,ur,lr,dr,At,Gt,Ut,Nt,Vt,Ft,Lt,u,ee,ce,pe,E,ie,Qe],Zs={r:function(a,d,f){return Qs(async()=>{await n.xb(a,d,f)})},b:function(a,d,f){throw a>>>=0,new Nr(a).gb(d>>>0,f>>>0),He=a,Ne++,He},O:function(a){Wn(a>>>0,!b,1,!$,131072,!1),oe.lb()},l:function(a){a>>>=0,v?postMessage({cmd:\"cleanupThread\",thread:a}):Rt(a)},I:mt,i:Dt,U:Wt,E:ir,G:sr,V:ur,S:lr,K:dr,R:At,p:Gt,F:Ut,C:Nt,T:Vt,D:Ft,q:()=>!0,A:function(a,d){a>>>=0,a==d>>>0?setTimeout(()=>ht()):v?postMessage({targetThread:a,cmd:\"checkMailbox\"}):(a=oe.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:It,X:function(a){w&&oe.Qa[a>>>0].ref()},u:function(a,d,f){a=d+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*d:NaN,f>>>=0,a=new Date(1e3*a),o()[f>>2>>>0]=a.getUTCSeconds(),o()[f+4>>2>>>0]=a.getUTCMinutes(),o()[f+8>>2>>>0]=a.getUTCHours(),o()[f+12>>2>>>0]=a.getUTCDate(),o()[f+16>>2>>>0]=a.getUTCMonth(),o()[f+20>>2>>>0]=a.getUTCFullYear()-1900,o()[f+24>>2>>>0]=a.getUTCDay(),a=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,o()[f+28>>2>>>0]=a},v:function(a,d,f){a=d+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*d:NaN,f>>>=0,a=new Date(1e3*a),o()[f>>2>>>0]=a.getSeconds(),o()[f+4>>2>>>0]=a.getMinutes(),o()[f+8>>2>>>0]=a.getHours(),o()[f+12>>2>>>0]=a.getDate(),o()[f+16>>2>>>0]=a.getMonth(),o()[f+20>>2>>>0]=a.getFullYear()-1900,o()[f+24>>2>>>0]=a.getDay(),d=(it(a.getFullYear())?cr:gt)[a.getMonth()]+a.getDate()-1|0,o()[f+28>>2>>>0]=d,o()[f+36>>2>>>0]=-(60*a.getTimezoneOffset()),d=new Date(a.getFullYear(),6,1).getTimezoneOffset();var y=new Date(a.getFullYear(),0,1).getTimezoneOffset();a=(d!=y&&a.getTimezoneOffset()==Math.min(y,d))|0,o()[f+32>>2>>>0]=a},w:function(a){a>>>=0;var d=new Date(o()[a+20>>2>>>0]+1900,o()[a+16>>2>>>0],o()[a+12>>2>>>0],o()[a+8>>2>>>0],o()[a+4>>2>>>0],o()[a>>2>>>0],0),f=o()[a+32>>2>>>0],y=d.getTimezoneOffset(),A=new Date(d.getFullYear(),6,1).getTimezoneOffset(),P=new Date(d.getFullYear(),0,1).getTimezoneOffset(),W=Math.min(P,A);return 0>f?o()[a+32>>2>>>0]=+(A!=P&&W==y):0<f!=(W==y)&&(A=Math.max(P,A),d.setTime(d.getTime()+6e4*((0<f?W:A)-y))),o()[a+24>>2>>>0]=d.getDay(),f=(it(d.getFullYear())?cr:gt)[d.getMonth()]+d.getDate()-1|0,o()[a+28>>2>>>0]=f,o()[a>>2>>>0]=d.getSeconds(),o()[a+4>>2>>>0]=d.getMinutes(),o()[a+8>>2>>>0]=d.getHours(),o()[a+12>>2>>>0]=d.getDate(),o()[a+16>>2>>>0]=d.getMonth(),o()[a+20>>2>>>0]=d.getYear(),a=d.getTime()/1e3,Un((at=a,1<=+Math.abs(at)?0<at?+Math.floor(at/4294967296)>>>0:~~+Math.ceil((at-+(~~at>>>0))/4294967296)>>>0:0)),a>>>0},s:Lt,t:u,z:function(a,d,f){function y(J){return(J=J.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?J[1]:\"GMT\"}a>>>=0,d>>>=0,f>>>=0;var A=new Date().getFullYear(),P=new Date(A,0,1),W=new Date(A,6,1);A=P.getTimezoneOffset();var te=W.getTimezoneOffset(),Z=Math.max(A,te);s()[a>>2>>>0]=60*Z,o()[d>>2>>>0]=+(A!=te),a=y(P),d=y(W),a=p(a),d=p(d),te<A?(s()[f>>2>>>0]=a,s()[f+4>>2>>>0]=d):(s()[f>>2>>>0]=d,s()[f+4>>2>>>0]=a)},d:()=>{Ye(\"\")},c:function(a,d,f){return a>>>=0,d=S(d>>>0,f>>>0),vt[a].apply(null,d)},k:function(a,d,f){return a>>>=0,d=S(d>>>0,f>>>0),vt[a].apply(null,d)},m:function(){},j:function(){return Date.now()},W:()=>{throw Te+=1,\"unwind\"},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return w?(to(),Tt(eo)).cpus().length:navigator.hardwareConcurrency},L:function(a,d,f,y){for(oe.Pb=d>>>0,F.length=f,d=y>>>0>>3,y=0;y<f;y++)F[y]=l()[d+y>>>0];return(0>a?vt[-a-1]:Js[a]).apply(null,F)},y:function(a){a>>>=0;var d=i().length;if(a<=d||4294901760<a)return!1;for(var f=1;4>=f;f*=2){var y=d*(1+.2/f);y=Math.min(y,a+100663296);var A=Math;y=Math.max(a,y);e:{A=A.min.call(A,4294901760,y+(65536-y%65536)%65536)-q.buffer.byteLength+65535>>>16;try{q.grow(A),N();var P=1;break e}catch{}P=void 0}if(P)return!0}return!1},P:ee,Q:ce,H:Ct,h:pe,o:E,x:ie,n:Qe,a:q||n.wasmMemory,J:Rn,e:function(a,d,f,y){return Rn(a>>>0,d>>>0,f>>>0,y>>>0)}};(function(){function a(f,y){return f=f.exports,f=Hs(f),L=f=eu(f),oe.mb.push(L.Da),ze.unshift(L.Y),De=y,Ot(),f}var d={a:Zs};if(or(),n.instantiateWasm)try{return n.instantiateWasm(d,a)}catch(f){R(\"Module.instantiateWasm callback failed with error: \"+f),m(f)}return st(d,function(f){a(f.instance,f.module)}).catch(m),{}})(),n._OrtInit=(a,d)=>(n._OrtInit=L.Z)(a,d),n._OrtGetLastError=(a,d)=>(n._OrtGetLastError=L._)(a,d),n._OrtCreateSessionOptions=(a,d,f,y,A,P,W,te,Z,J)=>(n._OrtCreateSessionOptions=L.$)(a,d,f,y,A,P,W,te,Z,J),n._OrtAppendExecutionProvider=(a,d)=>(n._OrtAppendExecutionProvider=L.aa)(a,d),n._OrtAddFreeDimensionOverride=(a,d,f)=>(n._OrtAddFreeDimensionOverride=L.ba)(a,d,f),n._OrtAddSessionConfigEntry=(a,d,f)=>(n._OrtAddSessionConfigEntry=L.ca)(a,d,f),n._OrtReleaseSessionOptions=a=>(n._OrtReleaseSessionOptions=L.da)(a),n._OrtCreateSession=(a,d,f)=>(n._OrtCreateSession=L.ea)(a,d,f),n._OrtReleaseSession=a=>(n._OrtReleaseSession=L.fa)(a),n._OrtGetInputOutputCount=(a,d,f)=>(n._OrtGetInputOutputCount=L.ga)(a,d,f),n._OrtGetInputName=(a,d)=>(n._OrtGetInputName=L.ha)(a,d),n._OrtGetOutputName=(a,d)=>(n._OrtGetOutputName=L.ia)(a,d),n._OrtFree=a=>(n._OrtFree=L.ja)(a),n._OrtCreateTensor=(a,d,f,y,A,P)=>(n._OrtCreateTensor=L.ka)(a,d,f,y,A,P),n._OrtGetTensorData=(a,d,f,y,A)=>(n._OrtGetTensorData=L.la)(a,d,f,y,A),n._OrtReleaseTensor=a=>(n._OrtReleaseTensor=L.ma)(a),n._OrtCreateRunOptions=(a,d,f,y)=>(n._OrtCreateRunOptions=L.na)(a,d,f,y),n._OrtAddRunConfigEntry=(a,d,f)=>(n._OrtAddRunConfigEntry=L.oa)(a,d,f),n._OrtReleaseRunOptions=a=>(n._OrtReleaseRunOptions=L.pa)(a),n._OrtCreateBinding=a=>(n._OrtCreateBinding=L.qa)(a),n._OrtBindInput=(a,d,f)=>(n._OrtBindInput=L.ra)(a,d,f),n._OrtBindOutput=(a,d,f,y)=>(n._OrtBindOutput=L.sa)(a,d,f,y),n._OrtClearBoundOutputs=a=>(n._OrtClearBoundOutputs=L.ta)(a),n._OrtReleaseBinding=a=>(n._OrtReleaseBinding=L.ua)(a),n._OrtRunWithBinding=(a,d,f,y,A)=>(n._OrtRunWithBinding=L.va)(a,d,f,y,A),n._OrtRun=(a,d,f,y,A,P,W,te)=>(n._OrtRun=L.wa)(a,d,f,y,A,P,W,te),n._OrtEndProfiling=a=>(n._OrtEndProfiling=L.xa)(a),n._JsepOutput=(a,d,f)=>(n._JsepOutput=L.ya)(a,d,f),n._JsepGetNodeName=a=>(n._JsepGetNodeName=L.za)(a);var mr=n._pthread_self=()=>(mr=n._pthread_self=L.Aa)(),Fr=n._malloc=a=>(Fr=n._malloc=L.Ba)(a),Dn=n._free=a=>(Dn=n._free=L.Ca)(a);n.__emscripten_tls_init=()=>(n.__emscripten_tls_init=L.Da)();var Wn=n.__emscripten_thread_init=(a,d,f,y,A,P)=>(Wn=n.__emscripten_thread_init=L.Fa)(a,d,f,y,A,P);n.__emscripten_thread_crashed=()=>(n.__emscripten_thread_crashed=L.Ga)();var zn=(a,d,f,y)=>(zn=L.Ha)(a,d,f,y),Hr=a=>(Hr=L.Ia)(a),Lr=n.__emscripten_thread_exit=a=>(Lr=n.__emscripten_thread_exit=L.Ja)(a),Gn=n.__emscripten_check_mailbox=()=>(Gn=n.__emscripten_check_mailbox=L.Ka)(),Un=a=>(Un=L.La)(a),Nn=(a,d)=>(Nn=L.Ma)(a,d),jr=()=>(jr=L.Na)(),hr=a=>(hr=L.Oa)(a),Kr=a=>(Kr=L.Pa)(a),Vn=n.dynCall_ii=(a,d)=>(Vn=n.dynCall_ii=L.Ra)(a,d),Fn=a=>(Fn=L.Sa)(a),Hn=()=>(Hn=L.Ta)(),Ln=a=>(Ln=L.Ua)(a),jn=()=>(jn=L.Va)();n.___start_em_js=922382,n.___stop_em_js=922543;function eu(a){a=Object.assign({},a);var d=y=>()=>y()>>>0,f=y=>A=>y(A)>>>0;return a.__errno_location=d(a.__errno_location),a.pthread_self=d(a.pthread_self),a.malloc=f(a.malloc),a.stackSave=d(a.stackSave),a.stackAlloc=f(a.stackAlloc),a}n.keepRuntimeAlive=Ae,n.wasmMemory=q,n.stackAlloc=Kr,n.stackSave=jr,n.stackRestore=hr,n.UTF8ToString=Xe,n.stringToUTF8=ar,n.lengthBytesUTF8=zt,n.ExitStatus=dt,n.PThread=oe;var gr;Ve=function a(){gr||Kn(),gr||(Ve=a)};function Kn(){function a(){if(!gr&&(gr=!0,n.calledRun=!0,!he)&&(v||pt(ze),c(n),n.onRuntimeInitialized&&n.onRuntimeInitialized(),!v)){if(n.postRun)for(typeof n.postRun==\"function\"&&(n.postRun=[n.postRun]);n.postRun.length;){var d=n.postRun.shift();Ge.unshift(d)}pt(Ge)}}if(!(0<Ue))if(v)c(n),v||pt(ze),startWorker(n);else{if(n.preRun)for(typeof n.preRun==\"function\"&&(n.preRun=[n.preRun]);n.preRun.length;)ge.unshift(n.preRun.shift());pt(ge),0<Ue||(n.setStatus?(n.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){n.setStatus(\"\")},1),a()},1)):a())}}if(n.preInit)for(typeof n.preInit==\"function\"&&(n.preInit=[n.preInit]);0<n.preInit.length;)n.preInit.pop()();return Kn(),t.ready}})();typeof no==\"object\"&&typeof en==\"object\"?en.exports=ro:typeof define==\"function\"&&define.amd&&define([],()=>ro)});var ao=Kt((Cd,uu)=>{uu.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason||e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(Module.__embind_initialize_bindings(),initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(`worker.js received unknown command ${e.data.cmd}`),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var nn,Yt,Xt,wr,Qt,po,on,ke=H(()=>{\"use strict\";nn=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},Yt=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},Xt=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],wr=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},Qt=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},po=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",on=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var yu,bu,fo,mo,ho,wu,Ie,lt=H(()=>{\"use strict\";ke();yu=[\"V\",\"I\",\"W\",\"E\",\"F\"],bu=(e,t)=>{console.log(`[${yu[e]},${new Date().toISOString()}]${t}`)},ho=(e,t)=>{fo=e,mo=t},wu=(e,t)=>{let r=Qt(e),i=Qt(fo);r>=i&&bu(r,typeof t==\"function\"?t():t)},Ie=(...e)=>{mo&&wu(...e)}});var go,yo=H(()=>{\"use strict\";ke();go=(e,t)=>new(wr(t))(e)});var bo=H(()=>{\"use strict\"});var vr,vu,wo,sn,an,vo,$o=H(()=>{\"use strict\";lt();bo();vr=e=>Math.ceil(e/16)*16,vu=1,wo=()=>vu++,sn=async(e,t,r,i)=>{let o=vr(r),s=e.device.createBuffer({size:o,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let l=e.getCommandEncoder();e.endComputePass(),l.copyBufferToBuffer(t,0,s,0,o),e.flush(),await s.mapAsync(GPUMapMode.READ);let n=s.getMappedRange();if(i){let c=i();return c.set(new Uint8Array(n,0,r)),c}else return new Uint8Array(n.slice(0,r))}finally{s.destroy()}},an=class{constructor(t){this.backend=t;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(t,r){let i=r.buffer,o=r.byteOffset,s=r.byteLength,l=vr(s),n=this.storageCache.get(t);if(!n)throw new Error(\"gpu data for uploading does not exist\");if(n.originalSize!==s)throw new Error(`inconsistent data size. gpu data size=${n.originalSize}, data size=${s}`);let c=this.backend.device.createBuffer({mappedAtCreation:!0,size:l,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),m=c.getMappedRange();new Uint8Array(m).set(new Uint8Array(i,o,s)),c.unmap();let g=this.backend.getCommandEncoder();this.backend.endComputePass(),g.copyBufferToBuffer(c,0,n.gpuData.buffer,0,l),Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${t})`),this.buffersForUploadingPending.push(c)}memcpy(t,r){let i=this.storageCache.get(t);if(!i)throw new Error(\"source gpu data for memcpy does not exist\");let o=this.storageCache.get(r);if(!o)throw new Error(\"destination gpu data for memcpy does not exist\");if(i.originalSize!==o.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let s=vr(i.originalSize),l=this.backend.getCommandEncoder();this.backend.endComputePass(),l.copyBufferToBuffer(i.gpuData.buffer,0,o.gpuData.buffer,0,s)}registerExternalBuffer(t,r,i){let o;if(i){if(o=this.externalBuffers.get(i),o===void 0)throw new Error(\"previous buffer is not registered\");if(t===i)return Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${o}, buffer is the same, skip.`),o;this.externalBuffers.delete(i)}else o=wo();return this.storageCache.set(o,{gpuData:{id:o,type:0,buffer:t},originalSize:r}),this.externalBuffers.set(t,o),Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${o}, registered.`),o}unregisterExternalBuffer(t){let r=this.externalBuffers.get(t);r!==void 0&&(this.storageCache.delete(r),this.externalBuffers.delete(t),Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${r}`))}create(t,r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let i=vr(t),o,s=(r&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,l=(r&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(s||l){let c=s?this.freeBuffers:this.freeUniformBuffers,m=c.get(i);m||(m=[],c.set(i,m)),m.length>0?o=m.pop():o=this.backend.device.createBuffer({size:i,usage:r})}else o=this.backend.device.createBuffer({size:i,usage:r});let n={id:wo(),type:0,buffer:o};return this.storageCache.set(n.id,{gpuData:n,originalSize:t}),Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${t}) => id=${n.id}`),n}get(t){return this.storageCache.get(t)?.gpuData}release(t){let r=this.storageCache.get(t);if(!r)throw new Error(\"releasing data does not exist\");return Ie(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${r.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(r.gpuData.buffer),r.originalSize}async download(t,r){let i=this.storageCache.get(t);if(!i)throw new Error(\"data does not exist\");await sn(this.backend,i.gpuData.buffer,i.originalSize,r)}refreshPendingBuffers(){for(let t of this.buffersForUploadingPending)t.destroy();this.buffersForUploadingPending=[];for(let t of this.buffersPending)(t.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(t.size).push(t):(t.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(t.size).push(t):t.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.freeUniformBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.storageCache.forEach(t=>{t.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},vo=(...e)=>new an(...e)});var un,ae,_e=H(()=>{\"use strict\";un=class{constructor(t){Object.assign(this,t)}get cacheKey(){return this._cacheKey||(this._cacheKey=Object.getOwnPropertyNames(this).sort().map(t=>`${this[t]}`).join(\";\")),this._cacheKey}},ae=e=>new un(e)});var ln,Ze,D,bt,$r,xr,Cr,me=H(()=>{\"use strict\";ln=class{static calcMatMulShape(t,r){return t[1]!==r[0]?void 0:[t[0],r[1]]}},Ze=class{static calcShape(t,r,i=!1){let o=t.length,s=r.length;if(o===0)return r;if(s===0)return t;let l=Math.max(t.length,r.length),n=new Array(l);if(i){if(o<2||s<2)return;let c=ln.calcMatMulShape([t[o-2],t[o-1]],[r[s-2],r[s-1]]);if(c===void 0)return;[n[l-2],n[l-1]]=c}for(let c=i?3:1;c<=l;c++){let m=o-c<0?1:t[o-c],g=s-c<0?1:r[s-c];if(m!==g&&m>1&&g>1)return;n[l-c]=Math.max(m,g)}return n}static isValidBroadcast(t,r){let i=t.length,o=r.length;if(i>o)return!1;for(let s=1;s<=i;s++)if(t[i-s]!==1&&t[i-s]!==r[o-s])return!1;return!0}},D=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,r,t.length)}static sizeToDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,r)}static getSizeFromDimensionRange(t,r,i){let o=1;for(let s=r;s<i;s++){if(t[s]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");o*=t[s]}return o}static computeStrides(t){let r=t.length;if(r===0)return[];if(r===1)return[1];let i=new Array(r);i[r-1]=1,i[r-2]=t[r-1];for(let o=r-3;o>=0;--o)i[o]=i[o+1]*t[o+1];return i}static normalizeAxis(t,r){if(t<-r&&t>=r)throw new Error(\"unsupported axis for this operation.\");return t<0?t+r:t}static normalizeAxes(t,r){return t.map(i=>this.normalizeAxis(i,r??t.length))}static sortBasedOnPerm(t,r){return r?r.map(i=>t[i]):t.slice().reverse()}static padShape(t,r){let i=t.length;return t.map((o,s)=>o+r[s]+r[s+i])}static areEqual(t,r){return t.length!==r.length?!1:t.every((i,o)=>i===r[o])}},bt=class e{static adjustPoolAttributes(t,r,i,o,s,l){if(!t&&i.length!==r.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let n=0;n<r.length-2;n++)n>=i.length?i.push(r[n+2]):i[n]=r[n+2];for(let n=0;n<i.length;n++)if(n<o.length){if(o[n]<0)throw new Error(\"strides should be greater than or equal to 1\")}else o.push(1);for(let n=0;n<i.length;n++)if(n<s.length){if(s[n]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else s.push(1);for(let n=0;n<i.length*2;n++)if(n<l.length){if(l[n]<0)throw new Error(\"pad should be greater than or equal to 1\")}else l.push(0);for(let n=0;n<i.length;n++){if(i[n]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(l[n]>=i[n]||l[n+i.length]>=i[n])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,r,i,o,s,l,n){if(n){if(s.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(o.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let c=0;c<t.length-2;c++)e.adjustPadAndReturnShape(t[c+(l?1:2)],r[c],i[c],o[c],s,c,c+t.length-2,n)}}static computePoolOutputShape(t,r,i,o,s,l,n){if(r.length<=0)throw new Error(\"input shape must be of size greater than 0\");let c=[r[0],r[1]];return e.computeShapeHelper(t,r,c,i,o,s,l,n),c}static computeConvOutputShape(t,r,i,o,s,l,n){if(t.length<=0||r.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let c=[t[0],r[0]];return e.computeShapeHelper(!1,t,c,i,o,s,l,n),c}static computeShapeHelper(t,r,i,o,s,l,n,c){if(t)for(let m=0;m<r.length-2;m++)i.push(1);else for(let m=0;m<r.length-2;m++)i.push(e.adjustPadAndReturnShape(r[m+2],o[m],s[m],l[m],n,m,m+r.length-2,c))}static adjustPadAndReturnShape(t,r,i,o,s,l,n,c){let m=i*(o-1)+1;if(c&&c!==\"NOTSET\")switch(c){case\"VALID\":return s[l]=0,s[n]=0,Math.floor((t-m)/r+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(i!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let C=((t+r-1)/r-1)*r+o-t;return s[l]=Math.floor(c===\"SAME_LOWER\"?(C+1)/2:C/2),s[n]=C-s[l],Math.floor((t+C-o)/r+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((t+s[l]+s[n]-m)/r+1)}},$r=class{static getShapeOfGemmResult(t,r,i,o,s){if(t.length!==2||i.length!==2)throw new Error(\"shape need to be of size 2\");let l,n,c;r?(l=t[1],n=t[0]):(l=t[0],n=t[1]);let m=-1;if(o?(c=i[0],m=1):(c=i[1],m=0),i[m]!==n)throw new Error(\"dimension mismatch\");if(l<=0||c<=0||n<=0)throw new Error(\"invalid shape specified\");if(s&&!Ze.isValidBroadcast(s,[l,c]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[l,c,n]}},xr=-34028234663852886e22,Cr=34028234663852886e22});var $u,xo,Pe,cn,Co,K,se,dn,So,pn,$e=H(()=>{\"use strict\";ke();me();$u=64,xo=(e,t)=>{if(t===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return t>1?`vec${t}<f16>`:\"f16\";case 1:return t>1?`vec${t}<f32>`:\"f32\";case 6:return t>1?`vec${t}<i32>`:\"i32\";case 12:return t>1?`vec${t}<u32>`:\"u32\";case 7:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(t!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},Pe=(e,t=1)=>{let r=xo(e,t);return typeof r==\"string\"?r:r[0]},cn=e=>[{type:\"uint32\",data:e},{type:\"uint32\",data:D.computeStrides(e)}],Co=(e,t,r,i,o)=>{let s=typeof r==\"number\",l=s?r:r.length,n=[...new Array(l).keys()],c=l<2?\"u32\":l<=4?`vec${l}<u32>`:`array<u32, ${l}>`,m=xo(t,o),g=typeof m==\"string\"?m:m[1],C=typeof m==\"string\"?m:m[0],x={indices:c,value:g,storage:C,tensor:t},$=N=>typeof N==\"string\"?N:`${N}u`,b={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},w=s?\"uniforms.\":\"\",v=`${w}${e}_shape`,I=`${w}${e}_strides`,B=\"\";for(let N=0;N<l-1;N++)B+=`\n    let dim${N} = current / ${I}[${N}];\n    let rest${N} = current % ${I}[${N}];\n    indices[${N}] = dim${N};\n    current = rest${N};\n    `;B+=`indices[${l-1}] = current;`;let z=l<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${x.indices} {\n    var indices: ${x.indices};\n    var current = offset;\n    ${B}\n    return indices;\n  }`,M=N=>(b.offsetToIndices=!0,l<2?N:`o2i_${e}(${N})`),G=[];if(l>=2)for(let N=l-1;N>=0;N--)G.push(`${I}[${N}] * (indices[${N}])`);let _=l<2?\"\":`\n  fn i2o_${e}(indices: ${x.indices}) -> u32 {\n    return ${G.join(\"+\")};\n  }`,U=N=>(b.indicesToOffset=!0,l<2?N:`i2o_${e}(${N})`),V=(...N)=>l===0?\"0u\":`${x.indices}(${N.map($).join(\",\")})`,j=(N,de)=>l<2?`${N}`:`${N}[${de}]`,le=(N,de,ge)=>l<2?`${N}=${ge};`:`${N}[${de}]=${ge};`,R={},X=(N,de)=>{b.broadcastedIndicesToOffset=!0;let ge=`${de.name}broadcastedIndicesTo${e}Offset`;if(ge in R)return`${ge}(${N})`;let ze=[];for(let Ge=l-1;Ge>=0;Ge--){let Te=de.indicesGet(\"outputIndices\",Ge+de.rank-l);ze.push(`${j(I,Ge)} * (${Te} % ${j(v,Ge)})`)}return R[ge]=`fn ${ge}(outputIndices: ${de.type.indices}) -> u32 {\n             return ${ze.length>0?ze.join(\"+\"):\"0u\"};\n           }`,`${ge}(${N})`},Se=(N,de)=>(()=>{if(x.storage===x.value)return`${e}[${N}]=${de};`;if(x.storage===\"vec2<u32>\"&&x.value===\"i32\")return`${e}[${N}]=vec2<u32>(u32(${de}), select(0u, 0xFFFFFFFFu, ${de} < 0));`;if(x.storage===\"vec2<u32>\"&&x.value===\"u32\")return`${e}[${N}]=vec2<u32>(u32(${de}), 0u);`;if(x.storage===\"u32\"&&x.value===\"vec4<bool>\")return`${e}[${N}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${de}));`;throw new Error(`not supported combination of storage type ${x.storage} and value type ${x.value} yet`)})(),q=N=>(()=>{if(x.storage===x.value)return`${e}[${N}]`;if(x.storage===\"vec2<u32>\"&&x.value===\"i32\")return`i32(${e}[${N}].x)`;if(x.storage===\"vec2<u32>\"&&x.value===\"u32\")return`u32(${e}[${N}].x)`;if(x.storage===\"u32\"&&x.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${N}] & 0xFFu), bool(${e}[${N}] & 0xFF00u), bool(${e}[${N}] & 0xFF0000u), bool(${e}[${N}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${x.storage} and value type ${x.value} yet`)})(),L=l<2?\"\":`\n  fn get_${e}ByIndices(indices: ${x.indices}) -> ${g} {\n    return ${q(`i2o_${e}(indices)`)};\n  }`,De=l<2?\"\":(()=>{let N=n.map(ge=>`d${ge}: u32`).join(\", \"),de=n.map(ge=>`d${ge}`).join(\", \");return`\n  fn get_${e}(${N}) -> ${g} {\n    return get_${e}ByIndices(${V(de)});\n  }`})(),he=(...N)=>{if(N.length!==l)throw new Error(`indices length must be ${l}`);let de=N.map($).join(\",\");return l===0?q(\"0u\"):l===1?q(de[0]):(b.get=!0,b.getByIndices=!0,b.indicesToOffset=!0,`get_${e}(${de})`)},Re=N=>l<2?q(N):(b.getByIndices=!0,b.indicesToOffset=!0,`get_${e}ByIndices(${N})`),we=l<2?\"\":`\n  fn set_${e}ByIndices(indices: ${x.indices}, value: ${g}) {\n    ${Se(`i2o_${e}(indices)`,\"value\")}\n  }`,Be=l<2?\"\":(()=>{let N=n.map(ge=>`d${ge}: u32`).join(\", \"),de=n.map(ge=>`d${ge}`).join(\", \");return`\n  fn set_${e}(${N}, value: ${g}) {\n    set_${e}ByIndices(${V(de)}, value);\n  }`})();return{impl:()=>{let N=[];return s||(N.push(`const ${v} = ${x.indices}(${r.join(\",\")});`),N.push(`const ${I} = ${x.indices}(${D.computeStrides(r).join(\",\")});`)),b.offsetToIndices&&N.push(z),b.indicesToOffset&&N.push(_),b.broadcastedIndicesToOffset&&Object.values(R).forEach(de=>N.push(de)),b.set&&N.push(Be),b.setByIndices&&N.push(we),b.get&&N.push(De),b.getByIndices&&N.push(L),N.join(`\n`)},type:x,offsetToIndices:M,indicesToOffset:U,broadcastedIndicesToOffset:X,indices:V,indicesGet:j,indicesSet:le,set:(...N)=>{if(N.length!==l+1)throw new Error(`indices length must be ${l}`);let de=N[l];if(typeof de!=\"string\")throw new Error(\"value must be string\");let ge=N.slice(0,l).map($).join(\",\");return l===0?Se(\"0u\",de):l===1?Se(ge[0],de):(b.set=!0,b.setByIndices=!0,b.indicesToOffset=!0,`set_${e}(${ge}, ${de})`)},setByOffset:Se,setByIndices:(N,de)=>l<2?Se(N,de):(b.setByIndices=!0,b.indicesToOffset=!0,`set_${e}ByIndices(${N}, ${de});`),get:he,getByOffset:q,getByIndices:Re,usage:i?\"input\":\"output\",name:e,strides:I,shape:v,rank:l}},K=(e,t,r,i=1)=>Co(e,t,r,!0,i),se=(e,t,r,i=1)=>Co(e,t,r,!1,i),dn=class{constructor(t){this.normalizedDispatchGroup=t;this.indicesHelpers=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(t){return`if (global_idx >= ${typeof t==\"number\"?`${t}u`:t}) { return; }`}mainStart(t=$u){let r=typeof t==\"number\"?t:t[0],i=typeof t==\"number\"?1:t[1],o=typeof t==\"number\"?1:t[2],s=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,l=s?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>`,n=s?\"let global_idx = global_id.x;\":`let global_idx = (workgroup_id.z * ${this.normalizedDispatchGroup[0]*this.normalizedDispatchGroup[1]}u +\n          workgroup_id.y * ${this.normalizedDispatchGroup[0]}u + workgroup_id.x) * ${r*i*o}u + local_index;`;return`@compute @workgroup_size(${r}, ${i}, ${o})\n  fn main(${l}) {\n    ${n}\n  `}declareVariable(t,r){this.indicesHelpers.push(t),t.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.shape.replace(\"uniforms.\",\"\"),type:t.type.indices}),t.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.strides.replace(\"uniforms.\",\"\"),type:t.type.indices});let i=t.usage===\"input\"?\"read\":\"read_write\",o=t.type.storage;return`@group(0) @binding(${r}) var<storage, ${i}> ${t.name}: array<${o}>;`}declareVariables(...t){return t.map(r=>this.declareVariable(r,this.variableIndex++)).join(`\n`)}registerUniform(t,r){return this.uniforms.push({name:t,type:r}),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let t=[];for(let{name:r,type:i}of this.uniforms)t.push(`${r}:${i}`);return`\n      struct Uniforms { ${t.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.indicesHelpers.map(t=>t.impl()).join(`\n`)}},So=e=>new dn(e),pn=(e,t)=>{let r=e.length,i=[];for(let o=0;o<r;o++){let s=r-1-o,l=e[s]||1;(t[t.length-1-o]||1)>1&&l===1&&i.unshift(s)}return i}});var et,xu,Sr,Cu,tt,Ao,Io,To,Eo,Oo,_o,Po,Ro,Bo,Mo,je,fn=H(()=>{\"use strict\";me();_e();$e();et=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},xu=e=>[\"\",\"\",`var value = ${e.getByOffset(\"inputOffset\")};`,\"\"],Sr=(e,t,r,i,o,s,l=!1,n=!1)=>{let c=[],m=r[0].dims,g=D.normalizeAxes(o,r[0].dims.length),C=!n&&g.length===0;m.forEach((U,V)=>{C||g.indexOf(V)>=0?l&&c.push(1):c.push(U)});let x=[],$=K(\"_A\",r[0].dataType,m),b=se(\"output\",s,c),w=i($,b,g),v=`inputOffset = ${$.indicesToOffset(\"inputIndices\")};`,I=`let ${v};`,B=`var ${v};`,z=w[1]===\"\"?\"\":B,M=(w[1]===\"\"?I:v)+`\n`+w[2];for(let U=0,V=0;U<r[0].dims.length;U++)C||g.indexOf(U)>=0?(l&&V++,M=`for(var j${U}: u32 = 0; j${U} < ${r[0].dims[U]}; j${U}++) {\n                ${w[2].includes(\"lastIndex\")?`let lastIndex = j${U};`:\"\"}\n                ${$.indicesSet(\"inputIndices\",U,`j${U}`)}\n                ${M}\n              }`):(x.push(`${$.indicesSet(\"inputIndices\",U,b.indicesGet(\"outputIndices\",V))};`),V++);let G=D.size(c);return{name:e,shaderCache:t,getShaderSource:U=>`\n        ${U.declareVariables($,b)}\n\n        ${U.mainStart()}\n          ${U.guardAgainstOutOfBoundsWorkgroupSizes(G)}\n          var inputIndices: ${$.type.indices};\n          let outputIndices = ${b.offsetToIndices(\"global_idx\")};\n\n          ${x.join(`\n`)}\n          ${w[0]}       // init ops for reduce max/min\n          ${z}\n          ${w[1]}\n          ${M}\n          ${w[3]}\n          ${w.length===4?b.setByOffset(\"global_idx\",\"value\"):w.slice(4).join(`\n`)}\n        }`,getRunData:()=>({outputs:[{dims:c,dataType:s}],dispatchGroup:{x:Math.ceil(G/64)}})}},Cu=(e,t)=>{let r=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(i=>r.push(Number(i))),ae({axes:r,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},tt=(e,t,r,i)=>{let o=e.inputs,s=o.length===1?r:Cu(o,r);e.compute(Sr(t,{hint:s.cacheKey},[o[0]],s.noopWithEmptyAxes&&s.axes.length===0?xu:i,s.axes,o[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},Ao=(e,t)=>{et(e.inputs),tt(e,\"ReduceLogSum\",t,(i,o)=>[`var value = ${o.type.storage}(0);`,\"\",`value += ${i.getByOffset(\"inputOffset\")};`,\"value = log(value);\"])},Io=(e,t)=>{et(e.inputs),tt(e,\"ReduceL1\",t,(i,o)=>[`var value = ${o.type.storage}(0);`,\"\",`value += abs(${i.getByOffset(\"inputOffset\")});`,\"\"])},To=(e,t)=>{et(e.inputs),tt(e,\"ReduceL2\",t,(i,o)=>[`var t = ${o.type.value}(0); var value = ${o.type.value}(0);`,\"\",`t = ${i.getByOffset(\"inputOffset\")}; value += (t * t);`,\"value = sqrt(value);\"])},Eo=(e,t)=>{et(e.inputs),tt(e,\"ReduceLogSumExp\",t,(i,o)=>[`var value = ${o.type.storage}(0);`,\"\",`value += exp(${i.getByOffset(\"inputOffset\")});`,\"value = log(value);\"])},Oo=(e,t)=>{et(e.inputs),tt(e,\"ReduceMax\",t,(i,o,s)=>{let l=[];for(let n=0;n<i.rank;n++)(s.indexOf(n)>=0||s.length===0)&&l.push(i.indicesSet(\"inputIndices\",n,0));return[`${l.join(`\n`)}`,`var value = ${i.getByOffset(\"inputOffset\")};`,`value = max(value, ${i.getByOffset(\"inputOffset\")});`,\"\"]})},_o=(e,t)=>{et(e.inputs),tt(e,\"ReduceMean\",t,(i,o,s)=>{let l=1;for(let n=0;n<i.rank;n++)(s.indexOf(n)>=0||s.length===0)&&(l*=e.inputs[0].dims[n]);return[\"var sum = f32(0);\",\"\",`sum += f32(${i.getByOffset(\"inputOffset\")});`,`let value = ${o.type.value}(sum / ${l});`]})},Po=(e,t)=>{et(e.inputs),tt(e,\"ReduceMin\",t,(i,o,s)=>{let l=[];for(let n=0;n<i.rank;n++)(s.indexOf(n)>=0||s.length===0)&&l.push(`inputIndices[${n}] = 0;`);return[`${l.join(`\n`)}`,`var value = ${i.getByOffset(\"inputOffset\")};`,`value = min(value, ${i.getByOffset(\"inputOffset\")});`,\"\"]})},Ro=(e,t)=>{et(e.inputs),tt(e,\"ReduceProd\",t,(i,o)=>[`var value = ${o.type.storage}(1);`,\"\",`value *= ${i.getByOffset(\"inputOffset\")};`,\"\"])},Bo=(e,t)=>{et(e.inputs),tt(e,\"ReduceSum\",t,(i,o)=>[`var value = ${o.type.storage}(0);`,\"\",`value += ${i.getByOffset(\"inputOffset\")};`,\"\"])},Mo=(e,t)=>{et(e.inputs),tt(e,\"ReduceSumSquare\",t,(i,o)=>[`var t = ${o.type.value}(0); var value = ${o.type.value}(0);`,\"\",`t = ${i.getByOffset(\"inputOffset\")}; value += t * t;`,\"\"])},je=e=>ae(e)});var ko,Do,Wo,zo,mn,Go=H(()=>{\"use strict\";ke();_e();fn();ko=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},Do=(e,t)=>ae({axis:t.axis,keepDims:t.keepDims,selectLastIndex:t.selectLastIndex}),Wo=(e,t)=>{ko(e.inputs);let r=(o,s,l)=>{let n=[];for(let c=0;c<o.rank;c++)(l.indexOf(c)>=0||l.length===0)&&n.push(`inputIndices[${c}] = 0;`);return[`${n.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${o.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${o.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",s.setByOffset(\"global_idx\",\"bestIndex\")]},i=e.inputs.length===1?t:Do(e.inputs,t);e.compute(Sr(\"ArgMin\",{hint:i.cacheKey},[e.inputs[0]],r,[i.axis],7,i.keepDims),{inputs:[0]})},zo=(e,t)=>{ko(e.inputs);let r=(o,s,l)=>{let n=[];for(let c=0;c<o.rank;c++)(l.indexOf(c)>=0||l.length===0)&&n.push(`inputIndices[${c}] = 0;`);return[`${n.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${o.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${o.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",s.setByOffset(\"global_idx\",\"bestIndex\")]},i=e.inputs.length===1?t:Do(e.inputs,t);e.compute(Sr(\"argMax\",{hint:i.cacheKey},[e.inputs[0]],r,[i.axis],7,i.keepDims),{inputs:[0]})},mn=e=>ae(e)});var Su,Au,Uo,No=H(()=>{\"use strict\";me();$e();Su=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},Au=e=>{let t=e[0].dims,r=e[0].dims[2],i=D.size(t)/4,o=e[0].dataType,s=K(\"input\",o,t,4),l=K(\"bias\",o,[r],4),n=K(\"residual\",o,t,4),c=se(\"output\",o,t,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(i/64)}}),getShaderSource:g=>`\n  const channels = ${r}u / 4;\n  ${g.declareVariables(s,l,n,c)}\n\n  ${g.mainStart()}\n    ${g.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n    let value = ${s.getByOffset(\"global_idx\")}\n      + ${l.getByOffset(\"global_idx % channels\")} + ${n.getByOffset(\"global_idx\")};\n    ${c.setByOffset(\"global_idx\",\"value\")}\n  }`}},Uo=e=>{Su(e.inputs),e.compute(Au(e.inputs))}});var Iu,xe,Vo,Fo,Ho,Lo,jo,Ko,qo,Yo,Xo,hn,Tu,Qo,Jo,Zo,ea,Ar,ta,Ir,ra,na,oa,aa,ia,sa,ua,la,da,ca,pa,fa,ma,ha,ga,ya,ba,gn=H(()=>{\"use strict\";ke();me();_e();$e();Iu=(e,t,r,i,o,s)=>{let l=Math.ceil(t/4),n=\"\";typeof o==\"string\"?n=`${o}(a)`:n=o(\"a\");let c=K(\"inputData\",r,[l],4),m=se(\"outputData\",i,[l],4);return`\n  ${e.declareVariables(c,m)}\n\n  ${s??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n\n    let a = ${c.getByOffset(\"global_idx\")};\n    ${m.setByOffset(\"global_idx\",n)}\n  }`},xe=(e,t,r,i,o,s=e.dataType)=>({name:t,shaderCache:{hint:o},getShaderSource:l=>Iu(l,D.size(e.dims),e.dataType,s,r,i),getRunData:l=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(D.size(l[0].dims)/64/4)}})}),Vo=e=>{e.compute(xe(e.inputs[0],\"Abs\",\"abs\"))},Fo=e=>{e.compute(xe(e.inputs[0],\"Acos\",\"acos\"))},Ho=e=>{e.compute(xe(e.inputs[0],\"Acosh\",\"acosh\"))},Lo=e=>{e.compute(xe(e.inputs[0],\"Asin\",\"asin\"))},jo=e=>{e.compute(xe(e.inputs[0],\"Asinh\",\"asinh\"))},Ko=e=>{e.compute(xe(e.inputs[0],\"Atan\",\"atan\"))},qo=e=>{e.compute(xe(e.inputs[0],\"Atanh\",\"atanh\"))},Yo=e=>ae(e),Xo=(e,t)=>{let r;switch(t.to){case 10:r=\"vec4<f16>\";break;case 1:r=\"vec4<f32>\";break;case 12:r=\"vec4<u32>\";break;case 6:r=\"vec4<i32>\";break;case 9:r=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute(xe(e.inputs[0],\"Cast\",r,void 0,t.cacheKey,t.to))},hn=(e,t)=>{let r=Pe(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Clip\",i=>`clamp(${i}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${r}> = vec4(${r}(${t.min}));\n    const clip_max_: vec4<${r}> = vec4(${r}(${t.max}));\n`,t.cacheKey),{inputs:[0]})},Tu=e=>{let t=e.length>=2?e[1].getFloat32Array()[0]:xr,r=e.length>=3?e[2].getFloat32Array()[0]:Cr;return ae({min:t,max:r})},Qo=e=>{let t=Tu(e.inputs);hn(e,t)},Jo=e=>{e.compute(xe(e.inputs[0],\"Ceil\",\"ceil\"))},Zo=e=>{e.compute(xe(e.inputs[0],\"Cos\",\"cos\"))},ea=e=>{e.compute(xe(e.inputs[0],\"Cosh\",\"cosh\"))},Ar=e=>ae(e),ta=(e,t)=>{e.compute(xe(e.inputs[0],\"Elu\",r=>`elu_vf32(${r})`,`\n  const elu_alpha_: f32 = f32(${t.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Ir=(e,t=\"f32\")=>`\nconst r0: ${t} = 0.3275911;\nconst r1: ${t} = 0.254829592;\nconst r2: ${t} = -0.284496736;\nconst r3: ${t} = 1.421413741;\nconst r4: ${t} = -1.453152027;\nconst r5: ${t} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,ra=e=>{let t=Pe(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Erf\",r=>`erf_vf32(${r})`,Ir(`vec4<${t}>`,t)))},na=e=>{e.compute(xe(e.inputs[0],\"Exp\",\"exp\"))},oa=e=>{e.compute(xe(e.inputs[0],\"Floor\",\"floor\"))},aa=e=>{let t=Pe(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Gelu\",r=>`0.5 * ${r} * (1.0 + erf_vf32(${r} * 0.7071067811865475))`,Ir(`vec4<${t}>`,t)))},ia=(e,t)=>{e.compute(xe(e.inputs[0],\"LeakyRelu\",r=>`select(leaky_relu_alpha_ * ${r}, ${r}, ${r} >= vec4<f32>(0.0))`,`const leaky_relu_alpha_: f32 = f32(${t.alpha});`,t.cacheKey))},sa=e=>{e.compute(xe(e.inputs[0],\"Not\",t=>`!${t}`))},ua=e=>{e.compute(xe(e.inputs[0],\"Neg\",t=>`-${t}`))},la=e=>{e.compute(xe(e.inputs[0],\"Reciprocal\",t=>`1.0/${t}`))},da=e=>{e.compute(xe(e.inputs[0],\"Relu\",t=>`select(vec4<f32>(0.0), ${t}, ${t} > vec4<f32>(0.0))`))},ca=e=>{e.compute(xe(e.inputs[0],\"Sigmoid\",t=>`(1.0 / (1.0 + exp(-${t})))`))},pa=e=>{e.compute(xe(e.inputs[0],\"Sin\",\"sin\"))},fa=e=>{e.compute(xe(e.inputs[0],\"Sinh\",\"sinh\"))},ma=e=>{e.compute(xe(e.inputs[0],\"Sqrt\",\"sqrt\"))},ha=e=>{e.compute(xe(e.inputs[0],\"Tan\",\"tan\"))},ga=e=>{e.compute(xe(e.inputs[0],\"Tanh\",\"tanh\"))},ya=(e,t)=>(e.compute(xe(e.inputs[0],\"ThresholdedRelu\",r=>`select(vec4<f32>(0.0), ${r}, ${r} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${t.alpha});`,t.cacheKey)),0),ba=e=>{e.compute(xe(e.inputs[0],\"Log\",\"log\"))}});var Ou,_u,wa,va=H(()=>{\"use strict\";me();$e();gn();Ou=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},_u=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let r=K(\"input\",e[0].dataType,e[0].dims,4),i=K(\"bias\",e[0].dataType,[e[0].dims[2]],4),o=se(\"output\",e[0].dataType,t,4),s=D.size(t)/4;return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:n=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${n.declareVariables(r,i,o)}\n\n  ${Ir(\"vec4f\")}\n\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${o.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},wa=e=>{Ou(e.inputs),e.compute(_u(e.inputs))}});var Pu,Ru,rt,$a,xa,Ca,Sa,Aa,Ia,Ta,Ea,Oa,_a,Pa=H(()=>{\"use strict\";ke();me();$e();Pu=(e,t,r,i,o,s,l,n,c,m,g)=>{let C=D.size(i),x=Math.ceil(C/4),$,b;typeof l==\"string\"?$=b=(M,G)=>`${l}((${M}),(${G}))`:typeof l==\"function\"?$=b=l:($=l.scalar,b=l.vector);let w=\"\",v=se(\"outputData\",m,i,4),I=K(\"aData\",n,t,4),B=K(\"bData\",c,r,4);if(s){let M=G=>{let _=D.computeStrides(G),U=[];for(let V=G.length-1;V>=0;V--){let j=v.indicesGet(\"outputIndices\",V+i.length-G.length);U.push(`${_[V]}u * (${j} % ${G[V]}u)`)}return U.length>0?U.join(\"+\"):\"0u\"};w=`\n          fn calcOffsetA(outputIndices: ${v.type.indices}) -> u32 {\n            return ${M(t)};\n          }\n\n          fn calcOffsetB(outputIndices: ${v.type.indices}) -> u32 {\n            return ${M(r)};\n          }\n        `}let z;if(o)if(s){let M=D.size(t)===1,G=D.size(r)===1;M||G?z=v.setByOffset(\"global_idx\",b(M?`${I.type.value}(${I.getByOffset(\"0\")}.x)`:I.getByOffset(\"global_idx\"),G?`${B.type.value}(${B.getByOffset(\"0\")}.x)`:B.getByOffset(\"global_idx\"))):z=`\n            let outputIndices = ${v.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = calcOffsetA(outputIndices);\n            let offsetB = calcOffsetB(outputIndices);\n            ${v.setByOffset(\"global_idx\",b(I.getByOffset(\"offsetA / 4u\"),B.getByOffset(\"offsetB / 4u\")))}\n          `}else z=v.setByOffset(\"global_idx\",b(I.getByOffset(\"global_idx\"),B.getByOffset(\"global_idx\")));else{if(!s)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let M=(G,_,U=\"\")=>{let V=`aData[indexA${_}][componentA${_}]`,j=`bData[indexB${_}][componentB${_}]`;return`\n            let outputIndices${_} = ${v.offsetToIndices(`global_idx * 4u + ${_}u`)};\n            let offsetA${_} = calcOffsetA(outputIndices${_});\n            let offsetB${_} = calcOffsetB(outputIndices${_});\n            let indexA${_} = offsetA${_} / 4u;\n            let indexB${_} = offsetB${_} / 4u;\n            let componentA${_} = offsetA${_} % 4u;\n            let componentB${_} = offsetB${_} % 4u;\n            ${G}[${_}] = ${U}(${$(V,j)});\n          `};m===9?z=`\n            var data = vec4<u32>(0);\n            ${M(\"data\",0,\"u32\")}\n            ${M(\"data\",1,\"u32\")}\n            ${M(\"data\",2,\"u32\")}\n            ${M(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:z=`\n            ${M(\"outputData[global_idx]\",0)}\n            ${M(\"outputData[global_idx]\",1)}\n            ${M(\"outputData[global_idx]\",2)}\n            ${M(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(I,B,v)}\n\n        ${g??\"\"}\n        ${w}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(x)}\n        ${z}\n      }`},Ru=(e,t,r,i,o,s,l=r.dataType)=>{let n=!D.areEqual(r.dims,i.dims),c=r.dims,m=D.size(r.dims),g=!1;if(n){let C=Ze.calcShape(r.dims,i.dims,!1);if(!C)throw new Error(\"Can't perform binary op on the given tensors\");c=C,m=D.size(c);let x=D.size(r.dims)===1,$=D.size(i.dims)===1,b=1;for(let w=1;w<c.length;w++){let v=r.dims[r.dims.length-w]??1,I=i.dims[i.dims.length-w]??1;if(v===I)b*=v;else break}(b%4===0||x||$)&&(g=!0)}else g=!0;return{name:e,shaderCache:{hint:t},getShaderSource:C=>Pu(C,r.dims,i.dims,c,g,n,o,r.dataType,i.dataType,l,s),getRunData:()=>({outputs:[{dims:c,dataType:l}],dispatchGroup:{x:Math.ceil(m/64/4)}})}},rt=(e,t,r,i,o,s)=>{e.compute(Ru(t,o??\"\",e.inputs[0],e.inputs[1],r,i,s))},$a=e=>{rt(e,\"Add\",(t,r)=>`${t}+${r}`)},xa=e=>{rt(e,\"Div\",(t,r)=>`${t}/${r}`)},Ca=e=>{rt(e,\"Equal\",{scalar:(t,r)=>`u32(${t}==${r})`,vector:(t,r)=>`vec4<u32>(${t}==${r})`},void 0,void 0,9)},Sa=e=>{rt(e,\"Mul\",(t,r)=>`${t}*${r}`)},Aa=e=>{let t=K(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;rt(e,\"Pow\",{scalar:(i,o)=>`pow_custom(${i},${o})`,vector:(i,o)=>`pow_vector_custom(${i},${o})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${t===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Ia=e=>{rt(e,\"Sub\",(t,r)=>`${t}-${r}`)},Ta=e=>{rt(e,\"Greater\",{scalar:(t,r)=>`u32(${t}>${r})`,vector:(t,r)=>`vec4<u32>(${t}>${r})`},void 0,void 0,9)},Ea=e=>{rt(e,\"Less\",{scalar:(t,r)=>`u32(${t}<${r})`,vector:(t,r)=>`vec4<u32>(${t}<${r})`},void 0,void 0,9)},Oa=e=>{rt(e,\"GreaterOrEqual\",{scalar:(t,r)=>`u32(${t}>=${r})`,vector:(t,r)=>`vec4<u32>(${t}>=${r})`},void 0,void 0,9)},_a=e=>{rt(e,\"LessOrEqual\",{scalar:(t,r)=>`u32(${t}<=${r})`,vector:(t,r)=>`vec4<u32>(${t}<=${r})`},void 0,void 0,9)}});var Mu,ku,Du,Wu,Ra,Ba,Ma=H(()=>{\"use strict\";me();_e();$e();Mu=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let t=e[0].dataType,r=e[0].dims.length;for(let i of e){if(i.dataType!==t)throw new Error(\"input tensors should be one type\");if(i.dims.length!==r)throw new Error(\"input tensors should have the same shape\")}},ku=e=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,Du=(e,t)=>{let r=e.length,i=[];for(let o=0;o<r;++o){let s=t.setByOffset(\"global_idx\",e[o].getByIndices(\"indices\"));r===1?i.push(s):o===0?i.push(`if (inputIndex == ${o}u) { ${s} }`):o===r-1?i.push(`else { ${s} }`):i.push(`else if (inputIndex == ${o}) { ${s} }`)}return i.join(`\n`)},Wu=(e,t)=>{let r=e[0].dims.slice();if(t>=r.length||t<-1*r.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let i=t<0?r.length+t:t,o=r.slice(0);for(let $=1;$<e.length;$++){let b=e[$].dims.slice();for(let w=0;w<r.length;w++)if(w===i)o[i]+=b[w];else if(r[w]!==b[w])throw new Error(\"non concat dimensions must match\")}let s=D.size(o),l=new Array(e.length),n=new Array(e.length),c=e[0].dataType,m=0;for(let $=0;$<e.length;++$)m+=e[$].dims[i],l[$]=m,n[$]=K(`input${$}`,c,e[$].dims);let g=se(\"output\",c,o),C=g.indicesGet(\"indices\",i),x=$=>`\n  ${$.declareVariables(...n,g)}\n\n  const sizeInConcatAxis = array<u32, ${l.length}>(${l.map(b=>`${b}u`).join(\",\")});\n  ${ku(l.length)}\n\n  ${$.mainStart()}\n    ${$.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n\n    var indices = ${g.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${C});\n    if (inputIndex != 0u) {\n      ${C} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${Du(n,g)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${t}`},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:x}},Ra=(e,t)=>{Mu(e.inputs),e.compute(Wu(e.inputs,t.axis))},Ba=e=>ae({axis:e.axis})});var Me,Tr,Er,Or=H(()=>{\"use strict\";Me=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},Tr=(e,t=!1,r=!1,i=3)=>\"\",Er=(e,t)=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      ${t?\"value = activation(value, coords);\":\"\"}\n      `});var _r,yn=H(()=>{\"use strict\";_r=`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`});var Pr,Rr,Jt=H(()=>{\"use strict\";me();Pr=e=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:\"value = max(value, 0.0);\"};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:\"value = (1.0 / (1.0 + exp(-value)));\"};case\"Clip\":return{activationFunction:`const clip_min_=f32(${e.clipMin});const clip_max_=f32(${e.clipMax});`,applyActivation:\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},Rr=e=>{let t=e?.activation||\"\";if(t===\"Clip\"){let[r,i]=e?.activation_params||[xr,Cr];return{activation:t,clipMax:i,clipMin:r,activationCacheKey:`${t}:${r},${i}`}}return{activation:t,activationCacheKey:t}}});var zu,Gu,Zt,ka,Uu,er,Nu,Br,tr=H(()=>{\"use strict\";me();$e();Jt();Or();zu=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `,Gu=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${t===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,Zt=(e,t,r=\"f32\",i,o=!1,s=32,l=!1,n=32)=>{let c=t[1]*e[1],m=t[0]*e[0],g=o?c:s,C=o?s:c,x=g/t[0],$=s/t[1];if(!((o&&x===4&&e[1]===4||!o&&(x===3||x===4))&&g%t[0]===0&&s%t[1]===0&&e[0]===4))throw new Error(`If transposeA ${o} is true, innerElementSize ${x} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${x} must be 3 or 4.\n  tileAWidth ${g} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${x}<${r}>, ${g/x}>, ${C}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${r}>, ${m/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${x};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${l?\"0\":\"i32(globalId.z)\"};\n  ${i?`let batchIndices = ${i.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${c};\n\n  let numTiles = ${l?`${Math.ceil(n/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n  var kStart = ${l?`i32(globalId.z) * ${n}`:\"0\"};\n\n  var acc: array<vec4<${r}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${$};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${zu(o,i)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${$}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${i?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${x===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${Gu(o,x)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},ka=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?\", batchIndices\":\"\"});\n            `,Uu=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",er=(e,t,r=\"f32\",i,o=!1,s=32,l=!1,n=32,c=!1)=>{let m=e[1]*t[1],g=e[0]*t[0],C=o?m:s,x=o?s:m;if(!(x%t[1]===0&&C%t[0]===0&&s%t[1]===0))throw new Error(`tileAHight ${x} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${C} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);let $=x/t[1],b=C/t[0],w=s/t[1],v=c?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${m};\n    let globalColStart = i32(workgroupId.x) * ${g};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${x}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${C}; inputCol = inputCol + ${t[0]}) {\n          ${ka(o,i)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${g}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${i?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${r}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${o?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${m};\n\nlet tileRowA = i32(localId.y) * ${$};\nlet tileColA = i32(localId.x) * ${b};\nlet tileRowB = i32(localId.y) * ${w};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${$}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${b}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${ka(o,i)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${w}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${i?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${r}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${Uu(o)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${r}, ${C}>, ${x}>;\n  var<workgroup> mm_Bsub : array<array<${r}, ${g}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${l?\"0\":\"i32(globalId.z)\"};\n    ${i?`let batchIndices = ${i.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${l?`${Math.ceil(n/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n    var kStart = ${l?`i32(globalId.z) * ${n}`:\"0\"};\n\n    var acc : array<array<${r}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${v}\n  }\n`},Nu=(e,t,r,i,o,s=!1)=>{let l=o[0],n=o[1],c=o[2],m=i[0],g=i[1],C=i[2],x=i[3],$=pn(l,c),b=pn(n,c),w=Pe(i[0].type.tensor),v=()=>{let z=g.rank,M=m.rank,G=`var aIndices: ${g.type.indices};`;for(let _=z-2-1,U=M-1;_>=0;_--,U--)G+=`\naIndices[${_}] = ${M>1?`batchIndices[${U}]`:\"batchIndices\"};`;return $.forEach(_=>{G+=`\naIndices[${_}] = 0;`}),G+=`\naIndices[${z-2}] = u32(row);\n                   aIndices[${z-1}] = u32(colIn);`,G},I=()=>{let z=C.rank,M=m.rank,G=`var bIndices: ${C.type.indices};`;for(let _=z-2-1,U=M-1;_>=0;_--,U--)G+=`\nbIndices[${_}] = ${M>1?`batchIndices[${U}]`:\"batchIndices\"};`;return b.forEach(_=>{G+=`\nbIndices[${_}] = 0;`}),G+=`\nbIndices[${z-2}] = u32(row);\n                   bIndices[${z-1}] = u32(colIn);`,G};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${m.type.indices}) -> ${Me(e,w)} {\n      var value = ${Me(e,w)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${v()}\n        value = ${g.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${m.type.indices}) -> ${Me(e,w)} {\n      var value = ${Me(e,w)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${I()}\n        value = ${C.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${Me(e,w)}) {\n      let col = colIn * ${e};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${s?\"bias[colIn]\":`${Me(e,w)}(bias[row])`};`:\"\"}\n        ${r}\n        ${x.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},Br=(e,t,r,i,o=!1)=>{let s=e[0].dims,l=e[1].dims,n=s.slice(0,-2),c=l.slice(0,-2),m=i?i.slice(0,-2):r.slice(0,-2),g=K(\"batchDims\",e[0].dataType,m),C=[g],x=[n,c,m],$=D.size(m),b=s[s.length-2],w=s[s.length-1],v=l[l.length-1],I=w%4===0&&v%4===0,{activationFunction:B,applyActivation:z}=Pr(t),M=b<=8?[4,1,1]:[4,4,1],G=[8,8,1],_=[Math.ceil(v/G[0]/M[0]),Math.ceil(b/G[1]/M[1]),Math.ceil($/G[2]/M[2])],U=Pe(e[0].dataType),V=I?4:1,j=K(\"a\",e[0].dataType,[...n,b,w/V],V),le=K(\"b\",e[1].dataType,[...c,w,v/V],V),R=se(\"result\",e[0].dataType,[$,b,v/V],V);C.push(j),C.push(le),C.push(R);let X=[j,le],Se=e.length>2,q=Nu(V,Se,z,C,x,o);if(Se){let De=o?V:1;X.push(K(\"bias\",e[2].dataType,e[2].dims,De))}let L=De=>`\n  const dimAOuter: i32 = ${b};\n  const dimBOuter: i32 = ${v};\n  const dimInner: i32 = ${w};\n  ${De.declareVariables(...X,R)}\n  ${q}\n  ${B}\n  ${I?Zt(M,G,U,g):er(M,G,U,g)}\n                   ${g.impl()}`;return{name:\"MatMul\",shaderCache:{hint:t.activationCacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:_[0],y:_[1],z:_[2]}}),getShaderSource:L}}});var Vu,Da,Wa=H(()=>{\"use strict\";lt();me();$e();Or();yn();tr();Vu=(e,t,r,i,o=!1,s,l=!1,n=4,c=4,m=4,g=\"f32\")=>{let C=le=>{switch(le){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${g}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${le} is not supported.`)}},x=le=>{switch(le){case 1:return\"return w[row * wShape[3] + colIn];\";case 4:return\"return w[row * wShape[3] / 4 + colIn];\";default:throw new Error(`innerElementSize ${le} is not supported.`)}},$=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,b=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,w=e?\"xShape[1]\":\"xShape[2]\",v=e?\"xShape[2]\":\"xShape[3]\",I=e?\"row\":\"col\",B=e?\"col\":\"row\",z=`\n    let inChannels = wShape[2];\n    let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n    let outRow = ${I} / outWidth;\n    let outCol = ${I} % outWidth;\n\n    let WRow = ${B} / (filterDims[1] * inChannels);\n    let WCol = ${B} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${B} % inChannels;\n    var resData = ${Me(n,g)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${w} && xCol >= 0 && xCol < ${v}) {\n      ${$}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${C(n)}\n    }\n    return resData;`,M=e?t&&i?`\n    let col = colIn * ${n};\n    ${z}`:`\n    let col = colIn * ${n};\n    if (row < dimAOuter && col < dimInner) {\n      ${z}\n    }\n    return ${Me(n,g)}(0.0);`:i&&r?`\n    let col = colIn * ${n};\n    ${z}`:`\n    let col = colIn * ${n};\n    if (row < dimInner && col < dimBOuter) {\n      ${z}\n    }\n    return ${Me(n,g)}(0.0);`,G=`${x(c)}`,_=Me(m,g),U=e?Me(n,g):Me(c,g),V=e?Me(c,g):Me(n,g);return`\n    ${Tr(s,l,m===4,4)}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${U} {\n      ${e?M:G}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${V} {\n      ${e?G:M}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${_}) {\n      let col = colIn * ${m};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${b}\n      ${Er(o,s)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},Da=(e,t,r,i,o,s,l,n)=>{let c=t.format===\"NHWC\",m=c?e[0].dims[3]:e[0].dims[1],g=r[0],C=c?r[2]:r[3],x=c?r[1]:r[2],$=c?r[3]:r[1],b=c&&(m%4===0||m%3===0)&&$%4===0,w=c?$:C*x,v=c?C*x:$,I=[8,8,1],B=i<=8?[4,1,1]:[4,4,1],z=[Math.ceil(w/I[0]/B[0]),Math.ceil(v/I[1]/B[1]),Math.ceil(g/I[2]/B[2])];Ie(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${z}`);let M=b?c&&m%4!==0?3:4:B[0],G=I[1]*B[1],_=I[0]*B[0],U=Math.max(I[0]*M,I[1]),V=i%G===0,j=o%_===0,le=s%U===0,R=b?[M,4,4]:[1,1,1],X=Pe(e[0].dataType),Se=[`@group(0) @binding(0) var<storage, read> x: array<${b&&M===4?`vec4<${X}>`:X}>;`,`@group(0) @binding(1) var<storage, read> w: array<${b?`vec4<${X}>`:X}>;`],q=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${b?`vec4<${X}>`:X}) {\n        result[flatIndex] = ${b?`vec4<${X}>`:X}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${b?`vec4<${X}>`:X}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${b?\"/ 4\":\"\"}, value);\n      }`;return l&&(Se.push(`@group(0) @binding(2) var<storage, read> bias: array<${b?`vec4<${X}>`:X}>;`),q+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${b?`vec4<${X}>`:X} {\n          return bias[coords.${c?\"w\":\"y\"}${b?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:z[0],y:z[1],z:z[2]}}),getShaderSource:()=>`\n        ${_r}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${Se.join(\"\")}\n        @group(0) @binding(${Se.length}) var<storage, read_write> result: array<${b?`vec4<${X}>`:X}>;\n        //@group(0) @binding(${Se.length+1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${D.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[0]}, ${t.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${t.pads[0]}, ${t.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${i};\n        const dimBOuter : i32 = ${o};\n        const dimInner : i32 = ${s};\n        ${q}\n        ${Vu(c,V,j,le,l,void 0,!1,R[0],R[1],R[2],X)}\n            ${b?Zt(B,I,X,void 0,!c,U):er(B,I,X,void 0,!c,U,!1,void 0,n)}`}}});var bn,za=H(()=>{\"use strict\";me();$e();vn();Jt();bn=(e,t,r)=>{let i=e.length>2,o=i?\"value += b[output_channel];\":\"\",s=e[0].dims,l=e[1].dims,n=l[0]/t.group,{activationFunction:c,applyActivation:m}=Pr(t),g=t.format===\"NHWC\",C=wn(s,l,t.dilations,t.pads,t.strides,g),x=D.size(C),$=se(\"output\",e[0].dataType,C),b=K(\"x\",e[0].dataType,s),w=K(\"w\",e[1].dataType,l),v=[b,w];i&&v.push(K(\"b\",e[2].dataType,e[2].dims));let I=B=>`\n  const strides: vec2<u32> = vec2(${t.strides[0]}u, ${t.strides[1]}u);\n  const pads: vec2<u32> = vec2(${t.pads[0]}u, ${t.pads[1]}u);\n\n  ${B.declareVariables(...v,$)}\n\n  ${c}\n\n  ${B.mainStart()}\n    ${B.guardAgainstOutOfBoundsWorkgroupSizes(x)}\n\n    let outputIndices = ${$.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${g?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${g?1:2}], outputIndices[${g?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${n}u;\n\n    var value: ${$.type.value} = ${$.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${l[1]}u; wInChannel++) {\n      let input_channel = group_id * ${l[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${l[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${t.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${s[g?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${l[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${t.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${s[g?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${g?b.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):b.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${w.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${o}\n    ${m}\n    ${$.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r?r(C):C,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(x/64)}}),getShaderSource:I}}});var Fu,Ga,Hu,Lu,Et,Ua,Na,Mr=H(()=>{\"use strict\";me();_e();$e();Fu=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},Ga=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,Hu=(e,t)=>D.sortBasedOnPerm(e,Ga(e.length,t)),Lu=(e,t,r,i)=>{let o=[];o.push(`fn perm(i: ${i.type.indices}) -> ${r.type.indices} {\n    var a: ${r.type.indices};`);for(let s=0;s<t;++s)o.push(r.indicesSet(\"a\",e[s],`i[${s}]`));return o.push(\"return a;}\"),o.join(`\n`)},Et=(e,t,r)=>{let i=Ga(t,r),o=se(\"output\",e,r&&r.length||t),s=K(\"a\",e,t),l=n=>`\n  ${n.registerUniform(\"output_size\",\"u32\").declareVariables(s,o)}\n\n  ${Lu(i,t,s,o)}\n\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${o.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${o.setByOffset(\"global_idx\",s.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${r}`,inputDependencies:[\"rank\"]},getRunData:n=>{let c=Hu(n[0].dims,i),m=D.size(c);return{outputs:[{dims:c,dataType:n[0].dataType}],dispatchGroup:{x:Math.ceil(m/64)},programUniforms:[{type:\"uint32\",data:m},...cn(n[0].dims),...cn(c)]}},getShaderSource:l}},Ua=(e,t)=>{Fu(e.inputs),e.compute(Et(e.inputs[0].dataType,e.inputs[0].dims.length,t.perm))},Na=e=>ae({perm:e.perm})});var wn,Va,ju,Fa,Ha,Ku,qu,La,vn=H(()=>{\"use strict\";me();_e();Wa();tr();za();Jt();Mr();wn=(e,t,r,i,o,s)=>{let l=e[0],n=e.slice(s?1:2,s?3:4),c=n.length,m=t[0],C=t.slice(2).map((b,w)=>b+(b-1)*(r[w]-1)),$=n.map((b,w)=>b+i[w]+i[w+c]).map((b,w)=>Math.floor((b-C[w]+o[w])/o[w]));return $.splice(0,0,l),$.splice(s?3:1,0,m),$},Va=[2,3,1,0],ju=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],i=e[1].dims[1]*t.group;if(r!==i)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let o=e[0].dims.length-2;if(t.dilations.length!==o)throw new Error(`dilations should be ${o}D`);if(t.strides.length!==o)throw new Error(`strides should be ${o}D`);if(t.pads.length!==o*2)throw new Error(`pads should be ${o*2}D`);if(t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},Fa=(e,t)=>{let r=e.kernelShape.slice();for(let s=2;s<t[1].dims.length;++s)r[s-2]===0&&(r[s-2]=t[1].dims[s]);let i=e.pads.slice();bt.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,r,i,e.format===\"NHWC\",e.autoPad);let o=Object.assign({},e);return Object.assign(o,{kernelShape:r,pads:i,cacheKey:e.cacheKey}),o},Ha=e=>{let t=Rr(e),r=e.format,i=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],o=e.dilations,s=e.group,l=e.kernel_shape,n=e.pads,c=e.strides,m=e.w_is_const();return ae({autoPad:i,format:r,dilations:o,group:s,kernelShape:l,pads:n,strides:c,wIsConst:m,...t})},Ku=(e,t,r)=>{let i=Fa(r,t);if(r.group!==1){e.compute(bn(t,i));return}let o=r.format===\"NHWC\",s=t.length===3,l=t[0].dims[o?1:2],n=t[0].dims[o?2:3],c=t[0].dims[o?3:1],m=t[1].dims[2],g=t[1].dims[3],C=wn(t[0].dims,t[1].dims,r.dilations,i.pads,r.strides,o),x=C[o?1:2],$=C[o?2:3],b=C[o?3:1],w=o&&m===l&&g===n&&r.pads[0]===0&&r.pads[1]===0;if(w||m===1&&g===1&&r.dilations[0]===1&&r.dilations[1]===1&&r.strides[0]===1&&r.strides[1]===1&&r.pads[0]===0&&r.pads[1]===0){let _=C[0],U,V,j,le=[];if(o){let R=e.kernelCustomData.wT??e.compute(Et(t[1].dataType,t[1].dims.length,Va),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];if(r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=R),w){let X=l*n*c;U=t[0].reshape([1,_,X]),V=R.reshape([1,X,b]),j=[1,_,b]}else U=t[0].reshape([_,l*n,c]),V=R.reshape([1,c,b]),j=[_,x*$,b];le.push(U),le.push(V)}else U=t[0].reshape([_,c,l*n]),V=t[1].reshape([1,b,c]),j=[_,b,x*$],le.push(V),le.push(U);s&&le.push(t[2]),e.compute(Br(le,i,C,j,o),{inputs:le});return}let v=!0,I=e.kernelCustomData.wT??e.compute(Et(t[1].dataType,t[1].dims.length,Va),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=I);let B=[t[0],I];s&&B.push(t[2]);let z=o?x*$:b,M=o?b:x*$,G=m*g*c;e.compute(Da(B,i,C,z,M,G,s,v),{inputs:B})},qu=(e,t)=>{let r=t.format===\"NHWC\",i=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&i.push(e.inputs[2]);let o=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),l=[1].concat(t.dilations),n=[1].concat(t.kernelShape),c=Fa({...t,pads:o,strides:s,dilations:l,kernelShape:n},i);e.compute(bn(i,c,m=>r?[m[0],m[2],m[3]]:[]))},La=(e,t)=>{ju(e.inputs,t),e.inputs[0].dims.length===3?qu(e,t):Ku(e,e.inputs,t)}});var Yu,ja,Ka=H(()=>{\"use strict\";lt();me();Or();yn();tr();Yu=(e,t=!1,r,i=!1,o=4)=>{let s=Me(o,\"f32\"),l=I=>{switch(I){case 1:return\"return W[getIndexFromCoords4D(coord, wShape)];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${I} is not supported.`)}},n=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,c=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,m=e?\"outBackprop[1]\":\"outBackprop[2]\",g=e?\"outBackprop[2]\":\"outBackprop[3]\",C=e?\"row\":\"col\",x=e?\"col\":\"row\",$=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      let outRow = ${C} / outWidth;\n      let outCol = ${C} % outWidth;\n\n      let WRow = ${x} / (filterDims[1] * inChannels);\n      let WCol = ${x} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${m}) || fract(xR) > 0.0) {\n        return ${s}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${g}) || fract(xC) > 0.0) {\n        return ${s}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${x} % inChannels;\n      ${n}\n      return x[getIndexFromCoords4D(coord, xShape)/${o}];`,b=e?`\n      let col = colIn * ${o};\n      if (row < dimAOuter && col < dimInner) {\n        ${$}\n      }\n      return ${s}(0.0);`:`\n      let col = colIn * ${o};\n      if (row < dimInner && col < dimBOuter) {\n        ${$}\n      }\n      return ${s}(0.0);`,w=`\n      let col = colIn * ${o};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < dimInner && col < dimBOuter\":\"row < dimInner && col < dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${l(o)}\n      }\n      return ${s}(0.0);\n      `;return`\n  ${Tr(r,i,o===4,4)}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${s} {\n    ${e?b:w}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${s} {\n    ${e?w:b}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${s}) {\n    let col = colIn * ${o};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${c}\n      ${Er(t,r)}\n      result[getIndexFromCoords4D(coords, outShape)/${o}] = value;\n    }\n  }`},ja=(e,t,r,i,o,s,l,n)=>{let c=t.format===\"NHWC\",m=c?e[0].dims[3]:e[0].dims[1],g=r[0],C=c?r[2]:r[3],x=c?r[1]:r[2],$=c?r[3]:r[1],b=c?m%4===0&&$%4===0:C%4===0&&$%4===0,w=c?$:C*x,v=c?C*x:$,I=b?[8,8,1]:[w<=4||v<=4?4:16,w>4&&v<=4?4:16,1],B=b?[4,4,1]:[w<=4?1:4,w>4&&v<=4?1:4,1],z=[Math.ceil(w/I[0]/B[0]),Math.ceil(v/I[1]/B[1]),Math.ceil(g/I[2]/B[2])];Ie(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${z}`);let M=b?4:1,G=Math.max(I[0]*M,I[1]),_=[`@group(0) @binding(0) var<storage, read> x: array<${b?\"vec4<f32>\":\"f32\"}>;`,\"@group(0) @binding(1) var<storage, read> W: array<f32>;\"],U=\"\";return l&&(_.push(`@group(0) @binding(2) var<storage, read> bias: array<${b?\"vec4<f32>\":\"f32\"}>;`),U+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${b?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${c?\"w\":\"y\"}${b?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:z[0],y:z[1],z:z[2]}}),getShaderSource:()=>`\n        ${_r}\n        ${_.join(`\n`)}\n        @group(0) @binding(${_.length}) var<storage, read_write> result: array<${b?\"vec4<f32>\":\"f32\"}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${D.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[c?1:2]}, ${t.kernelShape[c?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${t.dilations[0]<=1?0:(t.kernelShape[c?1:2]-1)*(t.dilations[0]-1)},\n              ${t.dilations[1]<=1?0:(t.kernelShape[c?2:3]-1)*(t.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${i};\n        const dimBOuter : i32 = ${o};\n        const dimInner : i32 = ${s};\n        ${U}\n        ${Yu(c,l,void 0,!1,M)}\n        ${b?Zt(B,I,\"f32\",void 0,!c,G):er(B,I,\"f32\",void 0,!c,G,!1,void 0,n)}`}}});var Xu,$n,qa=H(()=>{\"use strict\";lt();me();$e();Xu=(e,t,r,i,o,s,l=!1,n)=>{let c=r.format===\"NHWC\",m=c?1:2,g=c?2:3,C=c?3:1,x=D.size(i),$=l?2:1,b=r.group,w=t[1].dims,v=w[0]/b,I=w[1],B=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${l?`vec4<${n}>`:n}) {\n    result[flatIndex] = ${l?`vec4<${n}>`:n}(value);\n  }`;o&&(B+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${l?`vec4<${n}>`:n} {\n      return bias[coords.${c?\"w\":\"y\"}${l?\"/ 4\":\"\"}];\n    }`);let z=l?4:1,M=K(\"W\",t[1].dataType,t[1].dims,z),G=K(\"Dy\",t[0].dataType,t[0].dims,z),_=[G,M];o&&_.push(K(\"bias\",t[2].dataType,[i[C]],z));let U=se(\"result\",t[0].dataType,i,z),V=`{\n        let batch: u32 = ${s?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${s?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${s?\"global_id.y\":\"workgroup_id.y\"} * ${$};\n        let d1: u32 = ${s?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${n}>, ${$}>;\n        for (var i = 0; i < ${$}; i++) {\n          dotProd[i] = vec4<${n}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${n}(dyCorner.x) + ${n}(wR)) / ${n}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${n}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${n}(dyCorner.y) + ${n}(wC)) / ${n}(strides.y);\n            let dyC2 = (${n}(dyCorner.y) + 1.0 + ${n}(wC)) / ${n}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${n}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${n}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${G.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${n}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${G.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${n}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${C}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${G.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${n}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${G.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${n}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${$}; i = i + 1) {\n          let value = dotProd[i] + ${o?\"bias[c+i]\":\"0.0\"};\n          ${U.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,j=`\n          let outputIndices = ${U.offsetToIndices(\"global_idx\")};\n          let batch = ${U.indicesGet(\"outputIndices\",0)};\n          let d1 = ${U.indicesGet(\"outputIndices\",C)};\n          let r = ${U.indicesGet(\"outputIndices\",m)};\n          let c = ${U.indicesGet(\"outputIndices\",g)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${I};\n          let wOutChannel = d1 - groupId * ${I};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${n}(dyRCorner) + ${n}(wR)) / ${n}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${n}(outBackprop[${m}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${n}(dyCCorner) + ${n}(wC)) / ${n}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${n}(outBackprop[${g}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${v};\n              for (var d2: u32 = 0; d2 < ${v}; d2 = d2 + 1) {\n                let xValue = ${c?G.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):G.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${M.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${o?\"bias[d1]\":\"0.0\"};\n          ${U.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(..._,U)}\n  ${B}\n  const outShape : vec4<u32> = vec4<u32>(${i.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${t[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${r.strides[0]}, ${r.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${r.kernelShape[c?1:2]}, ${r.kernelShape[c?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${r.dilations[0]}, ${r.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${r.dilations[0]<=1?0:(r.kernelShape[c?1:2]-1)*(r.dilations[0]-1)},\n          ${r.dilations[1]<=1?0:(r.kernelShape[c?2:3]-1)*(r.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(x)};\n  ${l?V:j}}`},$n=(e,t,r)=>{let i=e.length>2,o=t.outputShape,s=D.size(o),l=[Math.ceil(s/64),1,1];Ie(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${l}`);let n=Pe(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:t.cacheKey},getRunData:()=>({dispatchGroup:{x:l[0],y:l[1],z:l[2]},outputs:[{dims:r?r(o):o,dataType:e[0].dataType}]}),getShaderSource:c=>Xu(c,e,t,o,i,l[1]===1&&l[2]===1,!1,n)}}});var Qu,Ju,Zu,Ya,Xa,el,tl,rl,nl,Qa,Ja=H(()=>{\"use strict\";_e();Ka();qa();Jt();Mr();Qu=(e,t,r,i,o,s)=>(e-1)*t+r+(i-1)*o+1-s,Ju=(e,t,r,i,o)=>{let s=Math.floor(e/2);t===\"SAME_UPPER\"?(r[i]=s,r[o]=e-s):t===\"SAME_LOWER\"&&(r[i]=e-s,r[o]=s)},Zu=(e,t,r,i,o,s,l,n,c,m)=>{let g=e.length-2,C=m.length===0;if(c.length===0)for(let b=0;b<g;++b)c.push(0);let x=e[0],$=t[n?3:1]*o;for(let b=0,w=e.length-g-(n?1:0);b<g;++b,++w){let v=e[w],I=C?v*l[b]:m[b],B=Qu(v,l[b],s[b],t[w],r[b],I);Ju(B,i,s,b,b+g),C&&m.push(l[b]*(v-1)+c[b]+(t[w]-1)*r[b]+1-s[b]-s[b+g])}m.splice(0,0,x),m.splice(n?3:1,0,$)},Ya=(e,t)=>{let r=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((x,$)=>x*$,1)===0){r.length=0;for(let x=2;x<t[1].dims.length;++x)r.push(t[1].dims[x])}let i=e.format===\"NHWC\";r.splice(0,0,t[1].dims[0]),r.splice(i?3:1,0,t[1].dims[1]);let o=e.pads.slice(),s=e.outputShape.slice(),l=e.outputPadding.slice(),n=t[0].dims,c=e.dilations.slice();if(c.reduce((x,$)=>x+$,0)===0){let x=t[0].dims.length-2;c=new Array(x).fill(1)}let m=e.strides.slice();if(m.reduce((x,$)=>x+$,0)===0){let x=t[0].dims.length-2;m=new Array(x).fill(1)}Zu(n,r,c,e.autoPad,e.group,o,m,i,l,s);let g=Object.assign({},e),C=e.cacheKey+[r.join(\"n,\"),o.join(\",\"),m.join(\",\"),l.join(\",\"),s.join(\",\"),c.join(\",\")].join(\"_\");return Object.assign(g,{kernelShape:r,pads:o,outputPadding:l,outputShape:s,dilations:c,strides:m,cacheKey:C}),g},Xa=e=>{let t=Rr(e),r=e.format,i=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],o=e.dilations,s=e.group,l=e.kernelShape,n=e.pads,c=e.strides,m=e.wIsConst(),g=e.outputPadding,C=e.outputShape;return ae({autoPad:i,format:r,dilations:o,group:s,kernelShape:l,outputPadding:g,outputShape:C,pads:n,strides:c,wIsConst:m,...t})},el=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],i=e[1].dims[0];if(r!==i)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let o=e[1].dims[1]*t.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==o))throw new Error(\"invalid bias\");let s=e[0].dims.length-2;if(t.dilations.reduce((g,C)=>g+C,0)>0&&t.dilations.length!==s)throw new Error(`dilations should be ${s}D`);if(t.strides.reduce((g,C)=>g+C,0)>0&&t.strides.length!==s)throw new Error(`strides should be ${s}D`);if(t.pads.reduce((g,C)=>g+C,0)>0&&t.pads.length!==s*2)throw new Error(`pads should be ${s*2}D`);if(t.outputPadding.length!==s&&t.outputPadding.length!==0)throw new Error(`output_padding should be ${s}D`);if(t.kernelShape.reduce((g,C)=>g+C,0)>0&&t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(t.outputShape.length!==0&&t.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},tl=[2,3,1,0],rl=(e,t,r)=>{let i=Ya(r,t),o=r.format===\"NHWC\",s=t.length===3;if(i.group!==1){e.compute($n(t,i));return}let l=i.outputShape,n=l[o?1:2],c=l[o?2:3],m=l[o?3:1],g=t[1].dims[2],C=t[1].dims[3],x=t[0].dims[o?3:1],$=o?n*c:m,b=o?m:n*c,w=g*C*x,v=!0,I=e.kernelCustomData.wT??e.compute(Et(t[1].dataType,t[1].dims.length,tl),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=I);let B=[t[0],I];s&&(!o&&t[2].dims.length===1?B.push(t[2].reshape([t[2].dims[0],1,1])):B.push(t[2])),e.compute(ja(B,i,l,$,b,w,s,v),{inputs:B})},nl=(e,t)=>{let r=t.format===\"NHWC\",i=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];i.length===3&&i.push(e.inputs[2]);let o=t.kernelShape;(o.length===0||o[0]===0)&&(o=[e.inputs[1].dims[2]]);let s=t.dilations;(s.length===0||s[0]===0)&&(s=[1]);let l=t.strides;(l.length===0||l[0]===0)&&(l=[1]);let n=t.pads;n.length===0&&(n=[0,0]),n=[0,n[0],0,n[1]],l=[1].concat(l),s=[1].concat(s),o=[1].concat(o);let c=Ya({...t,pads:n,strides:l,dilations:s,kernelShape:o},i);e.compute($n(i,c,m=>r?[m[0],m[2],m[3]]:[m[0],m[1],m[3]]))},Qa=(e,t)=>{el(e.inputs,t),e.inputs[0].dims.length===3?nl(e,t):rl(e,e.inputs,t)}});var xn,kr,Za,ol,al,Cn,Sn,il,ei,ti,ri=H(()=>{\"use strict\";me();_e();$e();xn=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",kr=\"(\"+xn+\")+\",Za=\"^\"+kr+\"$\",ol=\"(\"+kr+\",)*\"+kr,al=\"^\"+ol+\"$\",Cn=class{constructor(t=-1){this.symbolToIndices=new Map,this.inputIndex=t}addSymbol(t,r){let i=this.symbolToIndices.get(t);i===void 0?i=[r]:i.push(r),this.symbolToIndices.set(t,i)}},Sn=class{constructor(t,r){this.equation=r;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[i,o]=r.includes(\"->\")?r.split(\"->\",2):[r,\"\"];if(!i.match(RegExp(al)))throw new Error(\"Invalid LHS term\");if(i.split(\",\").forEach((n,c)=>{let m=t[c].dims.slice();if(!n.match(RegExp(Za)))throw new Error(\"Invalid LHS term\");let g=this.processTerm(n,!0,m,c);this.lhs.push(g)}),o===\"\")o+=[...this.symbolToInfo.entries()].filter(([n,c])=>c.count===1||n===\"...\").map(([n])=>n).join(\"\");else if(!o.match(RegExp(kr)))throw new Error(\"Invalid RHS\");o.match(RegExp(xn,\"g\"))?.forEach(n=>{if(n===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let c=this.symbolToInfo.get(n);if(c===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(c.dimValue)}}),this.rhs=this.processTerm(o,!0,this.outputDims)}addSymbol(t,r,i){let o=this.symbolToInfo.get(t);if(o!==void 0){if(o.dimValue!==r&&o.count!==1)throw new Error(\"Dimension mismatch\");o.count++,o.inputIndices.push(i)}else o={count:1,dimValue:r,inputIndices:[i]};this.symbolToInfo.set(t,o)}processTerm(t,r,i,o=-1){let s=i.length,l=!1,n=[],c=0;if(!t.match(RegExp(Za))&&!r&&t!==\"\")throw new Error(\"Invalid LHS term\");let m=t.match(RegExp(xn,\"g\")),g=new Cn(o);return m?.forEach((C,x)=>{if(C===\"...\"){if(l)throw new Error(\"Only one ellipsis is allowed per input term\");l=!0;let $=s-m.length+1;if($<0)throw new Error(\"Ellipsis out of bounds\");if(n=i.slice(c,c+$),this.hasEllipsis){if(this.ellipsisDims.length!==n.length||this.ellipsisDims.toString()!==n.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(r)this.hasEllipsis=!0,this.ellipsisDims=n;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let b=0;b<n.length;b++){let w=String.fromCharCode(\"0\".charCodeAt(0)+x);g.addSymbol(w,x+b),this.addSymbol(w,i[c++],o)}}else g.addSymbol(C,x),this.addSymbol(C,i[c++],o)}),g}},il=(e,t)=>{let r=e[0].dataType,i=new Array(e.length);for(let z=0;z<e.length;++z)i[z]=K(`input${z}`,r,e[z].dims);let o=t.outputDims,s=D.size(o),l=se(\"output\",r,o),n=[],c=Array.from(t.rhs.symbolToIndices.keys()),m=\"var prod = 1.0;\",g=\"var sum = 0.0;\",C=\"sum += prod;\",x=[],$=[],b=[],w=[],v=t.symbolToInfo.size===c.length;t.symbolToInfo.forEach((z,M)=>{if(c.includes(M)){let G=c.indexOf(M);t.lhs.forEach((_,U)=>{if(z.inputIndices.includes(U)){let V=_.symbolToIndices.get(M);if(V===void 0)throw new Error(\"Invalid symbol error\");V.forEach(j=>{n.push(`${i[U].indicesSet(`input${U}Indices`,j,l.indicesGet(\"outputIndices\",G))}`)})}})}else t.lhs.forEach((G,_)=>{let U=t.symbolToInfo.get(M);if(U===void 0)throw new Error(\"Invalid symbol error\");if(U.inputIndices.includes(_)){let V=G.symbolToIndices.get(M);if(V===void 0)throw new Error(\"Invalid symbol error\");V.forEach(j=>{x.push(`${i[_].indicesSet(`input${_}Indices`,j,`${M}`)}`)}),w.push(`prod *= ${i[_].getByIndices(`input${_}Indices`)};`)}}),$.push(`for(var ${M}: u32 = 0; ${M} < ${t.symbolToInfo.get(M)?.dimValue}; ${M}++) {`),b.push(\"}\")});let I=v?[...n,`let sum = ${i.map((z,M)=>z.getByIndices(`input${M}Indices`)).join(\" * \")};`]:[...n,g,...$,...x,m,...w,C,...b],B=z=>`\n      ${z.declareVariables(...i,l)}\n\n      ${z.mainStart()}\n        ${z.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n        var outputIndices = ${l.offsetToIndices(\"global_idx\")};\n        ${i.map((M,G)=>`var input${G}Indices: ${i[G].type.indices};`).join(`\n`)}\n        ${I.join(`\n`)};\n        ${l.setByOffset(\"global_idx\",\"sum\")};\n      }`;return{name:\"Einsum\",shaderCache:{hint:t.equation},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:B}},ei=(e,t)=>{let r=new Sn(e.inputs,t.equation);e.compute(il(e.inputs,r))},ti=e=>{let t=e.equation.replace(/\\s+/g,\"\");return ae({equation:t})}});var sl,ni,ul,ll,oi,ai=H(()=>{\"use strict\";me();$e();sl=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),i=r.length<t.length?0:r.length-t.length,o=t.length<r.length?0:t.length-r.length;for(;i<r.length&&o<t.length;++i,++o)if(r[i]!==t[o]&&r[i]!==1&&t[o]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},ni=(e,t)=>{let r=e.length-t.length,i=[];for(let o=0;o<r;++o)i.push(e[o]);for(let o=0;o<t.length;++o)i.push(t[o]===1?e[o+r]:t[o]);return i},ul=(e,t)=>e.length>t.length?ni(e,t):ni(t,e),ll=e=>{let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),i=ul(t,r),o=D.size(i),s=e[0].dataType,l=K(\"input\",s,t),n=se(\"output\",s,i),c=m=>`\n  const inputShape = ${l.indices(...t)};\n  ${m.declareVariables(l,n)}\n  ${m.mainStart()}\n  ${m.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n    let outputIndices = ${n.offsetToIndices(\"global_idx\")};\n    var inputIndices: ${l.type.indices};\n    for (var i = 0; i < ${t.length}; i++) {\n      if (${l.indicesGet(\"inputShape\",\"i\")} == 1) {\n        ${l.indicesSet(\"inputIndices\",\"i\",0)}\n      } else {\n        ${l.indicesSet(\"inputIndices\",\"i\",n.indicesGet(\"outputIndices\",`i + ${i.length-t.length}`))}\n      }\n    }\n    ${n.setByOffset(\"global_idx\",l.getByIndices(\"inputIndices\"))}\n  }`;return{name:\"Expand\",shaderCache:{hint:`${i}`},getShaderSource:c,getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}})}},oi=e=>{sl(e.inputs),e.compute(ll(e.inputs),{inputs:[0]})}});var dl,cl,ii,si,ui=H(()=>{\"use strict\";me();_e();$e();dl=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},cl=(e,t)=>{let r=e[0].dims,i=e[1].dims,o=r.length,s=D.normalizeAxis(t.axis,o),l=r.slice(0);l.splice(s,1,...i);let n=r[s],c=D.size(l),m=K(\"data\",e[0].dataType,e[0].dims),g=K(\"inputIndices\",e[1].dataType,e[1].dims),C=se(\"output\",e[0].dataType,l),x=()=>{let b=i.length,w=`var indicesIndices  = ${g.type.indices}(0);`;for(let v=0;v<b;v++)w+=`${b>1?`indicesIndices[${v}]`:\"indicesIndices\"} = ${l.length>1?`outputIndices[${s+v}]`:\"outputIndices\"};`;w+=`\n        var idx = ${g.getByIndices(\"indicesIndices\")};\n        if (idx < 0) {\n          idx = idx + ${n};\n        }\n        var dataIndices = ${m.type.indices}(0);\n      `;for(let v=0,I=0;v<o;v++)v===s?(w+=`${o>1?`dataIndices[${v}]`:\"dataIndices\"} = u32(idx);`,I+=b):(w+=`${o>1?`dataIndices[${v}]`:\"dataIndices\"} = ${l.length>1?`outputIndices[${I}]`:\"outputIndices\"};`,I++);return w},$=b=>`\n      ${b.declareVariables(m,g,C)}\n      ${b.mainStart()}\n        ${b.guardAgainstOutOfBoundsWorkgroupSizes(c)}\n        let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n        ${x()};\n        let value = ${m.getByIndices(\"dataIndices\")};\n        ${C.setByOffset(\"global_idx\",\"value\")};\n      }`;return{name:\"Gather\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:l,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(c/64)}}),getShaderSource:$}},ii=e=>ae({axis:e.axis}),si=(e,t)=>{let r=e.inputs;dl(r),e.compute(cl(e.inputs,t))}});var pl,fl,li,di,ci=H(()=>{\"use strict\";me();_e();$e();pl=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},fl=(e,t)=>{let r=e[0].dims,i=e[0].dataType,o=r.length,s=D.computeStrides(r),l=D.size(r),n=e[1].dims,c=e[1].dataType,m=D.size(n),g=D.normalizeAxis(t.axis,o),C=r[g],x=n.slice(0),$=D.size(x),b=K(\"input\",i,r),w=K(\"indices\",c,[m]),v=se(\"output\",i,x),I=B=>`\n      const inputStrides = array<u32, ${s.length}>(${s.map(z=>`${z}u`).join(\",\")});\n      ${B.declareVariables(b,w,v)}\n      ${B.mainStart()}\n      ${B.guardAgainstOutOfBoundsWorkgroupSizes($)}\n\n      let outputIndices = ${v.offsetToIndices(\"global_idx\")};\n\n      var idx = ${w.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + ${C};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${r.length}; i++) {\n        if (i == ${g}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${v.indicesGet(\"outputIndices\",\"i\")} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${l}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;return{name:\"GatherElements\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:x,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil($/64)}}),getShaderSource:I}},li=e=>ae({axis:e.axis}),di=(e,t)=>{let r=e.inputs;pl(r),e.compute(fl(e.inputs,t))}});var ml,hl,gl,pi,fi,mi=H(()=>{\"use strict\";me();_e();$e();ml=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},hl=(e,t,r)=>{if(r.length===0)return\"0u\";let i=r.length===1&&e!==1||r.length===2&&r[0]!==e,o=r[r.length-1]!==t,s=\"0u\";return i||(s+=`+ m * ${r[r.length-1]}u`),o||(s+=\"+n\"),s},gl=(e,t)=>{let r=e[0].dims.slice(),i=e[1].dims.slice(),[o,s,l]=$r.getShapeOfGemmResult(r,t.transA,i,t.transB,e.length===3?e[2].dims:void 0),n=[o,s];if(!n)throw new Error(\"Can't use gemm on the given tensors\");let c=D.size(n),m=\"\";t.transA&&t.transB?m=\"value += a[k * M + m] * b[n * K + k];\":t.transA&&!t.transB?m=\"value += a[k * M + m] * b[k * N + n];\":!t.transA&&t.transB?m=\"value += a[m * K + k] * b[n * K + k];\":!t.transA&&!t.transB&&(m=\"value += a[m * K + k] * b[k * N + n];\");let g=Pe(e[0].dataType),C=t.alpha===1?\"\":\"value *= alpha;\",x=e.length===3?`value += beta * c[${hl(o,s,e[2].dims)}];`:\"\",$=[`@group(0) @binding(0) var<storage, read> a : array<${g}>;`,`@group(0) @binding(1) var<storage, read> b : array<${g}>;`];e.length===3&&$.push(`@group(0) @binding(2) var<storage, read> c : array<${g}>;`);let b=w=>`\n  const M: u32 = ${o}u;\n  const N: u32 = ${s}u;\n  const K: u32 = ${l}u;\n  const alpha = ${g}(${t.alpha});\n  const beta = ${g}(${t.beta});\n\n  ${$.join(`\n`)}\n  @group(0) @binding(${e.length}) var<storage, read_write> output : array<${g}>;\n\n  ${w.mainStart()}\n    ${w.guardAgainstOutOfBoundsWorkgroupSizes(c)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${g}(0);\n    for (var k: u32 = 0u; k<${l}u; k++) {\n      ${m}\n    }\n\n    ${C}\n    ${x}\n    output[global_id.x] = value;\n\n  }`;return{name:\"Gemm\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(c/64)}}),getShaderSource:b}},pi=(e,t)=>{ml(e.inputs),e.compute(gl(e.inputs,t))},fi=e=>ae(e)});var hi,yl,bl,gi,yi,bi=H(()=>{\"use strict\";me();_e();$e();hi={name:\"InstanceNormalization\"},yl=(e,t)=>{let r=e[0].dims,i=r,o=2,s=D.sizeToDimension(r,o),l=D.sizeFromDimension(r,o),n=r[1],c=K(\"x\",e[0].dataType,[r[0],r[1],l]),m=K(\"scale\",e[1].dataType,e[1].dims),g=K(\"bias\",e[2].dataType,e[2].dims),C=se(\"output\",e[0].dataType,[r[0],r[1],l]),x=[c,m,g,C],$=c.type.value,b=64,w=v=>`\n\n  const C: u32 = ${n};\n  const normSize: u32 = ${l};\n  const epsilon: f32 = ${t.epsilon};\n  var<workgroup> meanShared : ${$};\n  var<workgroup> squaredNormShared : ${$};\n  var<workgroup> workgroupShared : array<${$}, ${b}>;\n  const workgroupSize = ${b}u;\n  ${v.declareVariables(...x)}\n  ${v.mainStart(b)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${$} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${c.get(\"batch\",\"channel\",\"h\")};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${$}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${c.get(\"batch\",\"channel\",\"h\")} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${$}(normSize) + epsilon);\n    let channelScale = invStdDev * ${m.getByOffset(\"channel\")};\n    let channelShift = ${g.getByOffset(\"channel\")} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${c.get(\"batch\",\"channel\",\"h\")} * channelScale + channelShift;\n      ${C.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`;return{...hi,shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:s}}),getShaderSource:w}},bl=(e,t)=>{let r=e[0].dims,i=r,o=D.size(i),s=r[0],l=r[r.length-1],n=D.sizeFromDimension(r,1)/l,c=Pe(e[0].dataType),m=l*s,g=C=>`\n  const N: u32 = ${s};\n  const H: u32 = ${n};\n  const C: u32 = ${l};\n  const normSizeTyped: ${c} = ${n};\n  const imageSize: u32 = ${n*l};\n  const epsilon: f32 = ${t.epsilon};\n\n  @group(0) @binding(0) var<storage, read> x : array<${c}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${c}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${c}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${c}>;\n\n  ${C.mainStart()}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    // offset is channel num * N\n    let offset = currentImageNumber * imageSize;\n    if (offset >= ${o}) { return; }\n    var mean: ${c} = 0;\n\n    for (var i: u32 = 0u; i < H; i++) {\n        mean = mean + x[offset + i * C + currentChannelNumber];\n    }\n    mean = mean / normSizeTyped;\n\n    var squaredNorm: ${c} = 0;\n    for (var i: u32 = 0u; i < H; i++) {\n        let deviation: f32 = x[offset + i * C + currentChannelNumber] - mean;\n        squaredNorm = squaredNorm + deviation * deviation;\n    }\n    let invStdDev = 1 / sqrt(squaredNorm / normSizeTyped + epsilon);\n    let channelScale = invStdDev * scale[currentChannelNumber];\n    let channelShift = bias[currentChannelNumber] - mean * channelScale;\n    for (var i: u32 = 0u; i < H; i++) {\n        let currentOffset = offset + i * C + currentChannelNumber;\n        output[currentOffset] = x[currentOffset] * channelScale + channelShift;\n    }\n  }`;return{...hi,shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(m/64)}}),getShaderSource:g}},gi=e=>ae({epsilon:e.epsilon,format:e.format}),yi=(e,t)=>{t.format===\"NHWC\"?e.compute(bl(e.inputs,t)):e.compute(yl(e.inputs,t))}});var wl,vl,wi,vi,$i=H(()=>{\"use strict\";ke();me();_e();$e();wl=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\");if(e[0].dataType!==1||e[1].dataType!==1)throw new Error(\"inputs should be float type\")},vl=(e,t,r)=>{let i=e[0].dims,o=e[1],s=e[2],l=i,n=D.size(l),c=D.normalizeAxis(t.axis,i.length),m=D.sizeToDimension(i,c),g=D.sizeFromDimension(i,c),C=D.size(o.dims),x=s?D.size(s.dims):0;if(C!==g||s&&x!==g)throw new Error(`Size of X.shape()[axis:] == ${g}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${C} and bias size of ${x}`);let $=[];for(let M=0;M<i.length;++M)M<c?$.push(i[M]):$.push(1);let b=Pe(e[0].dataType),w=r>1,v=r>2,I=0,B=M=>`\n  const normSize: u32 = ${g};\n  const normSizeTyped: ${b} = ${g};\n  const epsilon: f32 = ${t.epsilon};\n\n  @group(0) @binding(${I++}) var<storage, read> x : array<${b}>;\n  @group(0) @binding(${I++}) var<storage, read> scale : array<${b}>;\n  ${s?`@group(0) @binding(${I++}) var<storage, read> bias : array<${b}>;`:\"\"}\n  @group(0) @binding(${I++}) var<storage, read_write> output : array<${b}>;\n  ${w?`@group(0) @binding(${I++}) var<storage, read_write> meanDataOutput : array<${b}>`:\"\"};\n  ${v?`@group(0) @binding(${I++}) var<storage, read_write> invStdOutput : array<${b}>`:\"\"};\n\n  ${M.mainStart()}\n    let offset = global_idx * normSize;\n    if (offset >= ${n}) { return; }\n    var mean: ${b} = 0;\n    var meanSquare: ${b} = 0;\n\n    for (var h: u32 = 0u; h < normSize; h++) {\n      mean = mean + x[h + offset];\n      meanSquare = meanSquare + x[h + offset] * x[h + offset];\n    }\n    mean = mean / normSizeTyped;\n    meanSquare = sqrt(meanSquare / normSizeTyped - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSize; j++) {\n      output[j + offset] = (x[j + offset] - mean) / meanSquare * scale[j] ${s?\"+ bias[j]\":\"\"};\n    }\n\n    ${w?\"meanDataOutput[global_idx] = mean\":\"\"};\n    ${v?\"invStdOutput[global_idx] = 1 / meanSquare\":\"\"};\n  }`,z=[{dims:l,dataType:e[0].dataType}];return w&&z.push({dims:$,dataType:e[0].dataType}),v&&z.push({dims:$,dataType:e[0].dataType}),{name:\"LayerNormalization\",shaderCache:{hint:`${t.cacheKey}|${r}|${e.length}`},getRunData:()=>({outputs:z,dispatchGroup:{x:Math.ceil(m/64)}}),getShaderSource:B}},wi=e=>ae({axis:e.axis,epsilon:e.epsilon}),vi=(e,t)=>{wl(e.inputs),e.compute(vl(e.inputs,t,e.outputCount))}});var $l,xi,Ci=H(()=>{\"use strict\";me();tr();$l=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},xi=e=>{$l(e.inputs);let t=Ze.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error(\"Can't use matmul on the given tensors\");e.compute(Br(e.inputs,{activation:\"\",activationCacheKey:\"\"},t))}});var xl,Cl,Sl,Al,Il,Tl,El,Ol,_l,Si,Ai,Ii=H(()=>{\"use strict\";ke();me();_e();$e();xl=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let t=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(t=e[3].dims[0]*2===e[1].dims[0]),!t)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},Cl=(e,t,r,i,o,s,l)=>{let n=r.length,c=\"\";for(let m=n-1;m>=0;--m)c+=`\n            k = i32(${e.indicesGet(\"indices\",m)}) - ${o[m]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${r[m]}) {\n              break;\n            }\n            offset += k * ${i[m]};\n        `;return`\n          value = ${s}(${l});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${c}\n            value = x[offset];\n          }\n      `},Sl=(e,t,r,i,o)=>{let s=r.length,l=\"\";for(let n=s-1;n>=0;--n)l+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${o[n]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2*(r[n]-1)};\n                  k = k % _2n_1;\n                  if(k >= ${r[n]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${i[n]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${l}\n              value = x[offset];\n          `},Al=(e,t,r,i,o)=>{let s=r.length,l=\"\";for(let n=s-1;n>=0;--n)l+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${o[n]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${r[n]}) {\n                  k = ${r[n]-1};\n                }\n                offset += k * ${i[n]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${l}\n              value = x[offset];\n          `},Il=(e,t,r,i,o)=>{let s=r.length,l=\"\";for(let n=s-1;n>=0;--n)l+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${o[n]};\n                if (k < 0)  {\n                  k += ${r[n]};\n                }\n                if (k >= ${r[n]}) {\n                  k -= ${r[n]};\n                }\n                offset += k * ${i[n]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${l}\n              value = x[offset];\n          `},Tl=(e,t,r,i,o,s)=>{switch(o.mode){case 0:return Cl(e,t,r,i,o.pads,s,o.value);case 1:return Sl(e,t,r,i,o.pads);case 2:return Al(e,t,r,i,o.pads);case 3:return Il(e,t,r,i,o.pads);default:throw new Error(\"Invalid mode\")}},El=(e,t,r,i)=>{let o=t[0].dims,s=D.padShape(o.slice(),r.pads),l=D.size(s),n=D.computeStrides(o),c=se(\"output\",t[0].dataType,s),m=K(\"x\",t[0].dataType,o),g=Tl(c,s,o,n,r,i);return`\n              ${e.declareVariables(m,c)}\n              ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n\n              let indices = ${c.offsetToIndices(\"global_idx\")};\n\n              var value = ${i}(0);\n              ${g}\n              output[global_idx] = value;\n          }`},Ol=(e,t)=>{let r=D.padShape(e[0].dims.slice(),t.pads);return{name:\"Pad\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(D.size(r)/64)}}),getShaderSource:i=>El(i,e,t,\"f32\")}},_l=(e,t)=>{if(e.length>1){let r=e[1].getBigInt64Array(),i=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,o=e[0].dims.length,s=new Int32Array(2*o).fill(0);if(e.length>=4){let n=e[3].getBigInt64Array();for(let c=0;c<n.length;c++)s[Number(n[c])]=Number(r[c]),s[Number(n[c])+o]=Number(r[c+n.length])}else r.forEach((n,c)=>s[Number(c)]=Number(n));let l=[];return s.forEach(n=>l.push(n)),ae({mode:t.mode,value:i,pads:l})}else return t},Si=(e,t)=>{xl(e.inputs);let r=_l(e.inputs,t);e.compute(Ol(e.inputs,r),{inputs:[0]})},Ai=e=>{let t=e.mode,r=e.value,i=e.pads;return ae({mode:t,value:r,pads:i})}});var Dr,Ti,Ei,Oi,_i,Pi,Ri,Bi,Mi,ki,Di,Wi,zi,Gi,Ui,Ni=H(()=>{\"use strict\";me();_e();$e();Dr=e=>{if(!e||e.length!==1)throw new Error(\"Pool ops requires 1 input.\");if(e[0].dims.length!==4)throw new Error(\"Pool ops supports 2-D inputs only for now.\")},Ti=(e,t,r)=>{let i=t.format===\"NHWC\",o=i?[e.dims[0],e.dims[3],e.dims[1],e.dims[2]]:e.dims.slice(),s=Object.hasOwnProperty.call(t,\"dilations\"),l=t.kernelShape.slice(),n=t.strides.slice(),c=s?t.dilations.slice():[],m=t.pads.slice();bt.adjustPoolAttributes(r,o,l,n,c,m);let g=bt.computePoolOutputShape(r,o,n,c,l,m,t.autoPad),C=Object.assign({},t);return s?Object.assign(C,{kernelShape:l,strides:n,pads:m,dilations:c,cacheKey:t.cacheKey}):Object.assign(C,{kernelShape:l,strides:n,pads:m,cacheKey:t.cacheKey}),[C,i?[g[0],g[2],g[3],g[1]]:g]},Ei=(e,t,r,i,o,s,l,n)=>{let c=o.format===\"NHWC\",m=r,g=t.type.value,C=m.length,x=D.size(i),$=se(\"output\",t.type.tensor,i);if(o.kernelShape.length<=2){let b=o.kernelShape[o.kernelShape.length-1],w=o.strides[o.strides.length-1],v=o.pads[o.pads.length/2-1],I=o.pads[o.pads.length-1],B=C-(c?2:1),z=\"\",M=\"\",G=\"\";if(v+I!==0?z=`\n              for (var i: u32 = 0u; i < ${b}u; i++) {\n                xIndices[${B}] = indices[${B}] * ${w} - ${v} + i;\n                if (xIndices[${B}] < 0 || xIndices[${B}] >= ${m[B]}) {\n                  pad++;\n                  continue;\n                }\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`:z=`\n              for (var i: u32 = 0u; i < ${b}u; i++) {\n                xIndices[${B}] = indices[${B}] * ${w} - ${v} + i;\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`,o.kernelShape.length===2){let U=o.kernelShape[o.kernelShape.length-2],V=o.strides[o.strides.length-2],j=o.pads[o.pads.length/2-2],le=o.pads[o.pads.length-2],R=C-(c?3:2),X=m[R];j+le!==0?M=`\n                for (var j: u32 = 0u; j < ${U}u; j++) {\n                  xIndices[${R}] = indices[${R}] * ${V} - ${j} + j;\n                  if (xIndices[${R}] < 0 || xIndices[${R}] >= ${X}) {\n                    pad+= ${b};\n                    continue;\n                  }\n              `:M=`\n                for (var j: u32 = 0u; j < ${U}u; j++) {\n                  xIndices[${R}] = indices[${R}] * ${V} - ${j} + j;\n                `,G=`\n              }\n            `}return`\n            ${e.declareVariables(t,$)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(x)}\n\n              let indices = ${$.offsetToIndices(\"global_idx\")};\n              var xIndices = ${$.offsetToIndices(\"global_idx\")};\n\n              var value: ${g} = ${g}(${n});\n              var pad = 0;\n              ${M}\n              ${z}\n              ${G}\n              ${l}\n\n              output[global_idx] = value;\n            }`}else{if(c)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let b=D.size(o.kernelShape),w=D.computeStrides(o.kernelShape),v=w.length,I=o.pads.length,B=o.pads.reduce((G,_)=>G+_),z=\"\";return B?z=`\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`:z=`\n              }\n              let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n              ${s}\n            `,`\n            ${e.declareVariables(t,$)}\n\n            const pads = array<u32, ${I}>(${o.pads.map(G=>`${G}u`).join(\",\")});\n            const inputDims = array<u32, ${C}>(${m.map(G=>`${G}u`).join(\",\")});\n            const kernelStrides = array<u32, ${v}>(${w.map(G=>`${G}u`).join(\",\")});\n            const strides = array<u32, ${v}>(${o.strides.map(G=>`${G}u`).join(\",\")});\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(x)}\n\n              let indices = ${$.offsetToIndices(\"global_idx\")};\n              let xIndices = ${$.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${v}>;\n\n              var value = ${$.type.value}(${n});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${b}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${v-1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${v-1}] = offset;\n\n                isPad = false;\n                for (var j = ${C-v}u; j < ${C}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${C-v}u]\n                    + offsets[j - ${C-v}u] - pads[j - 2u];\n                  ${z}\n              }\n              ${l}\n\n              output[global_idx] = value;\n            }`}},Oi=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),_i=(e,t,r,i)=>{let[o,s]=Ti(t,i,r),l=D.size(o.kernelShape),n=K(\"x\",t.dataType,t.dims),c=n.type.value,m=\"value += x_val;\",g=\"\";return o.countIncludePad?g+=`value /= ${c}(${l});`:g+=`value /= ${c}(${l} - pad);`,{name:e,shaderCache:{hint:i.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(D.size(s)/64)}}),getShaderSource:C=>Ei(C,n,t.dims,s,o,m,g,\"0.0\")}},Pi=e=>{let t=e.count_include_pad!==0,r=Oi(e);if(r.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return ae({countIncludePad:t,...r})},Ri=(e,t)=>{Dr(e.inputs),e.compute(_i(\"AveragePool\",e.inputs[0],!1,t))},Bi={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},Mi=e=>{let t=e.format;return{format:t,...Bi,cacheKey:t}},ki=(e,t)=>{Dr(e.inputs),e.compute(_i(\"GlobalAveragePool\",e.inputs[0],!0,t))},Di=(e,t,r,i)=>{let[o,s]=Ti(t,i,r),l=`\n      value = max(x_val, value);\n    `,n=\"\",c=K(\"x\",t.dataType,t.dims);return{name:e,shaderCache:{hint:i.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(D.size(s)/64)}}),getShaderSource:m=>Ei(m,c,t.dims,s,o,l,n,\"-1e5\")}},Wi=(e,t)=>{Dr(e.inputs),e.compute(Di(\"MaxPool\",e.inputs[0],!1,t))},zi=e=>{let t=e.storage_order,r=e.dilations,i=Oi(e);if(t!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(i.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return ae({storageOrder:t,dilations:r,...i})},Gi=e=>{let t=e.format;return{format:t,...Bi,cacheKey:t}},Ui=(e,t)=>{Dr(e.inputs),e.compute(Di(\"GlobalMaxPool\",e.inputs[0],!0,t))}});var An=H(()=>{\"use strict\"});var Vi=H(()=>{\"use strict\";An()});var Fi,Hi=H(()=>{\"use strict\";Fi=\"1.17.0\"});var Li,In,ji=H(()=>{\"use strict\";Hi();Li=\"warning\",In={wasm:{},webgl:{},webgpu:{},versions:{common:Fi},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);Li=e}},get logLevel(){return Li}};Object.defineProperty(In,\"logLevel\",{enumerable:!0})});var Ki,qi=H(()=>{\"use strict\";ji();Ki=In});var Yi=H(()=>{\"use strict\"});var Xi=H(()=>{\"use strict\";Wr()});var Ji=H(()=>{\"use strict\"});var Zi=H(()=>{\"use strict\";Wr()});var Wr=H(()=>{\"use strict\";Yi();Xi();Ji();Zi()});var Tn=H(()=>{\"use strict\";Wr()});var es=H(()=>{\"use strict\";An();Tn()});var ts=H(()=>{\"use strict\";es()});var rs=H(()=>{\"use strict\"});var ns=H(()=>{\"use strict\"});var os=H(()=>{\"use strict\";ns()});var as=H(()=>{\"use strict\";Vi();qi();ts();Tn();rs();os()});var Rl,Bl,is,ss=H(()=>{\"use strict\";as();ke();$e();Rl=(e,t,r)=>{let i=e===t,o=e<t&&r<0,s=e>t&&r>0;if(i||o||s)throw new Error(\"Range these inputs' contents are invalid.\")},Bl=(e,t,r,i)=>{let o=Math.abs(Math.ceil((t-e)/r)),s=[o],l=o,n=se(\"output\",i,s),c=n.type.storage,m=g=>`\n        ${g.declareVariables(n)}\n        ${g.mainStart()}\n        ${g.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n        output[global_idx] = ${c}(${e}) + ${c}(global_idx) * ${c}(${r});\n      }`;return{name:\"Range\",shaderCache:{hint:[e,t,r].map(g=>g.toString()).join(\"_\")},getShaderSource:m,getRunData:()=>({outputs:[{dims:s,dataType:i}],dispatchGroup:{x:Math.ceil(l/64)}})}},is=e=>{let t=0,r=0,i=0;e.inputs[0].dataType===6?(t=e.inputs[0].getInt32Array()[0],r=e.inputs[1].getInt32Array()[0],i=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(t=e.inputs[0].getFloat32Array()[0],r=e.inputs[1].getFloat32Array()[0],i=e.inputs[2].getFloat32Array()[0]),Ki.webgpu.validateInputContent&&Rl(t,r,i),e.compute(Bl(t,r,i,e.inputs[0].dataType),{inputs:[]})}});var Ml,kl,Dl,Wl,zl,Gl,Ul,Nl,Vl,Fl,Hl,Ll,jl,Kl,ql,us,ls,ds=H(()=>{\"use strict\";me();_e();$e();Ml=(e,t)=>{if(e.every(r=>r>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(t.mode===\"linear\"){if(!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for linear mode\")}else if(t.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},kl=(e,t,r)=>{t.every(o=>o>=0&&o<r||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let i=new Array(r).fill(1);return t.forEach((o,s)=>i[o]=e[s]),i},Dl=(e,t,r,i,o,s)=>{let[l,n,c]=r>10?[1,2,3]:[-1,e.length>1?1:-1,-1],m=e[0].dims.length;if(l>0&&e.length>l&&e[l].dims.length>0)e[l].getFloat32Array().forEach(g=>s.push(g));else if(t.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(n>0&&e.length>n&&e[n].dims.length>0){if(e[n].getFloat32Array().forEach(g=>i.push(g)),i.length!==0&&i.length!==m&&r>=18&&i.length!==t.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");Ml(i,t),t.axes.length>0&&kl(i,t.axes,m).forEach((g,C)=>i[C]=g)}if(c>0&&e.length>c&&(e[c].getBigInt64Array().forEach(g=>o.push(Number(g))),o.length!==m||r>=18&&o.length===t.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(t.axes.length>0){if(i.length!==t.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(o.length!==t.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof i<\"u\"&&typeof o<\"u\"&&i.length>0&&o.length>m)throw new Error(\"Resize requires only of scales or sizes to be specified\")},Wl=e=>\"fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { \"+(()=>{switch(e){case\"asymmetric\":return\"return xResized / xScale;\";case\"pytorch_half_pixel\":return\"if (lengthResized > 1) {                     return (xResized + 0.5) / xScale - 0.5;                   } else {                     return 0.0;                   }\";case\"tf_half_pixel_for_nn\":return\"return (xResized + 0.5) / xScale;\";case\"align_corners\":return\"if (lengthResized == 1) {                     return 0.0;                   } else {                     return xResized * (lengthOriginal - 1) / (lengthResized - 1);                   }\";case\"tf_crop_and_resize\":return\"if (lengthResized > 1) {                     return roiStart * (lengthOriginal - 1) +                           (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1);                   } else {                     return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1);                   }\";case\"half_pixel_symmetric\":return[\"const outputWidth = xScale * lengthResized;\",\"const adjustment = lengthResized / outputWidth;\",\"const center = lengthOriginal / 2;\",\"const offset = center * (1 - adjustment);\",\"return offset + ((xResized + 0.5) / xScale) - 0.5;\"].join(`\n`);case\"half_pixel\":return\"return ((xResized + 0.5) / xScale) - 0.5;\";default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",zl=(e,t)=>\"fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {\"+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(t<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",Gl=(e,t,r)=>{let i=new Array(r).fill(0).concat(new Array(r).fill(1)),o=e.length===0?i:e.slice();return t.length>0?(t.forEach((s,l)=>{i[s]=o[l],i[l+r]=o[t.length+l]}),i):o},Ul=(e,t,r,i)=>{let o=[];if(r.length>0)if(i.length>0){if(e.forEach(s=>o.push(s)),Math.max(...i)>e.length)throw new Error(\"axes is out of bound\");i.forEach((s,l)=>o[s]=r[l])}else r.forEach(s=>o.push(s));else{if(t.length===0)throw new Error(\"Resize requires either scales or sizes.\");o=e.map((s,l)=>Math.round(s*t[l]))}return o},Nl=(e,t,r,i)=>{let o=(()=>{switch(i.keepAspectRatioPolicy){case\"not_larger\":return i.axes.length>0?Math.min(...i.axes.map(l=>r[l]),Number.MAX_VALUE):Math.min(...r,Number.MAX_VALUE);case\"not_smaller\":return i.axes.length>0?Math.max(...i.axes.map(l=>r[l]),Number.MIN_VALUE):Math.max(...r,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${i.keepAspectRatioPolicy} is not supported`)}})();r.fill(1,0,r.length);let s=e.slice();return i.axes.length>0?(i.axes.forEach(l=>r[l]=o),i.axes.forEach(l=>s[l]=Math.round(e[l]*r[l]))):(r.fill(o,0,r.length),s.forEach((l,n)=>s[n]=Math.round(l*r[n]))),s},Vl=(e,t,r,i,o)=>`\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${e.type.indices}) -> array<f32, ${r.length}> {\n      const inputShape = array<u32, ${t.length}>(${t.map(s=>`${s}u`).join(\",\")});\n      const outputShape = array<u32, ${r.length}>(${r.map(s=>`${s}u`).join(\",\")});\n      const scales = array<f32, ${i.length}>(${i.map(s=>`${s}f`).join(\",\")});\n      const roi = array<f32, ${o.length}>(${o.map(s=>`${s}f`).join(\",\")});\n      var originalIndices: array<f32, ${r.length}>;\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var outputIndex = ${r.length===1?\"outputIndices\":\"outputIndices[i]\"};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${t.length}]);\n        }\n      }\n      return originalIndices;\n    }`,Fl=(e,t,r,i,o,s,l)=>`\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n        const inputShape = array<u32, ${r.length}>(${r.map(n=>`${n}u`).join(\",\")});\n        const outputShape = array<u32, ${i.length}>(${i.map(n=>`${n}u`).join(\",\")});\n        const scales = array<f32, ${o.length}>(${o.map(n=>`${n}f`).join(\",\")});\n        const roi = array<f32, ${s.length}>(${s.map(n=>`${n}f`).join(\",\")});\n        var inputIndices: ${e.type.indices};\n        for (var i:u32 = 0; i < ${i.length}; i++) {\n          var outputIndex = ${i.length===1?\"outputIndices\":\"outputIndices[i]\"};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${r.length}]);\n            if (!${l} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${e.indicesSet(\"inputIndices\",\"i\",\"inputIndex\")}\n        }\n        return inputIndices;\n    }`,Hl=(e,t)=>`\n    fn checkInputIndices(inputIndices: ${e.type.indices}) -> bool {\n      const inputShape = array<u32, ${t.length}>(${t.map(r=>`${r}u`).join(\",\")});\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var inputIndex = ${t.length===1?\"inputIndices\":\"inputIndices[i]\"};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`,Ll=(e,t,r,i,o,s,l)=>{let[n,c,m,g]=r.length===2?[-1,0,1,-1]:o[1]===1?[0,2,3,1]:[0,1,2,3];return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${e.type.indices};\n      inputIndices[${c}] = max(0, min(row, ${r[c]} - 1));\n      inputIndices[${m}] = max(0, min(col, ${r[m]} - 1));\n      if (${r.length} > 2) {\n        inputIndices[${g}] = channel;\n        inputIndices[${n}] = batch;\n      };\n      return input[${e.indicesToOffset(\"inputIndices\")}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${c}];\n      var col:f32 = originalIndices[${m}];\n      if (${s} && (row < 0 || row > (${r[c]} - 1) || col < 0 || col > ${r[m]} - 1)) {\n        return ${l};\n      }\n      row = max(0, min(row, ${r[c]} - 1));\n      col = max(0, min(col, ${r[m]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${r.length>2}) {\n        channel = u32(originalIndices[${g}]);\n        batch = u32(originalIndices[${n}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},jl=(e,t,r,i,o,s,l,n,c,m)=>{let[g,C]=r.length===2?[0,1]:o[1]===1?[2,3]:[1,2],x=$=>{let b=$===g?\"row\":\"col\";return`\n      fn ${b}CubicInterpolation(inputIndices: ${e.type.indices}, outputIndices: ${t.type.indices}) -> f32 {\n        var outputIndex = ${i.length===1?\"outputIndices\":`outputIndices[${$}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${o[$]},\n        f32(${i[$]}), f32(${r[$]}), ${s[$]}, ${s[$]} + ${r.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${n} && (originalIdx < 0 || originalIdx > (${r[$]} - 1))) {\n          return ${c};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${b}: f32 = originalIdx + f32(i);\n          if (${b} < 0 || ${b} >= ${r[$]}) {\n            if (${m}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${n}) {\n              return ${c};\n            } else {\n              ${b} = max(0, min(${b}, ${r[$]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${e.type.indices} = inputIndices;\n          inputIndicesCopy[${$}] = u32(${b});\n          data[i + 1] = ${$===g?`input[${e.indicesToOffset(\"inputIndicesCopy\")}];`:`\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${x(g)};\n    ${x(C)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${l} * onePlusAbsS - 5 * ${l}) * onePlusAbsS + 8 * ${l}) * onePlusAbsS - 4 * ${l};\n    coeffs[1] = ((${l} + 2) * absS - (${l} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${l} + 2) * oneMinusAbsS - (${l} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${l} * twoMinusAbsS - 5 * ${l}) * twoMinusAbsS + 8 * ${l}) * twoMinusAbsS - 4 * ${l};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n    var inputIndices: ${e.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `},Kl=(e,t,r,i,o,s)=>{let l=e.dims,n=Gl(s,t.axes,l.length),c=Ul(l,i,o,t.axes),m=i.slice();i.length===0&&(m=l.map((v,I)=>v===0?1:c[I]/v),t.keepAspectRatioPolicy!==\"stretch\"&&(c=Nl(l,c,m,t)));let g=se(\"output\",e.dataType,c),C=K(\"input\",e.dataType,l),x=D.size(c),$=l.length===c.length&&l.every((v,I)=>v===c[I]),b=t.coordinateTransformMode===\"tf_crop_and_resize\",w=v=>`\n      ${Wl(t.coordinateTransformMode)};\n      ${(()=>{switch(t.mode){case\"nearest\":return`\n              ${Hl(C,l)};\n              ${zl(t.nearestMode,r)};\n              ${Fl(C,g,l,c,m,n,b)};\n              `;case\"linear\":return`\n              ${Vl(g,l,c,m,n)};\n              ${Ll(C,g,l,c,m,b,t.extrapolationValue)};\n              `;case\"cubic\":return`\n            ${jl(C,g,l,c,m,n,t.cubicCoeffA,b,t.extrapolationValue,t.excludeOutside)};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      ${v.declareVariables(C,g)}\n      ${v.mainStart()}\n        ${v.guardAgainstOutOfBoundsWorkgroupSizes(x)}\n        if (${$}) {\n          output[global_idx] = input[global_idx];\n        } else {\n          let outputIndices = ${g.offsetToIndices(\"global_idx\")};\n          var inputIndices: ${C.type.indices};\n          ${(()=>{switch(t.mode){case\"nearest\":return`inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                  if (checkInputIndices(inputIndices)) {\n                    output[global_idx] = input[${C.indicesToOffset(\"inputIndices\")}];\n                  } else {\n                    output[global_idx] = ${t.extrapolationValue};\n                  }`;case\"linear\":return\"output[global_idx] = bilinearInterpolation(outputIndices);\";case\"cubic\":return\"output[global_idx] = bicubicInterpolation(outputIndices);\";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n        }\n      }`;return{name:\"Resize\",shaderCache:{hint:`${t.cacheKey}|${r}|${m.length>0?m:\"\"}|${o.length>0?o:\"\"}`},getShaderSource:w,getRunData:()=>({outputs:[{dims:c,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(x/64)}})}},ql=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},us=(e,t)=>{let r=[],i=[],o=[],s=ql(e);Dl(e.inputs,t,s,r,i,o),e.compute(Kl(e.inputs[0],t,s,r,i,o),{inputs:[0]})},ls=e=>{let t=e.antialias,r=e.axes,i=e.coordinateTransformMode,o=e.cubicCoeffA,s=e.excludeOutside!==0,l=e.extrapolationValue,n=e.keepAspectRatioPolicy,c=e.mode,m=e.nearestMode===\"\"?\"simple\":e.nearestMode;return ae({antialias:t,axes:r,coordinateTransformMode:i,cubicCoeffA:o,excludeOutside:s,extrapolationValue:l,keepAspectRatioPolicy:n,mode:c,nearestMode:m})}});var Yl,Xl,cs,ps,fs=H(()=>{\"use strict\";ke();me();_e();$e();Yl=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");if(e[0].dataType!==1||e[1].dataType!==1)throw new Error(\"inputs should be float type\");let t=e[0],r=e[1],i=e[2];if(t.dataType!==r.dataType||t.dataType!==i.dataType)throw new Error(\"All inputs must have the same data type\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let o=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(r.dims[r.dims.length-1]!==o)throw new Error(\"Skip must have the same hidden size as input\");if(r.dims[r.dims.length-2]!==s)throw new Error(\"Skip must have the same sequence length as input\");if(i.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(i.dims[i.dims.length-1]!==o)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let l=e[3];if(l.dims.length!==1)throw new Error(\"Beta must be 1D\");if(l.dims[l.dims.length-1]!==o)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let l=e[4];if(l.dims.length!==1)throw new Error(\"Bias must be 1D\");if(l.dims[l.dims.length-1]!==o)throw new Error(\"Bias must have the same hidden size as input\")}},Xl=(e,t,r,i)=>{let o=e[0].dims,s=D.size(o),l=o,n=s,c=o.slice(-1)[0],m=i?o.slice(0,-1).concat(1):[],g=e.length>3,C=e.length>4,x=Pe(e[0].dataType),$=i&&r>1,b=i&&r>2,w=r>3,v=0,I=z=>`\n      const hiddenSize: u32 = ${c};\n      const epsilon: f32 = ${t.epsilon};\n\n      @group(0) @binding(${v++}) var<storage, read> x : array<${x}>;\n      @group(0) @binding(${v++}) var<storage, read> skip : array<${x}>;\n      @group(0) @binding(${v++}) var<storage, read> gamma : array<${x}>;\n      ${g?`@group(0) @binding(${v++}) var<storage, read> beta : array<${x}>;`:\"\"}\n      ${C?`@group(0) @binding(${v++}) var<storage, read> bias : array<${x}>;`:\"\"}\n      @group(0) @binding(${v++}) var<storage, read_write> output : array<${x}>;\n      ${$?`@group(0) @binding(${v++}) var<storage, read_write> meanOutput : array<${x}>;`:\"\"}\n      ${b?`@group(0) @binding(${v++}) var<storage, read_write> invStdOutput : array<${x}>;`:\"\"}\n      ${w?`@group(0) @binding(${v++}) var<storage, read_write> inputSkipBiasSum : array<${x}>;`:\"\"}\n\n      ${z.mainStart()}\n        ${z.guardAgainstOutOfBoundsWorkgroupSizes(n/c)}\n        let offset = global_idx * hiddenSize;\n        var sum: f32 = 0.0;\n        var squareSum: f32 = 0.0;\n        for (var i: u32 = 0; i < hiddenSize; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${C?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${w?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          sum += value;\n          squareSum += value * value;\n        }\n        let mean: f32 = sum / f32(hiddenSize);\n        let variance: f32 = sqrt(squareSum / f32(hiddenSize) - mean * mean + epsilon);\n        ${$?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${b?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSize; i++) {\n          output[offset + i] = (output[offset + i] - mean) / variance * gamma[i] + ${g?\"beta[i]\":\"0.0\"};\n        }\n      }`,B=[{dims:l,dataType:e[0].dataType}];return r>1&&B.push({dims:m,dataType:e[0].dataType}),r>2&&B.push({dims:m,dataType:e[0].dataType}),r>3&&B.push({dims:o,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:t.cacheKey},getShaderSource:I,getRunData:()=>({outputs:B,dispatchGroup:{x:Math.ceil(n/c/64)}})}},cs=(e,t)=>{Yl(e.inputs);let i=[0];e.outputCount>1&&i.push(-3),e.outputCount>2&&i.push(-3),e.outputCount>3&&i.push(3),e.compute(Xl(e.inputs,t,e.outputCount,!1),{outputs:i})},ps=e=>{let t=e.epsilon;return ae({epsilon:t})}});var Ql,zr,Jl,ms,Zl,ed,hs,gs,ys=H(()=>{\"use strict\";ke();me();_e();$e();Ql=(e,t)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(t.axes.length!==0){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(t.starts.length!==t.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((r,i)=>{if(e[i+1].dataType!==6&&e[i+1].dataType!==7)throw new Error(`Input ${i} must be an array of int32 or int64`)})},zr=(e,t)=>{let r=[];if(e.length>t)if(e[t].dataType===7)e[t].getBigInt64Array().forEach(i=>r.push(Number(i)));else if(e[t].dataType===6)e[t].getInt32Array().forEach(i=>r.push(Number(i)));else throw new Error(`Input ${t} must be an array of int32 or int64`);return r},Jl=(e,t)=>{if(e.length>1){let r=zr(e,1),i=zr(e,2),o=zr(e,3);return o.length===0&&(o=[...Array(e[0].dims.length).keys()]),ae({starts:r,ends:i,axes:o})}else return t},ms=(e,t,r,i,o)=>{let s=e;return e<0&&(s+=r[i[t]]),o[t]<0?Math.max(0,Math.min(s,r[i[t]]-1)):Math.max(0,Math.min(s,r[i[t]]))},Zl=(e,t,r,i)=>`fn calculateInputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n          var inputIndices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${r.length}; i >= 0; i--) {\n            var outputIndex = ${i.length===1?\"outputIndices\":\"outputIndices[i]\"};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${r.length===1?\"inputIndices\":\"inputIndices[i]\"} = inputIndex;\n          }\n          return inputIndices;\n      }`,ed=(e,t)=>{let r=e[0].dims,i=D.size(r),o=t.axes.length>0?D.normalizeAxes(t.axes,r.length):[...Array(r.length).keys()],s=zr(e,4);s.forEach(w=>w!==0||(()=>{throw new Error(\"step cannot be 0\")})),s.length===0&&(s=Array(o.length).fill(1));let l=t.starts.map((w,v)=>ms(w,v,r,o,s)),n=t.ends.map((w,v)=>ms(w,v,r,o,s));if(o.length!==r.length)for(let w=0;w<r.length;++w)o.includes(w)||(l.splice(w,0,0),n.splice(w,0,r[w]),s.splice(w,0,1));let c=s.map(w=>Math.sign(w));s.forEach((w,v,I)=>{if(w<0){let B=(n[v]-l[v])/w,z=l[v],M=z+B*s[v];l[v]=M,n[v]=z,I[v]=-w}});let m=r.slice(0);o.forEach((w,v)=>{m[w]=Math.ceil((n[w]-l[w])/s[w])});let g={dims:m,dataType:e[0].dataType},C=se(\"output\",e[0].dataType,m),x=K(\"input\",e[0].dataType,r),$=D.size(m),b=w=>`\n      ${w.declareVariables(x,C)}\n        const signs = array<i32, ${c.length}>(${c.map(v=>`${v}i`).join(\",\")});\n        const starts = array<u32, ${l.length}>(${l.map(v=>`${v}u`).join(\",\")});\n        const ends = array<u32, ${n.length}>(${n.map(v=>`${v}u`).join(\",\")});\n        const steps = array<u32, ${s.length}>(${s.map(v=>`${v}u`).join(\",\")});\n        const inputShape = array<u32, ${r.length}>(${r.map(v=>`${v}u`).join(\",\")});\n\n        ${Zl(x,C,r,m)}\n        ${w.mainStart()}\n          ${w.guardAgainstOutOfBoundsWorkgroupSizes($)}\n          let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${C.setByOffset(\"global_idx\",x.getByIndices(\"inputIndices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:`${t.cacheKey}|${e[4]?.dims??\"\"}`},getShaderSource:b,getRunData:()=>({outputs:[g],dispatchGroup:{x:Math.ceil(i/64)}})}},hs=(e,t)=>{Ql(e.inputs,t);let r=Jl(e.inputs,t);e.compute(ed(e.inputs,r),{inputs:[0]})},gs=e=>{let t=e.starts,r=e.ends,i=e.axes;return ae({starts:t,ends:r,axes:i})}});var td,rd,bs,ws,vs=H(()=>{\"use strict\";me();_e();$e();td=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},rd=(e,t)=>{let r=Pe(e.dataType),i=e.dims,o=D.size(i),s=64,l=t.axis;if(l<0&&(l=i.length+l),l<i.length-1)throw new Error(\"softmax only supports last axis for now.\");let n=i[l],c=o/n,m=r===\"f32\"?\"var threadMax: f32 = -3.402823e+38f;\":\"var threadMax: f16 = -65504.0h;\";return{name:\"Softmax\",getRunData:()=>({outputs:[{dims:i,dataType:e.dataType}],dispatchGroup:{x:c}}),getShaderSource:C=>`\n      var<workgroup> rowMaxShared : ${r};\n      var<workgroup> rowSumShared : ${r};\n      var<workgroup> threadShared : array<${r}, ${s}>;\n\n      @group(0) @binding(0) var<storage, read> x : array<${r}>;\n      @group(0) @binding(1) var<storage, read_write> result : array<${r}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${r} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${r}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n\n      @compute @workgroup_size(${s}, 1, 1)\n      fn main(@builtin(local_invocation_id) local_id : vec3<u32>, @builtin(global_invocation_id) global_id : vec3u) {\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${s};\n        let row = gindex / wg;\n        let cols = ${n};\n        let row_stride : i32 = ${n};\n\n        // find the rows max\n        ${m}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = threadShared[0];\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum: ${r} = 0.0;\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = threadShared[0];\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`}},bs=(e,t)=>{td(e.inputs),e.compute(rd(e.inputs[0],t))},ws=e=>ae({axis:e.axis})});var nd,od,ad,id,sd,$s,xs,Cs=H(()=>{\"use strict\";me();_e();$e();nd=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},od=(e,t)=>{let r=[],i=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(o=>r.push(Number(o))),i=r.length),ae({numOutputs:i,axis:t.axis,splitSizes:r})},ad=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,id=e=>{let t=e.length,r=[];for(let i=0;i<t;++i){let o=e[i].setByIndices(\"indices\",\"input[global_idx]\");t===1?r.push(o):i===0?r.push(`if (outputNumber == ${i}u) { ${o} }`):i===t-1?r.push(`else { ${o} }`):r.push(`else if (outputNumber == ${i}) { ${o} }`)}return`\n      fn writeBufferData(outputNumber: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${r.join(`\n`)}\n      }`},sd=(e,t)=>{let r=e[0].dims,i=D.size(r),o=e[0].dataType,s=r.length,l=t.axis,n=l<0?r.length+l:l,c=new Array(t.numOutputs),m=K(\"input\",o,r),g=new Array(t.numOutputs),C=[],x=[],$=0;for(let v=0;v<t.numOutputs;v++){$+=t.splitSizes[v],g[v]=$;let I=r.slice();I[t.axis]=t.splitSizes[v],x.push(I),c[v]=se(`output${v}`,o,x[v]),C.push({dims:x[v],dataType:e[0].dataType})}let b=s<2?\"indices\":`indices[${n}]`,w=v=>`\n  ${v.declareVariables(m,...c)}\n  const sizeInConcatAxis = array<u32, ${g.length}>(${g.map(I=>`${I}u`).join(\",\")});\n  ${ad(g.length)}\n  ${id(c)}\n\n  ${v.mainStart()}\n    ${v.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n\n    var indices = ${m.offsetToIndices(\"global_idx\")};\n    let outputNumber = calculateOutputIndex(${b});\n    if (outputNumber != 0) {\n        ${b} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:t.cacheKey},getShaderSource:w,getRunData:()=>({outputs:C,dispatchGroup:{x:Math.ceil(i/64)}})}},$s=(e,t)=>{nd(e.inputs);let r=e.inputs.length===1?t:od(e.inputs,t);e.compute(sd(e.inputs,r),{inputs:[0]})},xs=e=>{let t=e.axis,r=e.splitSizes,i=e.numOutputs<0?r.length:e.numOutputs;if(i!==r.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return ae({axis:t,numOutputs:i,splitSizes:r})}});var Ss,ud,ld,dd,As,Is=H(()=>{\"use strict\";ke();me();$e();Ss=e=>Array.from(e.getBigInt64Array(),Number),ud=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(Ss(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},ld=(e,t)=>{let r=[];for(let i=0;i<e.length;++i)r.push(e[i]*t[i]);return r},dd=e=>{let t=e[0].dims,r=Ss(e[1]),i=ld(t,r),o=D.size(i),s=e[0].dataType,l=K(\"input\",s,t),n=se(\"output\",s,i),c=m=>`\n      const inputShape = ${l.indices(...t)};\n      ${m.declareVariables(l,n)}\n      ${m.mainStart()}\n      ${m.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n      let outputIndices = ${n.offsetToIndices(\"global_idx\")};\n      var inputIndices: ${l.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let inputDimValue = ${n.indicesGet(\"outputIndices\",\"i\")}  % ${l.indicesGet(\"inputShape\",\"i\")};\n\n        ${l.indicesSet(\"inputIndices\",\"i\",\"inputDimValue\")}\n      }\n      ${n.setByOffset(\"global_idx\",l.getByIndices(\"inputIndices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${r}`},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}}),getShaderSource:c}},As=e=>{ud(e.inputs),e.compute(dd(e.inputs),{inputs:[0]})}});var cd,pd,Ts,Es=H(()=>{\"use strict\";ke();me();$e();cd=(e,t,r,i,o)=>{let s=D.size(r),l=Math.ceil(s/4),n=se(\"outputData\",o,r,4),c=K(\"aData\",t[1].dataType,t[1].dims,4),m=K(\"bData\",t[2].dataType,t[2].dims,4),g=K(\"cData\",t[0].dataType,t[0].dims,4),C,x=($,b,w)=>`select(${b}, ${$}, ${w})`;if(!i)C=n.setByOffset(\"global_idx\",x(c.getByOffset(\"global_idx\"),m.getByOffset(\"global_idx\"),g.getByOffset(\"global_idx\")));else{let $=(b,w,v=\"\")=>{let I=`aData[indexA${w}][componentA${w}]`,B=`bData[indexB${w}][componentB${w}]`,z=`bool(cData[indexC${w}] & ${4278190080>>>(3-w)*8}u)`;return`\n            let outputIndices${w} = ${n.offsetToIndices(`global_idx * 4u + ${w}u`)};\n            let offsetA${w} = ${c.broadcastedIndicesToOffset(`outputIndices${w}`,n)};\n            let offsetB${w} = ${m.broadcastedIndicesToOffset(`outputIndices${w}`,n)};\n            let offsetC${w} = ${g.broadcastedIndicesToOffset(`outputIndices${w}`,n)};\n            let indexA${w} = offsetA${w} / 4u;\n            let indexB${w} = offsetB${w} / 4u;\n            let indexC${w} = offsetC${w} / 4u;\n            let componentA${w} = offsetA${w} % 4u;\n            let componentB${w} = offsetB${w} % 4u;\n            ${b}[${w}] = ${v}(${x(I,B,z)});\n          `};o===9?C=`\n            var data = vec4<u32>(0);\n            ${$(\"data\",0,\"u32\")}\n            ${$(\"data\",1,\"u32\")}\n            ${$(\"data\",2,\"u32\")}\n            ${$(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:C=`\n            ${$(\"outputData[global_idx]\",0)}\n            ${$(\"outputData[global_idx]\",1)}\n            ${$(\"outputData[global_idx]\",2)}\n            ${$(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(g,c,m,n)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n        ${C}\n      }`},pd=e=>{let t=e[1].dims,r=e[2].dims,i=e[0].dims,o=e[1].dataType,s=!(D.areEqual(t,r)&&D.areEqual(r,i)),l=t,n=D.size(t);if(s){let c=Ze.calcShape(Ze.calcShape(t,r,!1),i,!1);if(!c)throw new Error(\"Can't perform where op on the given tensors\");l=c,n=D.size(l)}return{name:\"Where\",getShaderSource:c=>cd(c,e,l,s,o),getRunData:()=>({outputs:[{dims:l,dataType:o}],dispatchGroup:{x:Math.ceil(n/64/4)}})}},Ts=e=>{e.compute(pd(e.inputs))}});var Os,_s=H(()=>{\"use strict\";Go();No();va();Pa();Ma();vn();Ja();ri();ai();ui();ci();mi();bi();$i();Ci();Ii();Ni();ss();fn();ds();fs();ys();vs();Cs();Is();Mr();gn();Es();Os=new Map([[\"Abs\",[Vo]],[\"Acos\",[Fo]],[\"Acosh\",[Ho]],[\"Add\",[$a]],[\"ArgMax\",[zo,mn]],[\"ArgMin\",[Wo,mn]],[\"Asin\",[Lo]],[\"Asinh\",[jo]],[\"Atan\",[Ko]],[\"Atanh\",[qo]],[\"AveragePool\",[Ri,Pi]],[\"BiasAdd\",[Uo]],[\"BiasSplitGelu\",[wa]],[\"Cast\",[Xo,Yo]],[\"Ceil\",[Jo]],[\"ClipV10\",[hn]],[\"Clip\",[Qo]],[\"Concat\",[Ra,Ba]],[\"Conv\",[La,Ha]],[\"ConvTranspose\",[Qa,Xa]],[\"Cos\",[Zo]],[\"Cosh\",[ea]],[\"Div\",[xa]],[\"Einsum\",[ei,ti]],[\"Elu\",[ta,Ar]],[\"Equal\",[Ca]],[\"Erf\",[ra]],[\"Exp\",[na]],[\"Expand\",[oi]],[\"Floor\",[oa]],[\"Gather\",[si,ii]],[\"GatherElements\",[di,li]],[\"Gelu\",[aa]],[\"Gemm\",[pi,fi]],[\"GlobalAveragePool\",[ki,Mi]],[\"GlobalMaxPool\",[Ui,Gi]],[\"Greater\",[Ta]],[\"GreaterOrEqual\",[Oa]],[\"InstanceNormalization\",[yi,gi]],[\"LayerNormalization\",[vi,wi]],[\"LeakyRelu\",[ia,Ar]],[\"Less\",[Ea]],[\"LessOrEqual\",[_a]],[\"Log\",[ba]],[\"MatMul\",[xi]],[\"MaxPool\",[Wi,zi]],[\"Mul\",[Sa]],[\"Neg\",[ua]],[\"Not\",[sa]],[\"Pad\",[Si,Ai]],[\"Pow\",[Aa]],[\"Range\",[is]],[\"Reciprocal\",[la]],[\"ReduceMin\",[Po,je]],[\"ReduceMean\",[_o,je]],[\"ReduceMax\",[Oo,je]],[\"ReduceSum\",[Bo,je]],[\"ReduceProd\",[Ro,je]],[\"ReduceL1\",[Io,je]],[\"ReduceL2\",[To,je]],[\"ReduceLogSum\",[Ao,je]],[\"ReduceLogSumExp\",[Eo,je]],[\"ReduceSumSquare\",[Mo,je]],[\"Relu\",[da]],[\"Resize\",[us,ls]],[\"Sigmoid\",[ca]],[\"Sin\",[pa]],[\"Sinh\",[fa]],[\"Slice\",[hs,gs]],[\"SkipLayerNormalization\",[cs,ps]],[\"Split\",[$s,xs]],[\"Sqrt\",[ma]],[\"Softmax\",[bs,ws]],[\"Sub\",[Ia]],[\"Tan\",[ha]],[\"Tanh\",[ga]],[\"ThresholdedRelu\",[ya,Ar]],[\"Tile\",[As]],[\"Transpose\",[Ua,Na]],[\"Where\",[Ts]]])});var Gr,Ps=H(()=>{\"use strict\";ke();lt();$e();Gr=class{constructor(t){this.backend=t;this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,r){this.repo.set(t,r)}run(t,r,i,o,s,l,n){let c=this.backend.device,m=this.backend.getComputePassEncoder(),g=this.backend.supportTimestampQuery&&this.backend.env.webgpu.profilingMode===\"default\";g&&m.writeTimestamp(this.backend.profilingQuerySet,0),m.setPipeline(t.computePipeline);let C=[];for(let $ of o)C.push({binding:C.length,resource:{buffer:$.buffer}});for(let $ of s)C.push({binding:C.length,resource:{buffer:$.buffer}});n&&C.push({binding:C.length,resource:n});let x=c.createBindGroup({layout:t.computePipeline.getBindGroupLayout(0),entries:C,label:t.programInfo.name});if(m.setBindGroup(0,x),m.dispatchWorkgroups(...l),this.backend.pendingDispatchNumber++,g){m.writeTimestamp(this.backend.profilingQuerySet,1),this.backend.profilingQueryData==null&&(this.backend.profilingQueryData=this.backend.gpuDataManager.create(16,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let $=this.backend.gpuDataManager.create(16,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.profilingQuerySet,0,2,this.backend.profilingQueryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.profilingQueryData.buffer,0,$.buffer,0,16),this.backend.flush();let b=this.backend.currentKernelId,w=this.backend.kernels.get(b),v=`[${w[0]}] ${w[1]}`;$.buffer.mapAsync(GPUMapMode.READ).then(()=>{let I=new BigUint64Array($.buffer.getMappedRange()),B=I[0],z=I[1];$.buffer.unmap(),typeof this.backend.profilingTimeBase>\"u\"&&(this.backend.profilingTimeBase=B);let M=Number(B-this.backend.profilingTimeBase),G=Number(z-this.backend.profilingTimeBase);if(!Number.isSafeInteger(M)||!Number.isSafeInteger(G))throw new RangeError(\"incorrect timestamp range\");this.backend.gpuDataManager.release($.id);let _=\"\";r.forEach((V,j)=>{_+=`input[${j}]: [${V.dims}] | ${Yt(V.dataType)}, `});let U=\"\";i.forEach((V,j)=>{U+=`output[${j}]: [${V.dims}] | ${Yt(V.dataType)}, `}),console.log(`[profiling] kernel \"${b}|${v}\" ${_}${U}execution time: ${G-M} ns`)})}this.backend.pendingDispatchNumber>=16&&this.backend.flush()}dispose(){}build(t,r){let i=this.backend.device,o=[];i.features.has(\"shader-f16\")&&o.push(\"enable f16;\");let s=So(r),l=t.getShaderSource(s),n=`${o.join(`\n`)}\n${s.additionalImplementations}\n${l}`,c=i.createShaderModule({code:n,label:t.name});Ie(\"verbose\",()=>`[WebGPU] shader code: ${n}`);let m=i.createComputePipeline({compute:{module:c,entryPoint:\"main\"},layout:\"auto\",label:t.name});return{programInfo:t,computePipeline:m}}normalizeDispatchGroupSize(t){let r=typeof t==\"number\"?t:t.x,i=typeof t==\"number\"?1:t.y||1,o=typeof t==\"number\"?1:t.z||1,s=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(r<=s&&i<=s&&o<=s)return[r,i,o];let l=r*i*o,n=Math.ceil(Math.sqrt(l));if(n>s){if(n=Math.ceil(Math.cbrt(l)),n>s)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[n,n,n]}else return[n,n,1]}}});var fd,md,Ur,Rs=H(()=>{\"use strict\";lt();yo();$o();_s();Ps();fd=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let r=[];for(let i=0;i<e.length;++i){let o=e[i].dataType;switch(t[i]){case\"none\":{r.push(\"\");break}case\"type\":{r.push(`${o}`);break}case\"rank\":{let s=e[i].dims.length;r.push(`${o};${s}`);break}case\"dims\":{let s=e[i].dims.join(\",\");r.push(`${o};${s}`);break}default:throw new Error(`unsupported input dependency: ${t[i]}`)}}return r.join(\"|\")},md=(e,t)=>{let r=e.name;return e.shaderCache?.hint&&(r+=\"[\"+e.shaderCache.hint+\"]\"),r+=`:${fd(t,e.shaderCache?.inputDependencies??new Array(t.length).fill(\"dims\"))}`,r},Ur=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.supportTimestampQuery=!1;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let t=this.kernelCustomData.get(this.currentKernelId);return t||(t={},this.kernelCustomData.set(this.currentKernelId,t)),t}async initialize(t){if(!navigator.gpu)throw new Error(\"WebGpuBackend: WebGPU is not available.\");let r=await navigator.gpu.requestAdapter();if(!r)throw new Error(\"WebGpuBackend: Failed to get GPU adapter.\");this.env=t;let i=[],o={requiredLimits:{maxComputeWorkgroupStorageSize:r.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:r.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:r.limits.maxStorageBufferBindingSize,maxBufferSize:r.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:r.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:r.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:r.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:r.limits.maxComputeWorkgroupSizeZ},requiredFeatures:i};r.features.has(\"timestamp-query-inside-passes\")&&(this.supportTimestampQuery=!0,i.push(\"timestamp-query-inside-passes\")),r.features.has(\"shader-f16\")&&i.push(\"shader-f16\"),this.device=await r.requestDevice(o),this.gpuDataManager=vo(this),this.programManager=new Gr(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,ho(t.logLevel,!!t.debug),this.device.onuncapturederror=s=>{s.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${s.error.message}`)},this.supportTimestampQuery&&(this.profilingQuerySet=this.device.createQuerySet({type:\"timestamp\",count:2})),Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){return this.computePassEncoder||(this.computePassEncoder=this.getCommandEncoder().beginComputePass()),this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}run(t,r,i,o,s){let l=[];for(let I=0;I<r.length;++I){let B=this.gpuDataManager.get(r[I].data);if(!B)throw new Error(`no GPU data for input: ${r[I].data}`);l[I]=B}let n=md(t,r),c=this.programManager.getArtifact(n),{outputs:m,dispatchGroup:g,programUniforms:C}=t.getRunData(r),x=i.length===0?m.map((I,B)=>B):i;if(x.length!==m.length)throw new Error(`Output size ${x.length} must be equal to ${m.length}.`);let $=[],b=[];for(let I=0;I<m.length;++I){if(!Number.isInteger(x[I])||x[I]<-3||x[I]>=m.length)throw new Error(`Invalid output index: ${x[I]}`);if(x[I]===-3)continue;let B=x[I]===-1,z=x[I]===-2,M=B||z?s(m[I].dataType,m[I].dims):o(x[I],m[I].dataType,m[I].dims),G=this.gpuDataManager.get(M.data);if(!G)throw new Error(`no GPU data for output: ${M.data}`);if(B&&this.temporaryData.push(G),z){let _=this.kernelPersistentData.get(this.currentKernelId);_||(_=[],this.kernelPersistentData.set(this.currentKernelId,_)),_.push(G)}$.push(M),b.push(G)}let w;if(C){let I=0,B=0,z=[],M=1;C.forEach(U=>{let V=typeof U.data==\"number\"?[U.data]:U.data,j;switch(V.length){case 1:j=4;break;case 2:j=8;break;case 3:j=16;break;case 4:j=16;break;case 5:j=16;break;case 6:j=16;break;default:throw new Error(`unsupported data length: ${V.length}`)}(B===5||B===6)&&(j=16),j>M&&(M=j),I=Math.ceil(I/j)*j,B=V.length,z.push(I),I+=V.length*4}),I=Math.ceil(I/M)*M;let G=new ArrayBuffer(I);C.forEach((U,V)=>{let j=z[V],le=typeof U.data==\"number\"?[U.data]:U.data;U.type===\"int32\"?new Int32Array(G,j,le.length).set(le):U.type===\"uint32\"?new Uint32Array(G,j,le.length).set(le):new Float32Array(G,j,le.length).set(le)});let _=this.gpuDataManager.create(I,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(_.buffer,0,G,0,I),this.gpuDataManager.release(_.id),w={offset:0,size:I,buffer:_.buffer}}let v=this.programManager.normalizeDispatchGroupSize(g);return c||(c=this.programManager.build(t,v),this.programManager.setArtifact(n,c)),Ie(\"info\",()=>`[ProgramManager] run \"${t.name}\" (key=${n}) with ${v[0]}x${v[1]}x${v[2]}`),this.programManager.run(c,r,$,l,b,v,w),$}upload(t,r){this.gpuDataManager.upload(t,r)}memcpy(t,r){this.gpuDataManager.memcpy(t,r)}async download(t,r){await this.gpuDataManager.download(t,r)}alloc(t){return this.gpuDataManager.create(t).id}free(t){return this.gpuDataManager.release(t)}createKernel(t,r,i,o){let s=Os.get(t);if(!s)throw new Error(`kernel not implemented: ${t}`);this.kernels.set(r,[t,o,s[0],[s[1],i]])}releaseKernel(t){let r=this.kernelPersistentData.get(t);if(r){for(let i of r)this.gpuDataManager.release(i.id);this.kernelPersistentData.delete(t)}this.kernelCustomData.delete(t),this.kernels.delete(t)}computeKernel(t,r,i){let o=this.kernels.get(t);if(!o)throw new Error(`kernel not created: ${t}`);let[s,l,n,c]=o;if(this.currentKernelId!==null)throw new Error(`kernel \"[${s}] ${l}\" is not allowed to be called recursively`);this.currentKernelId=t,c[0]&&(c[1]=c[0](c[1]),c[0]=void 0),Ie(\"info\",()=>`[WebGPU] Start to run kernel \"[${s}] ${l}\"...`);let m=this.env.debug;this.temporaryData=[];try{return m&&this.device.pushErrorScope(\"validation\"),n(r,c[1]),0}catch(g){return i.push(Promise.resolve(`[WebGPU] Kernel \"[${s}] ${l}\" failed. ${g}`)),1}finally{m&&i.push(this.device.popErrorScope().then(g=>g?`GPU validation error for kernel \"[${s}] ${l}\": ${g.message}`:null));for(let g of this.temporaryData)this.gpuDataManager.release(g.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(t,r,i,o){let s=this.sessionExternalDataMapping.get(t);s||(s=new Map,this.sessionExternalDataMapping.set(t,s));let l=s.get(r),n=this.gpuDataManager.registerExternalBuffer(i,o,l?.[1]);return s.set(r,[n,i]),n}unregisterBuffers(t){let r=this.sessionExternalDataMapping.get(t);r&&(r.forEach(i=>this.gpuDataManager.unregisterExternalBuffer(i[1])),this.sessionExternalDataMapping.delete(t))}getBuffer(t){let r=this.gpuDataManager.get(t);if(!r)throw new Error(`no GPU data for buffer: ${t}`);return r.buffer}createDownloader(t,r,i){return async()=>{let o=await sn(this,t,r);return go(o.buffer,i)}}}});var Bs={};yr(Bs,{init:()=>hd});var rr,En,hd,Ms=H(()=>{\"use strict\";ke();Rs();lt();me();rr=class e{constructor(t,r,i,o){this.module=t;this.dataType=r;this.data=i;this.dims=o}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let t=D.size(this.dims);return t===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,t)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let t=D.size(this.dims);return t===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,t)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let t=D.size(this.dims);return t===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,t)}reshape(t){if(D.size(t)!==D.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,t)}},En=class{constructor(t,r,i){this.module=t;this.backend=r;this.customDataOffset=0;this.customDataSize=0;let o=t.HEAPU32,s=i>>2;this.opKernelContext=o[s++];let l=o[s++];this.outputCount=o[s++],this.customDataOffset=o[s++],this.customDataSize=o[s++];let n=[];for(let c=0;c<l;c++){let m=o[s++],g=o[s++],C=o[s++],x=[];for(let $=0;$<C;$++)x.push(o[s++]);n.push(new rr(t,m,g,x))}this.inputs=n}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(t,r){let i=r?.inputs?.map(n=>typeof n==\"number\"?this.inputs[n]:n)??this.inputs,o=r?.outputs??[],s=(n,c,m)=>new rr(this.module,c,this.output(n,m),m),l=(n,c)=>{let m=Xt(n);if(!m)throw new Error(`Unsupported data type: ${n}`);let g=m*D.size(c);return new rr(this.module,n,this.backend.gpuDataManager.create(g).id,c)};return this.backend.run(t,i,o,s,l)}output(t,r){let i=this.module.stackSave();try{let o=this.module.stackAlloc((1+r.length)*4),s=o>>2;this.module.HEAPU32[s++]=r.length;for(let l=0;l<r.length;l++)this.module.HEAPU32[s++]=r[l];return this.module._JsepOutput(this.opKernelContext,t,o)}catch(o){throw new Error(`Failed to generate kernel's output[${t}] with dims [${r}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${o}`)}finally{this.module.stackRestore(i)}}},hd=async(e,t)=>{let r=e.jsepInit;if(r&&navigator.gpu){if(!t.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP\");let i=new Ur;await i.initialize(t),r(i,o=>i.alloc(o),o=>i.free(o),(o,s,l,n=!1)=>{if(n)Ie(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${o}, dst=${s}, size=${l}`),i.memcpy(o,s);else{Ie(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${o}, gpuDataId=${s}, size=${l}`);let c=e.HEAPU8.subarray(o,o+l);i.upload(s,c)}},async(o,s,l)=>{Ie(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${o}, dataOffset=${s}, size=${l}`),await i.download(o,()=>e.HEAPU8.subarray(s,s+l))},(o,s,l)=>i.createKernel(o,s,l,t.debug||t.webgpu.profilingMode===\"default\"?e.UTF8ToString(e._JsepGetNodeName(s)):`${s}`),o=>i.releaseKernel(o),(o,s,l,n)=>{Ie(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${l}, kernel=${o}, contextDataOffset=${s}`);let c=new En(e,i,s);return i.computeKernel(o,c,n)})}}});var so;so=Qn();var lu=oo(),tn,rn=!1,br=!1,io=!1,du=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},cu=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},pu=(e,t)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":t?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",uo=async e=>{if(rn)return Promise.resolve();if(br)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(io)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");br=!0;let t=e.initTimeout,r=e.numThreads,i=e.simd,o=r>1&&du(),s=i&&cu(),l=e.wasmPaths,n=typeof l==\"string\"?l:void 0,c=pu(s,o),m=typeof l==\"object\"?l[c]:void 0,g=!1,C=[];if(t>0&&C.push(new Promise(x=>{setTimeout(()=>{g=!0,x()},t)})),C.push(new Promise((x,$)=>{let b=o?lu:so,w={locateFile:(v,I)=>{if(o&&v.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([ao()],{type:\"text/javascript\"}));if(v.endsWith(\".wasm\")){if(m)return m;let B=n??I;return c===\"ort-wasm-simd.wasm\"?B+\"ort-wasm-simd.jsep.wasm\":c===\"ort-wasm-simd-threaded.wasm\"?B+\"ort-wasm-simd-threaded.jsep.wasm\":B+c}return I+v}};if(o)if(typeof Blob>\"u\")w.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let v=`var ortWasmThreaded=${b.toString()};`;w.mainScriptUrlOrBlob=new Blob([v],{type:\"text/javascript\"})}b(w).then(v=>{br=!1,rn=!0,tn=v,x()},v=>{br=!1,io=!0,$(v)})})),await Promise.race(C),g)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Ee=()=>{if(rn&&tn)return tn;throw new Error(\"WebAssembly is not initialized yet.\")};var Oe=(e,t)=>{let r=Ee(),i=r.lengthBytesUTF8(e)+1,o=r._malloc(i);return r.stringToUTF8(e,o,i),t.push(o),o},qt=(e,t,r,i)=>{if(typeof e==\"object\"&&e!==null){if(r.has(e))throw new Error(\"Circular reference in options\");r.add(e)}Object.entries(e).forEach(([o,s])=>{let l=t?t+o:o;if(typeof s==\"object\")qt(s,l+\".\",r,i);else if(typeof s==\"string\"||typeof s==\"number\")i(l,s.toString());else if(typeof s==\"boolean\")i(l,s?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof s}`)})},Ce=e=>{let t=Ee(),r=t.stackSave();try{let i=t.stackAlloc(8);t._OrtGetLastError(i,i+4);let o=t.HEAP32[i/4],s=t.HEAPU32[i/4+1],l=s?t.UTF8ToString(s):\"\";throw new Error(`${e} ERROR_CODE: ${o}, ERROR_MESSAGE: ${l}`)}finally{t.stackRestore(r)}};var lo=e=>{let t=Ee(),r=0,i=[],o=e||{};try{if(e?.logSeverityLevel===void 0)o.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)o.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(o.terminate=!1);let s=0;return e?.tag!==void 0&&(s=Oe(e.tag,i)),r=t._OrtCreateRunOptions(o.logSeverityLevel,o.logVerbosityLevel,!!o.terminate,s),r===0&&Ce(\"Can't create run options.\"),e?.extra!==void 0&&qt(e.extra,\"\",new WeakSet,(l,n)=>{let c=Oe(l,i),m=Oe(n,i);t._OrtAddRunConfigEntry(r,c,m)!==0&&Ce(`Can't set a run config entry: ${l} - ${n}.`)}),[r,i]}catch(s){throw r!==0&&t._OrtReleaseRunOptions(r),i.forEach(l=>t._free(l)),s}};var fu=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},mu=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},hu=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(r=>(typeof r==\"string\"?r:r.name)===\"webgpu\")&&(e.enableMemPattern=!1)},gu=(e,t,r)=>{for(let i of t){let o=typeof i==\"string\"?i:i.name;switch(o){case\"xnnpack\":o=\"XNNPACK\";break;case\"webnn\":if(o=\"WEBNN\",typeof i!=\"string\"){let l=i;if(l?.deviceType){let n=Oe(\"deviceType\",r),c=Oe(l.deviceType,r);Ee()._OrtAddSessionConfigEntry(e,n,c)!==0&&Ce(`Can't set a session config entry: 'deviceType' - ${l.deviceType}.`)}if(l?.numThreads){let n=l.numThreads;(typeof n!=\"number\"||!Number.isInteger(n)||n<0)&&(n=0);let c=Oe(\"numThreads\",r),m=Oe(n.toString(),r);Ee()._OrtAddSessionConfigEntry(e,c,m)!==0&&Ce(`Can't set a session config entry: 'numThreads' - ${l.numThreads}.`)}if(l?.powerPreference){let n=Oe(\"powerPreference\",r),c=Oe(l.powerPreference,r);Ee()._OrtAddSessionConfigEntry(e,n,c)!==0&&Ce(`Can't set a session config entry: 'powerPreference' - ${l.powerPreference}.`)}}break;case\"webgpu\":if(o=\"JS\",typeof i!=\"string\"){let l=i;if(l?.preferredLayout){if(l.preferredLayout!==\"NCHW\"&&l.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${l.preferredLayout}`);let n=Oe(\"preferredLayout\",r),c=Oe(l.preferredLayout,r);Ee()._OrtAddSessionConfigEntry(e,n,c)!==0&&Ce(`Can't set a session config entry: 'preferredLayout' - ${l.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${o}`)}let s=Oe(o,r);Ee()._OrtAppendExecutionProvider(e,s)!==0&&Ce(`Can't append execution provider: ${o}.`)}},co=e=>{let t=Ee(),r=0,i=[],o=e||{};hu(o);try{let s=fu(o.graphOptimizationLevel??\"all\"),l=mu(o.executionMode??\"sequential\"),n=typeof o.logId==\"string\"?Oe(o.logId,i):0,c=o.logSeverityLevel??2;if(!Number.isInteger(c)||c<0||c>4)throw new Error(`log serverity level is not valid: ${c}`);let m=o.logVerbosityLevel??0;if(!Number.isInteger(m)||m<0||m>4)throw new Error(`log verbosity level is not valid: ${m}`);let g=typeof o.optimizedModelFilePath==\"string\"?Oe(o.optimizedModelFilePath,i):0;if(r=t._OrtCreateSessionOptions(s,!!o.enableCpuMemArena,!!o.enableMemPattern,l,!!o.enableProfiling,0,n,c,m,g),r===0&&Ce(\"Can't create session options.\"),o.executionProviders&&gu(r,o.executionProviders,i),o.freeDimensionOverrides)for(let[C,x]of Object.entries(o.freeDimensionOverrides)){if(typeof C!=\"string\")throw new Error(`free dimension override name must be a string: ${C}`);if(typeof x!=\"number\"||!Number.isInteger(x)||x<0)throw new Error(`free dimension override value must be a non-negative integer: ${x}`);let $=Oe(C,i);t._OrtAddFreeDimensionOverride(r,$,x)!==0&&Ce(`Can't set a free dimension override: ${C} - ${x}.`)}return o.extra!==void 0&&qt(o.extra,\"\",new WeakSet,(C,x)=>{let $=Oe(C,i),b=Oe(x,i);t._OrtAddSessionConfigEntry(r,$,b)!==0&&Ce(`Can't set a session config entry: ${C} - ${x}.`)}),[r,i]}catch(s){throw r!==0&&t._OrtReleaseSessionOptions(r),i.forEach(l=>t._free(l)),s}};ke();var gd=e=>{let t=Ee(),r=t.stackSave();try{let i=t.stackAlloc(8);return t._OrtGetInputOutputCount(e,i,i+4)!==0&&Ce(\"Can't get session input/output count.\"),[t.HEAP32[i/4],t.HEAP32[i/4+1]]}finally{t.stackRestore(r)}},yd=(e,t)=>{Ee()._OrtInit(e,t)!==0&&Ce(\"Can't initialize onnxruntime.\")},Ds=async e=>{yd(e.wasm.numThreads,Qt(e.logLevel));{let t=(Ms(),Tt(Bs)).init;await t(Ee(),e)}},nr=new Map,On=e=>{let t=Ee(),r=t._malloc(e.byteLength);if(r===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},_n=(e,t)=>{let r=Ee(),i=0,o=0,s=0,l=[],n=[],c=[];try{[o,l]=co(t),i=r._OrtCreateSession(e[0],e[1],o),i===0&&Ce(\"Can't create a session.\");let[m,g]=gd(i),C=[],x=[],$=[];for(let w=0;w<m;w++){let v=r._OrtGetInputName(i,w);v===0&&Ce(\"Can't get an input name.\"),n.push(v),C.push(r.UTF8ToString(v))}for(let w=0;w<g;w++){let v=r._OrtGetOutputName(i,w);v===0&&Ce(\"Can't get an output name.\"),c.push(v);let I=r.UTF8ToString(v);x.push(I);{let B=typeof t?.preferredOutputLocation==\"string\"?t.preferredOutputLocation:t?.preferredOutputLocation?.[I]??\"cpu\";if(B!==\"cpu\"&&B!==\"cpu-pinned\"&&B!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${B}.`);$.push(B)}}let b=null;return $.some(w=>w===\"gpu-buffer\")&&(s=r._OrtCreateBinding(i),s===0&&Ce(\"Can't create IO binding.\"),b={handle:s,outputPreferredLocations:$,outputPreferredLocationsEncoded:$.map(w=>on(w))}),nr.set(i,[i,n,c,b]),[i,C,x]}catch(m){throw n.forEach(g=>r._OrtFree(g)),c.forEach(g=>r._OrtFree(g)),s!==0&&r._OrtReleaseBinding(s),i!==0&&r._OrtReleaseSession(i),m}finally{r._free(e[0]),o!==0&&r._OrtReleaseSessionOptions(o),l.forEach(m=>r._free(m))}},Ws=(e,t)=>{let r=On(e);return _n(r,t)},zs=e=>{let t=Ee(),r=nr.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);let[i,o,s,l]=r;l&&t._OrtReleaseBinding(l.handle),t.jsepUnregisterBuffers?.(e),o.forEach(n=>t._OrtFree(n)),s.forEach(n=>t._OrtFree(n)),t._OrtReleaseSession(i),nr.delete(e)},ks=(e,t,r,i,o)=>{if(!e){t.push(0);return}let s=Ee(),l=e[0],n=e[1],c=e[3],m,g;if(l===\"string\"&&c===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(c===\"gpu-buffer\"){let $=e[2].gpuBuffer,b=Xt(nn(l));g=n.reduce((w,v)=>w*v,1)*b,m=s.jsepRegisterBuffer(i,o,$,g)}else{let $=e[2];if(Array.isArray($)){g=4*$.length,m=s._malloc(g),r.push(m);let b=m/4;for(let w=0;w<$.length;w++){if(typeof $[w]!=\"string\")throw new TypeError(`tensor data at index ${w} is not a string`);s.HEAPU32[b++]=Oe($[w],r)}}else g=$.byteLength,m=s._malloc(g),r.push(m),s.HEAPU8.set(new Uint8Array($.buffer,$.byteOffset,g),m)}let C=s.stackSave(),x=s.stackAlloc(4*n.length);try{let $=x/4;n.forEach(w=>s.HEAP32[$++]=w);let b=s._OrtCreateTensor(nn(l),m,g,x,n.length,on(c));b===0&&Ce(`Can't create tensor for input/output. session=${i}, index=${o}.`),t.push(b)}finally{s.stackRestore(C)}},Gs=async(e,t,r,i,o,s)=>{let l=Ee(),n=nr.get(e);if(!n)throw new Error(`cannot run inference. invalid session id: ${e}`);let[c,m,g,C]=n,x=t.length,$=i.length,b=0,w=[],v=[],I=[],B=[],z=l.stackSave(),M=l.stackAlloc(x*4),G=l.stackAlloc(x*4),_=l.stackAlloc($*4),U=l.stackAlloc($*4);try{[b,w]=lo(s);for(let q=0;q<x;q++)ks(r[q],v,B,e,t[q]);for(let q=0;q<$;q++)ks(o[q],I,B,e,x+i[q]);let V=M/4,j=G/4,le=_/4,R=U/4;for(let q=0;q<x;q++)l.HEAPU32[V++]=v[q],l.HEAPU32[j++]=m[t[q]];for(let q=0;q<$;q++)l.HEAPU32[le++]=I[q],l.HEAPU32[R++]=g[i[q]];if(C){let{handle:q,outputPreferredLocations:L,outputPreferredLocationsEncoded:De}=C;if(m.length!==x)throw new Error(`input count from feeds (${x}) is expected to be always equal to model's input count (${m.length}).`);for(let he=0;he<x;he++){let Re=t[he];await l._OrtBindInput(q,m[Re],v[he])!==0&&Ce(`Can't bind input[${he}] for session=${e}.`)}for(let he=0;he<$;he++){let Re=i[he];o[he]?.[3]?l._OrtBindOutput(q,g[Re],I[he],0)!==0&&Ce(`Can't bind pre-allocated output[${he}] for session=${e}.`):l._OrtBindOutput(q,g[Re],0,De[Re])!==0&&Ce(`Can't bind output[${he}] to ${L[he]} for session=${e}.`)}}let X;C?X=await l._OrtRunWithBinding(c,C.handle,$,_,b):X=await l._OrtRun(c,G,M,x,U,$,_,b),X!==0&&Ce(\"failed to call OrtRun().\");let Se=[];for(let q=0;q<$;q++){let L=l.HEAPU32[_/4+q];if(L===I[q]){Se.push(o[q]);continue}let De=l.stackSave(),he=l.stackAlloc(4*4),Re=!1,we,Be=0;try{l._OrtGetTensorData(L,he,he+4,he+8,he+12)!==0&&Ce(`Can't access output tensor data on index ${q}.`);let We=he/4,nt=l.HEAPU32[We++];Be=l.HEAPU32[We++];let N=l.HEAPU32[We++],de=l.HEAPU32[We++],ge=[];for(let Te=0;Te<de;Te++)ge.push(l.HEAPU32[N/4+Te]);l._OrtFree(N);let ze=ge.reduce((Te,Ae)=>Te*Ae,1);we=Yt(nt);let Ge=C?.outputPreferredLocations[i[q]];if(we===\"string\"){if(Ge===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Te=[],Ae=Be/4;for(let Ue=0;Ue<ze;Ue++){let qe=l.HEAPU32[Ae++],Ve=Ue===ze-1?void 0:l.HEAPU32[Ae]-qe;Te.push(l.UTF8ToString(qe,Ve))}Se.push([we,ge,Te,\"cpu\"])}else if(Ge===\"gpu-buffer\"&&ze>0){let Te=l.jsepGetBuffer(Be),Ae=Xt(nt);if(Ae===void 0||!po(we))throw new Error(`Unsupported data type: ${we}`);Re=!0,Se.push([we,ge,{gpuBuffer:Te,download:l.jsepCreateDownloader(Te,ze*Ae,we),dispose:()=>{l._OrtReleaseTensor(L)}},\"gpu-buffer\"])}else{let Te=wr(we),Ae=new Te(ze);new Uint8Array(Ae.buffer,Ae.byteOffset,Ae.byteLength).set(l.HEAPU8.subarray(Be,Be+Ae.byteLength)),Se.push([we,ge,Ae,\"cpu\"])}}finally{l.stackRestore(De),we===\"string\"&&Be&&l._free(Be),Re||l._OrtReleaseTensor(L)}}return C&&l._OrtClearBoundOutputs(C.handle),Se}finally{l.stackRestore(z),v.forEach(V=>l._OrtReleaseTensor(V)),I.forEach(V=>l._OrtReleaseTensor(V)),B.forEach(V=>l._free(V)),b!==0&&l._OrtReleaseRunOptions(b),w.forEach(V=>l._free(V))}},Us=e=>{let t=Ee(),r=nr.get(e);if(!r)throw new Error(\"invalid session id\");let i=r[0],o=t._OrtEndProfiling(i);o===0&&Ce(\"Can't get an profile file name.\"),t._OrtFree(o)},Ns=e=>{let t=[];for(let r of e){let i=r[2];!Array.isArray(i)&&\"buffer\"in i&&t.push(i.buffer)}return t};self.onmessage=e=>{switch(e.data.type){case\"init-wasm\":try{uo(e.data.in).then(()=>postMessage({type:\"init-wasm\"}),t=>postMessage({type:\"init-wasm\",err:t}))}catch(t){postMessage({type:\"init-wasm\",err:t})}break;case\"init-ort\":try{Ds(e.data.in).then(()=>postMessage({type:\"init-ort\"}),t=>postMessage({type:\"init-ort\",err:t}))}catch(t){postMessage({type:\"init-ort\",err:t})}break;case\"create_allocate\":try{let{model:t}=e.data.in,r=On(t);postMessage({type:\"create_allocate\",out:r})}catch(t){postMessage({type:\"create_allocate\",err:t})}break;case\"create_finalize\":try{let{modeldata:t,options:r}=e.data.in,i=_n(t,r);postMessage({type:\"create_finalize\",out:i})}catch(t){postMessage({type:\"create_finalize\",err:t})}break;case\"create\":try{let{model:t,options:r}=e.data.in,i=Ws(t,r);postMessage({type:\"create\",out:i})}catch(t){postMessage({type:\"create\",err:t})}break;case\"release\":try{let t=e.data.in;zs(t),postMessage({type:\"release\"})}catch(t){postMessage({type:\"release\",err:t})}break;case\"run\":try{let{sessionId:t,inputIndices:r,inputs:i,outputIndices:o,options:s}=e.data.in;Gs(t,r,i,o,s).then(l=>{postMessage({type:\"run\",out:l},Ns(l))},l=>{postMessage({type:\"run\",err:l})})}catch(t){postMessage({type:\"run\",err:t})}break;case\"end-profiling\":try{let t=e.data.in;Us(t),postMessage({type:\"end-profiling\"})}catch(t){postMessage({type:\"end-profiling\",err:t})}break;default:}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\n// resolve; reject\ntype PromiseCallbacks<T = void> = [(result: T) => void, (reason: unknown) => void];\n\nlet initWasmCallbacks: PromiseCallbacks;\nlet initOrtCallbacks: PromiseCallbacks;\nconst createSessionAllocateCallbacks: Array<PromiseCallbacks<SerializableModeldata>> = [];\nconst createSessionFinalizeCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst createSessionCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst releaseSessionCallbacks: Array<PromiseCallbacks<void>> = [];\nconst runCallbacks: Array<PromiseCallbacks<SerializableTensorMetadata[]>> = [];\nconst endProfilingCallbacks: Array<PromiseCallbacks<void>> = [];\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ort':\n      if (ev.data.err) {\n        initOrtCallbacks[1](ev.data.err);\n      } else {\n        initOrtCallbacks[0]();\n      }\n      break;\n    case 'create_allocate':\n      if (ev.data.err) {\n        createSessionAllocateCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionAllocateCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create_finalize':\n      if (ev.data.err) {\n        createSessionFinalizeCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionFinalizeCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create':\n      if (ev.data.err) {\n        createSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'release':\n      if (ev.data.err) {\n        releaseSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        releaseSessionCallbacks.shift()![0]();\n      }\n      break;\n    case 'run':\n      if (ev.data.err) {\n        runCallbacks.shift()![1](ev.data.err);\n      } else {\n        runCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'end-profiling':\n      if (ev.data.err) {\n        endProfilingCallbacks.shift()![1](ev.data.err);\n      } else {\n        endProfilingCallbacks.shift()![0]();\n      }\n      break;\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyInstance = async(): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    if (initialized) {\n      return;\n    }\n    if (initializing) {\n      throw new Error('multiple calls to \\'initWasm()\\' detected.');\n    }\n    if (aborted) {\n      throw new Error('previous call to \\'initWasm()\\' failed.');\n    }\n\n    initializing = true;\n\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env.wasm};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    return initializeWebAssembly(env.wasm);\n  }\n};\n\nexport const initializeRuntime = async(env: Env): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      initOrtCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-ort', in : env};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initRuntime(env);\n  }\n};\n\nexport const createSessionAllocate = async(model: Uint8Array): Promise<SerializableModeldata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableModeldata>((resolve, reject) => {\n      createSessionAllocateCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create_allocate', in : {model}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSessionAllocate(model);\n  }\n};\n\nexport const createSessionFinalize = async(modeldata: SerializableModeldata, options?: InferenceSession.SessionOptions):\n    Promise<SerializableSessionMetadata> => {\n      if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n        ensureWorker();\n        return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n          createSessionFinalizeCallbacks.push([resolve, reject]);\n          const message: OrtWasmMessage = {type: 'create_finalize', in : {modeldata, options}};\n          proxyWorker!.postMessage(message);\n        });\n      } else {\n        return core.createSessionFinalize(modeldata, options);\n      }\n    };\n\nexport const createSession =\n    async(model: Uint8Array, options?: InferenceSession.SessionOptions): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      createSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      releaseSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      runCallbacks.push([resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      endProfilingCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {env, InferenceSession, InferenceSessionHandler, SessionHandler, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, TensorMetadata} from './proxy-messages';\nimport {createSession, createSessionAllocate, createSessionFinalize, endProfiling, initializeRuntime, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nlet runtimeInitialized: boolean;\nlet runtimeInitializationPromise: Promise<void>|undefined;\n\nconst encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nconst decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async createSessionAllocate(path: string): Promise<SerializableModeldata> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return createSessionAllocate(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    if (!runtimeInitialized) {\n      if (!runtimeInitializationPromise) {\n        runtimeInitializationPromise = initializeRuntime(env);\n      }\n      await runtimeInitializationPromise;\n      runtimeInitializationPromise = undefined;\n      runtimeInitialized = true;\n    }\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        const model = await readFile(pathOrBuffer);\n        [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n      } else {\n        // browser\n        // fetch model and move to wasm heap.\n        const modelData: SerializableModeldata = await this.createSessionAllocate(pathOrBuffer);\n        // create the session\n        [this.sessionId, this.inputNames, this.outputNames] = await createSessionFinalize(modelData, options);\n      }\n    } else {\n      [this.sessionId, this.inputNames, this.outputNames] = await createSession(pathOrBuffer, options);\n    }\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeWebAssemblyInstance} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  async init(): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyInstance();\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU && typeof navigator !== 'undefined' && navigator.gpu) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    registerBackend('webnn', wasmBackend, 9);\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n"],
  "mappings": ";;;;;wgBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,EAAA,kBAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAI,GAEpD,MAAMA,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,EAAA,kBA2EAC,OC3EA,IAMaC,GANbC,GAAAC,EAAA,kBAMaF,GAAU,WCNvB,IAQIG,GAESC,GAVbC,GAAAC,EAAA,kBAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IAmKaM,GAnKbC,GAAAC,EAAA,kBAGAC,KAgKaH,GAAWA,KCnKxB,IASaI,GA0FAC,GAnGbC,GAAAC,EAAA,kBASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,GAAMnB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EY,EAAIN,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEjB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEkB,EACJ,GAAIlB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAiB,EACArB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcqB,IAAa,GAAKrB,EAAQ,SAAW,QACrEqB,IAAa,GAAMrB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMsB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEhB,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BW,EAAQlB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBoB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMR,IAC/FM,EAAM,KAAKG,CAAa,GAAMxB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKI,CAAa,GAAMzB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKK,CAAa,GAAM1B,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKM,CAAa,EAAIb,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOa,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,EAAA,kBAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,EAAA,kBAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,EAAA,kBAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,EAAA,kBAIAC,KAoUaH,GAASA,KCxUtB,IAeaI,GAfbC,GAAAC,EAAA,kBAGAC,KAIAC,KAQaJ,GAAP,MAAOK,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1E,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOJ,GAAU,UAAYA,IAAU,MAAQA,aAAiBK,IAAU,MAAM,QAAQL,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIM,EAAiB,GAErB,GAAI,OAAOL,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBI,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQJ,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DK,EAAiB,GAEjB,QAAWC,KAAQN,EAAM,CACvB,GAAI,OAAOM,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIM,EAAY,GACVC,EAAW,OAAO,oBAAoBR,CAAI,EAChD,QAAWM,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKT,EAA4DM,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDE,EAAUH,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWM,KAAQ,KAAK,WACtB,GAAI,OAAOP,EAAMO,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIX,EAAOG,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTG,EAAyCd,EAA8BC,EACvEc,EAAqB,CAEvB,IAAIC,EACAb,EAA0B,CAAA,EAE9B,GAAI,OAAOW,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7Cc,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDc,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOjB,GAAS,SAAU,CAE5B,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCZ,EAAUY,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOd,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDgB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMjB,EAAQ,oBAAsB,CAAA,GACjB,IAAIkB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DvB,EAAU,MADA,MAAMwB,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBb,CAAO,EACzF,OAAO,IAAIN,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCrNF,IAqcayB,GArcbC,GAAAC,EAAA,kBAGAC,KAkcaH,GAA4CA,KCrczD,IAAAI,GAAAC,EAAA,oBCAA,IASaC,GATbC,GAAAC,EAAA,kBASaF,GAAP,KAAsB,CAC1B,YAAoBG,EAA+B,CACjD,KAAK,QAAUA,CACjB,CAGA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,aAAa,OAAOC,EAAgDC,EAAgC,CAElG,MAAM,IAAI,MAAM,wBAAwB,CAC1C,CAEA,MAAM,qBAAqBC,EAAoBC,EAAuB,CACpE,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,wBAAwBA,EAAuB,CACnD,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAOA,MAAM,aAAaC,EAAiBC,EAAoBC,EAAkB,CAExE,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KC/CF,IAqIaC,GArIbC,GAAAC,EAAA,kBAIAC,KAiIaH,GAA0CA,KCrIvD,IAAAI,GAAAC,EAAA,kBAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCxBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EAC1DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,EAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,GAAEI,CAAC,EAAEL,EAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,GAAEC,KAAIX,EAAE,eAAeQ,EAAEC,EAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,KAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAE,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAEC,EAAEC,EAChP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAEO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAE,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAE1B,IAAIA,EAAEwB,EAAExB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAE,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SACnfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAEA,EAAEE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAExB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIK,EAAE1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GACvfwB,EAAE,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAEjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAErB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIkC,EAAElC,EAAE,aAAakC,EAAElC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,GAAE,iCAAiC,EACve,IAAIC,EAAEC,EAAEC,EAAE,GAAGC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAG,SAASC,GAAI,CAAC,IAAI3C,EAAEkC,EAAE,OAAOrC,EAAE,MAAMyC,EAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,GAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,EAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ,IAAI,aAAaG,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,CAAC,CAAC,IAAI4C,EAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAI/C,EAAEH,EAAE,OAAO,MAAM,EAAE+C,EAAG,QAAQ5C,CAAC,CAAC,CAAC,IAAIgD,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAC7X,SAASjB,GAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAE9B,CAAC,EAAEoC,EAAE,GAAGC,EAAE,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASmD,GAAGnD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIoD,EAAyB,GAAvBA,EAAE,qBAAwB,CAACD,GAAGC,CAAC,EAAE,CAAC,IAAIC,GAAGD,EAAEA,EAAEvD,EAAE,WAAWA,EAAE,WAAWwD,GAAG9B,CAAC,EAAEA,EAAE8B,EAAE,CAAC,SAASC,GAAGtD,EAAE,CAAC,GAAGA,GAAGoD,GAAGrB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGL,EAAE,OAAOA,EAAE1B,CAAC,EAAE,KAAK,iDAAkD,CACnc,SAASuD,GAAGvD,EAAE,CAAC,GAAG,CAAC+B,IAAIX,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIqD,GAAGtD,CAAC,CAAC,EAAE,GAAGyB,EAAE,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAEzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIoD,GAAGtD,CAAC,CAAC,CAAC,CAAC,SAASwD,GAAGxD,EAAEC,EAAEC,EAAE,CAAC,OAAOqD,GAAGvD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAE,0CAA0C3B,CAAC,EAAE8B,GAAE9B,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASsD,GAAGzD,EAAEC,EAAE,CAAC,IAAIC,EAAEkD,EAAE,OAAOrB,GAAe,OAAO,YAAY,sBAA/B,YAAqDoB,GAAGjD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBkC,GAAGtD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAE,kCAAkC1B,CAAC,EAAE0B,EAAE,2CAA2C,EAAS0B,GAAGtD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9W,IAAIyD,GAAEC,GAAG,CAAC,OAAO3D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IACnf,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EACjgB,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,IAAI,CAACZ,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GACpfC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOc,EAAE,OAAO,OAAO,SAASb,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,EAAEC,EAAC,EAAE,QAAQ,CAACC,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC0B,EAAEvB,KAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,IAAI,CAACZ,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOc,EAAE,OAAO,OAAO,SAASb,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,EAAEC,EAAC,EAAE,QAAQ,CAACC,GAAEC,EAAC,EAAE,WAAW,IAC/f,CAAC,CAAC0B,EAAEvB,KAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EACnfA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IACrgB,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EACpf,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAC1fC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EACpfC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IACjf,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,CAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EACnf,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAC/eG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EACtZ,SAAS4D,GAAG9D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAI+D,GAAG/D,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAAE,SAASmE,GAAGhE,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACuC,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CACnW,IAAIwB,GAAG,EAAEC,GAAG,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACpE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQmE,GAAG,OAAOA,GAAG,OAAOnE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EACxgB0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGoE,GAAG7B,GAAEvC,EAAEC,CAAC,EAAE,GAAGoE,GAAGrE,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEqE,GAAG,CAACtE,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EACnf,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEmE,GAAEvE,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAWwE,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG1E,GAAG,CAAC,IAAIC,EAAEoE,GAAGrE,CAAC,EAAE,EAAEE,EAAEyE,GAAG1E,CAAC,EAAE,OAAAC,GAAGoE,GAAGtE,EAAEuC,GAAErC,EAAED,CAAC,EAASC,CAAC,EAAE0E,GAAG,CAAC,EAAEC,GAAG,CAAC7E,EAAEC,IAAI,CAAC2E,GAAG,OAAO,EAAE,IAAI1E,EAAE,IAAID,IAAI,EAAEC,EAAEqC,GAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE2E,GAAG,KAAU1E,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAEyC,GAAGzC,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO2E,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAIhF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IACtf,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAG,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK6E,GAAYA,GAAG7E,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE6E,GAAG7E,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAE+E,GAAG9E,CAAC,CAAC,OAAO8E,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGpF,EAAE,CAAC,IAAIC,EAAE,MAAMoE,GAAGrE,CAAC,EAAE,CAAC,EAAE,OAAAsE,GAAGtE,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACtb,SAASoF,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE6C,GAAE,CAAC,IAAI9C,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAE8C,GAAE,CAAC,EAAE9C,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS6C,GAAE0B,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE3B,GAAE9C,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDwE,GAAE3B,GAAE9C,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCwE,GAAE3B,GAAE9C,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUwE,EAAC,CAAC,SAAShF,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI6C,GAAE9C,EAAE,SAAS,EAAEyE,IAAGhB,GAAEzD,EAAE,YAAY,CAAC,EAAEoE,GAAGC,IAAIvB,EAAC,EAAE,GAAG7C,GAAEwE,GAAEzE,EAAE,QAAQ,EAAEC,IAAGwE,GAAEzE,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAG8C,GAAE9C,EAAE,SAAS8C,GAAE,CAAC,GAAG9C,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA6C,GAAE,IAAI,KAAK9C,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAE8C,GAAErD,GAAEqD,EAAC,EAAS,GAAGtD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEsD,GAAE9C,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEoD,GAAEpD,CAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE6C,GAAE,EAAEA,IAAG9C,EAAE,GAAG,EAAEC,KAAIwD,GAAEzD,EAAE,GAAG,IAAI,EAAEoE,GAAGC,IAAIvB,IAAG,EAAE,CAAC,OAAOvD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GACvf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ6C,IAAG9C,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAK8C,IAAH,GAASA,IAAH,GAAMW,GAAEzD,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI6C,IAAG9C,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAM8C,IAAH,GAASA,IAAH,GAAMW,GAAEzD,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,EAAEP,EAAE,SAASQ,EAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GACzgB,GAAG,EAAED,EAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE0E,GAAGlF,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEqC,EAAE,IAAI5B,GAAEV,IAAI,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS8E,GAAExF,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,GAAEhC,CAAC,CAAC,CAAC,CAAC,SAASwF,GAAGzF,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACsF,GAAE,KAAKvF,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAIsD,GAAE,IAAI,IAAIvF,GAAG8B,GAAE,EAAEpB,IAAO8E,KAAJ,GAAWD,GAAE,SAAN,IAAeC,GAAE,EAAEH,GAAEI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAExF,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI0F,GAAE,EAAE9E,GAAE,KAAKgF,GAAG,EAAEH,GAAE,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC9c,SAASlF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACgG,GAAG,CAAC,QAAQjG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASkG,IAAI,CAAC,IAAInG,EAAE2E,GAAG,KAAK,EAAE1E,EAAED,EAAE,GAAGyC,EAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,EAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAEyF,GAAE,CAAC,EAAE,IAAIxF,EAAE4F,GAAG7F,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE8F,KAAKF,GAAG7F,CAAC,EAAEC,EAAE6F,GAAG7F,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC5N,SAASoG,GAAGpG,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAOuD,KAAJ,EAAM,CAAC,IAAI1F,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAIyD,GAAG1F,EAAEF,EAAE,GAAGC,GAAG,CAACyF,GAAE,EAAEH,GAAE,IAAIa,GAAGxF,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAE4D,GAAGvD,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE2F,GAAG3F,IAAI2F,GAAG,MAAM9F,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI0F,GAAE,EAAE9E,GAAEsF,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAE,IAAIc,GAAGzF,EAAC,CAAC,EAAE,MAAU8E,KAAJ,GAAOA,GAAE,EAAEH,GAAEe,EAAE,EAAEC,GAAG3F,EAAC,EAAEA,GAAE,KAAKqF,GAAG,QAAQ/F,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAEA,EAAElC,EAAEkC,EAAML,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAC7hBiC,EAAE,IAAGjB,EAAEhB,EAAE,IAAI2D,GAAG3D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa0D,IAAc1D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa0D,IAAc1D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,GAAE,kBAAkB0D,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAGzG,EAAE,CAAC,OAAOoG,GAAGnG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CACnM,IAAIyG,GAAG,CAAC,EAAE,SAAS1G,EAAEC,EAAEC,EAAE,CAAC,OAAOuG,GAAG,SAAS,CAAC,MAAM5G,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIgE,GAAGhE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAE+D,GAAGjE,EAAEkE,KAAWD,EAAG,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,IAAI,GAAG,EAAE,SAASjE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EACnfF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAClf,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGqE,GAAEvE,EAAE,YAAY,CAAC,EAAEwE,GAAGC,IAAIzE,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAC5fG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAGuE,GAAEtE,EAAE,YAAY,CAAC,EAAEuE,GAAGC,IAAIxE,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAC7f,IAAW0G,IAAIjD,GAAE1D,EAAE,GAAG,CAAC,KAAK,IAAI0D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE1D,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEmC,EAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,EAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE0E,GAAG1E,CAAC,EAAEC,EAAEyE,GAAGzE,CAAC,EAAEM,GAAEH,GAAGqC,EAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,EAAEvC,EACnf,GAAG,IAAI,CAAC,EAAED,IAAIwC,EAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,EAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACiC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE4E,GAAG5E,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE4E,GAAG5E,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,GAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,GAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KACpfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAK9B,CAAC,EAAEuC,EAAG,EAAE,IAAItC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAE,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA6E,GAAG,EAAE,QAAQ,SAAS5E,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,EAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,EAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,EAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE6E,GAAG,EAAEtC,EAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,EAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EAAE,EAAE,IACrf,GAAG,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,EAAExC,GAAG,IAAI,CAAC,EAAEM,GAAEkC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,EAAE8B,GAAEjC,EAAEE,IAAI,CAAC,EAAEE,GAAEuE,GAAGjF,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAGsC,GAAG1D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAkC,EAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,EAAEiF,GAAG,EAAE,SAASrF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOkF,GAAGrF,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GAC7V,UAAU,CAAC,SAASH,EAAEE,EAAE,CAAoH,GAAnHA,EAAEA,EAAE,QAAQA,EAAEuF,GAAGvF,CAAC,EAAEiC,EAAEjC,EAAE0G,GAAG1G,CAAC,EAAEgC,EAAEC,EAAE,EAAEQ,EAAG,EAAEE,GAAG,QAAQV,EAAE,CAAC,EAAEa,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAI/C,EAAE+C,GAAEA,GAAE,KAAK/C,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAEyG,EAAE,EAA4D,GAA1D1D,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,EAAKnD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAE,sDAAsD5B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAuD,GAAGxD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAC1dF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,KAAKZ,EAAE,yBAAyBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,GAAGnC,CAAC,EAC1fH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAC/dP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACtV,IAAI2E,GAAG9E,EAAE,QAAQG,IAAI2E,GAAG9E,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAEwG,GAAG3G,EAAE,MAAMG,IAAIwG,GAAG3G,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAE2G,GAAG3G,IAAI2G,GAAGxE,EAAE,IAAInC,CAAC,EAAE6G,GAAG,KAAKA,GAAG1E,EAAE,IAAI,EAAE2E,GAAG9G,IAAI8G,GAAG3E,EAAE,IAAInC,CAAC,EAAE+G,GAAG/G,IAAI+G,GAAG5E,EAAE,IAAInC,CAAC,EAAEsG,GAAGtG,IAAIsG,GAAGnE,EAAE,IAAInC,CAAC,EAAE4F,GAAG,KAAKA,GAAGzD,EAAE,IAAI,EAAEkE,GAAGrG,IAAIqG,GAAGlE,EAAE,IAAInC,CAAC,EAAEuG,GAAG,KAAKA,GAAGpE,EAAE,IAAI,EAAEtC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAAO,SAAS+G,GAAG5G,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAWkH,GAC5elH,EAAE,UAAUgH,GAAGhH,EAAE,aAAaiH,GAAGjH,EAAE,aAAagE,GAAEhE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAIoE,GAAGtE,EAAEuC,GAAEtC,EAAEC,CAAC,EAAEL,EAAE,gBAAgBwE,GAAG,IAAI2C,GAAE9D,GAAE,SAAS+D,GAAI,CAACD,IAAGE,GAAG,EAAEF,KAAI9D,GAAE+D,EAAG,EAClJ,SAASC,IAAI,CAAC,SAASlH,GAAG,CAAC,GAAG,CAACgH,KAAIA,GAAE,GAAGnH,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE2B,GAAGlB,EAAE,EAAE/C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEiD,GAAG,QAAQ7C,CAAC,CAAC,CAAC8D,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGnD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQkD,GAAG,EAAEgB,GAAGnB,CAAE,EAAE,EAAEI,KAAInD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC1e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAqH,GAAG,EAGvGtH,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IC5E1B,IAAAyH,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,EAAE,QAAQC,GAAE,QAAQC,EAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,EAAE,QAAQC,GAAE,QAAQC,EAAE,EAASE,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAL,EAAE,QAAQC,GAAE,QAAQC,EAAE,EAASI,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAP,EAAE,QAAQC,GAAE,QAAQC,EAAE,EAASM,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAT,EAAE,QAAQC,GAAE,QAAQC,EAAE,EAASQ,EAAE,CAAC,IAAIC,EAAEb,EAAUc,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EACrSJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,EAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,GAAEI,CAAC,EAAEL,EAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,GAAEC,KAAIX,EAAE,eAAeQ,EAAEC,EAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,KAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE1B,EAAE,wBAAwB,GAAG,EAAE,GAAG,SAAS2B,EAAGxB,EAAE,CAAC,OAAOH,EAAE,WAAWA,EAAE,WAAWG,EAAE,CAAC,EAAE,EAAEA,CAAC,CAAC,IAAIyB,EAAGC,EAAEC,EAC7U,GAAGL,EAAE,CAAC,IAAIM,EAAG,cAAcC,EAAG,cAAgB,EAAER,EAAEQ,EAAG,QAAQ,CAAC,EAAE,IAAI,UAAU,IAAIJ,EAAG,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAG1B,IAAIA,EAAEwB,EAAGxB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACT,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEL,EAAE,QAAQ,IAAI,6BAA6B,IAAIG,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgB,EAAE,SAAS,cAAc,KAAM,OAAOtC,EAAe,KAAeA,IAAc,EAAEA,GAAgB,EAAE,QAAQ,OAAO,IAArB,EAAuB,EAAE,EAAE,OAAO,EAAE,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAE,EAAE,GAAGuC,IAAIG,EAAGzB,GAAG,CAAC,IAAIC,EAC9hB,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIM,EAAG3B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAGyB,EAAE,CAAC1B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aACrd,IAAIQ,EAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,EAAG,QAAQ,MAAM,KAAK,OAAO,EAAET,IAAIQ,EAAG,IAAI9B,IAAI4B,EAAG,UAAU,EAAE5B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAE+B,EAAG,IAAI/B,IAAI4B,EAAG,UAAU,EAAE5B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIgC,GAAGnC,EAAE,OAAOiC,EAAGG,EAAEpC,EAAE,UAAUkC,EAAG,OAAO,OAAOlC,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIqC,EAAErC,EAAE,aAAaqC,EAAErC,EAAE,YAAY,IAAIsC,GAActC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BuC,GAAE,iCAAiC,EAAE,IAAIlD,EAAEmD,EAAEC,GAAGC,GAAE,GAAGC,GAAErD,GAAEG,GAAGE,GAAGE,GAAGE,GAC7b,SAASR,GAAG,CAAC,IAAIY,EAAEd,EAAE,OAAOW,EAAE,MAAMV,GAAE,IAAI,UAAUa,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAOL,GAAG,IAAI,WAAWQ,CAAC,EAAEH,EAAE,OAAOP,GAAG,IAAI,WAAWU,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQH,GAAG,IAAI,YAAYM,CAAC,EAAEH,EAAE,QAAQ,IAAI,aAAaG,CAAC,EAAEH,EAAE,QAAQD,GAAG,IAAI,aAAaI,CAAC,CAAC,CAAC,IAAIyC,GAAG5C,EAAE,gBAAgB,SACnS,GAD4S,SAAS4C,IAAIL,GAAE,wDAAwDK,GAAG,wBAAwB,EAC3YlB,EAAErC,EAAEW,EAAE,mBAAmBA,EAAE,WAAWX,EAAEW,EAAE,mBAAmBX,EAAE,IAAI,YAAY,OAAO,CAAC,QAAQuD,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAEvD,EAAE,kBAAkB,mBAAmB,MAAM+C,EAAE,6NAA6N,EAAEX,GAAGW,EAAE,2GAA2G,EACrgB,MAAM,YAAY,EAAE7C,EAAE,EAAEqD,GAAGvD,EAAE,OAAO,WAAW,IAAIwD,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAE,SAASC,IAAI,CAAC,OAAOX,IAAe,EAAEU,EAAE,CAAC,IAAIE,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAAK,SAASC,IAAI,CAACH,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,CAAC,CAAC,SAASI,IAAI,CAA2D,GAA1DJ,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIjD,EAAEiD,GAAEA,GAAE,KAAKjD,EAAE,CAAC,CAAC,CAClW,SAASoC,GAAEpC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAIiC,EAAEjC,CAAC,EAAEuC,GAAE,GAAGC,GAAE,EAAExC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASoD,GAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,GAAEA,GAAE,8BAA8BD,GAAGC,EAAC,IAAIA,GAAE7B,EAAG6B,EAAC,GAAG,SAASC,GAAGtD,EAAE,CAAC,GAAGA,GAAGqD,IAAGnB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGP,EAAG,OAAOA,EAAG3B,CAAC,EAAE,KAAK,iDAAkD,CACpa,SAASuD,GAAGvD,EAAE,CAAC,GAAG,CAACkC,IAAId,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIqD,GAAGtD,CAAC,CAAC,EAAE,GAAG0B,EAAE,OAAO,IAAI,QAAQ,CAACzB,EAAEC,IAAI,CAACwB,EAAE1B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIoD,GAAGtD,CAAC,CAAC,CAAC,CAAC,SAASwD,GAAGxD,EAAEC,EAAEC,EAAE,CAAC,OAAOqD,GAAGvD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC8B,EAAE,0CAA0C9B,CAAC,EAAEiC,GAAEjC,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASsD,GAAGzD,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,GAAE,OAAOnB,GAAe,OAAO,YAAY,sBAA/B,YAAqDkB,GAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAe,OAAO,OAAnB,WAAyBkC,GAAGtD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA6B,EAAE,kCAAkC7B,CAAC,EAAE6B,EAAE,2CAA2C,EAASuB,GAAGtD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC7W,IAAIyD,GAAEC,GAAG,CAAC,OAAO3D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IACnf,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EACngB,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EACnf,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKV,EAAE,EAAE,SAASW,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,IAAI,CAACZ,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,WAAW,IAAI,CAAC,CAACtB,EAAE,EAAEwB,IAClf,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOc,EAAE,OAAO,OAAO,SAASb,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,EAAEC,EAAC,EAAE,QAAQ,CAACC,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC3B,EAAE,EAAE8B,KAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,IAAI,CAACZ,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,WAAW,IAAI,CAAC,CAACtB,EAAE,EAAEwB,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOc,EAAE,OAAO,OAAO,SAASb,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EACpfC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,EAAEC,EAAC,EAAE,QAAQ,CAACC,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC3B,EAAE,EAAE8B,KAAI,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACtB,EAAE,EAAEwB,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKnB,EAAE,EAAE,SAASoB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASuB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKV,EAAE,EAAE,SAASW,IAAI,EAAEA,EACpf,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACrB,EAAE,EAAEuB,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACtB,EAAE,EAAEwB,IAAI,CAAC,EAAE,cAAcC,GAC5f,MAAM,KAAKnB,EAAE,EAAE,SAASoB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASuB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKV,EAAE,EAAE,SAASW,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACrB,EAAE,EAAEuB,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EACnfE,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAC7f,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE6C,KAAI,CAAC/D,EAAE,GAAG,UAC3eG,EAAE,CAAC,OAAO4D,GAAE,OAAO,OAAO,SAAS3D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EACrf,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKX,EAAE,EAAE,SAASY,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,CAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAC5f,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKV,EAAE,EAAE,SAASW,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAClfG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EACpf,SAAS4D,GAAG9D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,SAAS+D,GAAG/D,EAAE,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,CAAC,SAASgE,GAAGhE,EAAE,EAAEA,EAAEiE,GAAE,GAAGjE,CAAC,IAAIoC,GAAE,EAAE6B,GAAE,GAAGjE,CAAC,CAAC,CAAC,SAASkE,GAAGlE,EAAE,CAAC,IAAIC,EAAEgE,GAAE,GAAG,EAAE,GAAG,CAAChE,EAAE,MAAO,GAAEgE,GAAE,GAAG,KAAKhE,CAAC,EAAEgE,GAAE,GAAGjE,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,CACvX,IAAImE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACpE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQmE,GAAG,OAAOA,GAAG,OAAOnE,EAAE,kBAAkB,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GACpf,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAE0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGoE,GAAG/E,EAAE,EAAEW,EAAEC,CAAC,EAAE,GAAG,SAASoE,GAAGrE,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,CAAC,EAAEwC,GAAExC,EAAM8C,GAAG,IAAGmB,GAAE,GAAG,EAAKpE,EAAE,QAAOA,EAAE,OAAOG,CAAC,EAAEuC,GAAE,IAAGpB,EAAEnB,EAAE,IAAI8D,GAAG9D,CAAC,CAAC,CAAC,CACjM,IAAIuE,GAAGvE,GAAG,CAAK,GAAJwC,GAAExC,EAAKuB,EAAE,MAAMiD,GAAGxE,CAAC,EAAE,SAASqE,GAAGrE,CAAC,CAAC,EAAEiE,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC1C,EAAE0C,GAAE,GAAG,EAAEA,GAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAACvB,GAAG,QAAQ,IAAI,CAACQ,GAAG,EAAEe,GAAE,GAAG,IAAId,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAACc,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAG9B,GAAc,EAAE,EAAE,GAAG,SAASnC,EAAE,CAACwC,GAAExC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,UAAU,CAAC,QAAQA,KAAKiE,GAAE,GAAGF,GAAG/D,CAAC,EAAE,IAAIA,KAAKiE,GAAE,GAAGF,GAAG/D,CAAC,EAAEiE,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAASjE,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAOiE,GAAE,GAAGhE,CAAC,EAAEgE,GAAE,GAAG,KAAKjE,CAAC,EAAEiE,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQjE,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,EAAEyE,GAAGxE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,EACtf,GAAG,UAAU,CAACgE,GAAE,GAAG,QAAQjE,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,EAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcqE,GAAG,EAAE,CAAC,IAAInE,GAAE0D,GAAE,GAAG5D,EAAE,EAAE,EAAEE,GAAEA,GAAE,YAAYF,EAAEA,EAAE,YAAY,EAAE4B,EAAE,0CAA0C3B,EAAE,uBAAuBD,EAAE,aAAa,qCAAqC,CAAC,MAA0BC,IAAjB,eAAmBqE,GAAG,EAA0BrE,IAAhB,cAAkB4D,GAAG7D,CAAC,EAA4BC,IAAlB,gBAAoB0D,GAAG3D,EAAE,MAAM,EAAyBC,IAAf,cAAiBD,EAAEA,EAAE,OAAOC,EAAE2D,GAAE,GAAG5D,CAAC,EAAE,OAAO4D,GAAE,GAAG5D,CAAC,EAAE0D,GAAGzD,CAAC,EAAEmE,GAAGpE,CAAC,EAAE4D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ3D,CAAC,EAClgB,CAAC,EAAEA,EAAE,GAAG,GAA2BA,IAAjB,eAAmB2D,GAAE,GAAG5D,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,IAAX,UAAaN,EAAE,OAAO,GAAGC,EAAED,CAAC,GAAoBM,IAAV,QAAY,MAAM,UAAUD,EAAE,SAAS,KAAKA,EAAE,IAAI,EAA2BA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,IAAhB,cAAkBT,EAAEQ,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,GAAG2B,EAAE,kCAAkC3B,CAAC,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,MAAA4B,EAAE,yBAAyB5B,EAAE,SAAS,IAAIA,EAAE,OAAO,KAAKA,EAAE,OAAO,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAU,SAASK,EAAE,CAACL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,CAAC,EAAEL,EAAE,GAAG,QAAQ,SAASK,EAAE,CAACL,EAAE,QAAQK,CAAC,CAAC,CAAC,GAC/f,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,SAAS,UAAU,QAAQ,UAAU,EAAEC,EAAE,IAAIA,KAAKD,EAAEN,EAAE,eAAeO,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUL,EAAE,qBAAqBd,EAAW,WAAWG,EAAE,WAAWoD,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,SAAStC,EAAE,CAACA,EAAE,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIA,EAAEwB,EAAG,kCAAkC,EAAExB,EAAE,IAAI,OAAOA,CAAC,EAAEiE,GAAE,GAAG,KAAKjE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAGiE,GAAE,GAAG,QAAR,IAAiBA,GAAE,GAAG,EAAEA,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,GAAUA,GAAE,GAAG,IAAI,CAAC,CAAC,EAAEpE,EAAE,QAAQoE,GAAE,IAAIW,GAAG5E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EACzbA,EAAE,oBAAoB,UAAU,CAAC,IAAIG,EAAE0E,GAAG,EAAEzE,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAET,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAE6E,GAAG5E,EAAEA,EAAED,CAAC,EAAE8E,GAAG7E,CAAC,CAAC,EAAE,SAASuE,GAAGxE,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,CAAC,EAAEuE,GAAGvE,CAAC,CAAC,CAACH,EAAE,iBAAiB,SAASG,EAAEC,EAAE,CAACD,EAAE+E,GAAG,MAAM,KAAK,CAAC/E,EAAEC,CAAC,CAAC,EAAE6C,GAAG,EAAEmB,GAAE,GAAGjE,CAAC,EAAEgF,GAAGhF,CAAC,CAAC,EAAE,SAASiF,GAAGjF,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACR,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEQ,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACR,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEQ,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACT,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAIyF,GAAG,EAAEC,GAAG,EAC/b,SAASC,GAAGpF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAEkF,GAAGrF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASkF,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAO8B,EAAE,qFAAqF,EAAE,EAAE,IAAI7B,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoBgF,GAAGpF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAG8D,GAAGlE,CAAC,EAAC,CAAC,SAASsF,GAAGtF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASqF,GAAGvF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CACrc,IAAIuF,GAAGxF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEwF,GAAG,CAACzF,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEsF,GAAG,CAAC1F,EAAEC,EAAEC,IAAIuF,GAAGzF,EAAEX,EAAE,EAAEY,EAAEC,CAAC,EAAE,SAASyF,GAAG3F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAAS2F,GAAG5F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS2F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAG/F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAGhG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAGjG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGlG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9d,SAASgG,GAAGnG,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,CAAC,CAAC,CAAC,SAASoG,GAAGpG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAASoG,GAAGrG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIoG,GAAGtG,GAAG,CAAC,GAAG,CAACuC,GAAE,GAAG,CAAC,GAAGvC,EAAE,EAAE,CAAC8C,GAAG,EAAE,GAAG,CAACvB,EAAEyD,GAAGxC,EAAC,EAAE+B,GAAG/B,EAAC,CAAC,OAAOvC,EAAE,CAACA,aAAa6D,IAAc7D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa6D,IAAc7D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,EAAE,SAASsG,GAAGvG,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGT,EAAE,EAAES,GAAG,EAAEA,CAAC,EAAE,MAAM,KAAK2E,EAAE,EAAE3E,GAAG,IAAI,QAAQ,MAAMT,EAAE,EAAES,GAAG,EAAE,CAAC,EAAE,CAACH,EAAE,kCAAkC0G,GAAG,SAAS5B,IAAI,CAAC,IAAI3E,EAAE0E,GAAG,EAAE1E,IAAIuG,GAAGvG,CAAC,EAAEsG,GAAG,IAAIE,GAAG,CAAC,EAAE,CAAC3G,EAAE,aAAa8E,GACpf,IAAI8B,GAAEzG,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW0G,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,GAAG5G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAE,CAAC,OAAOgB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAE,GAAG,CAAC,SAASsG,EAAG7G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGiB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIwG,EAAG9G,GAAG,CAAC,IAAIC,EAAEuF,GAAGxF,CAAC,EAAE,EAAEE,EAAE6G,GAAG9G,CAAC,EAAE,OAAAC,GAAGwF,GAAG1F,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAE8G,EAAG,CAAC,EAAEC,EAAG,CAACjH,EAAEC,IAAI,CAAC+G,EAAG,OAAO,EAAE,IAAI9G,EAAE,IAAID,IAAI,EAAEC,EAAEb,EAAE,EAAEW,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE+G,EAAG,KAAU9G,GAAL,IAAOX,EAAE,EAAEU,IAAI,CAAC,EAAEN,EAAG,EAAEM,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO+G,CAAE,EAAEE,EAAGlH,GAAG,CAAC,IAAIC,EAAEkH,GAAG,EAAE,OAAAnH,EAAEA,EAAE,EAAE8E,GAAG7E,CAAC,EAASD,CAAC,EACve,SAASsE,EAAEtE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAO+G,EAAG,IAAI,CAAC,QAAQ9G,EAAEgH,GAAG,EAAElH,CAAC,EAAEG,EAAED,GAAG,EAAEE,EAAE,EAAEA,EAAEJ,EAAEI,IAAI,CAAC,IAAIC,GAAEJ,EAAE,EAAEG,CAAC,EAAEX,EAAG,EAAEU,EAAEC,IAAI,CAAC,EAAEC,EAAC,CAAC,OAAO8G,GAAGrH,EAAEE,EAAEE,EAAEH,CAAC,CAAC,CAAC,CAAC,CAC3J,IAAIqH,EAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,EAAG,IAAI,CAAC,GAAG,CAACC,EAAG,CAAC,IAAIzH,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKsH,GAAYA,GAAGtH,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEsH,GAAGtH,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEwH,EAAGvH,CAAC,CAAC,OAAOuH,CAAE,EAAEA,EACtW,SAASC,GAAG1H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAsH,EAAG,EAAE,QAAQ,SAASrH,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAwB,IAAtBE,EAAEX,EAAE,EAAEO,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEpB,EAAE,EAAEmB,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEpB,EAAE,EAAEmB,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAASwH,GAAG3H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEsH,EAAG,EAAE/H,EAAE,EAAEO,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEX,EAAE,EAAEQ,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAASyH,GAAG5H,EAAE,CAAC,OAAOuB,EAAE+C,EAAE,GAAG,EAAEtE,CAAC,EAAE,EAAE,CAAC,SAAS6H,EAAG7H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAC/c,SAAS2H,GAAG9H,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAI2H,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGhI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEb,EAAE,EAAEQ,GAAG,IAAI,CAAC,EAAEM,GAAEd,EAAE,EAAEQ,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,EAAEpB,EAAE,EAAEiB,EAAEE,IAAI,CAAC,EAAEE,GAAEqH,GAAG/H,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAMgC,GAAGC,GAAGmC,GAAG1D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAd,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAI6H,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGnI,EAAE,CAAC,IAAIC,EAAE,MAAMuF,GAAGxF,CAAC,EAAE,CAAC,EAAE,OAAAyF,GAAGzF,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACjf,IAAImI,GAAG,CAACpI,EAAEC,IAAI,CAAChB,EAAE,EAAE,IAAIe,EAAEC,IAAI,CAAC,CAAC,EAC/B,SAASoI,GAAGrI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE6C,GAAE,CAAC,IAAI9C,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAE8C,GAAE,CAAC,EAAE9C,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS6C,GAAE0E,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE3E,GAAE9C,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDwH,GAAE3E,GAAE9C,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCwH,GAAE3E,GAAE9C,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUwH,EAAC,CAAC,SAAShI,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI6C,GAAE9C,EAAE,SAAS,EAAEyH,IAAG9B,GAAE3F,EAAE,YAAY,CAAC,EAAEmH,GAAGC,IAAItE,EAAC,EAAE,GAAG7C,GAAEwH,GAAEzH,EAAE,QAAQ,EAAEC,IAAGwH,GAAEzH,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAG8C,GAAE9C,EAAE,SAAS8C,GAAE,CAAC,GAAG9C,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA6C,GAAE,IAAI,KAAK9C,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAE8C,GAAErD,GAAEqD,EAAC,EAAS,GAAGtD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEsD,GAAE9C,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAElB,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGZ,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGZ,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEoD,GAAEpD,CAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WACxf,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GACzfF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE6C,GAAE,EAAEA,IAAG9C,EAAE,GAAG,EAAEC,KAAI0F,GAAE3F,EAAE,GAAG,IAAI,EAAEmH,GAAGC,IAAItE,IAAG,EAAE,CAAC,OAAOvD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GACnf,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ6C,IAAG9C,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAK8C,IAAH,GAASA,IAAH,GAAM6C,GAAE3F,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI6C,IAAG9C,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAM8C,IAAH,GAASA,IAAH,GAAM6C,GAAE3F,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,EAAEP,EAAE,SAASQ,EAAC,IACrgBR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAEyH,GAAGjI,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEmI,GAAG1H,GAAEV,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS8H,GAAGxI,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACmC,GAAEnC,CAAC,CAAC,CAAC,CAAC,SAASwI,GAAGzI,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACsI,GAAG,KAAKvI,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQmC,KAAImG,GAAG,IAAI,IAAIvI,GAAGiC,GAAE,EAAEvB,IAAO8H,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAE9F,IAAI,EAAE2F,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAExI,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI0I,GAAE,EAAE9H,GAAE,KAAKgI,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC7e,SAASlI,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACgJ,GAAG,CAAC,QAAQjJ,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASkJ,IAAI,CAAC,IAAInJ,EAAE+G,GAAG,KAAK,EAAE9G,EAAED,EAAE,GAAGP,EAAE,EAAEO,GAAG,IAAI,CAAC,EAAEC,EAAER,EAAE,EAAEO,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAEyI,GAAG,CAAC,EAAE,IAAIxI,EAAE4I,GAAG7I,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE8I,KAAKF,GAAG7I,CAAC,EAAEC,EAAE6I,GAAG7I,CAAC,EAAED,GAAGA,EAAEC,EAAEX,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAASoJ,IAAI,CAAC,IAAIpJ,EAAET,EAAE,EAAEsB,GAAE,GAAG,IAAI,CAAC,EAAE,OAAAb,EAAEqC,EAAE0G,GAAG/I,CAAC,CAAC,EAAE,EAAE6C,GAAU7C,EAAE,CAAC,CACtS,SAASqJ,GAAGrJ,EAAE,CAAC,GAAG,CAACuC,GAAE,CAAC,GAAOoG,KAAJ,EAAM,CAAC,IAAI1I,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACoC,KAAIsG,GAAG1I,EAAEF,EAAE,GAAGC,GAAG,CAACyI,GAAE,EAAEH,GAAG,IAAIc,GAAGzI,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEgJ,GAAG,CAAC,OAAO7I,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE2I,GAAG3I,IAAI2I,GAAG,MAAM9I,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI0I,GAAE,EAAE9H,GAAEsI,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIe,GAAG1I,EAAC,CAAC,EAAE,MAAU8H,KAAJ,GAAOA,GAAE,EAAEH,GAAGgB,EAAE,EAAEC,GAAG5I,EAAC,EAAEA,GAAE,KAAKqI,GAAG,QAAQ/I,GAAGmG,GAAGnG,CAAC,CAAC,GAAGiC,GAAE,kBAAkBuG,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC/d,SAASa,GAAG1J,EAAE,CAAC,OAAOqJ,GAAGpJ,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAACgE,GAAE,GAAG,EAChD,IAAI0F,GAAG,CAAC,KAAKtF,GAAGG,GAAGY,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGO,GAAGC,EAAGa,GAAGC,GAAGC,GAAGC,EAAGC,GAAGE,EAAE,EAAE4B,GAAG,CAAC,EAAE,SAAS5J,EAAEC,EAAEC,EAAE,CAAC,OAAOwJ,GAAG,SAAS,CAAC,MAAM7J,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIiF,GAAGjF,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEgF,GAAGlF,EAAEmF,KAAWD,EAAG,EAAE,EAAE,SAASlF,EAAE,CAAC6J,GAAG7J,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE6C,GAAE,GAAG,CAAC,EAAE,EAAE,SAASjE,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,EAAEgE,GAAGhE,CAAC,CAAC,EAAE,EAAEqF,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAE,IAAI,GAAG,EAAE,SAASrG,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAI0E,GAAG,CAAC,EAAEpD,EAAE,YAAY,CAAC,aAAavB,EAC5f,IAAI,cAAc,CAAC,GAAGA,EAAEiE,GAAE,GAAGjE,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,EAAE,EAAE,EAAEuG,GAAG,EAAE,SAASvG,EAAE,CAACsB,GAAG2C,GAAE,GAAGjE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAET,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKT,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAC3f,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAET,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKT,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEC,GAAGwG,GAAEzG,EAAE,YAAY,CAAC,EAAE0G,GAAGC,IAAI3G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAED,EAAEV,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EACrf,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGC,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,EAAEV,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKT,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAET,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAET,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAET,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAET,EAAE,EAAES,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEX,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEX,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAClf,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGZ,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGuG,GAAExG,EAAE,YAAY,CAAC,EAAEyG,GAAGC,IAAI1G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEE,EAAEX,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEV,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEV,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAW6J,IAAIpG,GAAE1D,EAAE,GAAG,CAAC,KAAK,IAAI0D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE1D,IAAI,CAAC,EAAE,EAAE4G,GAAG,EAAEC,EACpf,EAAE,SAAS7G,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEE,EAAE,KAAK,IAAIJ,EAAEG,EAAC,EAAEd,EAAE,EAAEO,GAAG,IAAI,CAAC,EAAE,GAAGQ,EAAEjB,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE8G,EAAG9G,CAAC,EAAEC,EAAE6G,EAAG7G,CAAC,EAAEM,GAAEH,GAAGX,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEF,EAAEP,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAED,IAAIR,EAAE,EAAES,GAAG,IAAI,CAAC,EAAED,EAAER,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACoC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASpC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEgH,EAAGhH,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EACtfC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEgH,EAAGhH,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAA4C,IAAI,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,UAAU,CAAC,OAAOvB,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,mBAAmB,EAAE,EAAE,SAAStB,EAAEC,EAAEC,EAAEC,EAAE,CAAmC,IAAlC8D,GAAE,GAAGhE,IAAI,EAAEqH,EAAG,OAAOpH,EAAED,EAAEE,IAAI,GAAG,EAAMA,EAAE,EAAEA,EAAED,EAAEC,IAAImH,EAAGnH,CAAC,EAAER,EAAG,EAAEM,EAAEE,IAAI,CAAC,EAAE,OAAO,EAAEH,EAAE2D,GAAG,CAAC3D,EAAE,CAAC,EAAE2J,GAAG3J,CAAC,GAAG,MAAM,KAAKsH,CAAE,CAAC,EAAE,EAAE,SAAStH,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEZ,EAAE,EAAE,OAAO,GAAGW,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EACxf,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAEjB,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAKkB,CAAC,EAAEhB,EAAE,EAAE,IAAIiB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAEqH,GAAG,EAAEC,GAAG,EAAEpD,GAAG,EAAEqD,GAAG,EAAEC,EAAG,EAAEC,GAAG,EAAEE,GAAG,EAAE9I,GAAGW,EAAE,WAAW,EAAEwI,GAAG,EAAE,SAASrI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOkI,GAAGrI,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GACrW,UAAU,CAAC,SAASH,EAAEE,EAAEC,EAAE,CAAC,OAAAD,EAAEA,EAAE,QAAQA,EAAEuI,GAAGvI,CAAC,EAAEmC,EAAEnC,EAAE6J,GAAG7J,CAAC,EAAE+D,GAAE,GAAG,KAAK5B,EAAE,EAAE,EAAEM,GAAG,QAAQN,EAAE,CAAC,EAAEC,GAAGnC,EAAEgD,GAAG,EAASjD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE2J,EAAE,EAAO,GAAL1G,GAAG,EAAKrD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC+B,EAAE,sDAAsD/B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAuD,GAAGxD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,SAASA,EAAE,MAAM,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAAEF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASwC,EAAE,GAAGrC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBwC,EAAE,GAAGrC,EAAEC,CAAC,EAC7ZJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,KAAKZ,EAAE,yBAAyBwC,EAAE,GAAGrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAC7dL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBwC,EAAE,IAAIrC,CAAC,EAC5dH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAewC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBwC,EAAE,IAAIrC,CAAC,EACxeH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBwC,EAAE,IAAIrC,CAAC,EAAE,IAAI0E,GAAG7E,EAAE,cAAc,KAAK6E,GAAG7E,EAAE,cAAcwC,EAAE,IAAI,EAAE0E,GAAGlH,EAAE,QAAQG,IAAI+G,GAAGlH,EAAE,QAAQwC,EAAE,IAAIrC,CAAC,EAAEyJ,GAAG5J,EAAE,MAAMG,IAAIyJ,GAAG5J,EAAE,MAAMwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,sBAAsB,KAAKA,EAAE,sBAAsBwC,EAAE,IAAI,EAC7d,IAAIwH,GAAGhK,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwJ,GAAGhK,EAAE,yBAAyBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,4BAA4B,KAAKA,EAAE,4BAA4BwC,EAAE,IAAI,EAC1K,IAAIgF,GAAG,CAACrH,EAAEC,EAAEC,EAAEC,KAAKkH,GAAGhF,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsE,GAAGzE,IAAIyE,GAAGpC,EAAE,IAAIrC,CAAC,EAAEgF,GAAGnF,EAAE,yBAAyBG,IAAIgF,GAAGnF,EAAE,yBAAyBwC,EAAE,IAAIrC,CAAC,EAAEwG,GAAG3G,EAAE,2BAA2B,KAAK2G,GAAG3G,EAAE,2BAA2BwC,EAAE,IAAI,EAAEyH,GAAG9J,IAAI8J,GAAGzH,EAAE,IAAIrC,CAAC,EAAE6E,GAAG,CAAC7E,EAAEC,KAAK4E,GAAGxC,EAAE,IAAIrC,EAAEC,CAAC,EAAEkH,GAAG,KAAKA,GAAG9E,EAAE,IAAI,EAAEyC,GAAG9E,IAAI8E,GAAGzC,EAAE,IAAIrC,CAAC,EAAEoH,GAAGpH,IAAIoH,GAAG/E,EAAE,IAAIrC,CAAC,EAAE+E,GAAGlF,EAAE,WAAW,CAACG,EAAEC,KAAK8E,GAAGlF,EAAE,WAAWwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEsJ,GAAGvJ,IAAIuJ,GAAGlH,EAAE,IAAIrC,CAAC,EAAE4I,GAAG,KAAKA,GAAGvG,EAAE,IAAI,EAAEiH,GAAGtJ,IAAIsJ,GAAGjH,EAAE,IAAIrC,CAAC,EAAEwJ,GAAG,KAAKA,GAAGnH,EAAE,IAAI,EAAExC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAC1d,SAASkK,GAAG/J,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,aAAaC,EAAED,EAAE,YAAY,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,iBAAiBiD,GAAGjD,EAAE,WAAWX,EAAEW,EAAE,WAAWuH,GAAGvH,EAAE,UAAUsH,GAAGtH,EAAE,aAAaiF,GAAGjF,EAAE,aAAagE,GAAEhE,EAAE,aAAa6F,GAAG7F,EAAE,gBAAgB2F,GAAG3F,EAAE,WAAWiE,GAAGjE,EAAE,QAAQoE,GAAE,IAAI+F,GAAG/G,GAAE,SAASgH,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAK/G,GAAEgH,EAAG,EAC/b,SAASC,IAAI,CAAC,SAASlK,GAAG,CAAC,GAAG,CAACgK,KAAKA,GAAG,GAAGnK,EAAE,UAAU,GAAG,CAAC0C,MAAIhB,GAAGqD,GAAGjC,EAAE,EAAE7C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAK,CAAC0B,GAAE,CAAC,GAAG1B,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAE+C,GAAG,QAAQ3C,CAAC,CAAC,CAAC2E,GAAGhC,EAAE,CAAC,CAAE,CAAC,GAAG,EAAE,EAAEG,IAAG,GAAGxB,EAAEzB,EAAGD,CAAC,EAAE0B,GAAGqD,GAAGjC,EAAE,EAAE,YAAY9C,CAAC,MAAM,CAAC,GAAGA,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQ6C,GAAG,QAAQ7C,EAAE,OAAO,MAAM,CAAC,EAAE+E,GAAGlC,EAAE,EAAE,EAAEK,KAAIlD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EACpiB,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAAC,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAqK,GAAG,EAGzHlL,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC7FlC,IAAAqL,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,kiFCAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA8GAC,GAxMbC,GAAAC,EAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA6ErC,GA1EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EACrC,GAAI,OAAO,KAAS,IAClBc,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC9MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,EAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,EAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GA+EOC,GArIbC,GAAAC,EAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,WAAY,CAC5B,IAAIM,EAAaN,EAAa,YAE1B,OAAOM,GAAc,UAAY,CAAC,OAAO,UAAUA,CAAU,GAAKA,EAAa,KACjFA,EAAa,GAEf,IAAML,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBI,EAAW,SAAS,EAAGR,CAAM,EACjEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMY,EAAgBZ,EACtB,GAAIY,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAMN,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBK,EAAc,gBAAiBT,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDE,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCR,CAAM,EAAE,CACjE,CAEA,IAAMS,EAAmBN,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBY,CAAgB,IAAM,GACxFH,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMgB,EAAOL,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBY,EAAkDjB,GAAW,CAAC,EACpET,GAAqB0B,CAAc,EAEnC,GAAI,CACF,IAAMnB,EAAyBT,GAAyB4B,EAAe,wBAA0B,KAAK,EAChGlB,EAAgBT,GAAiB2B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWR,GAAgBQ,EAAe,MAAOZ,CAAM,EAAI,EAEzFc,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFR,GAAgBQ,EAAe,uBAAwBZ,CAAM,EAC7D,EAcJ,GAZAF,EAAuBa,EAAK,yBACxBlB,EAAwB,CAAC,CAACmB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBlB,EAC/F,CAAC,CAACkB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BlB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CK,EAAe,oBACjBzB,GAAsBW,EAAsBc,EAAe,mBAAoBZ,CAAM,EAGnFY,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAaf,GAAgBa,EAAMjB,CAAM,EAC3CW,EAAK,6BAA6Bb,EAAsBqB,EAAYD,CAAK,IAAM,GACjFX,GAAe,wCAAwCU,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMf,EAAgBC,GAAgBiB,EAAKrB,CAAM,EAC3CK,EAAkBD,GAAgBc,EAAOlB,CAAM,EAEjDW,EAAK,0BAA0Bb,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCc,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACpB,EAAsBE,CAAM,CACtC,OAASsB,EAAG,CACV,MAAIxB,IAAyB,GAC3Ba,EAAK,0BAA0Bb,CAAoB,EAErDE,EAAO,QAAQuB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IC/MA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,EAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,EAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,EAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,EAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,EAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,EAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,YACR,KAAK,UACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,SACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,EAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASC,EAAIN,EAAW,EAAI,EAAGM,GAAKH,EAAOG,IAAK,CAC9C,IAAMC,EAAON,EAAQK,EAAI,EAAI,EAAIR,EAAMG,EAAQK,CAAC,EAC1CE,EAAON,EAAQI,EAAI,EAAI,EAAIP,EAAMG,EAAQI,CAAC,EAEhD,GAAIC,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFJ,EAAMD,EAAQG,CAAC,EAAI,KAAK,IAAIC,EAAMC,CAAI,CACxC,CAEA,OAAOJ,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASN,EAAI,EAAGA,GAAKK,EAAWL,IAC9B,GAAIG,EAAME,EAAYL,CAAC,IAAM,GAAKG,EAAME,EAAYL,CAAC,IAAMI,EAAWE,EAAYN,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGajB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASZ,EAAIU,EAAOV,EAAIW,EAAKX,IAAK,CAGhC,GAAIQ,EAAKR,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHY,GAAQJ,EAAKR,CAAC,CAChB,CACA,OAAOY,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASb,EAAIa,EAAO,EAAGb,GAAK,EAAG,EAAEA,EAC/Bc,EAAQd,CAAC,EAAIc,EAAQd,EAAI,CAAC,EAAIQ,EAAKR,EAAI,CAAC,EAE1C,OAAOc,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGnB,IAAMmB,EAAIC,EAAIpB,CAAC,EAAIoB,EAAIpB,EAAIa,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGnB,IAAMmB,IAAMG,EAAOtB,CAAC,CAAC,CAC/C,CACF,EAEahB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAqMPC,GAoCOC,GAUAC,GAaPC,GAuSOC,EAaAC,GAyDPC,GA+EOC,GAYAC,GAztBbC,GAAAC,EAAA,kBAGAC,KACAC,KAaab,GAAiB,GAqMxBC,GAAoB,CAACa,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEaZ,GAA8B,CAACY,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAaf,GAAkBa,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAOab,GAA8Bc,GACnB,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAYvGb,GACF,CAACe,EAAcC,EAAoBC,EAAuCC,EACzEP,IAAuC,CACtC,IAAMQ,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFR,EAAaf,GAAkBmB,EAAYL,CAAU,EACrDY,EAAY,OAAOX,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEY,EAAc,OAAOZ,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASY,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,GAA+B,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGb,CAAI,SAC/Be,EAAU,GAAGF,CAAa,GAAGb,CAAI,WACnCgB,EAAa,GACjB,QAASC,EAAI,EAAGA,EAAIZ,EAAO,EAAGY,IAC5BD,GAAc;AAAA,aACTC,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC5BA,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC7BA,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,oBAAoBL,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzBqB,CAAU;AAAA;AAAA,KAIJG,EAAmBC,IACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,EAAY,OAAOpB,CAAI,IAAIoB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,EAAIZ,EAAO,EAAGY,GAAK,EAAGA,IAC7BI,EAAQ,KAAK,GAAGN,CAAO,IAAIE,CAAC,gBAAgBA,CAAC,IAAI,EAIrD,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,aAAaL,EAAK,OAAO;AAAA,aAC3B0B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,IACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,EAAa,OAAOxB,CAAI,IAAIwB,CAAU,KAGpDC,EAAU,IAAIC,IAChBrB,IAAS,EAAI,KAAO,GAAGV,EAAK,OAAO,IAAI+B,EAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,EAAa,CAACH,EAAoBI,KAClCvB,EAAO,EACF,GAAGmB,CAAU,GAEb,GAAGA,CAAU,IAAII,EAAG,IAIzBC,GAAa,CAACL,EAAoBI,GAAoBE,KACtDzB,EAAO,EACF,GAAGmB,CAAU,IAAIM,EAAK,IAEtB,GAAGN,CAAU,IAAII,EAAG,KAAKE,EAAK,IAInCC,EAAoE,CAAC,EACrEC,EAA6B,CAACR,EAAoBS,KAA0B,CAChFrB,EAAmB,2BAA6B,GAChD,IAAMsB,GAAU,GAAGD,GAAO,IAAI,uBAAuBjC,CAAI,SACzD,GAAIkC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIV,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMK,GAAO,WAAW,gBAAiBhB,GAAIgB,GAAO,KAAO5B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,EAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,EAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAc,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,GAAO,KAAK,OAAO;AAAA,sBACzCZ,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGa,EAAO,IAAIV,CAAU,GACjC,EAEMW,GAAc,CAACC,EAAuBN,MAAmB,IAAM,CACnE,GAAInC,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGK,CAAI,IAAIoC,CAAM,KAAKN,EAAK,IAC7B,GAAInC,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGK,CAAI,IAAIoC,CAAM,mBAAmBN,EAAK,8BAA8BA,EAAK,UAC9E,GAAInC,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGK,CAAI,IAAIoC,CAAM,mBAAmBN,EAAK,UAC3C,GAAInC,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGK,CAAI,IAAIoC,CAAM,8DAA8DN,EAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CnC,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG0C,EAAeD,IAA2B,IAAM,CACpD,GAAIzC,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGK,CAAI,IAAIoC,CAAM,IACnB,GAAIzC,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOK,CAAI,IAAIoC,CAAM,OACvB,GAAIzC,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOK,CAAI,IAAIoC,CAAM,OACvB,GAAIzC,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBK,CAAI,IAAIoC,CAAM,oBAAoBpC,CAAI,IAAIoC,CAAM,sBAAsBpC,CAAI,IAChGoC,CAAM,wBAAwBpC,CAAI,IAAIoC,CAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6CzC,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG2C,EAA6BjC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBL,EAAK,OAAO,QAAQa,CAAS;AAAA,aACrD6B,EAAY,OAAOrC,CAAI,WAAW,CAAC;AAAA,KAGpCuC,GAAoBlC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMmC,EAAiBlC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DwB,GAAanC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIwC,CAAc,QAAQhC,CAAS;AAAA,iBACjCR,CAAI,aAAayB,EAAQgB,EAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIjB,IAA0C,CACxD,GAAIA,EAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMsC,GAAoBlB,EAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJgC,EAAY,IAAI,EACdhC,IAAS,EACXgC,EAAYM,GAAkB,CAAC,CAAC,GAEvC/B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI2C,EAAiB,IAE3C,EAEMC,GAAgBpB,GAChBnB,EAAO,EACFgC,EAAYb,CAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAIvCqB,GAA6BxC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBL,EAAK,OAAO,YAAYa,CAAS;AAAA,MAChE2B,GAAY,OAAOnC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC8C,GAAoBzC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMmC,EAAiBlC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DwB,GAAanC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIwC,CAAc,YAAYhC,CAAS;AAAA,UAC5CR,CAAI,aAAayB,EAAQgB,EAAU,CAAC;AAAA,IAExC,GAAG,EAiEH,MAAO,CACL,KA/BW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACf,OAAK3C,IACH2C,EAAM,KAAK,SAASjC,CAAK,MAAMnB,EAAK,OAAO,IAAIO,EAAY,KAAK,GAAG,CAAC,IAAI,EACxE6C,EAAM,KAAK,SAAShC,CAAO,MAAMpB,EAAK,OAAO,IAAII,EAAU,eAAeG,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,GAElGU,EAAmB,iBACrBmC,EAAM,KAAK7B,CAA6B,EAEtCN,EAAmB,iBACrBmC,EAAM,KAAKzB,CAA6B,EAEtCV,EAAmB,4BACrB,OAAO,OAAOmB,CAAwC,EAAE,QAAQiB,IAAQD,EAAM,KAAKC,EAAI,CAAC,EAEtFpC,EAAmB,KACrBmC,EAAM,KAAKD,EAAiB,EAE1BlC,EAAmB,cACrBmC,EAAM,KAAKF,EAA0B,EAEnCjC,EAAmB,KACrBmC,EAAM,KAAKR,EAAiB,EAE1B3B,EAAmB,cACrBmC,EAAM,KAAKT,CAA0B,EAEhCS,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAApD,EACA,gBAAAwB,EACA,gBAAAI,EACA,2BAAAS,EACA,QAAAP,EACA,WAAAE,EACA,WAAAE,GACA,IAxEU,IAAIoB,IAAkD,CAChE,GAAIA,EAAgB,SAAW5C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMyB,GAAQmB,EAAgB5C,CAAI,EAClC,GAAI,OAAOyB,IAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAMa,GAAoBM,EAAgB,MAAM,EAAG5C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ8B,GAAY,KAAML,EAAK,EACrBzB,IAAS,EACX8B,GAAYQ,GAAkB,CAAC,EAAGb,EAAK,GAE9ClB,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI2C,EAAiB,KAAKb,EAAK,IAErD,EAoDE,YAAAK,GACA,aAnDmB,CAACX,EAAoBM,KACpCzB,EAAO,EACF8B,GAAYX,EAAYM,EAAK,GAEpClB,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAAKM,EAAK,MA8CrD,IAAAY,GACA,YAAAL,EACA,aAAAO,GAEA,MAAOzC,EAAU,QAAU,SAC3B,KAAAH,EACA,QAAAe,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWSnB,EACT,CAACc,EAAcL,EAAcO,EAAuCN,EAAsB,IACtFX,GAAoBe,EAAML,EAAMO,EAAa,GAAMN,CAAU,EAWxDT,GACT,CAACa,EAAcL,EAAcO,EAAuCN,EAAsB,IACtFX,GAAoBe,EAAML,EAAMO,EAAa,GAAON,CAAU,EAuDhER,GAAN,KAA+C,CAC7C,YAAoB8D,EAAmD,CAAnD,6BAAAA,EAoDpB,KAAQ,eAAkC,CAAC,EAC3C,KAAQ,SAAgD,CAAC,EAezD,KAAQ,cAAgB,CApEgD,CAExE,sCAAsCC,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUC,EAAiDvE,GAAgB,CACzE,IAAMwE,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA,wDAEA;AAAA,qDAEnCE,EAAsBF,EACxB,gCACA,sCAAsC,KAAK,wBAAwB,CAAC,EAAI,KAAK,wBAAwB,CAAC,CAAC;AAAA,6BAClF,KAAK,wBAAwB,CAAC,CAAC,yBAChDH,EAAiBC,EAAiBC,CAAc,mBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,gBAAgBC,EAAyBC,EAA8B,CAC7E,KAAK,eAAe,KAAKD,CAAQ,EAC7BA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAE7FA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAEnG,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/ClD,EAAckD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWlD,CAAW,IAC3G,CAEA,oBAAoBqD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEA,gBAAgB/D,EAAcL,EAA4B,CACxD,YAAK,SAAS,KAAK,CAAC,KAAAK,EAAM,KAAAL,CAAI,CAAC,EACxB,IACT,CAIQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMqE,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAAhE,EAAM,KAAAL,CAAI,IAAK,KAAK,SAC9BqE,EAAgB,KAAK,GAAGhE,CAAI,IAAIL,CAAI,EAAE,EAGxC,MAAO;AAAA,0BACeqE,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,eAAe,IAAI/C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACrF,CACF,EAEa5B,GAAsB4E,GAA4C,IAAI7E,GAAiB6E,CAAa,EAYpG3E,GAAmB,CAAC4E,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjBpE,EAAiB,CAAC,EACxB,QAASmB,EAAI,EAAGA,EAAImD,EAAQnD,IAAK,CAC/B,IAAMN,EAAMyD,EAAS,EAAInD,EACnBoD,EAAIH,EAAQvD,CAAG,GAAK,GAChBwD,EAASA,EAAS,OAAS,EAAIlD,CAAC,GAAK,GACvC,GAAKoD,IAAM,GACjBvE,EAAK,QAAQa,CAAG,CAEpB,CACA,OAAOb,CACT,ICruBA,IAWMwE,GAoBAC,GACOC,GA4EPC,GAUAC,GAeOC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GA/QbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAEMpB,GAAkBqB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYMpB,GAAkBqB,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,YAAY,aAAa,CAAC,IAAK,EAAE,EACpFpB,GACT,CAACqB,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KAEvBW,EAAOC,EAAU,cAAcP,EAAWL,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/Da,EAAkB,CAACL,GAAqBG,EAAK,SAAW,EAC9DD,EAAW,QAAQ,CAACI,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCR,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKK,CAAC,CAEtB,CAAC,EAED,IAAME,EAAoB,CAAC,EAErBf,EAAQgB,EAAc,KAAMjB,EAAO,CAAC,EAAE,SAAUU,CAAU,EAC1DQ,EAASC,GAAe,SAAUb,EAAgBG,CAAW,EAC7DW,EAAMhB,EAASH,EAAOiB,EAAQP,CAAI,EAClCU,EAAwB,iBAAiBpB,EAAM,gBAAgB,cAAc,CAAC,IAC9EqB,EAAqB,OAAOD,CAAqB,IACjDE,EAAqB,OAAOF,CAAqB,IACjDG,EAAmBJ,EAAI,CAAC,IAAM,GAAM,GAAKG,EAC3CE,GAAcL,EAAI,CAAC,IAAM,GAAME,EAAqBD,GAAyB;AAAA,EAAOD,EAAI,CAAC,EAE7F,QAASM,EAAI,EAAGC,EAAI,EAAGD,EAAI1B,EAAO,CAAC,EAAE,KAAK,OAAQ0B,IAE5Cb,GAAmBF,EAAK,QAAQe,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAM1B,EAAO,CAAC,EAAE,KAAK0B,CAAC,CAAC,MAAMA,CAAC;AAAA,kBAC/DN,EAAI,CAAC,EAAE,SAAS,WAAW,EAAI,oBAAoBM,CAAC,IAAM,EAAE;AAAA,kBAC5DzB,EAAM,WAAW,eAAgByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,kBAC5CD,CAAS;AAAA,mBAGjBT,EAAQ,KAAK,GAAGf,EAAM,WAAW,eAAgByB,EAAGR,EAAO,WAAW,gBAAiBS,CAAC,CAAC,CAAC,GAAG,EAC7FA,KAIJ,IAAMC,EAAahB,EAAU,KAAKH,CAAW,EAkB7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBApBuB0B,GAA+B;AAAA,UACpDA,EAAa,iBAAiB5B,EAAOiB,CAAM,CAAC;AAAA;AAAA,UAE5CW,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCD,CAAU,CAAC;AAAA,8BAC5C3B,EAAM,KAAK,OAAO;AAAA,gCAChBiB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNI,CAAe;AAAA,YACfJ,EAAI,CAAC,CAAC;AAAA,YACNK,CAAS;AAAA,YACTL,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,WAO1F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMX,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEE9C,GACF,CAACkB,EAA+B8B,IAAmD,CACjF,IAAMnB,EAAiB,CAAC,EACxB,OAAIX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ+B,GAAKpB,EAAK,KAAK,OAAOoB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAArB,EAAM,SAAUmB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEE/C,GACF,CAACkD,EAAyB/B,EAAc4B,EAA8B1B,IAA6B,CACjG,IAAMJ,EAASiC,EAAQ,OACjBC,EACFlC,EAAO,SAAW,EAAI8B,EAAahD,GAAiCkB,EAAQ8B,CAAU,EAE1FG,EAAQ,QACJpD,GACIqB,EAAM,CAAC,KAAMgC,EAAkB,QAAQ,EAAG,CAAClC,EAAO,CAAC,CAAC,EACpDkC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAItD,GAAOwB,EACpF8B,EAAkB,KAAMlC,EAAO,CAAC,EAAE,SAAUkC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAESlD,GAAe,CAACiD,EAAyBH,IAAuC,CAC3FnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,eAAgBH,EANf,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,qBACL,CAC8D,CAChE,EAEahB,GAAW,CAACgD,EAAyBH,IAAuC,CACvFnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,EACL,CAC0D,CAC5D,EAEaf,GAAW,CAAC+C,EAAyBH,IAAuC,CACvFnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,sBACvC,sBACL,CAC0D,CAC5D,EAEad,GAAkB,CAAC8C,EAAyBH,IAAuC,CAC9FnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,qBACL,CACiE,CACnE,EAEab,GAAY,CAAC6C,EAAyBH,IAAuC,CACxFnD,GAAesD,EAAQ,MAAM,EAgB7BlD,GAAiBkD,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAKnC,EAAM,WAAW,eAAgByB,EAAG,CAAC,CAAC,EAIvD,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEaZ,GAAa,CAAC4C,EAAyBH,IAAuC,CACzFnD,GAAesD,EAAQ,MAAM,EAiB7BlD,GAAiBkD,EAAS,aAAcH,EAhBb,CAAC7B,EAAOiB,EAAQP,IAAS,CAClD,IAAI0B,EAAO,EACX,QAASX,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,KAE1C0B,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKP,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,YAAY,aAAa,CAAC,KAC9C,eAAeiB,EAAO,KAAK,KAAK,UAAUmB,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEa/C,GAAY,CAAC2C,EAAyBH,IAAuC,CACxFnD,GAAesD,EAAQ,MAAM,EAgB7BlD,GAAiBkD,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAK,gBAAgBV,CAAC,QAAQ,EAI1C,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEaV,GAAa,CAAC0C,EAAyBH,IAAuC,CACzFnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,aAAcH,EANb,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC4D,CAC9D,EAEaT,GAAY,CAACyC,EAAyBH,IAAuC,CACxFnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,YAAaH,EANZ,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC2D,CAC7D,EAEaR,GAAkB,CAACwC,EAAyBH,IAAuC,CAC9FnD,GAAesD,EAAQ,MAAM,EAO7BlD,GAAiBkD,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,oBACvC,EACL,CACiE,CACnE,EAEaP,GAAyBoC,GAClCE,GAA4BF,CAAiE,IChRjG,IAcMQ,GAeAC,GAKOC,GA4BAC,GA4BAC,GA1FbC,GAAAC,EAAA,kBAOAC,KAEAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQMT,GACF,CAACS,EAA+BC,IAC5BC,GACI,CAAC,KAAMD,EAAW,KAAM,SAAUA,EAAW,SAAU,gBAAiBA,EAAW,eAAe,CAAC,EAElGT,GAAS,CAACW,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEajB,GAAS,CAACU,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEahB,GAA4BO,GACrCC,GAA4BD,CAAoE,IC3FpG,IASMW,GAkBAC,GAkCOC,GA7DbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,EAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,EAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,EAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,GAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAcOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BAC,GAWPC,GAMOC,GAKAC,GAIAC,GAIAC,GAQAC,GAGAC,GAeAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAMAC,GAIAC,GAIAC,GAIAC,GAKAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAOAC,GA5QbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMM1C,GACF,CAAC2C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,EAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,GAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,IACTN,EAAa,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAE5CL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCM,CAAO,CAAC;AAAA;AAAA,cAEnDE,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEjD,GACF,CAACkD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,CAAQ,EAC5B,gBAAiBb,GAAgB3C,GAC7B2C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,CACtG,EACF,GAESxD,GAAOyD,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaxD,GAAQwD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEavD,GAASuD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEatD,GAAQsD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEarD,GAASqD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapD,GAAQoD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACanD,GAASmD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOalD,GAAuBmD,GAChCC,GAA4BD,CAA0B,EAG7ClD,GAAO,CAACiD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOajD,GAAU,CAACgD,EAAyBC,IAAqC,CACpF,IAAMG,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QACJ1D,GACI0D,EAAQ,OAAO,CAAC,EAAG,OAAQM,GAAK,SAASA,CAAC,0BAA2B;AAAA,4BACnDF,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,4BAC9CG,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EACMhD,GAAoCsD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GAC9DC,EAAOH,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GACpE,OAAOT,GAA4B,CAAC,IAAAM,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEaxD,GAAQ8C,GAAkC,CACrD,IAAMC,EAAahD,GAAiC+C,EAAQ,MAAM,EAClEhD,GAAQgD,EAASC,CAAU,CAC7B,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOM,GAAK,YAAYA,CAAC,IAAK;AAAA,gCACvBL,EAAW,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAS1CA,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAAC4C,EAAkBQ,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFR,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5B3C,GAAOuC,GAAkC,CACpD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOM,GAAK,YAAYA,CAAC,IAAK9C,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEa1C,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQM,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjE9C,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEavC,GAAY,CAACmC,EAAyBC,IAAsC,CACvFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,YAAaM,GAAK,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,sBAChF,sCAAsCL,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACtF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOM,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEavC,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOM,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEatC,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,aAAcM,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEarC,GAAQ+B,GAAkC,CACrDA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQM,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,oBAAoB,CAAC,CAC5F,EAEapC,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,UAAWM,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEanC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,KACvDD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,kBAAmBM,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,8BAC5E,wDAAwDL,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC/F,GAGIxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,IC9QA,IAUMa,GAkBAC,GAwCOC,GApEbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,EAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,EAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,GAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAsBjD,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBE,GAA+B;AAAA;AAAA,yBAEjCT,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CS,EAAa,iBAAiBP,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDK,GAAQ,OAAO,CAAC;AAAA;AAAA,IAEhBD,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBiB,GAAkC,CAC9DnB,GAAemB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlB,GAA+BkB,EAAQ,MAAM,CAAC,CAChE,ICvEA,IAiBMC,GAsHAC,GAqDAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GAlQbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAA8BC,EAAeC,EACvFC,EAAoBC,IAAsC,CACzD,IAAMC,EAAaC,EAAU,KAAKT,CAAU,EACtCU,EAAU,KAAK,KAAKF,EAAa,CAAC,EAEpCG,EACAC,EACA,OAAOT,GAAa,SACtBQ,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGX,CAAQ,KAAKU,CAAC,MAAMC,CAAC,KAC/D,OAAOX,GAAa,WAC7BQ,EAAmBC,EAAmBT,GAEtCQ,EAAmBR,EAAS,OAC5BS,EAAmBT,EAAS,QAG9B,IAAIY,EAAgB,GACdC,EAASC,GAAe,aAAcX,EAAYN,EAAY,CAAC,EAC/Da,EAAIK,EAAc,QAASd,EAAON,EAAO,CAAC,EAC1CgB,EAAII,EAAc,QAASb,EAAON,EAAO,CAAC,EAChD,GAAIG,EAAa,CACf,IAAMiB,EAAkBC,GAA4B,CAClD,IAAMC,EAAUZ,EAAU,eAAeW,CAAI,EACvCE,EAAoB,CAAC,EAC3B,QAASC,EAAIH,EAAK,OAAS,EAAGG,GAAK,EAAGA,IAAK,CACzC,IAAMC,EAAMR,EAAO,WAAW,gBAAiBO,EAAIvB,EAAW,OAASoB,EAAK,MAAM,EAClFE,EAAQ,KAAK,GAAGD,EAAQE,CAAC,CAAC,QAAQC,CAAG,MAAMJ,EAAKG,CAAC,CAAC,IAAI,CACxD,CACA,OAAOD,EAAQ,OAAS,EAAIA,EAAQ,KAAK,GAAG,EAAI,IAClD,EAEAP,EAAgB;AAAA,0CACkBC,EAAO,KAAK,OAAO;AAAA,qBACxCG,EAAerB,CAAK,CAAC;AAAA;AAAA;AAAA,0CAGAkB,EAAO,KAAK,OAAO;AAAA,qBACxCG,EAAepB,CAAK,CAAC;AAAA;AAAA,SAGpC,CAEA,IAAI0B,EACJ,GAAIxB,EACF,GAAIC,EAAa,CACf,IAAMwB,EAAgBjB,EAAU,KAAKX,CAAK,IAAM,EAC1C6B,EAAgBlB,EAAU,KAAKV,CAAK,IAAM,EAC5C2B,GAAiBC,EACnBF,EAAaT,EAAO,YAChB,aACAJ,EACIc,EAAgB,GAAGb,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFc,EAAgB,GAAGb,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGW,EAAa;AAAA,kCACST,EAAO,gBAAgB,iBAAiB,CAAC;AAAA;AAAA;AAAA,cAI3DA,EAAO,YACH,aAAcJ,EAAiBC,EAAE,YAAY,cAAc,EAAGC,EAAE,YAAY,cAAc,CAAC,CAAC,CAAC;AAAA,WAGzG,MACEW,EAAaT,EAAO,YAChB,aAAcJ,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACZ,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAM0B,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMd,EAAO,gBAAgB,qBAAqBc,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,+BAA+BA,CAAC;AAAA,yBACjCA,CAAC,+BAA+BA,CAAC;AAAA,wBAClCA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIpB,EAAiBqB,EAAaC,CAAW,CAAC;AAAA,WAE9E,EACI3B,IAAe,EACjBmB,EAAa;AAAA;AAAA,cAETG,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCH,EAAa;AAAA,cACTG,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH/B,EAAa,iBAAiBgB,EAAGC,EAAGE,CAAM,CAAC;AAAA;AAAA,UAE3CT,GAA4B,EAAE;AAAA,UAC9BQ,CAAa;AAAA;AAAA,UAEblB,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCa,CAAO,CAAC;AAAA,UAC3De,CAAU;AAAA,QAEhB,EAEE7C,GACF,CAACsD,EAAcC,EAAkBtB,EAAeC,EAAeX,EAC9DI,EAAmC6B,EAAyBvB,EAAE,WAA0B,CACvF,IAAMwB,EAAc,CAAC5B,EAAU,SAASI,EAAE,KAAMC,EAAE,IAAI,EAClDwB,EAAczB,EAAE,KAChBL,EAAaC,EAAU,KAAKI,EAAE,IAAI,EAElCZ,EAAY,GAIhB,GAAIoC,EAAa,CACf,IAAME,EAAkBC,GAAc,UAAU3B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAACyB,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjED,EAAcC,EACd/B,EAAaC,EAAU,KAAK6B,CAAW,EACvC,IAAMZ,EAAgBjB,EAAU,KAAKI,EAAE,IAAI,IAAM,EAC3Cc,EAAgBlB,EAAU,KAAKK,EAAE,IAAI,IAAM,EAG7C2B,EAAkB,EACtB,QAASlB,EAAI,EAAGA,EAAIe,EAAY,OAAQf,IAAK,CAC3C,IAAMmB,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAASU,CAAC,GAAK,EACpCoB,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAASS,CAAC,GAAK,EAC1C,GAAImB,IAASC,EACXF,GAAmBC,MAEnB,MAEJ,EACID,EAAkB,IAAM,GAAKf,GAAiBC,KAChD1B,EAAY,GAEhB,MAEEA,EAAY,GAGd,MAAO,CACL,KAAAiC,EACA,YAAa,CAAC,KAAMC,CAAQ,EAC5B,gBAAkBtC,GAAiBlB,GAC/BkB,EAAcgB,EAAE,KAAMC,EAAE,KAAMwB,EAAarC,EAAWoC,EAAalC,EAAUU,EAAE,SAAUC,EAAE,SAC3FsB,EAAgB7B,CAAwB,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM+B,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAK5B,EAAa,GAA0B,CAAsB,CAAC,CAC7F,EACF,CACF,EAEE3B,GACF,CAAC+D,EAAyBV,EAAc/B,EAA8BI,EACrE4B,EAAmBC,IAAkC,CACpDQ,EAAQ,QAAQhE,GACZsD,EAAMC,GAAY,GAAIS,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGzC,EAAUI,EACtE6B,CAAc,CAAC,CACrB,EAEStD,GAAO8D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa/B,GAAO6D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa9B,GAAS4D,GAAkC,CACtD/D,GACI+D,EAAS,QAAU,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa7B,GAAO2D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa5B,GAAO0D,GAAkC,CACpD,IAAMC,EAAO3B,EAAc,QAAS0B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7F/D,GACI+D,EAAS,MAAQ,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,cAAcD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,qBAAqBD,CAAC,IAAIC,CAAC,GAAG,EAC7G;AAAA,wBACkB+B,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa1D,GAAOyD,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa1B,GAAWwD,GAAkC,CACxD/D,GACI+D,EAAS,UAAY,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEazB,GAAQuD,GAAkC,CACrD/D,GACI+D,EAAS,OAAS,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEaxB,GAAkBsD,GAAkC,CAC/D/D,GACI+D,EAAS,iBAAmB,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEavB,GAAeqD,GAAkC,CAC5D/D,GACI+D,EAAS,cAAgB,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,ICtQA,IAcMgC,GAqBAC,GAUAC,GAmBAC,GAqEOC,GAKAC,GA1IbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA2Bc,GAAoC;AAAA;AAAA,gCAErCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCK,IAA0B,CACpF,IAAMD,EAAkBJ,EAAO,OAEzBM,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcL,EAAOO,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMd,GAA0B,CAACQ,EAA+BS,IAA8B,CAC5F,IAAMC,EAAaV,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIS,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIP,EAAO,OAAQO,IAAK,CACtC,IAAMM,EAAab,EAAOO,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAcjB,EAAO,MAAM,EAClDkB,EAAY,IAAI,MAAqBlB,EAAO,MAAM,EAClDmB,EAAWnB,EAAO,CAAC,EAAE,SAEvBoB,EAAc,EAClB,QAASb,EAAI,EAAGA,EAAIP,EAAO,OAAQ,EAAEO,EACnCa,GAAepB,EAAOO,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EAEtBF,EAAUX,CAAC,EAAIc,EAAc,QAAQd,CAAC,GAAIY,EAAUnB,EAAOO,CAAC,EAAE,IAAI,EAGpE,IAAMF,EAASiB,GAAe,SAAUH,EAAUP,CAAW,EAEvDW,EAAclB,EAAO,WAAW,UAAWM,CAAY,EACvDa,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiB,GAAGP,EAAWb,CAAM,CAAC;AAAA;AAAA,wCAEfY,EAAiB,MAAM,KAAKA,EAAiB,IAAIV,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GjB,GAAwB2B,EAAiB,MAAM,CAAC;AAAA;AAAA,IAEhDQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCV,CAAU,CAAC;AAAA;AAAA,oBAEhDV,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEbkB,CAAW;AAAA;AAAA,QAE9CA,CAAW;AAAA;AAAA;AAAA,MAGbhC,GAAiB2B,EAAWb,CAAM,CAAC;AAAA,KAEvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,EAAE,EAC7B,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMG,EAAa,SAAUZ,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAS,CACF,CACF,EAEa/B,GAAS,CAACiC,EAAyBC,IAAuC,CACrFtC,GAAeqC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlC,GAAwBkC,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEajC,GAAyBiC,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,IC3IjE,IAuBaE,GAeAC,GAUAC,GAhDbC,GAAAC,EAAA,kBAuBaJ,GAAc,CAACK,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaJ,GACT,CAACM,EAAyBC,EAA6B,GAAOC,EAAU,GAAOC,EAAgB,IAMtF,GAGAR,GAAwB,CAACS,EAAkBJ,IAAoC;AAAA,QACpFI,EAAU,iDAAmD,EAAE;AAAA,QAC/DJ,EAAa,qCAAuC,EAAE;UClD9D,IAqBaK,GArBbC,GAAAC,EAAA,kBAqBaF,GAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ICrB7B,IAYaG,GAmBAC,GA/BbC,GAAAC,EAAA,kBAGAC,KASaJ,GACRK,GAAoG,CACnG,OAAQA,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,0BAA0B,EAC7E,IAAK,UACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sCAAsC,EACzF,IAAK,OACH,MAAO,CACL,mBACI,uBAAuBA,EAAW,OAAQ,yBAAyBA,EAAW,OAAQ,KAC1F,gBAAiB,6CACnB,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAESJ,GACRI,GAAgF,CAC/E,IAAMC,EAAaD,GAAY,YAAwB,GAEvD,GAAIC,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIH,GAAY,mBAAyC,CAACI,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,ICxCJ,IA6BMK,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GAmFOC,GAvabC,GAAAC,EAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,iBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,mBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,IAAMC,EAAcF,EAAY,CAAC,EAC3BG,EAAcH,EAAY,CAAC,EAC3BI,EAAaJ,EAAY,CAAC,EAC1BK,EAAgBN,EAAU,CAAC,EAC3BO,EAAYP,EAAU,CAAC,EACvBQ,EAAYR,EAAU,CAAC,EACvBS,EAAiBT,EAAU,CAAC,EAC5BU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5F/C,EAAYsD,EAAc,YAAaT,EAAO,CAAC,EAAE,SAAUQ,CAAS,EACpEhC,EAAY,CAACrB,CAAS,EACtBsB,EAAc,CAAC6B,EAAYC,EAAYC,CAAS,EAChDE,EAAYC,EAAU,KAAKH,CAAS,EAEpCI,EAAYR,EAAOA,EAAO,OAAS,CAAC,EACpCS,EAAWT,EAAOA,EAAO,OAAS,CAAC,EACnCU,EAAYT,EAAOA,EAAO,OAAS,CAAC,EACpCU,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EACjD,CAAC,mBAAAE,EAAoB,gBAAAzC,CAAe,EAAI0C,GAAqBhB,CAAoB,EAGjFiB,EAAoBN,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDrD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD4D,EAAW,CACf,KAAK,KAAKL,EAAYvD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYrD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYnD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,CAC/D,EAEM7B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAaL,EAAS,EAAI,EAC1BM,EAAIZ,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGM,EAAYM,EAAWC,EAAWO,CAAU,EAAGA,CAAU,EACxGE,GAAIb,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGO,EAAYM,EAAUC,EAAYM,CAAU,EAAGA,CAAU,EACxGG,EACFtC,GAAe,SAAUe,EAAO,CAAC,EAAE,SAAU,CAACU,EAAWE,EAAWE,EAAYM,CAAU,EAAGA,CAAU,EAC3G5C,EAAU,KAAK6C,CAAC,EAChB7C,EAAU,KAAK8C,EAAC,EAChB9C,EAAU,KAAK+C,CAAM,EACrB,IAAMC,EAAiB,CAACH,EAAGC,EAAC,EACtBhD,GAAU0B,EAAO,OAAS,EAC1ByB,EACF/E,GAAwB0E,EAAY9C,GAASC,EAAiBC,EAAWC,EAAaC,CAAc,EACxG,GAAIJ,GAAS,CACX,IAAMoD,GAAiBhD,EAAiB0C,EAAa,EACrDI,EAAe,KAAKf,EAAc,OAAQT,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,EAAc,CAAC,CAC/F,CACA,IAAMC,EAAmBC,IAA+B;AAAA,2BACnChB,CAAS;AAAA,2BACTE,CAAS;AAAA,0BACVD,CAAQ;AAAA,IAC9Be,GAAa,iBAAiB,GAAGJ,EAAgBD,CAAM,CAAC;AAAA,IACxDE,CAAgB;AAAA,IAChBT,CAAkB;AAAA,IAEZD,EAASzE,GAA2B4E,EAAmB3D,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuByE,EAAmB3D,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAC3EA,EAAU,KAAK,CAAC,GAC/B,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM8C,EAAqB,kBAAkB,EAC3D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGmB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAAQ,CACF,CACF,IC1eJ,IAgCME,GA2HOC,GA3JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAEAC,KAGAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAAyBC,EAA4B,GAAOC,EAAoB,EAAGC,EAAoB,EACvGC,EAAmB,EAAGC,EAAW,QAAkB,CAClD,IAAMC,EAAeF,IAA6B,CAChD,OAAQA,GAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,EAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,IAA6B,CAChD,OAAQA,GAAkB,CACxB,IAAK,GACH,MAAO,qCACT,IAAK,GACH,MAAO,yCACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,EAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBb,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCc,EAAkBd,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCe,EAAUf,EAAiB,YAAc,YACzCgB,EAAShB,EAAiB,YAAc,YACxCiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAMlB,EAAiB,MAAQ,MAC/BmB,EAAe;AAAA;AAAA,qBAENnB,EAAiB,cAAgB,aAAa;AAAA,mBAChDiB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUrB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbP,GAAYD,EAAY;AAAA,wBACxCK,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFxB,EAAiBoB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFzB,EAAiBoB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EAsBvG,MArBiB;AAAA,MACjBgB,GAAoBrB,EAAYC,EAA2BG,IAAqB,EAAG,CAAC,CAAC;AAAA,yDAClCe,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDzB,EAAiBsB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBT,EAAiB,cAAgB,aAAa;AAAA,QAC7Dc,CAAe;AAAA,QACfa,GAAsBvB,EAASC,CAAU,CAAC;AAAA;AAAA;AAAA,MAK9C,EAESd,GACT,CAACqC,EAA+BC,EAA4BC,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiB6B,EAAW,SAAW,OACvCO,EAAapC,EAAiB4B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClES,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMrC,EAAmBgC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAKS,EAAkB,CAAC,EAElGG,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAInC,EAAkBmC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,EAAY8B,EAAYiB,IAAe,EACvC9C,GAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAAChC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D2C,EAAIC,GAA4BzB,EAAO,CAAC,EAAE,QAAQ,EAElD0B,GAAgB,CACpB,qDAAqDb,GAAUhC,IAAqB,EAAI,QAAQ2C,CAAC,IAAMA,CAAC,KACxG,qDAAqDX,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAChF,EACIG,EAAmB;AAAA,qDACwBd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,8BAChDX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,OAAIP,IACFoB,GAAc,KAAK,wDAAwDb,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAAI,EACxGG,GAAoB;AAAA,0DAC8Bd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,YAIlE,CACL,KAAM,eACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGkB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBU,EAAa;AAAA;AAAA;AAAA;AAAA,UAIbF,GAAc,KAAK,EAAE,CAAC;AAAA,6BACHA,GAAc,MAAM,4CACrCb,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACNE,GAAc,OAAS,CAAC;AAAA;AAAA,+CAER1B,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBE,EAAY,KAAK,GAAG,CAAC;AAAA,wDACd2B,EAAU,eAAe3B,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChED,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEE,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BsB,CAAgB;AAAA,UAEdjE,GACIU,EAAgBC,EAAWC,EAAWC,GAAU+B,EAAS,OAAW,GAAOiB,EAAa,CAAC,EACzFA,EAAa,CAAC,EAAGA,EAAa,CAAC,EAAGC,CAAC,CAAC;AAAA,cAExCX,EACIiB,GAA2Bb,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGS,GACId,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,IC7PJ,IAeayB,GAfbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhD,CAAC,mBAAAO,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBT,CAAU,EAEvEU,EAAgBV,EAAW,SAAW,OACtCW,EAAcC,GAChBR,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASU,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,GAAe,SAAUjB,EAAO,CAAC,EAAE,SAAUY,CAAW,EACjEM,EAAIC,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDe,EAAID,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDe,EAAY,CAACH,EAAGE,CAAC,EACnBjB,GACFkB,EAAU,KAAKF,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMsB,EAAmBC,GAA+B;AAAA,oCAC1BtB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEsB,EAAa,iBAAiB,GAAGF,EAAWL,CAAM,CAAC;AAAA;AAAA,IAEnDR,CAAkB;AAAA;AAAA,IAElBe,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYJ,CAAsB;AAAA;AAAA,iBAEhDS,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPV,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOM,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBL,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOM,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgBO,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnDA,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDE,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3EhB,CAAW;AAAA,MACXK,CAAe;AAAA,MACfO,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMf,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BU,CAAW,EAAIA,EAC7E,SAAUZ,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,ICjGJ,IAcME,GAMAC,GAGAC,GAGAC,GAWOC,GAuCAC,GAMAC,GAlFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GACT,CAACkB,EAAuBT,EAAmBU,IAAoC,CAC7E,IAAMT,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CJ,EAASK,GAAe,SAAUF,EAAgBC,GAAYA,EAAS,QAAWV,CAAS,EAC3FK,EAAQO,EAAc,IAAKH,EAAeT,CAAS,EAEnDa,EAAmBC,GAA+B;AAAA,IAC1DA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBT,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5DR,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEhE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAC9D,WAAaX,GAAW,CACtB,IAAMgB,EAAc1B,GAAeU,EAAO,CAAC,EAAE,KAAME,CAAI,EACjDe,EAAab,EAAU,KAAKY,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKiB,EAAa,EAAuB,CAAC,EAClE,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMA,CAAU,EACjC,GAAGC,GAA2BlB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGkB,GAA2BF,CAAW,CAC3C,CACF,CACF,EACA,gBAAAF,CACF,CACF,EAESrB,GAAY,CAAC0B,EAAyBC,IAA0C,CAC3FhC,GAAe+B,EAAQ,MAAM,EAC7BA,EAAQ,QACJ3B,GAA2B2B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,KAAK,OAAQC,EAAW,IAAI,CAAC,CAC5G,EAEa1B,GAA4B0B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,ICnFnE,IAcaE,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAsGAC,GA0BOC,GAnQbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KAEahB,GACT,CAACiB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAACU,EAAGC,IAAMD,GAAKA,EAAI,IAAMT,EAAUU,CAAC,EAAI,EAAE,EAEtFC,EAD2BN,EAAkB,IAAI,CAACI,EAAGC,IAAMD,EAAIR,EAAWS,CAAC,EAAIT,EAAWS,EAAIJ,CAAW,CAAC,EAEnF,IAAI,CAACG,EAAGC,IAAM,KAAK,OAAOD,EAAID,EAAmBE,CAAC,EAAIR,EAAQQ,CAAC,GAAKR,EAAQQ,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGP,CAAS,EAClCO,EAAY,OAAOR,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDI,CACT,EAcE7B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC6B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMN,EAAcM,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWP,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIO,EAAW,QAAQ,SAAWP,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIO,EAAW,KAAK,SAAWP,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIO,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM5B,GAA4B,CAA2B6B,EAAeD,IAAqC,CAC/G,IAAMb,EAAcc,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCX,EAAYW,EAAI,CAAC,IAAM,IACzBX,EAAYW,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWd,EAAaiB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAnB,EAAa,KAAAiB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEajC,GAAuB4B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFb,EAAYa,EAAW,UACvBU,EAAQV,EAAW,MACnBd,EAAcc,EAAW,aACzBG,EAAOH,EAAW,KAClBX,EAAUW,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAArB,EAAW,MAAAuB,EAAO,YAAAxB,EAAa,KAAAiB,EAAM,QAAAd,EAAS,SAAAsB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMjC,GAAS,CAACwC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB3C,GAA0B6B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc9B,GAChB+B,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CtB,EAAcI,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,EACpBC,GAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ9B,EAAwB,EAC9F,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAE5BN,EAAU,CACZ,IAAMQ,EAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,CAAS,CAAC,EACnDL,EAAYG,EAAiB,QAAQ,CAAC,EAAGE,EAAWvC,CAAW,CAAC,EAChEmC,EAAoB,CAAC,EAAGH,EAAOhC,CAAW,CAC5C,MACEiC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,EAAiB,QAAQ,CAAC,EAAGX,EAAe1B,CAAW,CAAC,EACpEmC,EAAoB,CAACH,EAAOH,EAAYC,EAAU9B,CAAW,EAE/DoC,GAAa,KAAKH,CAAS,EAC3BG,GAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGL,EAAa0B,CAAa,CAAC,EAC7DS,EAAoB,CAACH,EAAOhC,EAAa6B,EAAYC,CAAQ,EAC7DM,GAAa,KAAKF,CAAS,EAC3BE,GAAa,KAAKH,CAAS,EAEzBV,GACFa,GAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7Bc,EAAQ,QACJqB,GAAwBJ,GAAchB,EAAoBhB,EAAa+B,EAAmBb,CAAc,EACxG,CAAC,OAAQc,EAAY,CAAC,EAC1B,MACF,CAIA,IAAMK,EAAgE,GAGhEJ,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ9B,EAAwB,EAC9F,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMK,EAAa,CAACrC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFmB,EAAW,KAAKrC,EAAO,CAAC,CAAC,EAI3B,IAAMsC,EAAYrB,EAAiBO,EAAYC,EAAW9B,EACpD4C,EAAYtB,EAAiBtB,EAAc6B,EAAYC,EACvDe,EAAWlB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ2B,GACIJ,EAAYtB,EAAoBhB,EAAauC,EAAWC,EAAWC,EAAUtB,EAC7EkB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEM9D,GAAS,CAACuC,EAAyBb,IAAqC,CAE5E,IAAMV,EAAgBU,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdvB,EAEI,CAACuB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDX,EAAU,CAAC,CAAC,EAAE,OAAOW,EAAW,OAAO,EACvCb,EAAY,CAAC,CAAC,EAAE,OAAOa,EAAW,SAAS,EAC3Cd,EAAc,CAAC,CAAC,EAAE,OAAOc,EAAW,WAAW,EAC/Cc,EAAqB3C,GAA0B,CAAC,GAAG6B,EAAY,KAAAG,EAAM,QAAAd,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGa,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeR,EAAgB,CAACQ,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEavB,GAAO,CAACsC,EAAyBb,IAAqC,CACjF9B,GAAe2C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCvC,GAAOuC,EAASb,CAAU,EAE1B3B,GAAOwC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,IC1QA,IA+BMyC,GA4HOC,GA3JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAIAC,KACAC,KACAC,KAEMR,GACF,CAACS,EAAyBC,EAAU,GAAOC,EAAyBC,EAA4B,GAC/FC,EAAmB,IAAc,CAChC,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,iDACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBR,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCS,EAAkBT,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCU,EAAUV,EAAiB,iBAAmB,iBAC9CW,EAASX,EAAiB,iBAAmB,iBAC7CY,EAAMZ,EAAiB,MAAQ,MAC/Ba,EAAMb,EAAiB,MAAQ,MAE/Bc,EAAe;AAAA,yBACFd,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,cAAgB,aAAa;AAAA,qBAChDY,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,qDACgCJ,CAAgB,KAEzDW,EAAUf,EAAiB;AAAA,0BACbI,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBJ,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,oCACA,mCAAmC;AAAA;AAAA;AAAA,UAGpDO,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAwBb,MApBiB;AAAA,IACnBY,GAAoBf,EAAYC,EAA2BC,IAAqB,EAAG,CAAC,CAAC;AAAA,uDAClCC,CAAI;AAAA,MACrDL,EAAiBe,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDL,EAAiBgB,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBJ,EAAiB,cAAgB,aAAa;AAAA,QAC7DS,CAAe;AAAA,QACfS,GAAsBjB,EAASC,CAAU,CAAC;AAAA,sDACIE,CAAgB;AAAA;AAAA,IAIlE,EAESZ,GACT,CAAC2B,EAA+BC,EAAqCC,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBoB,EAAW,SAAW,OACvCO,EAAa3B,EAAiBmB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClES,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMjC,EAAmB4B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAI/B,EAAkB+B,EAAc,CAAC,CAAC,EAG1EK,EAAgB,CACpB,qDAAqDR,EAAS,YAAc,KAAK,KACjF,yDACF,EACIS,EAAmB,GACvB,OAAIhB,IACFe,EAAc,KAAK,wDAAwDR,EAAS,YAAc,KAAK,IAAI,EAC3GS,GAAoB;AAAA,0DAC8BT,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,YAGlE,CACL,KAAM,wBACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGkB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBK,EAAa;AAAA,UACbF,EAAc,KAAK;AAAA,CAAI,CAAC;AAAA,6BACLA,EAAc,MAAM,4CACrCR,EAAS,YAAc,KAAK;AAAA,oDACYb,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CAC7BA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBE,EAAY,KAAK,GAAG,CAAC;AAAA,wDACdsB,EAAU,eAAetB,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChED,EAAW,YAAYpB,EAAiB,EAAI,CAAC,CAAC,KACrFoB,EAAW,YAAYpB,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CoB,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYpB,EAAiB,EAAI,CAAC,EAAI,IAAMoB,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYpB,EAAiB,EAAI,CAAC,EAAI,IAAMoB,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEE,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BiB,CAAgB;AAAA,UAChBlD,GAA6BS,EAAgByB,EAAS,OAAW,GAAOrB,CAAgB,CAAC;AAAA,UAEvF4B,EAASY,GACIR,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFM,GACIT,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,ICtPJ,IA0BMoB,GAsNOC,GAhPbC,GAAAC,EAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,EAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,GAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,KAAK;AAAA,YACtDqB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,EAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAQ1CX,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,KAAK;AAAA,YAClDqB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,CAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAmDAC,GA6COC,GA/SbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGjB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMS,EAAiBJ,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOkB,EAAiB,EAAI,EAAG,EAAGH,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASe,EACzFb,EAAeC,CAAW,EAG9B,IAAMa,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EAC/CM,EAAWN,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOkB,EAAe,CAAC,YAAAnB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAiB,CAAQ,CAAC,EACnGD,CACT,EAES7C,GAAgCwC,GAAiE,CAC5G,IAAMO,EAAuBC,GAAkCR,CAAU,EAEnES,EAAST,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBU,EAAYV,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOW,GAA4B,CACjC,QAAA/B,EACA,OAAA6B,EACA,UAAAtB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAqB,EACA,GAAGH,CACL,CAAC,CACH,EAEM9C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMW,EAAcX,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFY,EAAkBZ,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIW,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMa,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMrB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnDH,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjDH,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9CH,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GACrDH,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EG,EAAiBJ,EAAW,SAAW,OACvCiB,EAAUhB,EAAO,SAAW,EAClC,GAAIe,EAAmB,QAAU,EAAG,CAClCD,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMxB,EAAcwB,EAAmB,YACjCG,EAAY3B,EAAYY,EAAiB,EAAI,CAAC,EAC9CgB,EAAW5B,EAAYY,EAAiB,EAAI,CAAC,EAC7CP,EAAcL,EAAYY,EAAiB,EAAI,CAAC,EAChDiB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC9BsB,EAAgBtB,EAAO,CAAC,EAAE,KAAKG,EAAiB,EAAI,CAAC,EAErDoB,EAAYpB,EAAiBe,EAAYC,EAAWvB,EACpD4B,EAAYrB,EAAiBP,EAAcsB,EAAYC,EACvDM,EAAWL,EAAeC,EAAcC,EAExCI,EAAgE,GAIhEC,EAAoBb,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJc,GAA2B5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQvC,EAAmB,EACzF,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKa,GAIhC,IAAME,EAAsB,CAAC7B,EAAO,CAAC,EAAG2B,CAAgB,EACpDX,IACE,CAACb,GAAkBH,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C6B,EAAoB,KAAK7B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE6B,EAAoB,KAAK7B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACID,EAAqBd,EAAoBxB,EAAagC,EAAWC,EAAWC,EAAUT,EACtFU,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEElE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICtTA,IAqBMgC,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GA4FOC,GAKAC,GApRbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAaMd,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYU,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMZ,GAAN,KAAqB,CACnB,YAAYa,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOjB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBiB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOrB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMuB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOrB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdqB,EAAI,MAAM,OAAOtB,GAAe,GAAG,CAAC,GAC3C,QAASgB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAM,KAAK,UAAU,CACxD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO3B,EAAe,CAAC,GAAM,CAAC4B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO7B,GAAe,GAAG,CAAC,EACpDyB,EAAa,IAAIpB,GAAWY,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIoB,CAAC,EACxDX,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,CAAC,EAC9B,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMlB,GAA0B,CAACY,EAA+BoB,IAAgD,CAC9G,IAAMC,EAAWrB,EAAO,CAAC,EAAE,SACrBsB,EAAY,IAAI,MAAqBtB,EAAO,MAAM,EACxD,QAASiB,EAAI,EAAGA,EAAIjB,EAAO,OAAQ,EAAEiB,EACnCK,EAAUL,CAAC,EAAIM,EAAc,QAAQN,CAAC,GAAII,EAAUrB,EAAOiB,CAAC,EAAE,IAAI,EAEpE,IAAMO,EAAcJ,EAAe,WAC7BK,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAASC,GAAe,SAAUP,EAAUG,CAAW,EACvDK,EAAoB,CAAC,EACrBC,EAAa,MAAM,KAAKV,EAAe,IAAI,gBAAgB,KAAK,CAAC,EACjEW,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBlB,EAAe,aAAa,OAASU,EAAW,OAC/EV,EAAe,aAAa,QAAQ,CAACZ,EAAMX,IAAW,CACpD,GAAIiC,EAAW,SAASjC,CAAM,EAAG,CAC/B,IAAM0C,EAAcT,EAAW,QAAQjC,CAAM,EAC7CuB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzB+B,EAAQ,KAAK,GACTP,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO6B,EAAO,WAAW,gBAAiBY,CAAW,CAAC,CAAC,EAAE,CAC3G,CAAC,CACH,CACF,CAAC,CACH,MACEnB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,IAAMT,EAAOY,EAAe,aAAa,IAAIvB,CAAM,EACnD,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,sBAAsB,EAExC,GAAIA,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzBoC,EAAoB,KAAK,GAAGZ,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO,GAAGD,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDwC,EAAgB,KAAK,WAAWf,EAAUL,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACDkB,EAAqB,KAAK,WAAWtC,CAAM,cAAcA,CAAM,MAC3DuB,EAAe,aAAa,IAAIvB,CAAM,GAAG,QAAQ,KAAKA,CAAM,OAAO,EACvEuC,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGT,EACH,aAAaP,EAAU,IAAI,CAACoB,EAAUzB,IAAMyB,EAAS,aAAa,QAAQzB,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGY,EACHG,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACEO,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB,GAAGtB,EAAWK,CAAM,CAAC;AAAA;AAAA,QAEnDiB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCnB,CAAU,CAAC;AAAA,8BAC1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDL,EAAU,IAAI,CAACoB,EAAUzB,IAAM,YAAYA,CAAC,YAAYK,EAAUL,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAChGwB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,UACpBd,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,SAE/C,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMP,EAAe,QAAQ,EAC3C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMI,EAAa,SAAUxB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAkB,CACF,CACF,EAEatD,GAAS,CAACwD,EAAyBC,IAAuC,CACrF,IAAM1B,EAAiB,IAAIjC,GAAe0D,EAAQ,OAAQC,EAAW,QAAQ,EAC7ED,EAAQ,QAAQzD,GAAwByD,EAAQ,OAAQzB,CAAc,CAAC,CACzE,EAEa9B,GAAyBwD,GAA0D,CAC9F,IAAM7C,EAAY6C,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOC,GAA4B,CAAC,SAAA9C,CAAQ,CAAC,CAC/C,ICvRA,IASM+C,GAiBAC,GAYAC,GAIAC,GAuCOC,GAjFbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMZ,GAAmB,CAACa,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMT,GAAuB,CAACQ,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUV,GAAiBS,EAAYC,CAAK,EAAIV,GAAiBU,EAAOD,CAAU,EAG3GP,GAA2BM,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBhB,GAAqBQ,EAAYC,CAAK,EAC9DQ,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWZ,EAAO,CAAC,EAAE,SACrBa,EAAQC,EAAc,QAASF,EAAUX,CAAU,EACnDc,EAASC,GAAe,SAAUJ,EAAUH,CAAW,EAEvDQ,EAAmBC,GAA+B;AAAA,uBACnCL,EAAM,QAAQ,GAAGZ,CAAU,CAAC;AAAA,IAC/CiB,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,IAC5CG,EAAa,UAAU,CAAC;AAAA,IACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,0BACxCK,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBACtCF,EAAM,KAAK,OAAO;AAAA,0BAChBZ,EAAW,MAAM;AAAA,YAC/BY,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA,UACrCA,EAAM,WAAW,eAAgB,IAAK,CAAC,CAAC;AAAA;AAAA,UAG5CA,EAAM,WACF,eAAgB,IAAKE,EAAO,WAAW,gBAAiB,OAAON,EAAY,OAASR,EAAW,MAAM,EAAE,CAAC,CAAC;AAAA;AAAA;AAAA,MAG7Gc,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,KAExE,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGJ,CAAW,EAAE,EACpC,gBAAAQ,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEaf,GAAUwB,GAAkC,CACvD5B,GAAe4B,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzB,GAAwByB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,ICpFA,IAcMC,GAMAC,GAiEOC,GAGAC,GAxFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMR,GAA0B,CAACQ,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaH,EAAU,KAAKC,CAAW,EAEvCG,EAAOC,EAAc,OAAQX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/DY,EAAUD,EAAc,eAAgBX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC1Ea,EAASC,GAAe,SAAUd,EAAO,CAAC,EAAE,SAAUO,CAAW,EACjEQ,EAAkB,IAAc,CACpC,IAAMC,EAAcb,EAAa,OAC7Bc,EAAU,yBAAyBL,EAAQ,KAAK,OAAO,OAC3D,QAASM,EAAI,EAAGA,EAAIF,EAAaE,IAC/BD,GAAW,GAAGD,EAAc,EAAI,kBAAkBE,CAAC,IAAM,gBAAgB,MACrEX,EAAY,OAAS,EAAI,iBAAiBF,EAAOa,CAAC,IAAM,eAAe,IAE7ED,GAAW;AAAA,oBACKL,EAAQ,aAAa,gBAAgB,CAAC;AAAA;AAAA,wBAElCJ,CAAY;AAAA;AAAA,4BAERE,EAAK,KAAK,OAAO;AAAA,QAEzC,QAASQ,EAAI,EAAGC,EAAI,EAAGD,EAAId,EAAWc,IAChCA,IAAMb,GACRY,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,eACjEC,GAAKH,IAELC,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,MAC7DX,EAAY,OAAS,EAAI,iBAAiBY,CAAC,IAAM,eAAe,IACpEA,KAGJ,OAAOF,CACT,EAEMG,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBX,EAAME,EAASC,CAAM,CAAC;AAAA,QACpDQ,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA,8BAC1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDE,EAAgB,CAAC;AAAA,sBACLL,EAAK,aAAa,aAAa,CAAC;AAAA,UAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,SAEjD,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMM,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,EAEa3B,GAAyBQ,GAClCqB,GAA4B,CAAC,KAAMrB,EAAW,IAAc,CAAC,EAEpDP,GAAS,CAAC6B,EAAyBtB,IAAuC,CACrF,IAAMD,EAASuB,EAAQ,OACvBhC,GAAeS,CAAM,EACrBuB,EAAQ,QAAQ/B,GAAwB+B,EAAQ,OAAQtB,CAAU,CAAC,CACrE,IC5FA,IAcMuB,GAeAC,GAqEOC,GAGAC,GArGbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OACvBG,EAAeC,EAAU,eAAeJ,CAAU,EAClDK,EAAYD,EAAU,KAAKJ,CAAU,EAErCM,EAAeR,EAAO,CAAC,EAAE,KACzBS,EAAkBT,EAAO,CAAC,EAAE,SAC5BU,EAAcJ,EAAU,KAAKE,CAAY,EAEzCG,EAAOL,EAAU,cAAcL,EAAW,KAAMG,CAAS,EACzDQ,EAAeV,EAAWS,CAAI,EAE9BE,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaR,EAAU,KAAKO,CAAW,EAEvCE,EAAQC,EAAc,QAASb,EAAqBD,CAAU,EAC9De,EAAUD,EAAc,UAAWP,EAAiB,CAACC,CAAW,CAAC,EACjEQ,EAASC,GAAe,SAAUhB,EAAqBU,CAAW,EAMlEO,EAAmBC,GAA+B;AAAA,wCACtBhB,EAAa,MAAM,KAAKA,EAAa,IAAIiB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,QAChGD,EAAa,iBAAiBN,EAAOE,EAASC,CAAM,CAAC;AAAA,QACrDG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCP,CAAU,CAAC;AAAA;AAAA,4BAE1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA,sBAE7BL,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKNV,EAAW,MAAM;AAAA,mBAC1BS,CAAI;AAAA;AAAA;AAAA,yBAGEO,EAAO,WAAW,gBAAiB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAMtBX,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,KAO7C,MAAO,CACL,KAAM,iBACN,YAAa,CAAC,KAAMN,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMY,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAM,CACF,CACF,EAES3B,GAAiCQ,GAC1CsB,GAA4B,CAAC,KAAMtB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC8B,EAAyBvB,IAA+C,CACrG,IAAMD,EAASwB,EAAQ,OACvBjC,GAAeS,CAAM,EACrBwB,EAAQ,QAAQhC,GAAgCgC,EAAQ,OAAQvB,CAAU,CAAC,CAC7E,ICzGA,IAUMwB,GA0BAC,GAmBAC,GAoEOC,GAKAC,GAhIbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMT,GAAU,CAACU,EAAWC,EAAWC,IAAoC,CACzE,GAAIA,EAAK,SAAW,EAClB,MAAO,KAGT,IAAMC,EAAcD,EAAK,SAAW,GAAKF,IAAM,GAAOE,EAAK,SAAW,GAAKA,EAAK,CAAC,IAAMF,EACjFI,EAAaF,EAAKA,EAAK,OAAS,CAAC,IAAMD,EAEzCI,EAAS,KACb,OAAKF,IACHE,GAAU,SAASH,EAAKA,EAAK,OAAS,CAAC,CAAC,KAErCE,IACHC,GAAU,MAGLA,CACT,EAEMd,GAAwB,CAACQ,EAA+BO,IAA4C,CACxG,IAAMC,EAASR,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BS,EAAST,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACU,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQP,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGc,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACzCG,EAAO,GACPV,EAAW,QAAUA,EAAW,OAClCU,EAAO,wCACEV,EAAW,QAAU,CAACA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAUA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAU,CAACA,EAAW,SAC3CU,EAAO,yCAGT,IAAMC,EAAWC,GAA4BnB,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAiBb,EAAW,QAAU,EAAI,GAAK,kBAC/Cc,EAAarB,EAAO,SAAW,EAAI,qBAAqBT,GAAQmB,EAAGC,EAAGX,EAAO,CAAC,EAAE,IAAI,CAAC,KAAO,GAC5FsB,EAAkC,CACtC,sDAAsDJ,CAAQ,KAC9D,sDAAsDA,CAAQ,IAChE,EACIlB,EAAO,SAAW,GACpBsB,EAAgC,KAAK,sDAAsDJ,CAAQ,IAAI,EAEzG,IAAMK,EAAmBC,GAA+B;AAAA,mBACvCd,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,kBACFM,CAAQ,IAAIX,EAAW,KAAK;AAAA,iBAC7BW,CAAQ,IAAIX,EAAW,IAAI;AAAA;AAAA,IAExCe,EAAgC,KAAK;AAAA,CAAI,CAAC;AAAA,uBACvBtB,EAAO,MAAM,6CAA6CkB,CAAQ;AAAA;AAAA,IAErFM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAKlDG,CAAQ;AAAA,8BACIN,CAAC;AAAA,QACvBK,CAAI;AAAA;AAAA;AAAA,MAGNG,CAAc;AAAA,MACdC,CAAU;AAAA;AAAA;AAAA,KAId,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAMd,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMO,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,EAEa9B,GAAO,CAACgC,EAAyBlB,IAAqC,CACjFjB,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAsBiC,EAAQ,OAAQlB,CAAU,CAAC,CACnE,EAEab,GAAuBa,GAChCmB,GAA4BnB,CAA+D,ICjI/F,IAeMoB,GAIAC,GA8FAC,GAiEOC,GAGAC,GArLbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAOMT,GAAW,CACf,KAAM,uBACR,EAEMC,GACF,CAACS,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KAEnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAIN,EAAO,CAAC,EACZO,EAAIC,EAAc,IAAKV,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EAC3EI,EAAQD,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEY,EAAOF,EAAc,OAAQV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/Da,EAASC,GAAe,SAAUd,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EACtFQ,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAgB,GAChBC,EAAmBC,GAA+B;AAAA;AAAA,mBAE3CX,CAAC;AAAA,0BACMD,CAAQ;AAAA,yBACTN,EAAW,OAAO;AAAA,gCACXe,CAAQ;AAAA,uCACDA,CAAQ;AAAA,2CACJA,CAAQ,KAAKC,CAAa;AAAA,0BAC3CA,CAAa;AAAA,IACnCE,EAAa,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IAC3CI,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAOtBD,CAAQ;AAAA;AAAA,4BAECP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAahBO,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOzBP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAkBJO,CAAQ;AAAA,qCACtBL,EAAM,YAAY,SAAS,CAAC;AAAA,yBACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEhCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA,QAC1CI,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,KAG9C,MAAO,CACL,GAAGvB,GACH,YAAa,CAAC,KAAMW,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,CAC9B,GACA,gBAAAa,CACF,CACF,EAEE1B,GACF,CAACQ,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACdkB,EAAad,EAAU,KAAKH,CAAW,EACvCkB,EAAInB,EAAO,CAAC,EACZM,EAAIN,EAAOA,EAAO,OAAS,CAAC,EAC5BoB,EAAIhB,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIM,EAE7CQ,EAAWO,GAA4BvB,EAAO,CAAC,EAAE,QAAQ,EAEzDK,EAAYG,EAAIa,EAChBH,EAAmBC,GAA+B;AAAA,mBAC3CE,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDd,CAAC;AAAA,yBACKQ,CAAQ,MAAMM,CAAC;AAAA,2BACbA,EAAId,CAAC;AAAA,yBACPP,EAAW,OAAO;AAAA;AAAA,uDAEYe,CAAQ;AAAA,2DACJA,CAAQ;AAAA,0DACTA,CAAQ;AAAA,kEACAA,CAAQ;AAAA;AAAA,IAEtEG,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAMRC,CAAU;AAAA,gBACdJ,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAODA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAazB,MAAO,CACL,GAAG1B,GACH,YAAa,CAAC,KAAMW,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAY,EAAuB,CAAC,CACnE,GACA,gBAAAa,CACF,CACF,EAESzB,GAA+BQ,GACxCuB,GAA4B,CAAC,QAASvB,EAAW,QAAS,OAAQA,EAAW,MAAM,CAAC,EAE3EP,GAAe,CAAC+B,EAAyBxB,IAA6C,CAC7FA,EAAW,SAAW,OACxBwB,EAAQ,QAAQjC,GAAkCiC,EAAQ,OAAQxB,CAAU,CAAC,EAE7EwB,EAAQ,QAAQlC,GAA8BkC,EAAQ,OAAQxB,CAAU,CAAC,CAE7E,IC3LA,IAgBMyB,GAUAC,GA4FOC,GAGAC,GAzHbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,EAClE,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMT,GACF,CAACS,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAAOD,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DO,EAAYF,EAAU,gBAAgBL,EAAQM,CAAI,EAClDE,EAAWH,EAAU,kBAAkBL,EAAQM,CAAI,EAEnDG,EAAYJ,EAAU,KAAKJ,EAAM,IAAI,EACrCS,EAAWR,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIO,IAAcD,GAAaN,GAAQQ,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAAmB,CAAC,EAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAO,OAAQ,EAAEY,EAC/BA,EAAIN,EACNK,EAAiB,KAAKX,EAAOY,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAI3B,IAAME,EAAWC,GAA4BjB,EAAO,CAAC,EAAE,QAAQ,EAEzDkB,EAAoBhB,EAAc,EAClCiB,EAAkBjB,EAAc,EAClCkB,EAAe,EACbC,EAAmBC,GAA+B;AAAA,0BACpCX,CAAQ;AAAA,yBACTK,CAAQ,MAAML,CAAQ;AAAA,yBACtBV,EAAW,OAAO;AAAA;AAAA,uBAEpBmB,GAAc,kCAAkCJ,CAAQ;AAAA,uBACxDI,GAAc,sCAAsCJ,CAAQ;AAAA,IAC/EX,EAAO,sBAAsBe,GAAc,qCAAqCJ,CAAQ,KAAO,EAAE;AAAA,uBAC9EI,GAAc,6CAA6CJ,CAAQ;AAAA,IAEhFE,EACI,sBAAsBE,GAAc,qDAAqDJ,CAAQ,IACjG,EAAE;AAAA,IAENG,EACI,sBAAsBC,GAAc,mDAAmDJ,CAAQ,IAC/F,EAAE;AAAA;AAAA,IAEZM,EAAa,UAAU,CAAC;AAAA;AAAA,oBAERf,CAAU;AAAA,gBACdS,CAAQ;AAAA,sBACFA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4EAU8CX,EAAO,YAAc,EAAE;AAAA;AAAA;AAAA,MAG7Fa,EAAoB,oCAAsC,EAAE;AAAA,MAC5DC,EAAkB,4CAA8C,EAAE;AAAA,KAE5DI,EAAU,CAAC,CAAC,KAAMjB,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIkB,GACFK,EAAQ,KACJ,CAAC,KAAMT,EAAkB,SAAUd,EAAO,CAAC,EAAE,QAAQ,CACzD,EAEEmB,GACFI,EAAQ,KACJ,CAAC,KAAMT,EAAkB,SAAUd,EAAO,CAAC,EAAE,QAAQ,CACzD,EAGK,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGC,EAAW,QAAQ,IAAIC,CAAW,IAAIF,EAAO,MAAM,EAAE,EAC5E,WAAY,KAAO,CAAC,QAAAuB,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKb,EAAY,EAAuB,CAAC,CAAC,GAC/F,gBAAAW,CACF,CACF,EAES7B,GAA4BS,GACrCuB,GAA4B,CAAC,KAAMvB,EAAW,KAAM,QAASA,EAAW,OAAO,CAAC,EAEvER,GAAY,CAACgC,EAAyBxB,IAA0C,CAC3FX,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlC,GAA2BkC,EAAQ,OAAQxB,EAAYwB,EAAQ,WAAW,CAAC,CAC7F,IC5HA,IASMC,GAUOC,GAnBbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEML,GAAkBM,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaL,GAAUM,GAAkC,CACvDP,GAAeO,EAAQ,MAAM,EAC7B,IAAMC,EAAcC,GAAc,UAAUF,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1DD,EAAQ,QAAQG,GAAwBH,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGC,CAAW,CAAC,CAChH,IC1BA,IAkBMG,GAmBAC,GA8BAC,GA+BAC,GA2BAC,GA2BAC,GAkBAC,GA0BAC,GAaAC,GA0BOC,GAMAC,GAjPbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KASMhB,GAAkBiB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMjB,GACF,CAACkB,EAAuBC,EAA+BC,EACtDC,EAAiCC,EAAgBC,EAAkBC,IAAkC,CACpG,IAAMC,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACKR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI5CP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA,4BAGPN,EAAaM,CAAC,CAAC;AAAA,UAIrC,MAAO;AAAA,oBACOJ,CAAQ,IAAIC,CAAa;AAAA;AAAA;AAAA;AAAA,cAI/BE,CAAK;AAAA;AAAA;AAAA,OAIf,EAEEzB,GACF,CAACiB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKvC,GAAKP,EAAUO,CAAC,EAAI,EAAE;AAAA;AAAA,4BAE1BP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,gCAIRN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEExB,GACF,CAACgB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI5CP,EAAUO,CAAC,CAAC;AAAA,wBACfP,EAAUO,CAAC,EAAI,CAAC;AAAA;AAAA,gCAERN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEvB,GACF,CAACe,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA,yBAE9CP,EAAUO,CAAC,CAAC;AAAA;AAAA,2BAEVP,EAAUO,CAAC,CAAC;AAAA,yBACdP,EAAUO,CAAC,CAAC;AAAA;AAAA,gCAELN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEtB,GACF,CAACc,EAAuBC,EAA+BC,EACtDC,EAAiCO,EAA2BL,IAA6B,CACxF,OAAQK,EAAW,KAAM,CACvB,IAAK,GACH,OAAO5B,GACHkB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,KAAML,EAAUK,EAAW,KAAK,EAC9F,IAAK,GACH,OAAO3B,GAAciB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EACnF,IAAK,GACH,OAAO1B,GAAWgB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,IAAK,GACH,OAAOzB,GAAWe,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEEvB,GACF,CAACwB,EAA4Bb,EAA+BY,EAA2BL,IACzE,CACR,IAAMH,EAAYJ,EAAO,CAAC,EAAE,KACtBG,EAAaW,EAAU,SAASV,EAAU,MAAM,EAAGQ,EAAW,IAAI,EAClEG,EAAaD,EAAU,KAAKX,CAAU,EACtCE,EAAeS,EAAU,eAAeV,CAAS,EAEjDF,EAASc,GAAe,SAAUhB,EAAO,CAAC,EAAE,SAAUG,CAAU,EAChEc,EAAQC,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUI,CAAS,EAExDe,EAAa/B,GAAcc,EAAQC,EAAYC,EAAWC,EAAcO,EAAYL,CAAQ,EAYlG,MAXgB;AAAA,gBACVM,EAAa,iBAAiBI,EAAOf,CAAM,CAAC;AAAA,gBAC5CW,EAAa,UAAU,CAAC;AAAA,gBACxBA,EAAa,sCAAsCE,CAAU,CAAC;AAAA;AAAA,8BAEhDb,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEtCK,CAAQ;AAAA,gBACpBY,CAAU;AAAA;AAAA,YAIlB,EAEF7B,GAAuB,CAACU,EAA+BY,IAA2C,CACtG,IAAMQ,EAAcN,EAAU,SAASd,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGY,EAAW,IAAI,EAC9E,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAMA,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMQ,EAAa,SAAUpB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAU,KAAKM,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBP,GAAgBxB,GAAgBwB,EAAcb,EAAQY,EAAY,KAAK,CAC1F,CACF,EAEMrB,GAAgC,CAACS,EAA+BY,IAA6C,CACjH,GAAIZ,EAAO,OAAS,EAAG,CACrB,IAAMqB,EAAerB,EAAO,CAAC,EAAE,iBAAiB,EAC1CsB,EAAStB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFS,EAAYT,EAAO,CAAC,EAAE,KAAK,OAC3BuB,EAAa,IAAI,WAAW,EAAId,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIT,EAAO,QAAU,EAAG,CACtB,IAAMwB,EAAOxB,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAASW,EAAI,EAAGA,EAAIa,EAAK,OAAQb,IAC/BY,EAAW,OAAOC,EAAKb,CAAC,CAAC,CAAC,EAAI,OAAOU,EAAaV,CAAC,CAAC,EACpDY,EAAW,OAAOC,EAAKb,CAAC,CAAC,EAAIF,CAAS,EAAI,OAAOY,EAAaV,EAAIa,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAGd,IAAMY,EAAW,OAAOZ,CAAC,CAAC,EAAK,OAAOc,CAAC,CAAE,EAGpE,IAAMnB,EAAiB,CAAC,EACxB,OAAAiB,EAAW,QAAQE,GAAKnB,EAAK,KAAKmB,CAAC,CAAC,EAE7BC,GAA4B,CAAC,KAAMd,EAAW,KAAM,MAAAU,EAAO,KAAAhB,CAAI,CAAC,CACzE,KACE,QAAOM,CAEX,EAEapB,GAAM,CAACmC,EAAyBf,IAAoC,CAC/E7B,GAAe4C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBrC,GAA8BoC,EAAQ,OAAQf,CAAU,EAClFe,EAAQ,QAAQrC,GAAqBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,EAEanC,GAAsBmB,GAAuD,CACxF,IAAMiB,EAAOjB,EAAW,KAClBU,EAAQV,EAAW,MACnBN,EAAOM,EAAW,KACxB,OAAOc,GAA4B,CAAC,KAAAG,EAAM,MAAAP,EAAO,KAAAhB,CAAI,CAAC,CACxD,ICtPA,IAgBMwB,GASAC,GAgCAC,GAwKAC,GAaAC,GA4BOC,GAYAC,GAKPC,GAYOC,GAKAC,GAUPC,GAqBOC,GAKAC,GAgBAC,GAKAC,GArWbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMnB,GAAkBoB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,4BAA4B,EAE9C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,4CAA4C,CAEhE,EAEMnB,GAA0C,CAC5CoB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EACFD,EAAiB,CAACH,EAAM,KAAK,CAAC,EAAGA,EAAM,KAAK,CAAC,EAAGA,EAAM,KAAK,CAAC,EAAGA,EAAM,KAAK,CAAC,CAAC,EAAIA,EAAM,KAAK,MAAM,EAC/FK,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAClD,OAAII,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAEnF,CACLW,EACAT,EACI,CACEQ,EAA0B,CAAC,EAAGA,EAA0B,CAAC,EAAGA,EAA0B,CAAC,EACvFA,EAA0B,CAAC,CAC7B,EACAA,CACN,CACF,EAEM9B,GAAsB,CACxBgC,EAA4BC,EAAkBC,EAA2BC,EACzEf,EAA2BgB,EAAaC,EAAaC,IAA0B,CACjF,IAAMhB,EAAiBF,EAAW,SAAW,OACvCmB,EAAYL,EACZM,EAAWP,EAAE,KAAK,MAClBQ,EAAOF,EAAU,OACjBG,EAAaC,EAAU,KAAKR,CAAW,EACvCS,EAASC,GAAe,SAAUZ,EAAE,KAAK,OAAQE,CAAW,EAElE,GAAIf,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM0B,EAAK1B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D2B,EAAK3B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD4B,EAAU5B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD6B,EAAQ7B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClD8B,EAAUT,GAAQnB,EAAiB,EAAI,GACzC6B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GAqBf,GApBIL,EAAUC,IAAU,EACtBE,EAAQ;AAAA,0CAC4BL,CAAE;AAAA,2BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,+BAC/CE,CAAO,qBAAqBA,CAAO,QAAQX,EAAUW,CAAO,CAAC;AAAA;AAAA;AAAA;AAAA,gCAI5DjB,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGfe,EAAQ;AAAA,0CAC4BL,CAAE;AAAA,2BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,gCAC9Cf,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAIbhB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMkC,EAAKlC,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DmC,EAAKnC,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDoC,EAAUpC,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDqC,GAAQrC,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDsC,EAAUjB,GAAQnB,EAAiB,EAAI,GACvCqC,EAAOpB,EAAUmB,CAAO,EAC1BF,EAAUC,KAAU,EACtBL,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQC,CAAI;AAAA,4BACpDb,CAAE;AAAA;AAAA;AAAA,gBAKtBM,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kBAG1EH,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVrB,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,cAExCZ,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2BAExCJ,CAAQ,MAAMA,CAAQ,IAAIF,CAAK;AAAA;AAAA,gBAE1Cc,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRhB,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIf,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMsC,EAAajB,EAAU,KAAKvB,EAAW,WAAW,EAClDyC,EAAgBlB,EAAU,eAAevB,EAAW,WAAW,EAC/D0C,EAAcD,EAAc,OAC5BE,EAAW3C,EAAW,KAAK,OAC3B4C,EAAU5C,EAAW,KAAK,OAAO,CAAC6C,EAAKC,IAAQD,EAAMC,CAAG,EAC1DC,EAAU,GACd,OAAIH,EACFG,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBlC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGf+B,EAAU;AAAA;AAAA,8BAEclC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,sCAEhBmB,CAAQ,KAAK3C,EAAW,KAAK,IAAIgD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,2CACnD3B,CAAI,KAAKF,EAAU,IAAI6B,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+CAC1CN,CAAW,KAAKD,EAAc,IAAIO,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC/DN,CAAW,KAAK1C,EAAW,QAAQ,IAAIgD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,cAEzFpC,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BkB,CAAW;AAAA;AAAA,4BAEvBlB,EAAO,KAAK,KAAK,IAAIN,CAAK;AAAA;AAAA;AAAA;AAAA,0CAIZsB,CAAU;AAAA;AAAA,uCAEbE,EAAc,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI5BA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVrB,EAAOqB,CAAW,UAAUrB,CAAI;AAAA,2DACJA,EAAOqB,CAAW;AAAA,oCACzCrB,EAAOqB,CAAW;AAAA,oBAClCK,CAAO;AAAA;AAAA,gBAEX9B,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMpC,GAA6BmB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMlB,GACF,CAACmE,EAAclD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACkD,EAAoBnC,CAAW,EAClCpC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEuC,EAAajB,EAAU,KAAK2B,EAAmB,WAAW,EAE1DrC,EAAIsC,EAAc,IAAKpD,EAAM,SAAUA,EAAM,IAAI,EACjDqB,EAAWP,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACV,OAAIiC,EAAmB,gBACrBjC,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,KAEzCvB,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,WAEpC,CACL,KAAAS,EACA,YAAa,CAAC,KAAMjD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMe,EAAa,SAAUhB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKwB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbhC,GAAoBgC,EAAcC,EAAGd,EAAM,KAAMgB,EAAamC,EAAoBlC,EAAKC,EAAK,KAAK,CACvG,CACF,EAESlC,GAA8BiB,GAA+D,CACxG,IAAMoD,EAAmBpD,EAAW,oBAAiC,EAE/DqD,EAAOxE,GAA0BmB,CAAU,EAEjD,GAAIqD,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,OAAOC,GAA4B,CAAC,gBAAAF,EAAiB,GAAGC,CAAI,CAAC,CAC/D,EAEarE,GAAc,CAACuE,EAAyBvD,IAA4C,CAC/FtB,GAAe6E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzE,GAA6B,cAAeyE,EAAQ,OAAO,CAAC,EAAG,GAAOvD,CAAU,CAAC,CACnG,EAEMf,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,EACZ,SAAU,EACZ,EAEaC,GAAoCc,GAA+D,CAC9G,IAAMwD,EAASxD,EAAW,OAC1B,MAAO,CAAC,OAAAwD,EAAQ,GAAGvE,GAAsB,SAAUuE,CAAM,CAC3D,EAEarE,GAAoB,CAACoE,EAAyBvD,IAA4C,CACrGtB,GAAe6E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzE,GAA6B,oBAAqByE,EAAQ,OAAO,CAAC,EAAG,GAAMvD,CAAU,CAAC,CACxG,EAOMZ,GACF,CAAC6D,EAAclD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACkD,EAAoBnC,CAAW,EAClCpC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEe,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIsC,EAAc,IAAKpD,EAAM,SAAUA,EAAM,IAAI,EACvD,MAAO,CACL,KAAAkD,EACA,YAAa,CAAC,KAAMjD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMe,EAAa,SAAUhB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKwB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbhC,GAAoBgC,EAAcC,EAAGd,EAAM,KAAMgB,EAAamC,EAAoBlC,EAAKC,EAAK,MAAM,CACxG,CACF,EAES5B,GAAU,CAACkE,EAAyBvD,IAAwC,CACvFtB,GAAe6E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnE,GAAyB,UAAWmE,EAAQ,OAAO,CAAC,EAAG,GAAOvD,CAAU,CAAC,CAC3F,EAEaV,GAA0BU,GAA2D,CAChG,IAAMyD,EAAezD,EAAW,cAC1BO,EAAYP,EAAW,UAEvBqD,EAAOxE,GAA0BmB,CAAU,EAEjD,GAAIyD,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAGtF,OAAOC,GAA4B,CAAC,aAAAG,EAAc,UAAAlD,EAAW,GAAG8C,CAAI,CAAC,CACvE,EAEa9D,GAAgCS,GAA2D,CACtG,IAAMwD,EAASxD,EAAW,OAC1B,MAAO,CAAC,OAAAwD,EAAQ,GAAGvE,GAAsB,SAAUuE,CAAM,CAC3D,EAEahE,GAAgB,CAAC+D,EAAyBvD,IAAwC,CAC7FtB,GAAe6E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnE,GAAyB,gBAAiBmE,EAAQ,OAAO,CAAC,EAAG,GAAMvD,CAAU,CAAC,CAChG,ICxWA,IAUM0D,GAUAC,GAwBOC,GA5CbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EAEbG,EAASC,GAAe,SAAUL,EAAUE,CAAW,EACvDI,EAAWF,EAAO,KAAK,QAEvBG,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,iBAAiBJ,CAAM,CAAC;AAAA,UACrCI,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,+BACzCG,CAAQ,IAAIZ,CAAK,OAAOY,CAAQ,kBAAkBA,CAAQ,IAAIV,CAAK;AAAA,SAEhG,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,CAACF,EAAOC,EAAOC,CAAK,EAAE,IAAIa,GAAKA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,CAAC,EAC1E,gBAAAF,EACA,WAAY,KACR,CAAC,QAAS,CAAC,CAAC,KAAML,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CAAC,EAC1E,CACF,EAEaf,GAASsB,GAAkC,CACtD,IAAIhB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRc,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACbzB,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3Cc,EAAQ,QAAQvB,GAAuBO,EAAOC,EAAOC,EAAOc,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC9DA,IAgCME,GAoBAC,GASAC,GA8CAC,GA0CAC,GAkCAC,GAaAC,GAwBAC,GA2BAC,GAsBAC,GAkCAC,GAYAC,GAiDAC,GAwEAC,GA2FAC,GAOOC,GAUAC,GAhiBbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAuBMrB,GAAiB,CAACsB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,gEAAgE,UAEzEC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMrB,GAAe,CAACqB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEMzB,GACF,CAAC2B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGvB,GAAesB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BtB,GAAaqB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEvB,GAA8CiC,GAChD,+JAEC,IAAM,CACL,OAAQA,EAAwB,CAC9B,IAAK,aACH,MAAO,4BACT,IAAK,qBACH,MAAO,sKAKT,IAAK,uBACH,MAAO,oCACT,IAAK,gBACH,MAAO,6LAKT,IAAK,qBACH,MAAO,gUAMT,IAAK,uBACH,MAAO,CACL,8CAA+C,kDAC/C,qCAAsC,4CACtC,oDACF,EAAE,KAAK;AAAA,CAAI,EACb,IAAK,aACH,MAAO,4CACT,QACE,MAAM,IAAI,MAAM,6BAA6BA,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACH,IAEEhC,GAA8B,CAACiC,EAA0BP,IAC3D,+EAAiF,IAAM,CACrF,OAAQO,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIP,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBO,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEhC,GAAY,CAAC2B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMY,EAAS,IAAI,MAAMZ,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Da,EAAWP,EAAI,SAAW,EAAIM,EAASN,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACe,EAAGC,IAAM,CACrBH,EAAOE,CAAC,EAAID,EAASE,CAAC,EACtBH,EAAOG,EAAIf,CAAI,EAAIa,EAASd,EAAK,OAASgB,CAAC,CAC7C,CAAC,EACMH,GAEFC,CACT,EAEMjC,GACF,CAACoC,EAA+BpB,EAA2BS,EAA0BN,IACrE,CACV,IAAIkB,EAAwB,CAAC,EAC7B,GAAIZ,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAiB,EAAW,QAASF,GAAMG,EAAY,KAAKH,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGf,CAAI,EAAIiB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExCjB,EAAK,QAAQ,CAACe,EAAGC,IAAME,EAAYH,CAAC,EAAIT,EAAMU,CAAC,CAAC,CAClD,MACEV,EAAM,QAASS,GAAMG,EAAY,KAAKH,CAAC,CAAC,MAErC,CACL,GAAIlB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDqB,EAAcD,EAAW,IAAI,CAAClB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOe,CACT,EAEFpC,GACF,CAACmC,EAA+BC,EAAgCrB,EAAkBC,IAClE,CACV,IAAMqB,GAAiB,IAAM,CAC3B,OAAQrB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMuB,EAAsBH,EAAW,MAAM,EAC7C,OAAInB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASiB,GAAMlB,EAAOkB,CAAC,EAAII,CAAa,EACxDrB,EAAW,KAAK,QAASiB,GAAMK,EAAoBL,CAAC,EAAI,KAAK,MAAME,EAAWF,CAAC,EAAIlB,EAAOkB,CAAC,CAAC,CAAC,IAE7FlB,EAAO,KAAKsB,EAAe,EAAGtB,EAAO,MAAM,EAC3CuB,EAAoB,QAAQ,CAACL,EAAGC,IAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMD,EAAIlB,EAAOmB,CAAC,CAAC,CAAC,GAEnFI,CACT,EAEFrC,GACF,CAACsC,EAAuBJ,EAA+BC,EAAgCrB,EACtFU,IAAmC;AAAA,kEAC0Bc,EAAO,KAAK,OAAO,mBAC7EH,EAAY,MAAM;AAAA,sCACYD,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,uCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+BACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCACrCE,EAAY,MAAM;AAAA,gCAC1BA,EAAY,MAAM;AAAA,4BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,2EAKhBD,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,OAMtFjC,GACF,CAACsC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBgB,IAAsC;AAAA,+DAC/BF,EAAO,KAAK,OAAO,QAAQC,EAAM,KAAK,OAAO;AAAA,wCACpEL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,iCACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,4BACnDM,EAAM,KAAK,OAAO;AAAA,kCACZJ,EAAY,MAAM;AAAA,8BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+EAMdD,EAAW,MAAM;AAAA,mBAC7EM,CAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAYvBD,EAAM,WAAW,eAAgB,IAAK,YAAY,CAAC;AAAA;AAAA;AAAA,OAKzDrC,GAAoB,CAACqC,EAAsBL,IAA0C;AAAA,yCAClDK,EAAM,KAAK,OAAO;AAAA,sCACrBL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,gCAClEC,EAAW,MAAM;AAAA,2BACtBA,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQjF/B,GACF,CAACoC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2B0B,EAA2BC,IAAuC,CAC5F,GAAM,CAACC,EAAUC,EAAWC,EAAUC,CAAU,EAC5CX,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAKpB,EAAO,CAAC,IAAM,EAAM,CAAC,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,EAC9F,MAAO;AAAA;AAAA,0BAEayB,EAAM,KAAK,OAAO;AAAA,qBACvBI,CAAS,uBAAuBT,EAAWS,CAAS,CAAC;AAAA,qBACrDC,CAAQ,uBAAuBV,EAAWU,CAAQ,CAAC;AAAA,YAC5DV,EAAW,MAAM;AAAA,uBACNW,CAAU;AAAA,uBACVH,CAAQ;AAAA;AAAA,qBAEVH,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,8CAGZD,EAAO,KAAK,OAAO;AAAA;AAAA,sCAE3BK,CAAS;AAAA,sCACTC,CAAQ;AAAA,YAClCJ,CAAgB,0BAA0BN,EAAWS,CAAS,CAAC,6BACjET,EAAWU,CAAQ,CAAC;AAAA,iBACbH,CAAkB;AAAA;AAAA,8BAELP,EAAWS,CAAS,CAAC;AAAA,8BACrBT,EAAWU,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOtCV,EAAW,OAAS,CAAC;AAAA,wCACOW,CAAU;AAAA,sCACZH,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAY1C,EAEEtC,GACF,CAACmC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBsB,EAAqBN,EACxEC,EAA4BM,IAAoC,CAC/D,GAAM,CAACJ,EAAWC,CAAQ,EAAIV,EAAW,SAAW,EAAI,CAAC,EAAG,CAAC,EAAKpB,EAAO,CAAC,IAAM,EAAO,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAE/FkC,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQN,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJO,CAAS,oCAAoCX,EAAM,KAAK,OAAO,oBAC9DD,EAAO,KAAK,OAAO;AAAA,4BACHH,EAAY,SAAW,EAAI,gBAAkB,iBAAiBc,CAAG,GAAG;AAAA,8FACFnC,EAAOmC,CAAG,CAAC;AAAA,cAC3Fd,EAAYc,CAAG,CAAC,UAAUf,EAAWe,CAAG,CAAC,MAAMzB,EAAIyB,CAAG,CAAC,KAAKzB,EAAIyB,CAAG,CAAC,MAAMf,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,cAI3FM,CAAgB,0CAA0CN,EAAWe,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA;AAAA;AAAA,gBAIrBS,CAAS;AAAA,gBACTA,CAAS,WAAWA,CAAS,OAAOhB,EAAWe,CAAG,CAAC;AAAA,kBACjDF,CAAc;AAAA;AAAA;AAAA,yBAGPP,CAAgB;AAAA,uBAClBC,CAAkB;AAAA;AAAA,gBAEzBS,CAAS,iBAAiBA,CAAS,KAAKhB,EAAWe,CAAG,CAAC;AAAA;AAAA;AAAA,kCAGrCV,EAAM,KAAK,OAAO;AAAA,6BACvBU,CAAG,WAAWC,CAAS;AAAA,0BAC1BD,IAAQN,EAAY,SAASJ,EAAM,gBAAgB,kBAAkB,CAAC,KAAO;AAAA,uGACA;AAAA;AAAA;AAAA,QAIjG,EAEA,MAAO;AAAA,MACPS,EAAiCL,CAAS,CAAC;AAAA,MAC3CK,EAAiCJ,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAO5BE,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CASfR,EAAO,KAAK,OAAO;AAAA,wBACtCC,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAItC,EAEElC,GACF,CAAC8C,EAAyBpC,EAA8BO,EAAsB8B,EAC7E7B,EAA0B8B,IAA6C,CACtE,IAAMnB,EAAaiB,EAAY,KACzB3B,EAAM3B,GAAUwD,EAAUtC,EAAW,KAAMmB,EAAW,MAAM,EAE9DC,EAAcrC,GAAgBoC,EAAYkB,EAAa7B,EAAOR,EAAW,IAAI,EAC7ED,EAASsC,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzBtC,EAASoB,EAAW,IAAI,CAAClB,EAAOI,IAAUJ,IAAU,EAAI,EAAMmB,EAAYf,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCoB,EAAcpC,GAAkBmC,EAAYC,EAAarB,EAAQC,CAAU,IAG/E,IAAMuB,EAASgB,GAAe,SAAUH,EAAY,SAAUhB,CAAW,EACnEI,EAAQgB,EAAc,QAASJ,EAAY,SAAUjB,CAAU,EAC/DsB,EAAaC,EAAU,KAAKtB,CAAW,EACvCuB,EAAUxB,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAACyB,EAAG1B,IAAM0B,IAAMxB,EAAYF,CAAC,CAAC,EACrGO,EAAmBzB,EAAW,0BAA4B,qBAC1D6C,EAAmBC,GAA+B;AAAA,QACtDlE,GAA2CoB,EAAW,uBAAuB,CAAC;AAAA,SAC7E,IAAM,CACP,OAAQA,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHb,GAAkBqC,EAAOL,CAAU,CAAC;AAAA,gBACpCtC,GAA4BmB,EAAW,YAAaO,CAAY,CAAC;AAAA,gBAEjErB,GACIsC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKgB,CAAgB,CAAC;AAAA,gBAEhF,IAAK,SACH,MAAO;AAAA,gBACHxC,GAA0CsC,EAAQJ,EAAYC,EAAarB,EAAQU,CAAG,CAAC;AAAA,gBAEvFrB,GACIoC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQ0B,EAAkBzB,EAAW,kBAAkB,CAAC;AAAA,gBAE1G,IAAK,QACH,MAAO;AAAA,cAEHX,GACImC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKT,EAAW,YAAayB,EAC7EzB,EAAW,mBAAoBA,EAAW,cAAc,CAAC;AAAA,cAEnE,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,QACF8C,EAAa,iBAAiBtB,EAAOD,CAAM,CAAC;AAAA,QAC5CuB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,cAC1DE,CAAO;AAAA;AAAA;AAAA,gCAGWpB,EAAO,gBAAgB,YAAY,CAAC;AAAA,8BACtCC,EAAM,KAAK,OAAO;AAAA,aACnC,IAAM,CACX,OAAQxB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,iDAE8BwB,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA,2CAE3CxB,EAAW,kBAAkB;AAAA,qBAE9D,IAAK,SACH,MAAO,6DACT,IAAK,QACH,MAAO,4DACT,QACE,MAAM,MAAM,4BAA4BA,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA;AAAA,SAIJ,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,EACnC,EACA,gBAAAqC,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMzB,EAAa,SAAUgB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEElD,GAAuCwD,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEaxD,GAAS,CAACuD,EAAyB/C,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoCwD,CAAO,EAChEpE,GAAeoE,EAAQ,OAAQ/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EsC,EAAQ,QACJzD,GAAwByD,EAAQ,OAAO,CAAC,EAAG/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAMiD,EAAYjD,EAAW,UACvBE,EAAOF,EAAW,KAClBkD,EACFlD,EAAW,wBACT+B,EAAc/B,EAAW,YACzBgC,EAAiBhC,EAAW,iBAA6B,EACzD0B,EAAqB1B,EAAW,mBAChCmD,EAA+CnD,EAAW,sBAC1DoD,EAAapD,EAAW,KAExBc,EAA4Bd,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOqD,GAA4B,CACjC,UAAAJ,EACA,KAAA/C,EACA,wBAAAgD,EACA,YAAAnB,EACA,eAAAC,EACA,mBAAAN,EACA,sBAAAyB,EACA,KAAAC,EACA,YAAAtC,CACF,CAAC,CACH,ICvjBA,IAeMwC,GA4DAC,GAiFOC,GAoBAC,GAhLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,EAClE,MAAM,IAAI,MAAM,6BAA6B,EAE/C,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EACpEC,IAAqC,CACpC,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAWC,GAA4BpB,EAAO,CAAC,EAAE,QAAQ,EACzDqB,EAAgBX,GAAcD,EAAc,EAC5Ca,EAAqBZ,GAAcD,EAAc,EACjDc,EAA4Bd,EAAc,EAC5Ce,EAAgB,EACdC,EAAmBC,GAA+B;AAAA,gCAC9BtB,CAAU;AAAA,6BACbI,EAAW,OAAO;AAAA;AAAA,2BAEpBgB,GAAe,kCAAkCL,CAAQ;AAAA,2BACzDK,GAAe,qCAAqCL,CAAQ;AAAA,2BAC5DK,GAAe,sCAAsCL,CAAQ;AAAA,QAChFF,EAAe,sBAAsBO,GAAe,qCAAqCL,CAAQ,KAAO,EAAE;AAAA,QAC1GD,EAAe,sBAAsBM,GAAe,qCAAqCL,CAAQ,KAAO,EAAE;AAAA,2BACvFK,GAAe,6CAA6CL,CAAQ;AAAA,QAErFE,EACI,sBAAsBG,GAAe,iDAAiDL,CAAQ,KAC9F,EAAE;AAAA,QAENG,EACI,sBAAsBE,GAAe,mDAAmDL,CAAQ,KAChG,EAAE;AAAA,QAENI,EACI,sBAAsBC,GAAe,uDAAuDL,CAAQ,KACpG,EAAE;AAAA;AAAA,QAERO,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCX,EAAaX,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMzDc,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDK,EAA4B,wCAA0C,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAO1EF,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,qFAEKL,EAAe,UAAY,KAAK;AAAA;AAAA,SAGzGU,EAAU,CAAC,CAAC,KAAMb,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChBkB,EAAQ,KAAK,CAAC,KAAMX,EAAkB,SAAUhB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAEjES,EAAc,GAChBkB,EAAQ,KAAK,CAAC,KAAMX,EAAkB,SAAUhB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAEjES,EAAc,GAChBkB,EAAQ,KAAK,CAAC,KAAMhB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAiB,EACA,WAAY,KAAO,CAAC,QAAAE,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKZ,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAESZ,GAAgB,CAACoC,EAAyBpB,IAA8C,CAGnGlB,GAAesC,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJrC,GAA+BqC,EAAQ,OAAQpB,EAAYoB,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEalC,GAAgCe,GAAiE,CAC5G,IAAMqB,EAAUrB,EAAW,QAC3B,OAAOsB,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICnLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GAkBAC,GA2EOC,GAYAC,GAvLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,EAA+BI,IAC/D,2CAA2CD,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,8BAC5EA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAEvBQ,EAAW,MAAM;AAAA,gCACVI,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAOjFJ,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA,SAKpErB,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBiB,EAAYC,EAAU,KAAKN,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKiB,EAAU,cAAcjB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASM,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBN,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACmB,EAAOC,IAAMhC,GAAkB+B,EAAOC,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACqB,EAAKD,IAAMhC,GAAkBiC,EAAKD,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWI,EAAW,OAC7B,QAASS,EAAI,EAAGA,EAAIT,EAAW,OAAQ,EAAES,EAClCb,EAAK,SAASa,CAAC,IAClBf,EAAO,OAAOe,EAAG,EAAG,CAAC,EACrBd,EAAK,OAAOc,EAAG,EAAGT,EAAWS,CAAC,CAAC,EAC/BR,EAAM,OAAOQ,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQV,EAAM,IAAIM,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CN,EAAM,QAAQ,CAACM,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYlB,EAAKc,CAAC,EAAIf,EAAOe,CAAC,GAAKF,EACnCO,EAASpB,EAAOe,CAAC,EACjBM,EAAWD,EAASD,EAAWZ,EAAMQ,CAAC,EAC5Cf,EAAOe,CAAC,EAAIM,EACZpB,EAAKc,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMH,EAAcJ,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACoB,EAAM1B,IAAM,CACxBc,EAAYY,CAAI,EAAI,KAAK,MAAMrB,EAAKqB,CAAI,EAAItB,EAAOsB,CAAI,GAAKf,EAAMe,CAAI,CAAC,CACzE,CAAC,EAED,IAAMC,EAA+B,CAAC,KAAMb,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASe,GAAe,SAAU9B,EAAO,CAAC,EAAE,SAAUgB,CAAW,EACjEZ,EAAQ2B,EAAc,QAAS/B,EAAO,CAAC,EAAE,SAAUY,CAAU,EAC7DoB,EAAad,EAAU,KAAKF,CAAW,EAEvCiB,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB9B,EAAOW,CAAM,CAAC;AAAA,mCACjBQ,EAAM,MAAM,KAAKA,EAAM,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACjDf,EAAO,MAAM,KAAKA,EAAO,IAAIe,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACtDd,EAAK,MAAM,KAAKA,EAAK,IAAIc,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,mCAC/CR,EAAM,MAAM,KAAKA,EAAM,IAAIQ,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCAC7CT,EAAW,MAAM,KAAKA,EAAW,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,UAE1F/B,GAA0Bc,EAAOW,EAAQH,EAAYI,CAAW,CAAC;AAAA,UACjEkB,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA,gCAC1CjB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDA,EAAO,YAAY,aAAcX,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,SAE9E,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGH,EAAW,QAAQ,IAAID,EAAO,CAAC,GAAG,MAAQ,EAAE,EAAE,EACrE,gBAAAiC,EACA,WAAY,KAAO,CACjB,QAAS,CAACJ,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKZ,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEazB,GAAQ,CAAC2C,EAAyBlC,IAAsC,CACnFf,GAAeiD,EAAQ,OAAQlC,CAAU,EACzC,IAAMmC,EAAoBhD,GAAgC+C,EAAQ,OAAQlC,CAAU,EACpFkC,EAAQ,QAAQ5C,GAAuB4C,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEa3C,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,IC5LA,IAcM6B,GAUAC,GAuGOC,GAKAC,GApIbC,GAAAC,EAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAWC,GAA4BH,EAAM,QAAQ,EACrDI,EAAQJ,EAAM,KACdK,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOP,EAAW,KAItB,GAHIO,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EAGpBE,EAAgBT,IAAa,MAAQ,uCAAyC,kCA8EpF,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CAAC,QAAS,CAAC,CAAC,KAAME,EAAO,SAAUJ,EAAM,QAAQ,CAAC,EAAG,cAAe,CAAC,EAAGU,CAAI,CAAC,GAChG,gBAhFuBE,GAAgC;AAAA,sCACrBV,CAAQ;AAAA,sCACRA,CAAQ;AAAA,4CACFA,CAAQ,KAAKK,CAAE;AAAA;AAAA,2DAEAL,CAAQ;AAAA,sEACGA,CAAQ;AAAA;AAAA,4DAElBA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKJA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,iCAKvCK,CAAE;AAAA;AAAA;AAAA;AAAA,qBAIdA,CAAE;AAAA;AAAA,qBAEFE,CAAI;AAAA,iCACQA,CAAI;AAAA;AAAA;AAAA,UAG3BE,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAwBET,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QA6B/B,CACF,EAGaV,GAAU,CAACqB,EAAyBZ,IAAwC,CACvFX,GAAeuB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAyBsB,EAAQ,OAAO,CAAC,EAAGZ,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCa,GAA4B,CAAC,KAAMb,EAAW,IAAc,CAAC,ICrIjE,IAgBMc,GAMAC,GAWAC,GASAC,GAqBAC,GAkDOC,GAOAC,GAxHbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,GAEtBf,GAAuBgB,GAAsC,CACjE,IAAMD,EAAkBC,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,uBAAuBC,CAAC,QAAQC,CAAa,IAAI,EACvDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,4BAA4BC,CAAC,OAAOC,CAAa,IAAI,CAExE,CACA,MAAO;AAAA,uDAC8CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACpEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMhB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMU,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWd,EAAO,CAAC,EAAE,SACrBe,EAAOJ,EAAW,OAClBK,EAAOf,EAAW,KAClBgB,EAAgBD,EAAO,EAAKL,EAAW,OAASK,EAAOA,EACvDT,EAAU,IAAI,MAAqBN,EAAW,UAAU,EACxDiB,EAAQC,EAAc,QAASL,EAAUH,CAAU,EACnDS,EAAmB,IAAI,MAAcnB,EAAW,UAAU,EAC1DoB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EAClB,QAASd,EAAI,EAAGA,EAAIR,EAAW,WAAYQ,IAAK,CAC9Cc,GAAetB,EAAW,WAAWQ,CAAC,EACtCW,EAAiBX,CAAC,EAAIc,EACtB,IAAMC,EAAcb,EAAW,MAAM,EACrCa,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWQ,CAAC,EACtDa,EAAa,KAAKE,CAAW,EAC7BjB,EAAQE,CAAC,EAAIgB,GAAe,SAAShB,CAAC,GAAIK,EAAUQ,EAAab,CAAC,CAAC,EACnEY,EAAkB,KAAK,CAAC,KAAMC,EAAab,CAAC,EAAG,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACA,IAAM0B,EAAcX,EAAO,EAAI,UAAY,WAAWE,CAAY,IAC5DU,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiBV,EAAO,GAAGX,CAAO,CAAC;AAAA,wCACZa,EAAiB,MAAM,KAAKA,EAAiB,IAAIX,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GnB,GAAyB8B,EAAiB,MAAM,CAAC;AAAA,IACjD7B,GAAoBgB,CAAO,CAAC;AAAA;AAAA,IAE5BqB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,oBAE/CM,EAAM,gBAAgB,YAAY,CAAC;AAAA,8CACTQ,CAAW;AAAA;AAAA,UAE/CA,CAAW;AAAA;AAAA;AAAA,KAInB,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASN,EACT,cAAe,CAAC,EAAG,KAAK,KAAKT,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEanB,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,IChIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAoCAC,GArFbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,EAAc,QAASF,EAAUN,CAAU,EACnDS,EAASC,GAAe,SAAUJ,EAAUJ,CAAW,EAEvDS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAC5CG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,4BAC1CK,EAAO,gBAAgB,YAAY,CAAC;AAAA,0BACtCF,EAAM,KAAK,OAAO;AAAA,4BAChBP,EAAW,MAAM;AAAA,8BACfS,EAAO,WAAW,gBAAiB,GAAG,CAAC,OAAOF,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA;AAAA,UAErGA,EAAM,WAAW,eAAgB,IAAK,eAAe,CAAC;AAAA;AAAA,QAExDE,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,OAG1E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,EAAE,EAChC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAO,CACF,CACF,EAEanB,GAAQqB,GAAkC,CACrDxB,GAAewB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAsBsB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,ICxFA,IAUMC,GA8DAC,GA+BOC,GAvGbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAU,KAAK,KAAKF,EAAa,CAAC,EAElCG,EAASC,GAAe,aAAcL,EAAYF,EAAY,CAAC,EAC/DQ,EAAIC,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEW,EAAID,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEY,EAAIF,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAElEa,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACV,EACHW,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IAE9CI,EAAc,oBAAoBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC5E,MAAO;AAAA,+BACcA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMR,EAAE,2BAA2B,gBAAgBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAMN,EAAE,2BAA2B,gBAAgBM,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAML,EAAE,2BAA2B,gBAAgBK,CAAC,GAAIV,CAAM,CAAC;AAAA,wBACjEU,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIlB,IAAe,EACjBU,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCF,EAAa;AAAA,cACTE,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACHhB,EAAa,iBAAiBa,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UAC9CR,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCO,CAAO,CAAC;AAAA,UAC3DO,CAAU;AAAA,QAEhB,EAEErB,GAA4BQ,GAA+C,CAC/E,IAAMsB,EAAQtB,EAAO,CAAC,EAAE,KAClBuB,EAAQvB,EAAO,CAAC,EAAE,KAClBwB,EAAQxB,EAAO,CAAC,EAAE,KAClByB,EAAiBzB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEG,EAAU,SAASiB,EAAOC,CAAK,GAAKlB,EAAU,SAASkB,EAAOC,CAAK,GACrFE,EAAcJ,EACdlB,EAAaC,EAAU,KAAKiB,CAAK,EAGrC,GAAIpB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUN,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhED,EAAcC,EACdvB,EAAaC,EAAU,KAAKqB,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,gBAAkB3B,GACdR,GAA2BQ,EAAcC,EAAQ0B,EAAaxB,EAAauB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKrB,EAAa,GAA0B,CAAgB,CAAC,CACvF,EACF,CACF,EAEaX,GAASoC,GAAkC,CACtDA,EAAQ,QAAQrC,GAAyBqC,EAAQ,MAAM,CAAC,CAC1D,ICzGA,IAqCaC,GArCbC,GAAAC,EAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOa9B,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAU+B,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAE1B,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,GAAcC,EAA2B,CAAC,EACrE,CAAC,qBAAsB,CAACC,GAAWC,EAAwB,CAAC,EAC5D,CAAC,YAAa,CAAUC,GAAoBvB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWwB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,GAAKC,EAAkB,CAAC,EACjC,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,GAAWC,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACC,GAAYD,EAAqB,CAAC,EAClD,CAAC,YAAa,CAACE,GAAWF,EAAqB,CAAC,EAChD,CAAC,YAAa,CAACG,GAAWH,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACI,GAAYJ,EAAqB,CAAC,EAClD,CAAC,WAAY,CAACK,GAAUL,EAAqB,CAAC,EAC9C,CAAC,WAAY,CAACM,GAAUN,EAAqB,CAAC,EAC9C,CAAC,eAAgB,CAACO,GAAcP,EAAqB,CAAC,EACtD,CAAC,kBAAmB,CAACQ,GAAiBR,EAAqB,CAAC,EAC5D,CAAC,kBAAmB,CAACS,GAAiBT,EAAqB,CAAC,EAC5D,CAAC,OAAQ,CAAUU,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BnE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACoE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,ICxHD,IAoBaC,GApBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAYaL,GAAN,KAAqB,CAI1B,YAAoBM,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5D,IAAMC,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EACxDC,EAAmB,KAAK,QAAQ,uBAAyB,KAAK,QAAQ,IAAI,OAAO,gBAAkB,UACrGA,GAIDD,EAA2B,eAAe,KAAK,QAAQ,kBAAmB,CAAC,EAG9EA,EAAmB,YAAYR,EAAc,eAAe,EAC5D,IAAMU,EAAU,CAAC,EACjB,QAAWC,KAASR,EAClBO,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUR,EACnBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEN,GACFI,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUJ,CAAoB,CAAC,EAExE,IAAMO,EAAYN,EAAO,gBACrB,CAAC,OAAQP,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAU,EAAS,MAAOV,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAQ,EAAmB,aAAa,EAAGK,CAAS,EAE5CL,EAAmB,mBAAmB,GAAGH,CAAa,EAEtD,KAAK,QAAQ,wBAETI,EAAkB,CAInBD,EAA2B,eAAe,KAAK,QAAQ,kBAAmB,CAAC,EACxE,KAAK,QAAQ,oBAAsB,OACrC,KAAK,QAAQ,mBAET,KAAK,QAAQ,eAAe,OAAO,GAAI,eAAe,SAAW,eAAe,aAAa,GAGnG,IAAMM,EAAW,KAAK,QAAQ,eAAe,OAAO,GAAI,eAAe,SAAW,eAAe,QAAQ,EAEzG,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAC7B,KAAK,QAAQ,kBAAmB,EAAG,EAAG,KAAK,QAAQ,mBAAmB,OAAQ,CAAC,EACnF,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,mBAAmB,OAAQ,EAAGA,EAAS,OAAQ,EAAG,EAAE,EACrE,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAC9CE,EAAa,IAAID,EAAW,CAAC,CAAC,KAAKA,EAAW,CAAC,CAAC,GAEtDF,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACnD,IAAMI,EAAa,IAAI,eAAeJ,EAAS,OAAO,eAAe,CAAC,EAChEK,EAAeD,EAAW,CAAC,EAC3BE,EAAaF,EAAW,CAAC,EAE/BJ,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,kBAAsB,MAC5C,KAAK,QAAQ,kBAAoBK,GAGnC,IAAME,EAAY,OAAOF,EAAe,KAAK,QAAQ,iBAAiB,EAChEG,EAAU,OAAOF,EAAa,KAAK,QAAQ,iBAAiB,EAElE,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,KAAK,QAAQ,eAAe,QAAQR,EAAS,EAAE,EAC/C,IAAIS,EAAc,GAClBtB,EAAiB,QAAQ,CAACuB,EAAOC,IAAM,CACrCF,GAAe,SAASE,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIG,EAAe,GACnBzB,EAAkB,QAAQ,CAACsB,EAAOC,IAAM,CACtCE,GAAgB,UAAUF,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIE,CAAU,KAAKM,CAAW,GAAGI,CAAY,mBACpFL,EAAUD,CAAS,KAAK,CAC9B,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,CAEvB,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/F,IAAMtB,EAAS,KAAK,QAAQ,OACtBuB,EAAuB,CAAC,EAC1BvB,EAAO,SAAS,IAAI,YAAY,GAClCuB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe5B,EAAO,mBAAmB,CAAC,KAAA2B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,yBAAyBF,CAAI,EAAE,EAE1D,IAAMG,EAAkB9B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ4B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,MAAO,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2BhC,EACE,CAC3B,IAAMiC,EAAI,OAAOjC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEkC,EAAI,OAAOlC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEmC,EAAI,OAAOnC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEoC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IC1KA,IAYMC,GA4CAC,GAmBOC,GA3EbC,GAAAC,EAAA,kBAKAC,KACAC,KACAC,KACAC,KACAC,KAGMT,GACF,CAACU,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEX,GAA0B,CAACgB,EAA0BP,IAAgD,CAGzG,IAAIQ,EAAMD,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BC,GAAO,IAAMD,EAAY,YAAY,KAAO,KAE9CC,GAAO,IACHlB,GACIU,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GACnFQ,CACT,EAMahB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,oBAAyC,KACzC,wBAAiD,KACjD,2BAAwB,EAExB,2BAAwB,GAUxB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAIiB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAyB,CACxC,GAAI,CAAC,UAAU,IAEb,MAAM,IAAI,MAAM,yCAAyC,EAG3D,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAGID,EAAQ,SAAS,IAAI,+BAA+B,IACtD,KAAK,sBAAwB,GAC7BC,EAAiB,KAAK,+BAAiD,GAErED,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEI,KAAK,wBACP,KAAK,kBAAoB,KAAK,OAAO,eAAe,CAClD,KAAM,YACN,MAAO,CACT,CAAC,GAGH,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CAKhB,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,OAAK,KAAK,qBACR,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiB,GAE/D,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CAErG,IAAMC,EAAwB,CAAC,EAC/B,QAASpB,EAAI,EAAGA,EAAIgB,EAAiB,OAAQ,EAAEhB,EAAG,CAChD,IAAMqB,EAAU,KAAK,eAAe,IAAIL,EAAiBhB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACqB,EACH,MAAM,IAAI,MAAM,0BAA0BL,EAAiBhB,CAAC,EAAE,IAAI,EAAE,EAEtEoB,EAAWpB,CAAC,EAAIqB,CAClB,CAGA,IAAMhB,EAAMjB,GAAwB2B,EAASC,CAAgB,EACzDM,EAAW,KAAK,eAAe,YAAYjB,CAAG,EAE5C,CAAC,QAAAkB,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIV,EAAQ,WAAWC,CAAgB,EAG/EU,EAAyBT,EAAc,SAAW,EAAIM,EAAQ,IAAI,CAACI,EAAG3B,IAAMA,CAAC,EAAIiB,EACvF,GAAIS,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS7B,EAAI,EAAGA,EAAIuB,EAAQ,OAAQ,EAAEvB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU0B,EAAuB1B,CAAC,CAAC,GAAK0B,EAAuB1B,CAAC,EAAI,IAC5E0B,EAAuB1B,CAAC,GAAKuB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB1B,CAAC,CAAC,EAAE,EAEtE,GAAI0B,EAAuB1B,CAAC,IAAM,GAChC,SAEF,IAAM8B,EAAcJ,EAAuB1B,CAAC,IAAM,GAC5C+B,EAAeL,EAAuB1B,CAAC,IAAM,GAC7CgC,EAAcF,GAAeC,EAC/BZ,EAAyBI,EAAQvB,CAAC,EAAE,SAAUuB,EAAQvB,CAAC,EAAE,IAAI,EAC7DkB,EAAmBQ,EAAuB1B,CAAC,EAAGuB,EAAQvB,CAAC,EAAE,SAAUuB,EAAQvB,CAAC,EAAE,IAAI,EAChFqB,EAAU,KAAK,eAAe,IAAIW,EAAW,IAAI,EACvD,GAAI,CAACX,EACH,MAAM,IAAI,MAAM,2BAA2BW,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKT,CAAO,EAE7BU,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKZ,CAAO,CAC7B,CACAO,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKR,CAAO,CAC1B,CAMA,IAAIa,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EAChBC,EAAY,EACVC,EAAoB,CAAC,EACvBC,EAAsB,EAC1Bb,EAAgB,QAAQc,GAAK,CAC3B,IAAMjC,EAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KAEnDC,EACJ,OAAQlC,EAAK,OAAQ,CACnB,IAAK,GACHkC,EAAgB,EAChB,MACF,IAAK,GACHA,EAAgB,EAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,QACE,MAAM,IAAI,MAAM,4BAA4BlC,EAAK,MAAM,EAAE,CAC7D,EAEI8B,IAAc,GAAKA,IAAc,KACnCI,EAAgB,IAEdA,EAAgBF,IAClBA,EAAsBE,GAExBL,EAAgB,KAAK,KAAKA,EAAgBK,CAAa,EAAIA,EAC3DJ,EAAY9B,EAAK,OACjB+B,EAAQ,KAAKF,CAAa,EAC1BA,GAAiB7B,EAAK,OAAS,CACjC,CAAC,EAED6B,EAAgB,KAAK,KAAKA,EAAgBG,CAAmB,EAAIA,EACjE,IAAMG,EAAc,IAAI,YAAYN,CAAa,EACjDV,EAAgB,QAAQ,CAACc,EAAGvC,IAAM,CAChC,IAAM0C,EAASL,EAAQrC,CAAC,EAClBM,GAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWE,EAAaC,EAAQpC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAChDiC,EAAE,OAAS,SACpB,IAAI,YAAYE,EAAaC,EAAQpC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAE1D,IAAI,aAAamC,EAAaC,EAAQpC,GAAK,MAAM,EAAE,IAAIA,EAAI,CAE/D,CAAC,EAED,IAAMqC,EAEF,KAAK,eAAe,OAAOR,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYQ,EAAkB,OAAQ,EAAGF,EAAa,EAAGN,CAAa,EACxF,KAAK,eAAe,QAAQQ,EAAkB,EAAE,EAChDT,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQQ,EAAkB,MAAM,CAC1F,CAGA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BpB,CAAa,EAE5F,OAAKF,IACHA,EAAW,KAAK,eAAe,MAAMP,EAAS6B,CAAuB,EACrE,KAAK,eAAe,YAAYvC,EAAKiB,CAAQ,GAG/CuB,GACI,OACA,IAAM,yBAAyB9B,EAAQ,IAAI,UAAUV,CAAG,UAAUuC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBtB,EAAUN,EAAkBY,EAAmBR,EAAYS,EAAae,EACxEV,CAAoB,EAEjBN,CACT,CAEA,OAAOkB,EAAmBxC,EAAwB,CAChD,KAAK,eAAe,OAAOwC,EAAWxC,CAAI,CAC5C,CAEA,OAAOyC,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMpB,EAAiB,KAAK,qBAAqB,IAAIoB,CAAQ,EAC7D,GAAIpB,EAAgB,CAClB,QAAW3B,KAAQ2B,EACjB,KAAK,eAAe,QAAQ3B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAO+C,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBjB,GAAU,OAAQ,IAAM,kCAAkCO,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW3D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe4D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMzB,EAAU,KAAK,eAAe,IAAIyB,CAAS,EACjD,GAAI,CAACzB,EACH,MAAM,IAAI,MAAM,2BAA2ByB,CAAS,EAAE,EAExD,OAAOzB,EAAQ,MACjB,CACA,iBAAiBoD,EAAsBvB,EAAcjD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMK,EAAO,MAAMoE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWrE,EAAK,OAAQL,CAAI,CACrC,CACF,CAEF,ICxhBA,IAAA2E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA6EOF,GApIbG,GAAAC,EAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,GAAqB,EACtC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIF,EAAYE,IAAK,CACnC,IAAMZ,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BI,EAAML,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASY,EAAI,EAAGA,EAAID,EAAKC,IACvBZ,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQI,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIJ,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFM,EAAgBF,GAAsB,SAAW,CAAC,EAClDG,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIa,EAASE,EAAcC,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAASU,EAAI,EAAGA,EAAIV,EAAK,OAAQU,IAC/B,KAAK,OAAO,QAAQc,GAAQ,EAAIxB,EAAKU,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBQ,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAEapC,GAAO,MAAMU,EAAuB6B,IAA4B,CAC3E,IAAMvC,EAAOU,EAAO,SACpB,GAAIV,GAAQ,UAAU,IAAK,CACzB,GAAI,CAACuC,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,mGAAmG,EAEzG,IAAMtB,EAAU,IAAIuB,GACpB,MAAMvB,EAAQ,WAAWsB,CAAG,EAE5BvC,EAEIiB,EAGCwB,GAAiBxB,EAAQ,MAAMwB,CAAI,EAGnCC,GAAgBzB,EAAQ,KAAKyB,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5FxB,EAAQ,OAAO0B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM7B,EAAOF,EAAO,OAAO,SAASiC,EAAKA,EAAMF,CAAI,EACnDxB,EAAQ,OAAO2B,EAAKhC,CAAI,CAC1B,CACF,EAGA,MAAMmC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAMxB,EAAQ,SAAS8B,EAAW,IAAMrC,EAAO,OAAO,SAASsC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBlC,EAAQ,aAC1DgC,EAAMC,EAAQC,EACdZ,EAAI,OAASA,EAAI,OAAO,gBAAkB,UAAY7B,EAAO,aAAaA,EAAO,iBAAiBwC,CAAM,CAAC,EACnD,GAAGA,CAAM,EAAE,EAGpEA,GAAmBjC,EAAQ,cAAciC,CAAM,EAGhD,CAACA,EAAgBhC,EAA2BkC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpEhC,CAAiB,EAAE,EAC3B,IAAMoC,EAAU,IAAIpD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAciC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,CACF,ICjMA,IAiBME,GAoBAC,GAWOC,GA6CPC,GAMOC,GAgBAC,GA+FAC,GAMAC,GAoBPC,GAqEOC,GA6NAC,GAgBAC,GA9hBbC,GAAAC,EAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAOMlB,GAA8BmB,GAA4C,CAC9E,IAAMC,EAAOC,GAAY,EACnBC,EAAQF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMG,EAAaH,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeI,EAAYA,EAAa,CAAC,IACtE,GAChBC,GAAe,uCAAwC,EAElD,CAACJ,EAAK,OAAOG,EAAa,CAAC,EAAGH,EAAK,OAAOG,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAH,EAAK,aAAaE,CAAK,CACzB,CACF,EAOMrB,GAAU,CAACwB,EAAoBC,IAA+B,CAChDL,GAAY,EAAE,SAASI,EAAYC,CAAY,IAC/C,GAChBF,GAAe,+BAAgC,CAEnD,EAMatB,GAAc,MAAMyB,GAA4B,CAE3D1B,GAAQ0B,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,EAEhC,CAI9B,IAAME,EAAW,cAAuB,KACxC,MAAMA,EAASR,GAAY,EAAGM,CAAG,CACnC,CACF,EAkCMxB,GAAiB,IAAI,IAMdC,GAAyB0B,GAAwC,CAC5E,IAAMV,EAAOC,GAAY,EACnBU,EAAkBX,EAAK,QAAQU,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAV,EAAK,OAAO,IAAIU,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAQazB,GACT,CAAC2B,EAAkCC,IAA2E,CAC5G,IAAMb,EAAOC,GAAY,EAErBF,EAAgB,EAChBe,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBN,CAAO,EAE1Dd,EAAgBC,EAAK,kBAAkBY,EAAU,CAAC,EAAGA,EAAU,CAAC,EAAGE,CAAoB,EACnFf,IAAkB,GACpBK,GAAe,yBAA0B,EAG3C,GAAM,CAACgB,EAAYC,CAAW,EAAIzC,GAA2BmB,CAAa,EAEpEuB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAO1B,EAAK,iBAAiBD,EAAe0B,CAAC,EAC/CC,IAAS,GACXtB,GAAe,0BAA2B,EAE5Ca,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKtB,EAAK,aAAa0B,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAO1B,EAAK,kBAAkBD,EAAe0B,CAAC,EAChDC,IAAS,GACXtB,GAAe,2BAA4B,EAE7Cc,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAa3B,EAAK,aAAa0B,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOf,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Bc,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBf,EAAK,kBAAkBD,CAAa,EAClDgB,IAAoB,GACtBX,GAAe,0BAA2B,EAG5CyB,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGF/C,GAAe,IAAIgB,EAAe,CAACA,EAAekB,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAAC9B,EAAeuB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EAEpDlB,IAAoB,GACtBf,EAAK,mBAAmBe,CAAe,EAGrChB,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjCiC,CACR,QAAE,CACAhC,EAAK,MAAMY,EAAU,CAAC,CAAC,EACnBE,IAAyB,GAC3Bd,EAAK,0BAA0Bc,CAAoB,EAErDE,EAAO,QAAQkB,GAASlC,EAAK,MAAMkC,CAAK,CAAC,CAC3C,CACF,EAOShD,GACT,CAACwB,EAAmBG,IAA2E,CAC7F,IAAMD,EAAmC5B,GAAsB0B,CAAK,EACpE,OAAOzB,GAAsB2B,EAAWC,CAAO,CACjD,EAES1B,GAAkBgD,GAA4B,CACzD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUrD,GAAe,IAAIoD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACFrC,EAAK,mBAAmBqC,EAAe,MAAM,EAG/CrC,EAAK,wBAAwBmC,CAAS,EAEtClB,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACxDjC,EAAK,mBAAmBD,CAAa,EACrChB,GAAe,OAAOoD,CAAS,CACjC,EAEM/C,GACF,CAACkD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMvC,EAAOC,GAAY,EAEnBwC,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAU3C,EAAK,mBAAmBmC,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEzB,EAAK,QAAQoD,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB3C,EAAK,OAAO,IAAI,IAAI,WAAWmD,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMzC,EAAQF,EAAK,UAAU,EACvBsD,EAAatD,EAAK,WAAW,EAAI0C,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKxD,EAAK,OAAOuD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAStC,EAAK,iBAChBgD,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACblC,GAAe,iDAAiD+B,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAtC,EAAK,aAAaE,CAAK,CACzB,CACF,EAKKb,GAAM,MACf8C,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2C/C,IAAoE,CACjH,IAAMb,EAAOC,GAAY,EACnBmC,EAAUrD,GAAe,IAAIoD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBlE,EAAK,UAAU,EAChCmE,EAAoBnE,EAAK,WAAWoB,EAAa,CAAC,EAClDgD,EAAmBpE,EAAK,WAAWoB,EAAa,CAAC,EACjDiD,EAAqBrE,EAAK,WAAWqB,EAAc,CAAC,EACpDiD,EAAoBtE,EAAK,WAAWqB,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc1D,CAAO,EAG5D,QAASY,EAAI,EAAGA,EAAIL,EAAYK,IAC9BrC,GAAyBsE,EAAajC,CAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,CAAC,CAAC,EAI7G,QAASA,EAAI,EAAGA,EAAIJ,EAAaI,IAC/BrC,GACIwE,EAAcnC,CAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,CAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,EAAkBL,EAAmB,EACrCM,GAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,EAAI,EAAGA,EAAIL,EAAYK,IAC9BzB,EAAK,QAAQwE,GAAkB,EAAIT,EAAmBtC,CAAC,EACvDzB,EAAK,QAAQyE,GAAiB,EAAIxD,EAAsBwC,EAAahC,CAAC,CAAC,EAEzE,QAASA,EAAI,EAAGA,EAAIJ,EAAaI,IAC/BzB,EAAK,QAAQ0E,IAAmB,EAAIV,EAAoBvC,CAAC,EACzDzB,EAAK,QAAQ2E,GAAkB,EAAIzD,EAAuByC,EAAclC,CAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,EAAQ,yBAAApD,EAA0B,gCAAAqD,EAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMzB,EAAK,cAAc4E,EAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChBrB,GAAe,oBAAoBqB,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBzB,EAAK,eAAe4E,EAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChBrB,GAAe,mCAAmCqB,EAAC,iBAAiBU,CAAS,GAAG,EAK9EnC,EAAK,eAAe4E,EAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,GAAgCrC,EAAK,CAAC,IACtF,GAChBpC,GAAe,qBAAqBqB,EAAC,QAAQD,EAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,EAE8BzC,EAChCyC,EAAY,MAAM9E,EAAK,mBACnBD,EAAesC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,EAAY,MAAM9E,EAAK,QACnBD,EAAeqE,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,IAAc,GAChB1E,GAAe,0BAA0B,EAG3C,IAAM2E,GAA2B,CAAC,EAElC,QAAStD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMa,EAAStC,EAAK,QAAQqE,EAAqB,EAAI5C,CAAC,EACtD,GAAIa,IAAW0B,EAAoBvC,CAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,CAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,GAA2BhF,EAAK,UAAU,EAE1CiF,GAAmBjF,EAAK,WAAW,EAAI,CAAC,EAE1CkF,GAAmB,GACnBC,GAA6BhF,GAAa,EAC9C,GAAI,CACgBH,EAAK,kBACnBsC,EAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChB7E,GAAe,4CAA4CqB,CAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWzC,EAAK,QAAQoF,IAAiB,EAC/CjF,GAAaH,EAAK,QAAQoF,IAAiB,EAC3C,IAAM9B,EAAatD,EAAK,QAAQoF,IAAiB,EAC3CC,GAAarF,EAAK,QAAQoF,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,GAAY5D,KAC9BiB,GAAK,KAAK1C,EAAK,QAAQsD,EAAa,EAAI7B,EAAC,CAAC,EAE5CzB,EAAK,SAASsD,CAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,CAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAYjD,GAAa,EAC7B,QAASsB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAAS1F,EAAK,QAAQoD,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYtF,EAAK,QAAQoD,EAAS,EAAIsC,GAC9ED,GAAW,KAAKzF,EAAK,aAAa0F,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAY7C,EAAK,cAAcG,EAAU,EACzCyF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAU7C,EAAK,qBAAqB6C,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACbnF,EAAK,kBAAkBsC,CAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAInD,EAAK,OAAO,SAASG,GAAYA,GAAagD,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAnD,EAAK,aAAagF,EAAwB,EACtCG,KAAS,UAAYhF,IACvBH,EAAK,MAAMG,EAAU,EAElB+E,IACHlF,EAAK,kBAAkBsC,CAAM,CAEjC,CACF,CAEA,OAAID,GACFrC,EAAK,sBAAsBqC,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACA/E,EAAK,aAAakE,CAAc,EAEhCH,EAAmB,QAAQiC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,EAExCpC,IAAqB,GACvB7D,EAAK,sBAAsB6D,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,CAC7C,CACF,EAKa3G,GAAgB6C,GAA4B,CACvD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUrD,GAAe,IAAIoD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMrC,EAAgBqC,EAAQ,CAAC,EAGzB8D,EAAkBlG,EAAK,iBAAiBD,CAAa,EACvDmG,IAAoB,GACtB9F,GAAe,iCAAkC,EAEnDJ,EAAK,SAASkG,CAAe,CAC/B,EAEa3G,GAA8B4G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,ICviBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,4whPCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAKAC,GACAC,GACEC,GACAC,GACAC,GACAC,GACAC,GACAC,GAEAC,GAMAC,GAiEAC,GAEOC,GA6CAC,GAaAC,GAaAC,GAcAC,GAkBAC,GAaAC,GAyBAC,GAjPbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAEM5B,GAAU,IAAe,CAAC,CAAC6B,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnE3B,GAAe,GACfC,GAAc,GACdC,GAAU,GAORG,GAAiF,CAAC,EAClFC,GAAuF,CAAC,EACxFC,GAA+E,CAAC,EAChFC,GAAyD,CAAC,EAC1DC,GAAsE,CAAC,EACvEC,GAAuD,CAAC,EAExDC,GAAe,IAAY,CAC/B,GAAIX,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMa,GAAwBgB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH5B,GAAe,GACX4B,EAAG,KAAK,KACV1B,GAAU,GACVC,GAAkB,CAAC,EAAEyB,EAAG,KAAK,GAAG,IAEhC3B,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,WACCyB,EAAG,KAAK,IACVxB,GAAiB,CAAC,EAAEwB,EAAG,KAAK,GAAG,EAE/BxB,GAAiB,CAAC,EAAE,EAEtB,MACF,IAAK,kBACCwB,EAAG,KAAK,IACVvB,GAA+B,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAG,EAEtDvB,GAA+B,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,kBACCA,EAAG,KAAK,IACVtB,GAA+B,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAG,EAEtDtB,GAA+B,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,SACCA,EAAG,KAAK,IACVrB,GAAuB,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAG,EAE9CrB,GAAuB,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAI,EAEjD,MACF,IAAK,UACCA,EAAG,KAAK,IACVpB,GAAwB,MAAM,EAAG,CAAC,EAAEoB,EAAG,KAAK,GAAG,EAE/CpB,GAAwB,MAAM,EAAG,CAAC,EAAE,EAEtC,MACF,IAAK,MACCoB,EAAG,KAAK,IACVnB,GAAa,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAG,EAEpCnB,GAAa,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAI,EAEvC,MACF,IAAK,gBACCA,EAAG,KAAK,IACVlB,GAAsB,MAAM,EAAG,CAAC,EAAEkB,EAAG,KAAK,GAAG,EAE7ClB,GAAsB,MAAM,EAAG,CAAC,EAAE,EAEpC,MACF,QACF,CACF,EAEMG,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAgC,SAA0B,CACrE,GAAsChB,GAAQ,EAAG,CAC/C,GAAIG,GACF,OAEF,GAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAG3D,OAAAF,GAAe,GAGX2B,GAAI,KAAK,YAAc,QACrBd,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Cc,GAAI,KAAK,UAAYd,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACgB,EAASC,IAAW,CAC5C/B,IAAa,UAAU,EAEvB,IAAMgC,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9BhC,GAAc,IAAI,OAAOgC,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnEhC,GAAY,QAAW6B,GAAmBE,EAAOF,CAAE,EACnD7B,GAAY,UAAYa,GACxB,IAAI,gBAAgBmB,CAAS,EAC7B5B,GAAoB,CAAC0B,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKL,GAAI,IAAI,EACjE5B,GAAY,YAAYiC,CAAO,CACjC,CAAC,CAEH,KACE,QAAOC,GAAsBN,GAAI,IAAI,CAEzC,EAEaZ,GAAoB,MAAMY,GAA4B,CACjE,GAAsC7B,GAAQ,EAC5C,OAAAa,GAAa,EACN,IAAI,QAAc,CAACkB,EAASC,IAAW,CAC5C1B,GAAmB,CAACyB,EAASC,CAAM,EACnC,IAAME,EAA0B,CAAC,KAAM,WAAY,GAAKL,CAAG,EAC3D5B,GAAa,YAAYiC,CAAO,CAClC,CAAC,EAED,MAAWE,GAAYP,CAAG,CAE9B,EAEaX,GAAwB,MAAMmB,GACHrC,GAAQ,GAC5Ca,GAAa,EACN,IAAI,QAA+B,CAACkB,EAASC,IAAW,CAC7DzB,GAA+B,KAAK,CAACwB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,MAAAG,CAAK,CAAC,EACtEpC,GAAa,YAAYiC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,GAEWnB,GAAsBmB,CAAK,EAI9BlB,GAAwB,MAAMmB,EAAkCC,IAEjCvC,GAAQ,GAC5Ca,GAAa,EACN,IAAI,QAAqC,CAACkB,EAASC,IAAW,CACnExB,GAA+B,KAAK,CAACuB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,UAAAI,EAAW,QAAAC,CAAO,CAAC,EACnFtC,GAAa,YAAYiC,CAAO,CAClC,CAAC,GAEWf,GAAsBmB,EAAWC,CAAO,EAI/CnB,GACT,MAAMiB,EAAmBE,IAAoF,CAC/G,GAAsCvC,GAAQ,EAAG,CAE/C,GAAIuC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA1B,GAAa,EACN,IAAI,QAAqC,CAACkB,EAASC,IAAW,CACnEvB,GAAuB,KAAK,CAACsB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAG,EAAO,QAAAE,CAAO,CAAC,EACtEtC,GAAa,YAAYiC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,CACH,KACE,QAAYjB,GAAciB,EAAOE,CAAO,CAE5C,EAEalB,GAAiB,MAAMmB,GAAqC,CACvE,GAAsCxC,GAAQ,EAC5C,OAAAa,GAAa,EACN,IAAI,QAAc,CAACkB,EAASC,IAAW,CAC5CtB,GAAwB,KAAK,CAACqB,EAASC,CAAM,CAAC,EAC9C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKM,CAAS,EAChEvC,GAAa,YAAYiC,CAAO,CAClC,CAAC,EAEIb,GAAemB,CAAS,CAEjC,EAEalB,GAAM,MACfkB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCL,IAAoE,CAC3G,GAAsCvC,GAAQ,EAAG,CAE/C,GAAI0C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAhC,GAAa,EACN,IAAI,QAAsC,CAACkB,EAASC,IAAW,CACpErB,GAAa,KAAK,CAACoB,EAASC,CAAM,CAAC,EACnC,IAAMc,EAAqBJ,EACrBR,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAM,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAJ,CAAO,CAAC,EACpGtC,GAAa,YAAYiC,EAAca,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYxB,GAAIkB,EAAWC,EAAcC,EAAQC,EAAeC,EAASL,CAAO,CAEpF,EAEahB,GAAe,MAAMiB,GAAqC,CACrE,GAAsCxC,GAAQ,EAC5C,OAAAa,GAAa,EACN,IAAI,QAAc,CAACkB,EAASC,IAAW,CAC5CpB,GAAsB,KAAK,CAACmB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKM,CAAS,EACtEvC,GAAa,YAAYiC,CAAO,CAClC,CAAC,EAEIX,GAAaiB,CAAS,CAE/B,IC5PA,IAUIQ,GACAC,GAEEC,GAWAC,GAiBOC,GAzCbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAKMP,GAAuB,CAACQ,EAAgBC,IAA0C,CACtF,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEMR,GAAwBO,GAAmC,CAC/D,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,sBAAsBc,EAA8C,CAGxE,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAsB,IAAI,WAAWD,CAAW,CAAC,CAC1D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CAUzG,GATKvB,KACEC,KACHA,GAA+BuB,GAAkBC,EAAG,GAEtD,MAAMxB,GACNA,GAA+B,OAC/BD,GAAqB,IAGnB,OAAOsB,GAAiB,SAC1B,GAAI,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAAM,CAE/E,IAAMI,EAAQ,KAAM,SAASJ,CAAY,EACzC,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMK,GAAcD,EAAOH,CAAO,CAC1F,KAAO,CAGL,IAAMK,EAAmC,MAAM,KAAK,sBAAsBN,CAAY,EAEtF,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMO,GAAsBD,EAAWL,CAAO,CACtG,KAEA,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMI,GAAcL,EAAcC,CAAO,CAEnG,CAEA,MAAM,SAAyB,CAC7B,OAAOO,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCT,EACzC,CACrC,IAAMU,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZzB,EAASyB,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKvB,CAAM,EACtBwB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZzB,EAASyB,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK5B,CAAM,EACvB6B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMxC,GAAqBuC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIvC,GAAqBuC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASpB,CAAO,EAEzFuB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKvC,GAAqByC,EAAQF,CAAC,CAAC,EAEnG,OAAOI,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,IC1IA,IAeaC,GAmBAC,GAlCbC,GAAAC,EAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAazC,IAZI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAC5D,MAAM,MAAsB,CAE1BD,GAAgB,EAGhB,MAAMS,GAA8B,CACtC,CAKA,MAAM,8BAA8BC,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICpDA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,EAAA,kBAGAC,KACaH,GAAc,IAAII,KCI/BC,KACAA,KCHO,IAAMC,GAAU,SDWO,CAC5B,IAAMC,EAA4C,cAAoC,YAEpD,OAAO,UAAc,KAAe,UAAU,KAC9EC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,EACzCC,GAAgB,QAASD,EAAa,CAAC,CAE3C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "B", "A", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "TrainingSession", "init_training_session_impl", "__esmMin", "handler", "_trainingOptions", "_sessionOptions", "_array", "_trainableOnly", "_feeds", "_fetches", "_options", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "d", "aa", "k", "a", "b", "c", "e", "f", "h", "l", "q", "m", "n", "p", "u", "v", "t", "g", "r", "ba", "ca", "x", "y", "da", "z", "ea", "A", "B", "C", "D", "fs", "fa", "ha", "E", "F", "noExitRuntime", "H", "I", "J", "K", "L", "M", "N", "O", "P", "ia", "ja", "ka", "la", "ma", "na", "Q", "oa", "R", "pa", "S", "qa", "ra", "sa", "ta", "ua", "T", "va", "w", "U", "wa", "xa", "ya", "za", "Aa", "Ba", "Ca", "Da", "Ea", "V", "Fa", "Ga", "Ia", "Ha", "Ja", "Ka", "Ma", "Oa", "Na", "Pa", "Qa", "Ra", "Sa", "Ta", "La", "G", "W", "Ua", "X", "Y", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "jb", "ib", "kb", "lb", "mb", "nb", "Z", "ob", "pb", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "d", "l", "p", "t", "v", "aa", "z", "ba", "A", "ca", "da", "ea", "B", "fa", "C", "a", "b", "c", "e", "f", "h", "k", "q", "n", "m", "r", "w", "x", "D", "g", "u", "ha", "ia", "ja", "E", "ka", "F", "G", "H", "la", "ma", "J", "na", "fs", "oa", "pa", "qa", "ra", "K", "L", "noExitRuntime", "M", "N", "sa", "P", "Q", "ta", "ua", "va", "wa", "xa", "ya", "R", "za", "S", "Aa", "Ba", "Ca", "T", "Da", "Ea", "Fa", "Ga", "U", "Ha", "y", "V", "Ia", "Ja", "Ka", "W", "La", "Ma", "Na", "Oa", "X", "Qa", "Pa", "Ra", "Sa", "Ta", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "Y", "wb", "xb", "yb", "zb", "Bb", "Ab", "Cb", "Db", "Fb", "Eb", "Gb", "Hb", "Ib", "Jb", "Lb", "Kb", "Mb", "Nb", "Ob", "Pb", "Qb", "Rb", "Tb", "Ub", "Vb", "Wb", "Xb", "Yb", "Sb", "O", "Zb", "$b", "ac", "Z", "bc", "cc", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "tc", "rc", "sc", "uc", "vc", "wc", "xc", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "numThreads", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "i", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "createTensorShapeVariables", "createIndicesHelper", "inputVariable", "outputVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "name", "tensorType", "shapeOrRank", "isInput", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "value", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "impl", "indicesAndValue", "normalizedDispatchGroup", "size", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "uniformSnippets", "dispatchGroup", "inShape", "outShape", "inRank", "a", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSum", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMean", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "parseReduceAttributes", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "inputOffsetAssignment", "initinputOffsetLet", "initinputOffsetVar", "initinputOffset", "reduceOps", "k", "l", "outputSize", "shaderHelper", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "validateInputs", "createArgMinMaxAttributesFromInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "attributes", "createAttributeWithCacheKey", "context", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "updatedAttributes", "createReduceProgramInfo", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "clipV10", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "dataType", "tensorTypeToWsglStorageType", "a", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "funcCall", "typeA", "typeB", "typeOutput", "additionalImplementation", "outputSize", "ShapeUtil", "vecSize", "expressionScalar", "expressionVector", "a", "b", "broadcastImpl", "output", "outputVariable", "inputVariable", "calcOffsetImpl", "dims", "strides", "offsets", "i", "idx", "assignment", "isAOneElement", "isBOneElement", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "calculatedShape", "BroadcastUtil", "sharedDimension", "dimA", "dimB", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputVariable", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "typeSnippet", "activationFnSnippet", "biasActivationSnippet", "init_activation_util", "__esmMin", "component", "dataType", "activation", "_hasPreluActivationWeights", "_packed", "_coordsLength", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "getActicationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "inputVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "activationFunction", "getActicationSnippet", "elementsPerThread", "dispatch", "components", "A", "B", "output", "inputVariables", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_util", "init_common", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "activation", "hasPreluActivationWeights", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFnSnippet", "biasActivationSnippet", "inputs", "attributes", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "activationFunction", "applyActivation", "getActicationSnippet", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "x", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputDataType", "permAttr", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputShape", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "v", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_util", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "activation", "hasPreluActivationWeights", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFnSnippet", "biasActivationSnippet", "inputs", "attributes", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "b", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "context", "adjustedAttributes", "hasBias", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "inputChannels", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "createConv2DTransposeMatMulProgramInfo", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "einsumEquation", "dataType", "inputVars", "inputVariable", "outputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "idxCopy", "rhsSymbols", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "outputSize", "data", "inputVariable", "indices", "output", "outputVariable", "calcDataIndices", "indicesRank", "calcStr", "i", "j", "getShaderSource", "shaderHelper", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "inputStrides", "ShapeUtil", "inputSize", "indicesShape", "indicesDataType", "indicesSize", "axis", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "getShaderSource", "shaderHelper", "i", "createAttributeWithCacheKey", "context", "validateInputs", "offsetC", "createGemmProgramInfo", "gemm", "parseGemmAttributes", "init_gemm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "m", "n", "dims", "broadcastM", "broadcastN", "offset", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "line", "dataType", "tensorTypeToWsglStorageType", "calculateAlpha", "calculateC", "inputStorageBuffersDeclarations", "getShaderSource", "shaderHelper", "context", "createAttributeWithCacheKey", "metadata", "createInstanceNormProgramInfo", "createInstanceNormNHWCProgramInfo", "parseInstanceNormAttributes", "instanceNorm", "init_instance_norm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "C", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "workgroupSize", "getShaderSource", "shaderHelper", "outputSize", "N", "H", "tensorTypeToWsglStorageType", "createAttributeWithCacheKey", "context", "validateInputs", "createLayerNormProgramInfo", "parseLayerNormAttributes", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "outputSize", "ShapeUtil", "axis", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "dataType", "tensorTypeToWsglStorageType", "hasMeanDataOutput", "hasInvStdOutput", "bindingIndex", "getShaderSource", "shaderHelper", "outputs", "createAttributeWithCacheKey", "context", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "inputs", "context", "outputShape", "BroadcastUtil", "createMatmulProgramInfo", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "generatePadCode", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "parsePadAttributes", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "validPads", "output", "outputDims", "inputDims", "inputStrides", "pads", "dataType", "constantValue", "inputRank", "block", "i", "attributes", "shaderHelper", "ShapeUtil", "outputSize", "outputVariable", "input", "inputVariable", "padSnippet", "outputShape", "bigInt64Pads", "value", "updatePads", "axes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "mode", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "generatePoolingCode", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "shaderHelper", "x", "xShape", "outputShape", "op1", "op2", "start", "inputDims", "dataType", "rank", "outputSize", "ShapeUtil", "output", "outputVariable", "kw", "sw", "pwStart", "pwEnd", "dimIdxW", "codeW", "codeH", "codeHEnd", "kh", "sh", "phStart", "phEnd", "dimIdxH", "dimH", "kernelSize", "kernelStrides", "stridesRank", "padsRank", "hasPads", "sum", "cur", "padCode", "i", "name", "adjustedAttributes", "inputVariable", "countIncludePad", "attr", "createAttributeWithCacheKey", "context", "format", "storageOrder", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "output", "outputVariable", "wgslType", "getShaderSource", "shaderHelper", "x", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "bilinearInterpolation", "bicubicInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "nearestMode", "roiTmp", "roiLocal", "v", "i", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "output", "input", "useExtrapolation", "extrapolationValue", "batchIdx", "heightIdx", "widthIdx", "channelIdx", "cubicCoeffA", "excludeOutside", "createCubicInterpolationFunction", "idx", "direction", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "getShaderSource", "shaderHelper", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "dataType", "tensorTypeToWsglStorageType", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "bindingNumber", "getShaderSource", "shaderHelper", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "outputShape", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "axis", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "dataType", "tensorTypeToWsglStorageType", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "threadMaxDecl", "_shaderHelper", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "rank", "axis", "adjustedAxis", "input", "inputVariable", "sizeInConcatAxis", "outputsTensorInfo", "outputShapes", "previousSum", "outputShape", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "outputSize", "ShapeUtil", "vecSize", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "outputShape", "calculatedShape", "BroadcastUtil", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "averagePool", "parseAveragePoolAttributes", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clipV10", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "parseInstanceNormAttributes", "layerNorm", "parseLayerNormAttributes", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "neg", "not", "pad", "parsePadAttributes", "pow", "range", "reciprocal", "reduceMin", "parseReduceAttributes", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "device", "computePassEncoder", "profilingEnabled", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "kernelName", "mappedData", "startTimeU64", "endTimeU64", "startTime", "endTime", "inputShapes", "value", "i", "tensorDataTypeEnumToString", "outputShapes", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "inputDatas", "gpuData", "artifact", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "preLength", "offsets", "maxAlignmentOfField", "v", "baseAlignment", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "LOG_DEBUG", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "i", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "getSessionInputOutputCount", "initOrt", "initRuntime", "activeSessions", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "sessionHandle", "wasm", "getInstance", "stack", "dataOffset", "checkLastError", "numThreads", "loggingLevel", "env", "logLevelStringToEnum", "initJsep", "model", "modelDataOffset", "modelData", "options", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "initOrtCallbacks", "createSessionAllocateCallbacks", "createSessionFinalizeCallbacks", "createSessionCallbacks", "releaseSessionCallbacks", "runCallbacks", "endProfilingCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyInstance", "initializeRuntime", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "run", "endProfiling", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "model", "modeldata", "options", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "runtimeInitialized", "runtimeInitializationPromise", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "createSessionAllocate", "pathOrBuffer", "options", "initializeRuntime", "env", "model", "createSession", "modelData", "createSessionFinalize", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler", "env", "numCpuLogicalCores", "initializeWebAssemblyInstance", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "init_esm", "version", "wasmBackend", "registerBackend", "env", "version"]
}
