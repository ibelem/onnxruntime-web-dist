{"version":3,"file":"ort-common.es5.min.js","mappings":";;;;;CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAa,IAAID,IAEjBD,EAAU,IAAIC,GACf,CATD,CASGK,MAAM,WACT,O,wBCTA,IAAIC,EAAsB,CCA1BA,EAAwB,SAASL,EAASM,GACzC,IAAI,IAAIC,KAAOD,EACXD,EAAoBG,EAAEF,EAAYC,KAASF,EAAoBG,EAAER,EAASO,IAC5EE,OAAOC,eAAeV,EAASO,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAG3E,ECPAF,EAAwB,SAASQ,EAAKC,GAAQ,OAAOL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,EAAO,ECCtGT,EAAwB,SAASL,GACX,oBAAXkB,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeV,EAASkB,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeV,EAAS,aAAc,CAAEoB,OAAO,GACvD,G,8LCQMC,EAAqC,IAAIC,IACzCC,EAAqC,GAY9BC,EAAkB,SAACC,EAAcC,EAAkBC,GAC9D,IAAID,GAAmC,mBAAjBA,EAAQE,MAAwE,mBAA1CF,EAAQG,8BA8BpE,MAAM,IAAIC,UAAU,uBA7BlB,IAAMC,EAAiBV,EAAST,IAAIa,GACpC,QAAuBO,IAAnBD,EACFV,EAASY,IAAIR,EAAM,CAACC,QAAO,EAAEC,SAAQ,QAChC,IAAII,EAAeJ,SAAWA,EAEnC,OACK,GAAII,EAAeJ,WAAaA,GACjCI,EAAeL,UAAYA,EAC7B,MAAM,IAAIQ,MAAM,mCAA4BT,EAAI,4BAAoBE,G,CAIxE,GAAIA,GAAY,EAAG,CACjB,IAAMQ,EAAIZ,EAAyBa,QAAQX,IAChC,IAAPU,GACFZ,EAAyBc,OAAOF,EAAG,GAGrC,IAAK,IAAI,EAAI,EAAG,EAAIZ,EAAyBe,OAAQ,IACnD,GAAIjB,EAAST,IAAIW,EAAyB,IAAKI,UAAYA,EAEzD,YADAJ,EAAyBc,OAAO,EAAG,EAAGZ,GAI1CF,EAAyBgB,KAAKd,E,CAMpC,EAUae,EAAiB,SAAMC,GAA+B,O,OAAA,E,OAAA,E,EAAA,W,8nCAC3DC,EAAuC,IAAxBD,EAAaH,OAAef,EAA2BkB,EACtEE,EAAS,G,IACW,EAAAD,E,sBAAA,YAAY,Y,GAA3BE,EAAW,OACdC,EAAcxB,EAAST,IAAIgC,IAC7B,YACF,GAAIC,EAAYC,YACd,MAAO,CAAP,EAAOD,EAAYnB,SACd,GAAImB,EAAYE,QACrB,YAGIC,IAAmBH,EAAYI,Y,iBAKnC,O,uBAHKD,IACHH,EAAYI,YAAcJ,EAAYnB,QAAQE,QAEhD,GAAMiB,EAAYI,a,OAElB,OAFA,SACAJ,EAAYC,aAAc,EACnB,CAAP,EAAOD,EAAYnB,S,yBAEdsB,GACHL,EAAOJ,KAAK,CAACd,KAAMmB,EAAaM,IAAK,IAEvCL,EAAYE,SAAU,E,2BAEfF,EAAYI,Y,kBAvBC,I,aA4B1B,MAAM,IAAIf,MAAM,2CAAoCS,EAAOQ,KAAI,SAAAC,GAAK,iBAAIA,EAAE3B,KAAI,aAAK2B,EAAEF,IAAjB,IAAwBG,KAAK,Q,iBA/BhC,K,+QC7D/DC,EAAwC,UAE/BC,EAAW,CACtBC,KAAM,CAAC,EACPC,MAAO,CAAC,EACRC,OAAQ,CAAC,EACTC,SAAU,CAACC,OCRU,UDUjBC,aAASzC,GACX,QAAcY,IAAVZ,EAAJ,CAGA,GAAqB,iBAAVA,IAA2F,IAArE,CAAC,UAAW,OAAQ,UAAW,QAAS,SAASgB,QAAQhB,GACxF,MAAM,IAAIc,MAAM,qCAA8Bd,IAEhDkC,EAAgBlC,C,CAClB,EACIyC,eACF,OAAOP,CACT,GAIF7C,OAAOC,eAAe6C,EAAK,WAAY,CAAC5C,YAAY,IEoI7C,IAAM,EAAW4C,EClJXO,EAAiB,SAACC,EAAqCC,G,UAClE,QAAehC,IAAX+B,EACF,MAAM,IAAI7B,MAAM,gCAElB,QAAuBF,IAAnBgC,EAAQC,aAA0CjC,IAAlBgC,EAAQE,MAC1C,MAAM,IAAIhC,MAAM,0CAElB,GAA6B,SAAzB8B,EAAQG,aACV,MAAM,IAAIjC,MAAM,2CAGX,IAGHkC,EACAC,EAJGJ,EAAiBD,EAAO,OAAhBE,EAASF,EAAO,MAEzBM,EAAmB,QAAZ,EAAAN,EAAQM,YAAI,QAAI,CAACC,KAAM,IAAKC,KAAM,GAK7CJ,EADyB,iBAAfE,EAAS,KACR,CAACA,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,MAEvC,CAACD,EAAKC,KAAM,GAAID,EAAKC,KAAM,GAAID,EAAKC,KAAM,GAAiB,QAAb,EAAAD,EAAKC,KAAM,UAAE,QAAI,KAI1EF,EADyB,iBAAfC,EAAS,KACR,CAACA,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,MAEvC,CAACF,EAAKE,KAAM,GAAIF,EAAKE,KAAM,GAAIF,EAAKE,KAAM,GAAiB,QAAb,EAAAF,EAAKE,KAAM,UAAE,QAAI,GAG5E,IAAMC,OAAiCzC,IAAnBgC,EAAQU,OAAuBV,EAAQU,OAAS,OAG9DC,OACuB3C,IAAzBgC,EAAQY,mBAAuD5C,IAAzBgC,EAAQY,aAA6BZ,EAAQY,aAAwB,MACzGC,EAASZ,EAASC,EAClBY,EAA+B,SAAjBH,EAA0B,IAAII,aAAsB,EAATF,GAAc,IAAIE,aAAsB,EAATF,GAG1FG,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,QAAhBf,IACFO,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,GAAiB,GAIE,SAAjBT,EACFa,EAA0B,EAATX,EACS,QAAjBF,GACTU,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GACS,QAAjBF,IACTY,EAAiB,EACjBD,EAAiBT,EACjBQ,EAA0B,EAATR,GAGnB,IAAK,IAAI1C,EAAI,EAAGA,EAAI0C,EACf1C,IAAK8C,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FF,EAAYO,MAAqBtB,EAAOkB,GAAiBZ,EAAS,IAAMD,EAAS,GACjFU,EAAYQ,MAAqBvB,EAAOmB,GAAiBb,EAAS,IAAMD,EAAS,GACjFU,EAAYS,MAAqBxB,EAAOoB,GAAiBd,EAAS,IAAMD,EAAS,IACzD,IAApBoB,IAA4C,IAAnBJ,IAC3BN,EAAYU,MAAqBzB,EAAOqB,GAAiBf,EAAS,IAAMD,EAAS,IAOrF,OAF+C,IAAIqB,EAAO,UAAWX,EAA/B,SAAjBH,EAA6D,CAAC,EAAG,EAAGV,EAAQC,GACf,CAAC,EAAG,EAAGD,EAAQC,GAEnG,EAKawB,EAAkB,SAC3BC,EACA3B,GACoB,O,OAAA,E,OAAA,E,EAAA,W,6mCAWtB,GATM4B,EAA+C,oBAAvB,kBAAsCD,aAAiBE,iBAC/EC,EAAwC,oBAAhB,WAA+BH,aAAiBI,UACxEC,EAAyC,oBAAlB,aAAiCL,aAAiBM,YACzEC,EAA4B,iBAAVP,EAGpBQ,EAA+CnC,QAAAA,EAAW,CAAC,EAG3D4B,EAAgB,CAOlB,IALMQ,EAASC,SAASC,cAAc,WAC/BpC,MAAQyB,EAAMzB,MACrBkC,EAAOnC,OAAS0B,EAAM1B,OAGC,OAFjBsC,EAAkBH,EAAOI,WAAW,OA4BxC,MAAM,IAAItE,MAAM,6BAlBhB,GAPI+B,EAAS0B,EAAM1B,OACfC,EAAQyB,EAAMzB,WACFlC,IAAZgC,QAAmDhC,IAA1BgC,EAAQyC,oBAAwDzE,IAAzBgC,EAAQ0C,eAC1EzC,EAASD,EAAQyC,cACjBvC,EAAQF,EAAQ0C,mBAGF1E,IAAZgC,EAAuB,CAEzB,GADAmC,EAAwBnC,OACKhC,IAAzBgC,EAAQY,aACV,MAAM,IAAI1C,MAAM,+DAEhBiE,EAAsBvB,aAAe,OAEvCuB,EAAsBlC,OAASA,EAC/BkC,EAAsBjC,MAAQA,C,MAE9BiC,EAAsBvB,aAAe,OACrCuB,EAAsBlC,OAASA,EAC/BkC,EAAsBjC,MAAQA,EAGhCqC,EAAgBI,UAAUhB,EAAO,EAAG,GACpCiB,EAAOL,EAAgBM,aAAa,EAAG,EAAG3C,EAAOD,GAAQ2C,I,KAItD,KAAId,EAoCJ,IAAIE,EAAe,CAExB,QAAgBhE,IAAZgC,EACF,MAAM,IAAI9B,MAAM,2DAQlB,IALMkE,EAASC,SAASC,cAAc,WAC/BpC,MAAQyB,EAAMzB,MACrBkC,EAAOnC,OAAS0B,EAAM1B,OAGC,OAFjBsC,EAAkBH,EAAOI,WAAW,OASxC,OANMvC,EAAS0B,EAAM1B,OACfC,EAAQyB,EAAMzB,MACpBqC,EAAgBI,UAAUhB,EAAO,EAAG,EAAGzB,EAAOD,GAC9C2C,EAAOL,EAAgBM,aAAa,EAAG,EAAG3C,EAAOD,GAAQ2C,KACzDT,EAAsBlC,OAASA,EAC/BkC,EAAsBjC,MAAQA,EACvB,CAAP,EAAOJ,EAAe8C,EAAMT,IAE5B,MAAM,IAAIjE,MAAM,4B,CAEb,GAAIgE,EACT,MAAO,CAAP,EAAO,IAAIY,SAAQ,SAACC,EAASC,GAC3B,IAAMZ,EAASC,SAASC,cAAc,UAChCW,EAAUb,EAAOI,WAAW,MAClC,IAAKb,IAAUsB,EACb,OAAOD,IAET,IAAME,EAAW,IAAIC,MACrBD,EAASE,YAAc,YACvBF,EAASG,IAAM1B,EACfuB,EAASI,OAAS,WAChBlB,EAAOlC,MAAQgD,EAAShD,MACxBkC,EAAOnC,OAASiD,EAASjD,OACzBgD,EAAQN,UAAUO,EAAU,EAAG,EAAGd,EAAOlC,MAAOkC,EAAOnC,QACvD,IAAMsD,EAAMN,EAAQJ,aAAa,EAAG,EAAGT,EAAOlC,MAAOkC,EAAOnC,QAE5DkC,EAAsBlC,OAASmC,EAAOnC,OACtCkC,EAAsBjC,MAAQkC,EAAOlC,MACrC6C,EAAQjD,EAAeyD,EAAIX,KAAMT,GACnC,CACF,KAEA,MAAM,IAAIjE,MAAM,iE,CA7DhB,GAlBI+B,OAAM,EACNC,OAAK,OAEOlC,IAAZgC,QAAkDhC,IAAzBgC,EAAQ0C,mBAAwD1E,IAA1BgC,EAAQyC,eACzExC,EAASD,EAAQyC,cACjBvC,EAAQF,EAAQ0C,eAEhBzC,EAAS0B,EAAM1B,OACfC,EAAQyB,EAAMzB,YAGAlC,IAAZgC,IACFmC,EAAwBnC,GAE1BmC,EAAsBzB,OAAS,OAC/ByB,EAAsBlC,OAASA,EAC/BkC,EAAsBjC,MAAQA,OAEdlC,IAAZgC,EAAuB,CAQzB,IAPMwD,EAAanB,SAASC,cAAc,WAE/BpC,MAAQA,EACnBsD,EAAWvD,OAASA,EAIG,OAFjBsC,EAAkBiB,EAAWhB,WAAW,OAM5C,MAAM,IAAItE,MAAM,6BAHhBqE,EAAgBkB,aAAa9B,EAAO,EAAG,GACvCiB,EAAOL,EAAgBM,aAAa,EAAG,EAAG3C,EAAOD,GAAQ2C,I,MAK3DA,EAAOjB,EAAMiB,I,CAiDjB,QAAa5E,IAAT4E,EACF,MAAO,CAAP,EAAO9C,EAAe8C,EAAMT,IAE5B,MAAM,IAAIjE,MAAM,iE,iBApII,K,+QA2IXwF,EAAoB,SAC7BC,EAAsC3D,GACjC,IAAAE,EAAoCF,EAAO,MAApCC,EAA6BD,EAAO,OAA5B4D,EAAqB5D,EAAO,SAAlB6D,EAAW7D,EAAO,QAGlD,OAAO,IAAIyB,EAAO,CAACqC,SAAU,UAAWC,KAAM,UAAWJ,QAAO,EAAEK,KADrD,CAAC,EAAG/D,EAAQC,EAAO,GACwC0D,SAAQ,EAAEC,QAAO,GAC3F,EAKaI,EAAsB,SAC/BC,EAA0ClE,GACrC,IAAAmE,EAAqCnE,EAAO,SAAlCgE,EAA2BhE,EAAO,KAA5B4D,EAAqB5D,EAAO,SAAlB6D,EAAW7D,EAAO,QACnD,OAAO,IAAIyB,EAAO,CAACqC,SAAU,aAAcC,KAAMI,QAAAA,EAAY,UAAWD,UAAS,EAAEF,KAAI,EAAEJ,SAAQ,EAAEC,QAAO,GAC5G,EAKaO,EAAyB,SAClCL,EAAShE,EAAwCiE,GACjD,WAAIvC,EAAO,CAACqC,SAAU,aAAcC,KAAI,EAAEnB,KAAM7C,EAAQiE,KAAMA,QAAAA,EAAQ,CAACjE,EAAOzB,SAA9E,EC5PS+F,EAAwC,IAAI/G,IAA6C,CACpG,CAAC,UAAWyD,cACZ,CAAC,QAASuD,YACV,CAAC,OAAQC,WACT,CAAC,SAAUC,aACX,CAAC,UAAWA,aACZ,CAAC,QAASC,YACV,CAAC,QAASC,YACV,CAAC,OAAQJ,YACT,CAAC,UAAWK,cACZ,CAAC,SAAUC,eAIAC,EAAwC,IAAIvH,IAAkD,CACzG,CAACyD,aAAc,WACf,CAACuD,WAAY,SACb,CAACC,UAAW,QACZ,CAACC,YAAa,UACd,CAACC,WAAY,SACb,CAACC,WAAY,SACb,CAACC,aAAc,WACf,CAACC,YAAa,YAMZE,GAAkB,EACTC,EAAc,WACzB,IAAKD,EAAiB,CACpBA,GAAkB,EAClB,IAAME,EAAoD,oBAAlBC,eAA+D,mBAAvBA,cAAcC,KACxFC,EACwB,oBAAnBC,gBAAiE,mBAAxBA,eAAeF,KAE/DF,IACFX,EAAsCpG,IAAI,QAASgH,eACnDJ,EAAsC5G,IAAIgH,cAAe,UAEvDE,IACFd,EAAsCpG,IAAI,SAAUmH,gBACpDP,EAAsC5G,IAAImH,eAAgB,U,CAGhE,EC7CaC,EAAgB,SAACrB,GAE5B,IADA,IAAIsB,EAAO,EACFnH,EAAI,EAAGA,EAAI6F,EAAK1F,OAAQH,IAAK,CACpC,IAAMoH,EAAMvB,EAAK7F,GACjB,GAAmB,iBAARoH,IAAqBC,OAAOC,cAAcF,GACnD,MAAM,IAAIzH,UAAU,eAAQK,EAAC,sCAA8BoH,IAE7D,GAAIA,EAAM,EACR,MAAM,IAAIG,WAAW,eAAQvH,EAAC,kDAA0CoH,IAE1ED,GAAQC,C,CAEV,OAAOD,CACT,EAKaK,EAAgB,SAACC,EAAgB5B,GAC5C,OAAQ4B,EAAO9B,UACb,IAAK,MACH,OAAO,IAAIrC,EAAOmE,EAAO7B,KAAM6B,EAAOhD,KAAMoB,GAC9C,IAAK,aACH,OAAO,IAAIvC,EAAO,CAChBqC,SAAU,aACVlB,KAAMgD,EAAOhD,KACbmB,KAAM6B,EAAO7B,KACbC,KAAI,IAER,IAAK,UACH,OAAO,IAAIvC,EAAO,CAChBqC,SAAU,UACVH,QAASiC,EAAOjC,QAChBI,KAAM6B,EAAO7B,KACbC,KAAI,IAER,IAAK,aACH,OAAO,IAAIvC,EAAO,CAChBqC,SAAU,aACVI,UAAW0B,EAAO1B,UAClBH,KAAM6B,EAAO7B,KACbC,KAAI,IAER,QACE,MAAM,IAAI9F,MAAM,yCAAkC0H,EAAO9B,SAAQ,sBAEvE,E,k2CCjCA,aAyCE,WACI+B,EAEAC,EAA8EC,GAIhF,IAAIhC,EACAC,EAEJ,GALAe,IAKoB,iBAATc,GAAqB,aAAcA,EAO5C,OAHAG,KAAKC,aAAeJ,EAAK/B,SACzBC,EAAO8B,EAAK9B,KACZC,EAAO6B,EAAK7B,KACJ6B,EAAK/B,UACX,IAAK,aACH,IAAMoC,EAAgC7B,EAAsCzH,IAAImH,GAChF,IAAKmC,EACH,MAAM,IAAIpI,UAAU,4BAAqBiG,EAAI,0CAE/C,KAAM8B,EAAKjD,gBAAgBsD,GACzB,MAAM,IAAIpI,UAAU,mCAA4BoI,EAA8BzI,OAEhFuI,KAAKG,QAAUN,EAAKjD,KACpB,MAEF,IAAK,UACH,GAAa,YAATmB,EACF,MAAM,IAAIjG,UAAU,4BAAqBiG,EAAI,oCAE/CiC,KAAKI,eAAiBP,EAAKlC,QAC3BqC,KAAKK,WAAaR,EAAKjC,SACvBoC,KAAKM,SAAWT,EAAKhC,QACrB,MAEF,IAAK,aACH,GAAc,YAATE,GAA+B,YAATA,GAA+B,UAATA,GAA6B,UAATA,GAA6B,WAATA,GAC3E,SAATA,EACH,MAAM,IAAIjG,UAAU,4BAAqBiG,EAAI,uCAE/CiC,KAAKO,cAAgBV,EAAK3B,UAC1B8B,KAAKK,WAAaR,EAAKjC,SACvBoC,KAAKM,SAAWT,EAAKhC,QACrB,MAEF,QACE,MAAM,IAAI3F,MAAM,oDAA6C8H,KAAKC,aAAY,UAE7E,CAIL,IAAIrD,OAAI,EACJ4D,OAAS,EAEb,GAAoB,iBAATX,EAMT,GAFA9B,EAAO8B,EACPW,EAAYT,EACC,WAATF,EAAmB,CAErB,IAAKY,MAAMC,QAAQZ,GACjB,MAAM,IAAIhI,UAAU,kDAItB8E,EAAOkD,C,KACF,CAEL,IAAMa,EAAwBtC,EAAsCzH,IAAIiJ,GACxE,QAA8B7H,IAA1B2I,EACF,MAAM,IAAI7I,UAAU,mCAA4B+H,EAAI,MAEtD,GAAIY,MAAMC,QAAQZ,GAAO,CACvB,GAAa,YAATD,EAIF,MAAM,IAAI/H,UACN,iGAaJ8E,EAZkB,WAATiD,GAA8B,UAATA,EAYtBc,EAA8BzB,KAAKY,EAAMc,QAIzCD,EAA8BzB,KAAKY,E,KAExC,MAAIA,aAAgBa,GAGzB,MAAM,IAAI7I,UAAU,YAAKiG,EAAI,0CAAkC4C,IAF/D/D,EAAOkD,C,OAUX,GADAU,EAAYV,EACRW,MAAMC,QAAQb,GAAO,CAEvB,GAAoB,IAAhBA,EAAKvH,OACP,MAAM,IAAIR,UAAU,uDAEtB,IAAM+I,SAA0BhB,EAAK,GACrC,GAAyB,WAArBgB,EACF9C,EAAO,SACPnB,EAAOiD,MACF,IAAyB,YAArBgB,EAOT,MAAM,IAAI/I,UAAU,8CAAuC+I,EAAgB,MAN3E9C,EAAO,OAIPnB,EAAO0B,WAAWY,KAAKW,E,MAIpB,CAEL,IAAMiB,EACFjC,EAAsCjI,IAAIiJ,EAAKkB,aACnD,QAAmB/I,IAAf8I,EACF,MAAM,IAAIhJ,UAAU,4CAAqC+H,EAAKkB,YAAW,MAE3EhD,EAAO+C,EACPlE,EAAOiD,C,CAKX,QAAkB7H,IAAdwI,EAEFA,EAAY,CAAC5D,EAAKtE,aACb,IAAKmI,MAAMC,QAAQF,GACxB,MAAM,IAAI1I,UAAU,0CAEtBkG,EAAOwC,EAEPR,KAAKG,QAAUvD,EACfoD,KAAKC,aAAe,K,CAItB,IAAMX,EAAOD,EAAcrB,GAE3B,GAAIgC,KAAKG,SAAWb,IAASU,KAAKG,QAAQ7H,OACxC,MAAM,IAAIJ,MAAM,wBAAiBoH,EAAI,wCAAgCU,KAAKG,QAAQ7H,OAAM,OAG1F0H,KAAKjC,KAAOA,EACZiC,KAAKhC,KAAOA,EACZgC,KAAKV,KAAOA,CACd,CA4LF,OAxLe,EAAA0B,UAAb,SACIrF,EACA3B,G,mEAEF,MAAO,CAAP,EAAO0B,EAAgBC,EAAO3B,G,QAGzB,EAAAiH,YAAP,SACItD,EAA4B3D,GAC9B,OAAO0D,EAAkBC,EAAS3D,EACpC,EAEO,EAAAkH,cAAP,SACIhD,EAAgClE,GAClC,OAAOiE,EAAoBC,EAAWlE,EACxC,EAEO,EAAAmH,iBAAP,SACIpD,EAAShE,EAAwCiE,GACnD,OAAOI,EAAuBL,EAAMhE,EAAQiE,EAC9C,EAKA,YAAAoD,UAAA,SAAUpH,GACR,OC7P2B,SAAC4F,EAAgB5F,GAC9C,IAAMoC,EAASC,SAASC,cAAc,UACtCF,EAAOlC,MAAQ0F,EAAO5B,KAAK,GAC3B5B,EAAOnC,OAAS2F,EAAO5B,KAAK,GAC5B,IAAMzB,EAAkBH,EAAOI,WAAW,MAE1C,GAAuB,MAAnBD,EAAyB,CAE3B,IAAIrC,OAAK,EACLD,OAAM,OACoBjC,KAA1BgC,aAAO,EAAPA,EAASG,eAAuD,SAAzBH,EAAQG,cACjDD,EAAQ0F,EAAO5B,KAAK,GACpB/D,EAAS2F,EAAO5B,KAAK,KAErB9D,EAAQ0F,EAAO5B,KAAK,GACpB/D,EAAS2F,EAAO5B,KAAK,IAGvB,IAAMvD,OAAkCzC,KAApBgC,aAAO,EAAPA,EAASU,QAAuBV,EAAQU,OAAS,MAE/DJ,EAAON,aAAO,EAAPA,EAASM,KAClBF,OAAQ,EACRC,OAAQ,OACCrC,IAATsC,QAAoCtC,IAAdsC,EAAKC,KAC7BH,EAAW,CAAC,IAAK,IAAK,IAAK,KAEA,iBAAfE,EAAS,KACnBF,EAAW,CAACE,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,OAElDH,EAAW,CAACE,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAI,QACjCvC,IAAjBsC,EAAKC,KAAK,KACZH,EAAS,GAAKE,EAAKC,KAAK,UAIjBvC,IAATsC,QAAoCtC,IAAdsC,EAAKE,KAC7BH,EAAW,CAAC,EAAG,EAAG,EAAG,GAEM,iBAAfC,EAAS,KACnBD,EAAW,CAACC,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,OAElDH,EAAW,CAACC,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAI,QACjCxC,IAAjBsC,EAAKE,KAAK,KACZH,EAAS,GAAKC,EAAKE,KAAK,KAK9B,IAAMK,EAASZ,EAASC,EAEpBmB,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,SAAhBf,GACFY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,EACjBW,EAA0B,EAATX,GACQ,QAAhBJ,GACTY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,GACQ,QAAhBJ,IACTY,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GAGnB,IAAK,IAAI1C,EAAI,EAAGA,EAAI8B,EAAQ9B,IAC1B,IAAK,IAAIkJ,EAAI,EAAGA,EAAInH,EAAOmH,IAAK,CAC9B,IAAMC,GAAM1B,EAAOhD,KAAKvB,KAA+BhB,EAAS,IAAMD,EAAS,GACzEmH,GAAM3B,EAAOhD,KAAKtB,KAA+BjB,EAAS,IAAMD,EAAS,GACzEoH,GAAM5B,EAAOhD,KAAKrB,KAA+BlB,EAAS,IAAMD,EAAS,GACzEqH,GAAwB,IAApBjG,EACN,KACEoE,EAAOhD,KAAKpB,KAA+BnB,EAAS,IAAMD,EAAS,GAEzEmC,EAAgBmF,UAAY,QAAUJ,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxElF,EAAgBoF,SAASN,EAAGlJ,EAAG,EAAG,E,CAGtC,OAAOiE,EAAOgF,W,CAEd,MAAM,IAAIlJ,MAAM,4BAEpB,CDwKW0J,CAAgB5B,KAAMhG,EAC/B,EAEA,YAAA6H,YAAA,SAAY7H,GACV,OCvK6B,SAAC4F,EAAgB5F,GAChD,IACI2B,EADEY,EAAkBF,SAASC,cAAc,UAAUE,WAAW,MAEpE,GAAuB,MAAnBD,EAsFF,MAAM,IAAIrE,MAAM,6BApFhB,IAAIgC,OAAK,EACLD,OAAM,EACN6H,OAAQ,OACkB9J,KAA1BgC,aAAO,EAAPA,EAASG,eAAuD,SAAzBH,EAAQG,cACjDD,EAAQ0F,EAAO5B,KAAK,GACpB/D,EAAS2F,EAAO5B,KAAK,GACrB8D,EAAWlC,EAAO5B,KAAK,KAEvB9D,EAAQ0F,EAAO5B,KAAK,GACpB/D,EAAS2F,EAAO5B,KAAK,GACrB8D,EAAWlC,EAAO5B,KAAK,IAEzB,IAAMvD,OAA0BzC,IAAZgC,QAA4ChC,IAAnBgC,EAAQU,OAAuBV,EAAQU,OAAkB,MAEhGJ,EAAON,aAAO,EAAPA,EAASM,KAClBF,OAAQ,EACRC,OAAQ,OACCrC,IAATsC,QAAoCtC,IAAdsC,EAAKC,KAC7BH,EAAW,CAAC,IAAK,IAAK,IAAK,KAEA,iBAAfE,EAAS,KACnBF,EAAW,CAACE,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,OAElDH,EAAW,CAACE,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAI,UACjCvC,IAAjBsC,EAAKC,KAAK,KACZH,EAAS,GAAKE,EAAKC,KAAK,UAIjBvC,IAATsC,QAAoCtC,IAAdsC,EAAKE,KAC7BH,EAAW,CAAC,EAAG,EAAG,EAAG,GAEM,iBAAfC,EAAS,KACnBD,EAAW,CAACC,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,OAElDH,EAAW,CAACC,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAI,QACjCxC,IAAjBsC,EAAKE,KAAK,KACZH,EAAS,GAAKC,EAAKE,KAAK,KAK9B,IAAMK,EAASZ,EAASC,EACxB,QAAgBlC,IAAZgC,SACqBhC,IAAnBgC,EAAQU,QAAsC,IAAboH,GAAqC,SAAnB9H,EAAQU,QAC7C,IAAboH,GAAsC,QAAnB9H,EAAQU,QAAuC,QAAnBV,EAAQU,QAC1D,MAAM,IAAIxC,MAAM,iDAKpB,IACI+C,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEC,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,SAAhBf,GACFY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,EACjBW,EAA0B,EAATX,GACQ,QAAhBJ,GACTY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,GACQ,QAAhBJ,IACTY,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GAGnBc,EAAQY,EAAgBwF,gBAAgB7H,EAAOD,GAE/C,IAAK,IAAI9B,EAAI,EAAGA,EAAI8B,EAASC,EACxBe,GAvBQ,EAuBeC,GAvBf,EAuBsCC,GAvBtC,EAuB6DC,GAvB7D,EAuBoFjD,IAC/FwD,EAAMiB,KAAK3B,IAAmB2E,EAAOhD,KAAKvB,KAA+BhB,EAAS,IAAMD,EAAS,GACjGuB,EAAMiB,KAAK1B,IAAmB0E,EAAOhD,KAAKtB,KAA+BjB,EAAS,IAAMD,EAAS,GACjGuB,EAAMiB,KAAKzB,IAAmByE,EAAOhD,KAAKrB,KAA+BlB,EAAS,IAAMD,EAAS,GACjGuB,EAAMiB,KAAKxB,IAAqC,IAApBI,EACxB,KACEoE,EAAOhD,KAAKpB,KAA+BnB,EAAS,IAAMD,EAAS,GAM7E,OAAOuB,CACT,CD2EWqG,CAAkBhC,KAAMhG,EACjC,EAgDA,sBAAI,mBAAI,C,IAAR,WAEE,GADAgG,KAAKiC,eACAjC,KAAKG,QACR,MAAM,IAAIjI,MACN,kJAGN,OAAO8H,KAAKG,OACd,E,gCAEA,sBAAI,uBAAQ,C,IAAZ,WACE,OAAOH,KAAKC,YACd,E,gCAEA,sBAAI,sBAAO,C,IAAX,WAEE,GADAD,KAAKiC,eACAjC,KAAKI,eACR,MAAM,IAAIlI,MAAM,8CAElB,OAAO8H,KAAKI,cACd,E,gCAEA,sBAAI,wBAAS,C,IAAb,WAEE,GADAJ,KAAKiC,eACAjC,KAAKO,cACR,MAAM,IAAIrI,MAAM,8CAElB,OAAO8H,KAAKO,aACd,E,gCAKM,YAAA2B,QAAN,SAAcC,G,uGACZnC,KAAKiC,cACGjC,KAAKC,c,IACN,M,IACA,yB,IAEA,U,IACA,yB,mBAFH,MAAO,CAAP,EAAOD,KAAKpD,M,OAGZ,IAAKoD,KAAKK,WACR,MAAM,IAAInI,MAAM,uEAElB,GAAI8H,KAAKoC,cACP,MAAM,IAAIlK,MAAM,2C,iBAIH,O,sBADb8H,KAAKoC,eAAgB,EACR,GAAMpC,KAAKK,c,OAUxB,OAVMzD,EAAO,SACboD,KAAKK,gBAAarI,EAClBgI,KAAKC,aAAe,MACpBD,KAAKG,QAAUvD,EAEXuF,GAAenC,KAAKM,WACtBN,KAAKM,WACLN,KAAKM,cAAWtI,GAGX,CAAP,EAAO4E,G,cAGPoD,KAAKoC,eAAgB,E,WAIvB,MAAM,IAAIlK,MAAM,yCAAkC8H,KAAKC,e,QAI7D,YAAApC,QAAA,WACE,GAAImC,KAAKoC,cACP,MAAM,IAAIlK,MAAM,2CAGd8H,KAAKM,WACPN,KAAKM,WACLN,KAAKM,cAAWtI,GAElBgI,KAAKG,aAAUnI,EACfgI,KAAKI,oBAAiBpI,EACtBgI,KAAKO,mBAAgBvI,EACrBgI,KAAKK,gBAAarI,EAClBgI,KAAKoC,mBAAgBpK,EAErBgI,KAAKC,aAAe,MACtB,EAKQ,YAAAgC,YAAR,WACE,GAA0B,SAAtBjC,KAAKC,aACP,MAAM,IAAI/H,MAAM,0BAEpB,EAEA,YAAAmK,QAAA,SAAQrE,GAEN,GADAgC,KAAKiC,cACDjC,KAAKK,YAAcL,KAAKM,SAC1B,MAAM,IAAIpI,MAAM,mDAElB,OAAOyH,EAAcK,KAAMhC,EAC7B,EAEF,EA5YA,GEgTa,EAASvC,E,k2CC4HT,ECrbb,WACE,WAAoB6G,GAClBtC,KAAKsC,QAAUA,CACjB,CAsMF,OAnMQ,YAAAC,IAAN,SAAUC,EAAkB1C,EAA+BC,G,0IAIzD,GAHM0C,EAA4C,CAAC,EAC/CzI,EAAsB,CAAC,EAEN,iBAAVwI,GAAgC,OAAVA,GAAkBA,aAAiB,GAAU/B,MAAMC,QAAQ8B,GAC1F,MAAM,IAAI1K,UACN,iGAKN,GAFI4K,GAAiB,EAED,iBAAT5C,EAAmB,CAC5B,GAAa,OAATA,EACF,MAAM,IAAIhI,UAAU,2CAEtB,GAAIgI,aAAgB,EAClB,MAAM,IAAIhI,UAAU,gCAGtB,GAAI2I,MAAMC,QAAQZ,GAAO,CACvB,GAAoB,IAAhBA,EAAKxH,OACP,MAAM,IAAIR,UAAU,uCAItB,IAFA4K,GAAiB,EAEZ,EAAL,EAAmB,EAAA5C,EAAA,eAAM,CACvB,GAAoB,iBADjB,QAED,MAAM,IAAIhI,UAAU,kDAEtB,IAAwC,IAApCkI,KAAK2C,YAAYvK,QAAQ,GAC3B,MAAM,IAAIsH,WAAW,kDAA2C,EAAI,MAEtE+C,EAAQ,GAAQ,I,CAGlB,GAAoB,iBAAT1C,GAA8B,OAATA,EAC9B/F,EAAU+F,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIjI,UAAU,+B,KAEjB,CAKL,IAFI8K,GAAY,EACVC,EAAWpM,OAAOqM,oBAAoBhD,GACvC,EAAL,EAAmB,EAAAE,KAAK2C,YAAL,eAAd,QAC6B,IAA5BE,EAASzK,QAAQ,KAET,QADJ2K,EAAKjD,EAA4D,KACrDiD,aAAa,KAC7BH,GAAY,EACZF,GAAiB,EACjBD,EAAQ,GAAQM,GAKtB,GAAIH,GACF,GAAoB,iBAAT7C,GAA8B,OAATA,EAC9B/F,EAAU+F,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIjI,UAAU,qCAGtBkC,EAAU8F,C,OAGT,QAAoB,IAATA,EAChB,MAAM,IAAIhI,UAAU,2DAItB,IAAK,EAAL,EAAmB,EAAAkI,KAAKgD,WAAL,eACjB,GADG,YACwB,IAAhBR,EAAM,GACf,MAAM,IAAItK,MAAM,iBAAU,EAAI,6BAKlC,GAAIwK,EACF,IAAK,EAAL,EAAmB,EAAA1C,KAAK2C,YAAL,eAAd,OACHF,EAAQ,GAAQ,KAMJ,SAAMzC,KAAKsC,QAAQC,IAAIC,EAAOC,EAASzI,I,OAEvD,IAAWzD,KAFL0M,EAAU,SACVC,EAA2C,CAAC,EAChCD,EACZxM,OAAOO,eAAeC,KAAKgM,EAAS1M,KAChC4M,EAASF,EAAQ1M,GAErB2M,EAAY3M,GADV4M,aAAkB,EACDA,EAEA,IAAI,EAAOA,EAAOpF,KAAMoF,EAAOvG,KAAMuG,EAAOnF,OAIrE,MAAO,CAAP,EAAOkF,G,QAGH,YAAAE,QAAN,W,mEACE,MAAO,CAAP,EAAOpD,KAAKsC,QAAQzE,U,QAQT,EAAAwF,OAAb,SACIxD,EAAyCC,EAA8BC,EACvEuD,G,4GAKF,GAFItJ,EAA0B,CAAC,EAEX,iBAAT6F,GAET,GADA0D,EAAuB1D,EACH,iBAATC,GAA8B,OAATA,EAC9B9F,EAAU8F,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIhI,UAAU,qCAEjB,GAAI+H,aAAgBvB,YAEzB,GADAiF,EAAuB1D,EACH,iBAATC,GAA8B,OAATA,EAC9B9F,EAAU8F,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIhI,UAAU,oCAEjB,MACH+H,aAAgB2D,aACc,oBAAtBC,mBAAqC5D,aAAgB4D,mBAoC/D,MAAM,IAAI3L,UAAU,uDAhCpB,GAHMiC,EAAS8F,EACX6D,EAAa,EACbC,EAAa9D,EAAK8D,WACF,iBAAT7D,GAA8B,OAATA,EAC9B9F,EAAU8F,OACL,GAAoB,iBAATA,EAAmB,CAEnC,GADA4D,EAAa5D,GACRN,OAAOC,cAAciE,GACxB,MAAM,IAAIhE,WAAW,oCAEvB,GAAIgE,EAAa,GAAKA,GAAc3J,EAAO4J,WACzC,MAAM,IAAIjE,WAAW,2CAAoC3F,EAAO4J,WAAU,OAG5E,GADAA,EAAa9D,EAAK8D,WAAaD,EACX,iBAAT3D,EAAmB,CAE5B,GADA4D,EAAa5D,GACRP,OAAOC,cAAckE,GACxB,MAAM,IAAIjE,WAAW,oCAEvB,GAAIiE,GAAc,GAAKD,EAAaC,EAAa5J,EAAO4J,WACtD,MAAM,IAAIjE,WAAW,2CAAoC3F,EAAO4J,WAAaD,EAAU,OAEzF,GAAoB,iBAATJ,GAA8B,OAATA,EAC9BtJ,EAAUsJ,OACL,QAAoB,IAATA,EAChB,MAAM,IAAIxL,UAAU,+B,MAEjB,QAAoB,IAATiI,EAChB,MAAM,IAAIjI,UAAU,iC,MAEjB,QAAoB,IAATgI,EAChB,MAAM,IAAIhI,UAAU,gCAEtByL,EAAuB,IAAIjF,WAAWvE,EAAQ2J,EAAYC,E,CAQ5C,OAFVC,EAAM5J,EAAQ6J,oBAAsB,GACpCpL,EAAemL,EAAIzK,KAAI,SAAAhB,GAAK,MAAa,iBAANA,EAAiBA,EAAIA,EAAEV,IAA9B,IAClB,GAAMe,EAAeC,I,OACrB,SADA,SACcZ,8BAA8B0L,EAAsBvJ,I,OAClF,MAAO,CAAP,EAAO,IAAI8J,EADK,W,QAIlB,YAAAC,eAAA,WACE/D,KAAKsC,QAAQyB,gBACf,EACA,YAAAC,aAAA,WACEhE,KAAKsC,QAAQ0B,cACf,EAEA,sBAAI,yBAAU,C,IAAd,WACE,OAAOhE,KAAKsC,QAAQU,UACtB,E,gCACA,sBAAI,0BAAW,C,IAAf,WACE,OAAOhD,KAAKsC,QAAQK,WACtB,E,gCAGF,EAzMA,G,k2CCsHa,EC5Hb,WACE,WAAoBL,GAClBtC,KAAKsC,QAAUA,CACjB,CAoCF,OAjCE,sBAAI,yBAAU,C,IAAd,WACE,OAAOtC,KAAKsC,QAAQU,UACtB,E,gCACA,sBAAI,0BAAW,C,IAAf,WACE,OAAOhD,KAAKsC,QAAQK,WACtB,E,gCAEa,EAAAU,OAAb,SAAoBY,EAAgDC,G,mEAElE,MAAM,IAAIhM,MAAM,yB,QAGZ,YAAAiM,qBAAN,SAA2BC,EAAoBC,G,mEAC7C,MAAM,IAAInM,MAAM,0B,QAGZ,YAAAoM,wBAAN,SAA8BD,G,mEAC5B,MAAM,IAAInM,MAAM,0B,QAQZ,YAAAqM,aAAN,SAAmBC,EAAiBC,EAAoBC,G,mEAEtD,MAAM,IAAIxM,MAAM,0B,QAGZ,YAAAkL,QAAN,W,mEACE,MAAO,CAAP,EAAOpD,KAAKsC,QAAQzE,U,QAExB,EAvCA,G","sources":["webpack://ort/webpack/universalModuleDefinition","webpack://ort/webpack/bootstrap","webpack://ort/webpack/runtime/define property getters","webpack://ort/webpack/runtime/hasOwnProperty shorthand","webpack://ort/webpack/runtime/make namespace object","webpack://ort/./lib/backend-impl.ts","webpack://ort/./lib/env-impl.ts","webpack://ort/./lib/version.ts","webpack://ort/./lib/env.ts","webpack://ort/./lib/tensor-factory-impl.ts","webpack://ort/./lib/tensor-impl-type-mapping.ts","webpack://ort/./lib/tensor-utils-impl.ts","webpack://ort/./lib/tensor-impl.ts","webpack://ort/./lib/tensor-conversion-impl.ts","webpack://ort/./lib/tensor.ts","webpack://ort/./lib/inference-session.ts","webpack://ort/./lib/inference-session-impl.ts","webpack://ort/./lib/training-session.ts","webpack://ort/./lib/training-session-impl.ts"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"ort\"] = factory();\n\telse\n\t\troot[\"ort\"] = factory();\n})(self, function() {\nreturn ","// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(_trainingOptions: TrainingSessionCreateOptions, _sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    throw new Error('Method not implemented');\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  runTrainStep(feeds: InferenceSession.OnnxValueMapType, options?: InferenceSession.RunOptions|undefined):\n      Promise<InferenceSession.OnnxValueMapType>;\n  runTrainStep(\n      feeds: InferenceSession.OnnxValueMapType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions|undefined): Promise<InferenceSession.OnnxValueMapType>;\n  async runTrainStep(_feeds: unknown, _fetches?: unknown, _options?: unknown):\n      Promise<InferenceSession.OnnxValueMapType> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n"],"names":["root","factory","exports","module","define","amd","self","__webpack_require__","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","backends","Map","backendsSortedByPriority","registerBackend","name","backend","priority","init","createInferenceSessionHandler","TypeError","currentBackend","undefined","set","Error","i","indexOf","splice","length","push","resolveBackend","backendHints","backendNames","errors","backendName","backendInfo","initialized","aborted","isInitializing","initPromise","err","map","e","join","logLevelValue","env","wasm","webgl","webgpu","versions","common","logLevel","bufferToTensor","buffer","options","height","width","tensorLayout","normMean","normBias","norm","mean","bias","inputformat","format","outputformat","tensorFormat","stride","float32Data","Float32Array","step","rImagePointer","gImagePointer","bImagePointer","aImagePointer","rTensorPointer","gTensorPointer","bTensorPointer","aTensorPointer","Tensor","tensorFromImage","image","isHTMLImageEle","HTMLImageElement","isImageDataEle","ImageData","isImageBitmap","ImageBitmap","isString","bufferToTensorOptions","canvas","document","createElement","pixels2DContext","getContext","resizedHeight","resizedWidth","drawImage","data","getImageData","Promise","resolve","reject","context","newImage","Image","crossOrigin","src","onload","img","tempCanvas","putImageData","tensorFromTexture","texture","download","dispose","location","type","dims","tensorFromGpuBuffer","gpuBuffer","dataType","tensorFromPinnedBuffer","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","Uint8Array","Int8Array","Uint16Array","Int16Array","Int32Array","Float64Array","Uint32Array","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","isBigIntChecked","checkBigInt","isBigInt64ArrayAvailable","BigInt64Array","from","isBigUint64ArrayAvailable","BigUint64Array","calculateSize","size","dim","Number","isSafeInteger","RangeError","tensorReshape","tensor","arg0","arg1","arg2","this","dataLocation","expectedTypedArrayConstructor","cpuData","gpuTextureData","downloader","disposer","gpuBufferData","maybeDims","Array","isArray","typedArrayConstructor","BigInt","firstElementType","mappedType","constructor","fromImage","fromTexture","fromGpuBuffer","fromPinnedBuffer","toDataURL","j","R","G","B","A","fillStyle","fillRect","tensorToDataURL","toImageData","channels","createImageData","tensorToImageData","ensureValid","getData","releaseData","isDownloading","reshape","handler","run","feeds","fetches","isFetchesEmpty","outputNames","isFetches","arg1Keys","getOwnPropertyNames","v","inputNames","results","returnValue","result","release","create","arg3","filePathOrUint8Array","ArrayBuffer","SharedArrayBuffer","byteOffset","byteLength","eps","executionProviders","InferenceSession","startProfiling","endProfiling","_trainingOptions","_sessionOptions","loadParametersBuffer","_array","_trainableOnly","getContiguousParameters","runTrainStep","_feeds","_fetches","_options"],"sourceRoot":""}