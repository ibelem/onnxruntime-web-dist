{"version":3,"file":"ort-common.min.js","mappings":";;;;;CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAa,IAAID,IAEjBD,EAAU,IAAIC,GACf,CATD,CASGK,MAAM,I,mBCRT,IAAIC,EAAsB,CCA1BA,EAAwB,CAACL,EAASM,KACjC,IAAI,IAAIC,KAAOD,EACXD,EAAoBG,EAAEF,EAAYC,KAASF,EAAoBG,EAAER,EAASO,IAC5EE,OAAOC,eAAeV,EAASO,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAE1E,ECNDF,EAAwB,CAACQ,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,GCClFT,EAAyBL,IACH,oBAAXkB,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeV,EAASkB,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeV,EAAS,aAAc,CAAEoB,OAAO,GAAO,G,+GCS9D,MAAMC,EAAqC,IAAIC,IACzCC,EAAqC,GAY9BC,EAAkB,CAACC,EAAcC,EAAkBC,KAC9D,IAAID,GAAmC,mBAAjBA,EAAQE,MAAwE,mBAA1CF,EAAQG,8BA8BpE,MAAM,IAAIC,UAAU,uBA9BpB,CACE,MAAMC,EAAiBV,EAAST,IAAIa,GACpC,QAAuBO,IAAnBD,EACFV,EAASY,IAAIR,EAAM,CAACC,UAASC,iBACxB,IAAII,EAAeJ,SAAWA,EAEnC,OACK,GAAII,EAAeJ,WAAaA,GACjCI,EAAeL,UAAYA,EAC7B,MAAM,IAAIQ,MAAM,4BAA4BT,qBAAwBE,I,CAIxE,GAAIA,GAAY,EAAG,CACjB,MAAMQ,EAAIZ,EAAyBa,QAAQX,IAChC,IAAPU,GACFZ,EAAyBc,OAAOF,EAAG,GAGrC,IAAK,IAAIA,EAAI,EAAGA,EAAIZ,EAAyBe,OAAQH,IACnD,GAAId,EAAST,IAAIW,EAAyBY,IAAKR,UAAYA,EAEzD,YADAJ,EAAyBc,OAAOF,EAAG,EAAGV,GAI1CF,EAAyBgB,KAAKd,E,EAKQ,EClD5C,IAAIe,EAAwC,UAErC,MAAMC,EAAW,CACtBC,KAAM,CAAC,EACPC,MAAO,CAAC,EACRC,OAAQ,CAAC,EACTC,SAAU,CAACC,OCRU,UDUjBC,aAAS3B,GACX,QAAcY,IAAVZ,EAAJ,CAGA,GAAqB,iBAAVA,IAA2F,IAArE,CAAC,UAAW,OAAQ,UAAW,QAAS,SAASgB,QAAQhB,GACxF,MAAM,IAAIc,MAAM,8BAA8Bd,KAEhDoB,EAAgBpB,C,CAClB,EACI2B,eACF,OAAOP,CACT,GAIF/B,OAAOC,eAAe+B,EAAK,WAAY,CAAC9B,YAAY,IEoI7C,MAAM,EAAW8B,EClJXO,EAAiB,CAACC,EAAqCC,K,UAClE,QAAelB,IAAXiB,EACF,MAAM,IAAIf,MAAM,gCAElB,QAAuBF,IAAnBkB,EAAQC,aAA0CnB,IAAlBkB,EAAQE,MAC1C,MAAM,IAAIlB,MAAM,0CAElB,GAA6B,SAAzBgB,EAAQG,aACV,MAAM,IAAInB,MAAM,2CAGlB,MAAM,OAACiB,EAAM,MAAEC,GAASF,EAElBI,EAAmB,QAAZ,EAAAJ,EAAQI,YAAI,QAAI,CAACC,KAAM,IAAKC,KAAM,GAC/C,IAAIC,EACAC,EAGFD,EADyB,iBAAfH,EAAS,KACR,CAACA,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,MAEvC,CAACD,EAAKC,KAAM,GAAID,EAAKC,KAAM,GAAID,EAAKC,KAAM,GAAiB,QAAb,EAAAD,EAAKC,KAAM,UAAE,QAAI,KAI1EG,EADyB,iBAAfJ,EAAS,KACR,CAACA,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,MAEvC,CAACF,EAAKE,KAAM,GAAIF,EAAKE,KAAM,GAAIF,EAAKE,KAAM,GAAiB,QAAb,EAAAF,EAAKE,KAAM,UAAE,QAAI,GAG5E,MAAMG,OAAiC3B,IAAnBkB,EAAQU,OAAuBV,EAAQU,OAAS,OAG9DC,OACuB7B,IAAzBkB,EAAQY,mBAAuD9B,IAAzBkB,EAAQY,aAA6BZ,EAAQY,aAAwB,MACzGC,EAASZ,EAASC,EAClBY,EAA+B,SAAjBH,EAA0B,IAAII,aAAsB,EAATF,GAAc,IAAIE,aAAsB,EAATF,GAG9F,IAAIG,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,QAAhBf,IACFO,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,GAAiB,GAIE,SAAjBT,EACFa,EAA0B,EAATX,EACS,QAAjBF,GACTU,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GACS,QAAjBF,IACTY,EAAiB,EACjBD,EAAiBT,EACjBQ,EAA0B,EAATR,GAGnB,IAAK,IAAI5B,EAAI,EAAGA,EAAI4B,EACf5B,IAAKgC,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FF,EAAYO,MAAqBtB,EAAOkB,GAAiBT,EAAS,IAAMD,EAAS,GACjFO,EAAYQ,MAAqBvB,EAAOmB,GAAiBV,EAAS,IAAMD,EAAS,GACjFO,EAAYS,MAAqBxB,EAAOoB,GAAiBX,EAAS,IAAMD,EAAS,IACzD,IAApBiB,IAA4C,IAAnBJ,IAC3BN,EAAYU,MAAqBzB,EAAOqB,GAAiBZ,EAAS,IAAMD,EAAS,IAOrF,OAF+C,IAAIkB,EAAO,UAAWX,EAA/B,SAAjBH,EAA6D,CAAC,EAAG,EAAGV,EAAQC,GACf,CAAC,EAAG,EAAGD,EAAQC,GAC9E,EClFRwB,EAAwC,IAAItD,IAA6C,CACpG,CAAC,UAAW2C,cACZ,CAAC,QAASY,YACV,CAAC,OAAQC,WACT,CAAC,SAAUC,aACX,CAAC,UAAWA,aACZ,CAAC,QAASC,YACV,CAAC,QAASC,YACV,CAAC,OAAQJ,YACT,CAAC,UAAWK,cACZ,CAAC,SAAUC,eAIAC,EAAwC,IAAI9D,IAAkD,CACzG,CAAC2C,aAAc,WACf,CAACY,WAAY,SACb,CAACC,UAAW,QACZ,CAACC,YAAa,UACd,CAACC,WAAY,SACb,CAACC,WAAY,SACb,CAACC,aAAc,WACf,CAACC,YAAa,YAMhB,IAAIE,GAAkB,ECff,MAAMV,EAyCXW,YACIC,EAEAC,EAA8EC,GAIhF,IAAIC,EACAC,EAEJ,GDnCuB,MACzB,IAAKN,EAAiB,CACpBA,GAAkB,EAClB,MAAMO,EAAoD,oBAAlBC,eAA+D,mBAAvBA,cAAcC,KACxFC,EACwB,oBAAnBC,gBAAiE,mBAAxBA,eAAeF,KAE/DF,IACFhB,EAAsC3C,IAAI,QAAS4D,eACnDT,EAAsCnD,IAAI4D,cAAe,UAEvDE,IACFnB,EAAsC3C,IAAI,SAAU+D,gBACpDZ,EAAsCnD,IAAI+D,eAAgB,U,GCiB5DC,GAKoB,iBAATV,GAAqB,aAAcA,EAO5C,OAHAW,KAAKC,aAAeZ,EAAKa,SACzBV,EAAOH,EAAKG,KACZC,EAAOJ,EAAKI,KACJJ,EAAKa,UACX,IAAK,aAAc,CACjB,MAAMC,EAAgCzB,EAAsChE,IAAI8E,GAChF,IAAKW,EACH,MAAM,IAAIvE,UAAU,qBAAqB4D,0CAE3C,KAAMH,EAAKe,gBAAgBD,GACzB,MAAM,IAAIvE,UAAU,4BAA4BuE,EAA8B5E,QAEhFyE,KAAKK,QAAUhB,EAAKe,KACpB,K,CAEF,IAAK,UACH,GAAa,YAATZ,EACF,MAAM,IAAI5D,UAAU,qBAAqB4D,oCAE3CQ,KAAKM,eAAiBjB,EAAKkB,QAC3BP,KAAKQ,WAAanB,EAAKoB,SACvBT,KAAKU,SAAWrB,EAAKsB,QACrB,MAEF,IAAK,aACH,GAAc,YAATnB,GAA+B,YAATA,GAA+B,UAATA,GAA6B,UAATA,GAA6B,WAATA,GAC3E,SAATA,EACH,MAAM,IAAI5D,UAAU,qBAAqB4D,uCAE3CQ,KAAKY,cAAgBvB,EAAKwB,UAC1Bb,KAAKQ,WAAanB,EAAKoB,SACvBT,KAAKU,SAAWrB,EAAKsB,QACrB,MAEF,QACE,MAAM,IAAI3E,MAAM,6CAA6CgE,KAAKC,qBAEjE,CAIL,IAAIG,EACAU,EAEJ,GAAoB,iBAATzB,EAMT,GAFAG,EAAOH,EACPyB,EAAYvB,EACC,WAATF,EAAmB,CAErB,IAAK0B,MAAMC,QAAQ1B,GACjB,MAAM,IAAI1D,UAAU,kDAItBwE,EAAOd,C,KACF,CAEL,MAAM2B,EAAwBvC,EAAsChE,IAAI2E,GACxE,QAA8BvD,IAA1BmF,EACF,MAAM,IAAIrF,UAAU,4BAA4ByD,MAElD,GAAI0B,MAAMC,QAAQ1B,GAAO,CACvB,GAAa,YAATD,EAIF,MAAM,IAAIzD,UACN,iGAaJwE,EAZkB,WAATf,GAA8B,UAATA,EAYtB4B,EAA8BrB,KAAKN,EAAM4B,QAIzCD,EAA8BrB,KAAKN,E,KAExC,MAAIA,aAAgB2B,GAGzB,MAAM,IAAIrF,UAAU,KAAK4D,mCAAsCyB,KAF/Db,EAAOd,C,OAUX,GADAwB,EAAYxB,EACRyB,MAAMC,QAAQ3B,GAAO,CAEvB,GAAoB,IAAhBA,EAAKjD,OACP,MAAM,IAAIR,UAAU,uDAEtB,MAAMuF,SAA0B9B,EAAK,GACrC,GAAyB,WAArB8B,EACF3B,EAAO,SACPY,EAAOf,MACF,IAAyB,YAArB8B,EAOT,MAAM,IAAIvF,UAAU,uCAAuCuF,MAN3D3B,EAAO,OAIPY,EAAOzB,WAAWiB,KAAKP,E,MAIpB,CAEL,MAAM+B,EACFlC,EAAsCxE,IAAI2E,EAAKD,aACnD,QAAmBtD,IAAfsF,EACF,MAAM,IAAIxF,UAAU,qCAAqCyD,EAAKD,gBAEhEI,EAAO4B,EACPhB,EAAOf,C,CAKX,QAAkBvD,IAAdgF,EAEFA,EAAY,CAACV,EAAKhE,aACb,IAAK2E,MAAMC,QAAQF,GACxB,MAAM,IAAIlF,UAAU,0CAEtB6D,EAAOqB,EAEPd,KAAKK,QAAUD,EACfJ,KAAKC,aAAe,K,CAItB,MAAMoB,ECpNmB,CAAC5B,IAC5B,IAAI4B,EAAO,EACX,IAAK,IAAIpF,EAAI,EAAGA,EAAIwD,EAAKrD,OAAQH,IAAK,CACpC,MAAMqF,EAAM7B,EAAKxD,GACjB,GAAmB,iBAARqF,IAAqBC,OAAOC,cAAcF,GACnD,MAAM,IAAI1F,UAAU,QAAQK,+BAA+BqF,KAE7D,GAAIA,EAAM,EACR,MAAM,IAAIG,WAAW,QAAQxF,2CAA2CqF,KAE1ED,GAAQC,C,CAEV,OAAOD,CAAI,EDwMIK,CAAcjC,GAE3B,GAAIO,KAAKK,SAAWgB,IAASrB,KAAKK,QAAQjE,OACxC,MAAM,IAAIJ,MAAM,iBAAiBqF,iCAAoCrB,KAAKK,QAAQjE,YAGpF4D,KAAKR,KAAOA,EACZQ,KAAKP,KAAOA,EACZO,KAAKqB,KAAOA,CACd,CAIAM,uBACIC,EACA5E,GAEF,MF7I2B6E,OAC3BD,EACA5E,KAGF,MAAM8E,EAA+C,oBAAvB,kBAAsCF,aAAiBG,iBAC/EC,EAAwC,oBAAhB,WAA+BJ,aAAiBK,UACxEC,EAAyC,oBAAlB,aAAiCN,aAAiBO,YACzEC,EAA4B,iBAAVR,EAExB,IAAIxB,EACAiC,EAA+CrF,QAAAA,EAAW,CAAC,EAG/D,GAAI8E,EAAgB,CAElB,MAAMQ,EAASC,SAASC,cAAc,UACtCF,EAAOpF,MAAQ0E,EAAM1E,MACrBoF,EAAOrF,OAAS2E,EAAM3E,OACtB,MAAMwF,EAAkBH,EAAOI,WAAW,MAE1C,GAAuB,MAAnBD,EA0BF,MAAM,IAAIzG,MAAM,6BA1BW,CAC3B,IAAIiB,EAAS2E,EAAM3E,OACfC,EAAQ0E,EAAM1E,MAMlB,QALgBpB,IAAZkB,QAAmDlB,IAA1BkB,EAAQ2F,oBAAwD7G,IAAzBkB,EAAQ4F,eAC1E3F,EAASD,EAAQ2F,cACjBzF,EAAQF,EAAQ4F,mBAGF9G,IAAZkB,EAAuB,CAEzB,GADAqF,EAAwBrF,OACKlB,IAAzBkB,EAAQY,aACV,MAAM,IAAI5B,MAAM,+DAEhBqG,EAAsBzE,aAAe,OAEvCyE,EAAsBpF,OAASA,EAC/BoF,EAAsBnF,MAAQA,C,MAE9BmF,EAAsBzE,aAAe,OACrCyE,EAAsBpF,OAASA,EAC/BoF,EAAsBnF,MAAQA,EAGhCuF,EAAgBI,UAAUjB,EAAO,EAAG,GACpCxB,EAAOqC,EAAgBK,aAAa,EAAG,EAAG5F,EAAOD,GAAQmD,I,MAItD,KAAI4B,EAoCJ,IAAIE,EAAe,CAExB,QAAgBpG,IAAZkB,EACF,MAAM,IAAIhB,MAAM,2DAGlB,MAAMsG,EAASC,SAASC,cAAc,UACtCF,EAAOpF,MAAQ0E,EAAM1E,MACrBoF,EAAOrF,OAAS2E,EAAM3E,OACtB,MAAMwF,EAAkBH,EAAOI,WAAW,MAE1C,GAAuB,MAAnBD,EAAyB,CAC3B,MAAMxF,EAAS2E,EAAM3E,OACfC,EAAQ0E,EAAM1E,MAKpB,OAJAuF,EAAgBI,UAAUjB,EAAO,EAAG,EAAG1E,EAAOD,GAC9CmD,EAAOqC,EAAgBK,aAAa,EAAG,EAAG5F,EAAOD,GAAQmD,KACzDiC,EAAsBpF,OAASA,EAC/BoF,EAAsBnF,MAAQA,EACvBJ,EAAesD,EAAMiC,E,CAE5B,MAAM,IAAIrG,MAAM,4B,CAEb,GAAIoG,EACT,OAAO,IAAIW,SAAQ,CAACC,EAASC,KAC3B,MAAMX,EAASC,SAASC,cAAc,UAChCU,EAAUZ,EAAOI,WAAW,MAClC,IAAKd,IAAUsB,EACb,OAAOD,IAET,MAAME,EAAW,IAAIC,MACrBD,EAASE,YAAc,YACvBF,EAASG,IAAM1B,EACfuB,EAASI,OAAS,KAChBjB,EAAOpF,MAAQiG,EAASjG,MACxBoF,EAAOrF,OAASkG,EAASlG,OACzBiG,EAAQL,UAAUM,EAAU,EAAG,EAAGb,EAAOpF,MAAOoF,EAAOrF,QACvD,MAAMuG,EAAMN,EAAQJ,aAAa,EAAG,EAAGR,EAAOpF,MAAOoF,EAAOrF,QAE5DoF,EAAsBpF,OAASqF,EAAOrF,OACtCoF,EAAsBnF,MAAQoF,EAAOpF,MACrC8F,EAAQlG,EAAe0G,EAAIpD,KAAMiC,GAAuB,CACzD,IAGH,MAAM,IAAIrG,MAAM,iE,CAhFS,CACzB,IAAIiB,EACAC,EAiBJ,QAfgBpB,IAAZkB,QAAkDlB,IAAzBkB,EAAQ4F,mBAAwD9G,IAA1BkB,EAAQ2F,eACzE1F,EAASD,EAAQ2F,cACjBzF,EAAQF,EAAQ4F,eAEhB3F,EAAS2E,EAAM3E,OACfC,EAAQ0E,EAAM1E,YAGApB,IAAZkB,IACFqF,EAAwBrF,GAE1BqF,EAAsB3E,OAAS,OAC/B2E,EAAsBpF,OAASA,EAC/BoF,EAAsBnF,MAAQA,OAEdpB,IAAZkB,EAAuB,CACzB,MAAMyG,EAAalB,SAASC,cAAc,UAE1CiB,EAAWvG,MAAQA,EACnBuG,EAAWxG,OAASA,EAEpB,MAAMwF,EAAkBgB,EAAWf,WAAW,MAE9C,GAAuB,MAAnBD,EAIF,MAAM,IAAIzG,MAAM,6BAHhByG,EAAgBiB,aAAa9B,EAAO,EAAG,GACvCxB,EAAOqC,EAAgBK,aAAa,EAAG,EAAG5F,EAAOD,GAAQmD,I,MAK3DA,EAAOwB,EAAMxB,I,EAiDjB,QAAatE,IAATsE,EACF,OAAOtD,EAAesD,EAAMiC,GAE5B,MAAM,IAAIrG,MAAM,iE,EEMT2H,CAAgB/B,EAAO5E,EAChC,CAEA2E,mBACIpB,EAA4BvD,GAC9B,MFJ6B,EAC7BuD,EAAsCvD,KACxC,MAAM,MAACE,EAAK,OAAED,EAAM,SAAEwD,EAAQ,QAAEE,GAAW3D,EAG3C,OAAO,IAAIyB,EAAO,CAACyB,SAAU,UAAWV,KAAM,UAAWe,UAASd,KADrD,CAAC,EAAGxC,EAAQC,EAAO,GACwCuD,WAAUE,WAAS,EEDlFiD,CAAkBrD,EAASvD,EACpC,CAEA2E,qBACId,EAAgC7D,GAClC,MFE+B,EAC/B6D,EAA0C7D,KAC5C,MAAM,SAAC6G,EAAQ,KAAEpE,EAAI,SAAEgB,EAAQ,QAAEE,GAAW3D,EAC5C,OAAO,IAAIyB,EAAO,CAACyB,SAAU,aAAcV,KAAMqE,QAAAA,EAAY,UAAWhD,YAAWpB,OAAMgB,WAAUE,WAAS,EELnGmD,CAAoBjD,EAAW7D,EACxC,CAEA2E,wBACInC,EAASzC,EAAwC0C,GACnD,MFMkC,EAClCD,EAASzC,EAAwC0C,IACjD,IAAIhB,EAAO,CAACyB,SAAU,aAAcV,OAAMY,KAAMrD,EAAQ0C,KAAMA,QAAAA,EAAQ,CAAC1C,EAAOX,UERvE2H,CAAuBvE,EAAMzC,EAAQ0C,EAC9C,CAKAuE,UAAUhH,GACR,ME7P2B,EAACiH,EAAgBjH,KAC9C,MAAMsF,EAASC,SAASC,cAAc,UACtCF,EAAOpF,MAAQ+G,EAAOxE,KAAK,GAC3B6C,EAAOrF,OAASgH,EAAOxE,KAAK,GAC5B,MAAMgD,EAAkBH,EAAOI,WAAW,MAE1C,GAAuB,MAAnBD,EAAyB,CAE3B,IAAIvF,EACAD,OAC0BnB,KAA1BkB,aAAO,EAAPA,EAASG,eAAuD,SAAzBH,EAAQG,cACjDD,EAAQ+G,EAAOxE,KAAK,GACpBxC,EAASgH,EAAOxE,KAAK,KAErBvC,EAAQ+G,EAAOxE,KAAK,GACpBxC,EAASgH,EAAOxE,KAAK,IAGvB,MAAMhC,OAAkC3B,KAApBkB,aAAO,EAAPA,EAASU,QAAuBV,EAAQU,OAAS,MAE/DN,EAAOJ,aAAO,EAAPA,EAASI,KACtB,IAAIG,EACAC,OACS1B,IAATsB,QAAoCtB,IAAdsB,EAAKC,KAC7BE,EAAW,CAAC,IAAK,IAAK,IAAK,KAEA,iBAAfH,EAAS,KACnBG,EAAW,CAACH,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,OAElDE,EAAW,CAACH,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAI,QACjCvB,IAAjBsB,EAAKC,KAAK,KACZE,EAAS,GAAKH,EAAKC,KAAK,UAIjBvB,IAATsB,QAAoCtB,IAAdsB,EAAKE,KAC7BE,EAAW,CAAC,EAAG,EAAG,EAAG,GAEM,iBAAfJ,EAAS,KACnBI,EAAW,CAACJ,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,OAElDE,EAAW,CAACJ,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAI,QACjCxB,IAAjBsB,EAAKE,KAAK,KACZE,EAAS,GAAKJ,EAAKE,KAAK,KAK9B,MAAMO,EAASZ,EAASC,EAExB,IAAImB,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,SAAhBf,GACFY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,EACjBW,EAA0B,EAATX,GACQ,QAAhBJ,GACTY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,GACQ,QAAhBJ,IACTY,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GAGnB,IAAK,IAAI5B,EAAI,EAAGA,EAAIgB,EAAQhB,IAC1B,IAAK,IAAIiI,EAAI,EAAGA,EAAIhH,EAAOgH,IAAK,CAC9B,MAAMC,GAAMF,EAAO7D,KAAK/B,KAA+Bb,EAAS,IAAMD,EAAS,GACzE6G,GAAMH,EAAO7D,KAAK9B,KAA+Bd,EAAS,IAAMD,EAAS,GACzE8G,GAAMJ,EAAO7D,KAAK7B,KAA+Bf,EAAS,IAAMD,EAAS,GACzE+G,GAAwB,IAApB9F,EACN,KACEyF,EAAO7D,KAAK5B,KAA+BhB,EAAS,IAAMD,EAAS,GAEzEkF,EAAgB8B,UAAY,QAAUJ,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxE7B,EAAgB+B,SAASN,EAAGjI,EAAG,EAAG,E,CAGtC,OAAOqG,EAAO0B,W,CAEd,MAAM,IAAIhI,MAAM,4B,EF0KTyI,CAAgBzE,KAAMhD,EAC/B,CAEA0H,YAAY1H,GACV,MEvK6B,EAACiH,EAAgBjH,KAChD,MAAMyF,EAAkBF,SAASC,cAAc,UAAUE,WAAW,MACpE,IAAId,EACJ,GAAuB,MAAnBa,EAsFF,MAAM,IAAIzG,MAAM,6BAtFW,CAE3B,IAAIkB,EACAD,EACA0H,OAC0B7I,KAA1BkB,aAAO,EAAPA,EAASG,eAAuD,SAAzBH,EAAQG,cACjDD,EAAQ+G,EAAOxE,KAAK,GACpBxC,EAASgH,EAAOxE,KAAK,GACrBkF,EAAWV,EAAOxE,KAAK,KAEvBvC,EAAQ+G,EAAOxE,KAAK,GACpBxC,EAASgH,EAAOxE,KAAK,GACrBkF,EAAWV,EAAOxE,KAAK,IAEzB,MAAMhC,OAA0B3B,IAAZkB,QAA4ClB,IAAnBkB,EAAQU,OAAuBV,EAAQU,OAAkB,MAEhGN,EAAOJ,aAAO,EAAPA,EAASI,KACtB,IAAIG,EACAC,OACS1B,IAATsB,QAAoCtB,IAAdsB,EAAKC,KAC7BE,EAAW,CAAC,IAAK,IAAK,IAAK,KAEA,iBAAfH,EAAS,KACnBG,EAAW,CAACH,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,KAAMD,EAAKC,OAElDE,EAAW,CAACH,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAID,EAAKC,KAAK,GAAI,UACjCvB,IAAjBsB,EAAKC,KAAK,KACZE,EAAS,GAAKH,EAAKC,KAAK,UAIjBvB,IAATsB,QAAoCtB,IAAdsB,EAAKE,KAC7BE,EAAW,CAAC,EAAG,EAAG,EAAG,GAEM,iBAAfJ,EAAS,KACnBI,EAAW,CAACJ,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,KAAMF,EAAKE,OAElDE,EAAW,CAACJ,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAIF,EAAKE,KAAK,GAAI,QACjCxB,IAAjBsB,EAAKE,KAAK,KACZE,EAAS,GAAKJ,EAAKE,KAAK,KAK9B,MAAMO,EAASZ,EAASC,EACxB,QAAgBpB,IAAZkB,SACqBlB,IAAnBkB,EAAQU,QAAsC,IAAbiH,GAAqC,SAAnB3H,EAAQU,QAC7C,IAAbiH,GAAsC,QAAnB3H,EAAQU,QAAuC,QAAnBV,EAAQU,QAC1D,MAAM,IAAI1B,MAAM,iDAKpB,MAAMgC,EAAO,EACb,IAAIC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEC,EAAiB,EAAGC,EAAiBT,EAAQU,EAA0B,EAATV,EAAYW,GAAkB,EAG5E,SAAhBf,GACFY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,EACjBW,EAA0B,EAATX,GACQ,QAAhBJ,GACTY,EAAiB,EACjBC,EAAiBT,EACjBU,EAA0B,EAATV,GACQ,QAAhBJ,IACTY,EAAiB,EACjBE,EAAiBV,EACjBS,EAA0B,EAATT,GAGnB+D,EAAQa,EAAgBmC,gBAAgB1H,EAAOD,GAE/C,IAAK,IAAIhB,EAAI,EAAGA,EAAIgB,EAASC,EACxBe,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAM/B,IAC/F2F,EAAMxB,KAAKnC,IAAmBgG,EAAO7D,KAAK/B,KAA+Bb,EAAS,IAAMD,EAAS,GACjGqE,EAAMxB,KAAKlC,IAAmB+F,EAAO7D,KAAK9B,KAA+Bd,EAAS,IAAMD,EAAS,GACjGqE,EAAMxB,KAAKjC,IAAmB8F,EAAO7D,KAAK7B,KAA+Bf,EAAS,IAAMD,EAAS,GACjGqE,EAAMxB,KAAKhC,IAAqC,IAApBI,EACxB,KACEyF,EAAO7D,KAAK5B,KAA+BhB,EAAS,IAAMD,EAAS,E,CAM7E,OAAOqE,CAAK,EF4EHiD,CAAkB7E,KAAMhD,EACjC,CAgDIoD,WAEF,GADAJ,KAAK8E,eACA9E,KAAKK,QACR,MAAM,IAAIrE,MACN,kJAGN,OAAOgE,KAAKK,OACd,CAEIH,eACF,OAAOF,KAAKC,YACd,CAEIM,cAEF,GADAP,KAAK8E,eACA9E,KAAKM,eACR,MAAM,IAAItE,MAAM,8CAElB,OAAOgE,KAAKM,cACd,CAEIO,gBAEF,GADAb,KAAK8E,eACA9E,KAAKY,cACR,MAAM,IAAI5E,MAAM,8CAElB,OAAOgE,KAAKY,aACd,CAKAiB,cAAckD,GAEZ,OADA/E,KAAK8E,cACG9E,KAAKC,cACX,IAAK,MACL,IAAK,aACH,OAAOD,KAAKI,KACd,IAAK,UACL,IAAK,aACH,IAAKJ,KAAKQ,WACR,MAAM,IAAIxE,MAAM,uEAElB,GAAIgE,KAAKgF,cACP,MAAM,IAAIhJ,MAAM,2CAElB,IACEgE,KAAKgF,eAAgB,EACrB,MAAM5E,QAAaJ,KAAKQ,aAUxB,OATAR,KAAKQ,gBAAa1E,EAClBkE,KAAKC,aAAe,MACpBD,KAAKK,QAAUD,EAEX2E,GAAe/E,KAAKU,WACtBV,KAAKU,WACLV,KAAKU,cAAW5E,GAGXsE,C,SAGPJ,KAAKgF,eAAgB,C,CAGzB,QACE,MAAM,IAAIhJ,MAAM,kCAAkCgE,KAAKC,gBAE7D,CAEAU,UACE,GAAIX,KAAKgF,cACP,MAAM,IAAIhJ,MAAM,2CAGdgE,KAAKU,WACPV,KAAKU,WACLV,KAAKU,cAAW5E,GAElBkE,KAAKK,aAAUvE,EACfkE,KAAKM,oBAAiBxE,EACtBkE,KAAKY,mBAAgB9E,EACrBkE,KAAKQ,gBAAa1E,EAClBkE,KAAKgF,mBAAgBlJ,EAErBkE,KAAKC,aAAe,MACtB,CAKQ6E,cACN,GAA0B,SAAtB9E,KAAKC,aACP,MAAM,IAAIjE,MAAM,0BAEpB,CAEAiJ,QAAQxF,GAEN,GADAO,KAAK8E,cACD9E,KAAKQ,YAAcR,KAAKU,SAC1B,MAAM,IAAI1E,MAAM,mDAElB,MCpYyB,EAACiI,EAAgBxE,KAC5C,OAAQwE,EAAO/D,UACb,IAAK,MACH,OAAO,IAAIzB,EAAOwF,EAAOzE,KAAMyE,EAAO7D,KAAMX,GAC9C,IAAK,aACH,OAAO,IAAIhB,EAAO,CAChByB,SAAU,aACVE,KAAM6D,EAAO7D,KACbZ,KAAMyE,EAAOzE,KACbC,SAEJ,IAAK,UACH,OAAO,IAAIhB,EAAO,CAChByB,SAAU,UACVK,QAAS0D,EAAO1D,QAChBf,KAAMyE,EAAOzE,KACbC,SAEJ,IAAK,aACH,OAAO,IAAIhB,EAAO,CAChByB,SAAU,aACVW,UAAWoD,EAAOpD,UAClBrB,KAAMyE,EAAOzE,KACbC,SAEJ,QACE,MAAM,IAAIzD,MAAM,kCAAkCiI,EAAO/D,6B,ED0WpDgF,CAAclF,KAAMP,EAC7B,EG1FK,MAAM,EAAShB,ECzTf,MAAM0G,EACX,YAAoBC,GAClBpF,KAAKoF,QAAUA,CACjB,CAGAvD,UAAUwD,EAAkB/F,EAA+BC,GACzD,MAAM+F,EAA4C,CAAC,EACnD,IAAItI,EAAsB,CAAC,EAE3B,GAAqB,iBAAVqI,GAAgC,OAAVA,GAAkBA,aAAiB,GAAUtE,MAAMC,QAAQqE,GAC1F,MAAM,IAAIzJ,UACN,iGAGN,IAAI2J,GAAiB,EAErB,GAAoB,iBAATjG,EAAmB,CAC5B,GAAa,OAATA,EACF,MAAM,IAAI1D,UAAU,2CAEtB,GAAI0D,aAAgB,EAClB,MAAM,IAAI1D,UAAU,gCAGtB,GAAImF,MAAMC,QAAQ1B,GAAO,CACvB,GAAoB,IAAhBA,EAAKlD,OACP,MAAM,IAAIR,UAAU,uCAEtB2J,GAAiB,EAEjB,IAAK,MAAMhK,KAAQ+D,EAAM,CACvB,GAAoB,iBAAT/D,EACT,MAAM,IAAIK,UAAU,kDAEtB,IAAwC,IAApCoE,KAAKwF,YAAYtJ,QAAQX,GAC3B,MAAM,IAAIkG,WAAW,2CAA2ClG,MAElE+J,EAAQ/J,GAAQ,I,CAGlB,GAAoB,iBAATgE,GAA8B,OAATA,EAC9BvC,EAAUuC,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI3D,UAAU,+B,KAEjB,CAGL,IAAI6J,GAAY,EAChB,MAAMC,EAAWnL,OAAOoL,oBAAoBrG,GAC5C,IAAK,MAAM/D,KAAQyE,KAAKwF,YACtB,IAAgC,IAA5BE,EAASxJ,QAAQX,GAAc,CACjC,MAAMqK,EAAKtG,EAA4D/D,IAC7D,OAANqK,GAAcA,aAAa,KAC7BH,GAAY,EACZF,GAAiB,EACjBD,EAAQ/J,GAAQqK,E,CAKtB,GAAIH,GACF,GAAoB,iBAATlG,GAA8B,OAATA,EAC9BvC,EAAUuC,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI3D,UAAU,qCAGtBoB,EAAUsC,C,OAGT,QAAoB,IAATA,EAChB,MAAM,IAAI1D,UAAU,2DAItB,IAAK,MAAML,KAAQyE,KAAK6F,WACtB,QAA2B,IAAhBR,EAAM9J,GACf,MAAM,IAAIS,MAAM,UAAUT,6BAK9B,GAAIgK,EACF,IAAK,MAAMhK,KAAQyE,KAAKwF,YACtBF,EAAQ/J,GAAQ,KAMpB,MAAMuK,QAAgB9F,KAAKoF,QAAQW,IAAIV,EAAOC,EAAStI,GACjDgJ,EAA2C,CAAC,EAClD,IAAK,MAAM3L,KAAOyL,EAChB,GAAIvL,OAAOO,eAAeC,KAAK+K,EAASzL,GAAM,CAC5C,MAAM4L,EAASH,EAAQzL,GAErB2L,EAAY3L,GADV4L,aAAkB,EACDA,EAEA,IAAI,EAAOA,EAAOzG,KAAMyG,EAAO7F,KAAM6F,EAAOxG,K,CAIrE,OAAOuG,CACT,CAEAnE,gBACE,OAAO7B,KAAKoF,QAAQzE,SACtB,CAOAgB,oBACItC,EAAyCC,EAA8BC,EACvE2G,GAEF,IAAIC,EACAnJ,EAA0B,CAAC,EAE/B,GAAoB,iBAATqC,GAET,GADA8G,EAAuB9G,EACH,iBAATC,GAA8B,OAATA,EAC9BtC,EAAUsC,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI1D,UAAU,qCAEjB,GAAIyD,aAAgBV,YAEzB,GADAwH,EAAuB9G,EACH,iBAATC,GAA8B,OAATA,EAC9BtC,EAAUsC,OACL,QAAoB,IAATA,EAChB,MAAM,IAAI1D,UAAU,oCAEjB,MACHyD,aAAgB+G,aACc,oBAAtBC,mBAAqChH,aAAgBgH,mBAoC/D,MAAM,IAAIzK,UAAU,uDApC+D,CACnF,MAAMmB,EAASsC,EACf,IAAIiH,EAAa,EACbC,EAAalH,EAAKkH,WACtB,GAAoB,iBAATjH,GAA8B,OAATA,EAC9BtC,EAAUsC,OACL,GAAoB,iBAATA,EAAmB,CAEnC,GADAgH,EAAahH,GACRiC,OAAOC,cAAc8E,GACxB,MAAM,IAAI7E,WAAW,oCAEvB,GAAI6E,EAAa,GAAKA,GAAcvJ,EAAOwJ,WACzC,MAAM,IAAI9E,WAAW,oCAAoC1E,EAAOwJ,gBAGlE,GADAA,EAAalH,EAAKkH,WAAaD,EACX,iBAAT/G,EAAmB,CAE5B,GADAgH,EAAahH,GACRgC,OAAOC,cAAc+E,GACxB,MAAM,IAAI9E,WAAW,oCAEvB,GAAI8E,GAAc,GAAKD,EAAaC,EAAaxJ,EAAOwJ,WACtD,MAAM,IAAI9E,WAAW,oCAAoC1E,EAAOwJ,WAAaD,OAE/E,GAAoB,iBAATJ,GAA8B,OAATA,EAC9BlJ,EAAUkJ,OACL,QAAoB,IAATA,EAChB,MAAM,IAAItK,UAAU,+B,MAEjB,QAAoB,IAAT2D,EAChB,MAAM,IAAI3D,UAAU,iC,MAEjB,QAAoB,IAAT0D,EAChB,MAAM,IAAI1D,UAAU,gCAEtBuK,EAAuB,IAAIxH,WAAW5B,EAAQuJ,EAAYC,E,EAM5D,MACMC,GADMxJ,EAAQyJ,oBAAsB,IACjBC,KAAIzK,GAAkB,iBAANA,EAAiBA,EAAIA,EAAEV,OAC1DC,OV/HoBqG,OAAM2E,IAClC,MAAMG,EAAuC,IAAxBH,EAAapK,OAAef,EAA2BmL,EACtEI,EAAS,GACf,IAAK,MAAMC,KAAeF,EAAc,CACtC,MAAMG,EAAc3L,EAAST,IAAImM,GACjC,GAAIC,EAAa,CACf,GAAIA,EAAYC,YACd,OAAOD,EAAYtL,QACd,GAAIsL,EAAYE,QACrB,SAGF,MAAMC,IAAmBH,EAAYI,YACrC,IAME,OALKD,IACHH,EAAYI,YAAcJ,EAAYtL,QAAQE,cAE1CoL,EAAYI,YAClBJ,EAAYC,aAAc,EACnBD,EAAYtL,O,CACnB,MAAO2L,GACFF,GACHL,EAAOvK,KAAK,CAACd,KAAMsL,EAAaO,IAAKD,IAEvCL,EAAYE,SAAU,C,gBAEfF,EAAYI,W,GAKzB,MAAM,IAAIlL,MAAM,oCAAoC4K,EAAOF,KAAIS,GAAK,IAAIA,EAAE5L,SAAS4L,EAAEC,QAAOC,KAAK,QAAQ,EUgGjFC,CAAed,GAC/BpB,QAAgB5J,EAAQG,8BAA8BwK,EAAsBnJ,GAClF,OAAO,IAAImI,EAAiBC,EAC9B,CAEAmC,iBACEvH,KAAKoF,QAAQmC,gBACf,CACAC,eACExH,KAAKoF,QAAQoC,cACf,CAEI3B,iBACF,OAAO7F,KAAKoF,QAAQS,UACtB,CACIL,kBACF,OAAOxF,KAAKoF,QAAQI,WACtB,EC+OK,MAAM,EAA4CL,EC/T5C,EC5HN,MACL,YAAoBC,GAClBpF,KAAKoF,QAAUA,CACjB,CAGIS,iBACF,OAAO7F,KAAKoF,QAAQS,UACtB,CACIL,kBACF,OAAOxF,KAAKoF,QAAQI,WACtB,CAEA7D,oBAAoB8F,EAAgDC,GAElE,MAAM,IAAI1L,MAAM,yBAClB,CAEA6F,2BAA2B8F,EAAoBC,GAC7C,MAAM,IAAI5L,MAAM,0BAClB,CAEA6F,8BAA8B+F,GAC5B,MAAM,IAAI5L,MAAM,0BAClB,CAOA6F,mBAAmBgG,EAAiBC,EAAoBC,GAEtD,MAAM,IAAI/L,MAAM,0BAClB,CAEA6F,gBACE,OAAO7B,KAAKoF,QAAQzE,SACtB,G","sources":["webpack://ort/webpack/universalModuleDefinition","webpack://ort/webpack/bootstrap","webpack://ort/webpack/runtime/define property getters","webpack://ort/webpack/runtime/hasOwnProperty shorthand","webpack://ort/webpack/runtime/make namespace object","webpack://ort/./lib/backend-impl.ts","webpack://ort/./lib/env-impl.ts","webpack://ort/./lib/version.ts","webpack://ort/./lib/env.ts","webpack://ort/./lib/tensor-factory-impl.ts","webpack://ort/./lib/tensor-impl-type-mapping.ts","webpack://ort/./lib/tensor-impl.ts","webpack://ort/./lib/tensor-utils-impl.ts","webpack://ort/./lib/tensor-conversion-impl.ts","webpack://ort/./lib/tensor.ts","webpack://ort/./lib/inference-session-impl.ts","webpack://ort/./lib/inference-session.ts","webpack://ort/./lib/training-session.ts","webpack://ort/./lib/training-session-impl.ts"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"ort\"] = factory();\n\telse\n\t\troot[\"ort\"] = factory();\n})(self, () => {\nreturn ","// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(_trainingOptions: TrainingSessionCreateOptions, _sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    throw new Error('Method not implemented');\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  runTrainStep(feeds: InferenceSession.OnnxValueMapType, options?: InferenceSession.RunOptions|undefined):\n      Promise<InferenceSession.OnnxValueMapType>;\n  runTrainStep(\n      feeds: InferenceSession.OnnxValueMapType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions|undefined): Promise<InferenceSession.OnnxValueMapType>;\n  async runTrainStep(_feeds: unknown, _fetches?: unknown, _options?: unknown):\n      Promise<InferenceSession.OnnxValueMapType> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n"],"names":["root","factory","exports","module","define","amd","self","__webpack_require__","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","backends","Map","backendsSortedByPriority","registerBackend","name","backend","priority","init","createInferenceSessionHandler","TypeError","currentBackend","undefined","set","Error","i","indexOf","splice","length","push","logLevelValue","env","wasm","webgl","webgpu","versions","common","logLevel","bufferToTensor","buffer","options","height","width","tensorLayout","norm","mean","bias","normMean","normBias","inputformat","format","outputformat","tensorFormat","stride","float32Data","Float32Array","step","rImagePointer","gImagePointer","bImagePointer","aImagePointer","rTensorPointer","gTensorPointer","bTensorPointer","aTensorPointer","Tensor","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","Uint8Array","Int8Array","Uint16Array","Int16Array","Int32Array","Float64Array","Uint32Array","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","isBigIntChecked","constructor","arg0","arg1","arg2","type","dims","isBigInt64ArrayAvailable","BigInt64Array","from","isBigUint64ArrayAvailable","BigUint64Array","checkBigInt","this","dataLocation","location","expectedTypedArrayConstructor","data","cpuData","gpuTextureData","texture","downloader","download","disposer","dispose","gpuBufferData","gpuBuffer","maybeDims","Array","isArray","typedArrayConstructor","BigInt","firstElementType","mappedType","size","dim","Number","isSafeInteger","RangeError","calculateSize","static","image","async","isHTMLImageEle","HTMLImageElement","isImageDataEle","ImageData","isImageBitmap","ImageBitmap","isString","bufferToTensorOptions","canvas","document","createElement","pixels2DContext","getContext","resizedHeight","resizedWidth","drawImage","getImageData","Promise","resolve","reject","context","newImage","Image","crossOrigin","src","onload","img","tempCanvas","putImageData","tensorFromImage","tensorFromTexture","dataType","tensorFromGpuBuffer","tensorFromPinnedBuffer","toDataURL","tensor","j","R","G","B","A","fillStyle","fillRect","tensorToDataURL","toImageData","channels","createImageData","tensorToImageData","ensureValid","releaseData","isDownloading","reshape","tensorReshape","InferenceSession","handler","feeds","fetches","isFetchesEmpty","outputNames","isFetches","arg1Keys","getOwnPropertyNames","v","inputNames","results","run","returnValue","result","arg3","filePathOrUint8Array","ArrayBuffer","SharedArrayBuffer","byteOffset","byteLength","backendHints","executionProviders","map","backendNames","errors","backendName","backendInfo","initialized","aborted","isInitializing","initPromise","e","err","join","resolveBackend","startProfiling","endProfiling","_trainingOptions","_sessionOptions","_array","_trainableOnly","_feeds","_fetches","_options"],"sourceRoot":""}