{
  "version": 3,
  "sources": ["../node_modules/onnxruntime-common/lib/backend-impl.ts", "../node_modules/onnxruntime-common/lib/backend.ts", "../node_modules/onnxruntime-common/lib/version.ts", "../node_modules/onnxruntime-common/lib/env-impl.ts", "../node_modules/onnxruntime-common/lib/env.ts", "../node_modules/onnxruntime-common/lib/tensor-conversion-impl.ts", "../node_modules/onnxruntime-common/lib/tensor-factory-impl.ts", "../node_modules/onnxruntime-common/lib/tensor-impl-type-mapping.ts", "../node_modules/onnxruntime-common/lib/tensor-utils-impl.ts", "../node_modules/onnxruntime-common/lib/tensor-impl.ts", "../node_modules/onnxruntime-common/lib/tensor.ts", "../node_modules/onnxruntime-common/lib/inference-session-impl.ts", "../node_modules/onnxruntime-common/lib/inference-session.ts", "../node_modules/onnxruntime-common/lib/onnx-value.ts", "../node_modules/onnxruntime-common/lib/training-session-impl.ts", "../node_modules/onnxruntime-common/lib/training-session.ts", "../node_modules/onnxruntime-common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../lib/wasm/binding/ort-wasm-threaded.worker.js", "../lib/wasm/wasm-factory.ts", "../lib/wasm/wasm-utils.ts", "../lib/wasm/run-options.ts", "../lib/wasm/session-options.ts", "../lib/wasm/wasm-common.ts", "../lib/wasm/jsep/log.ts", "../lib/wasm/jsep/tensor-view.ts", "../lib/wasm/jsep/webgpu/types.ts", "../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../lib/wasm/jsep/util.ts", "../lib/wasm/jsep/webgpu/ops/common.ts", "../lib/wasm/jsep/webgpu/ops/transpose.ts", "../lib/wasm/jsep/webgpu/ops/reduce-shared.ts", "../lib/wasm/jsep/webgpu/ops/reduce.ts", "../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../lib/wasm/jsep/webgpu/ops/attention.ts", "../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../lib/wasm/jsep/webgpu/ops/concat.ts", "../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../lib/wasm/jsep/webgpu/ops/conv.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../lib/wasm/jsep/webgpu/ops/einsum.ts", "../lib/wasm/jsep/webgpu/ops/expand.ts", "../lib/wasm/jsep/webgpu/ops/gather.ts", "../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../lib/wasm/jsep/webgpu/ops/gemm.ts", "../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../lib/wasm/jsep/webgpu/ops/matmul.ts", "../lib/wasm/jsep/webgpu/ops/multi-head-attentiion.ts", "../lib/wasm/jsep/webgpu/ops/pad.ts", "../lib/wasm/jsep/webgpu/ops/pool.ts", "../lib/wasm/jsep/webgpu/ops/range.ts", "../lib/wasm/jsep/webgpu/ops/resize.ts", "../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../lib/wasm/jsep/webgpu/ops/slice.ts", "../lib/wasm/jsep/webgpu/ops/softmax.ts", "../lib/wasm/jsep/webgpu/ops/split.ts", "../lib/wasm/jsep/webgpu/ops/tile.ts", "../lib/wasm/jsep/webgpu/ops/where.ts", "../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../lib/wasm/jsep/webgpu/program-manager.ts", "../lib/wasm/jsep/backend-webgpu.ts", "../lib/wasm/jsep/init.ts", "../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../lib/wasm/proxy-wrapper.ts", "../lib/wasm/session-handler-inference.ts", "../lib/backend-wasm.ts", "../lib/backend-wasm-inference.ts", "../lib/index.ts", "../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    numThreads?: number;\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {SessionHandler, TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\ntype FeedsType = InferenceSession.FeedsType;\ntype FetchesType = InferenceSession.FetchesType;\ntype ReturnType = InferenceSession.ReturnType;\ntype RunOptions = InferenceSession.RunOptions;\n\nconst noBackendErrMsg: string = 'Training backend could not be resolved. ' +\n    'Make sure you\\'re using the correct configuration & WebAssembly files.';\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    const evalModel: string|Uint8Array = trainingOptions.evalModel || '';\n    const optimizerModel: string|Uint8Array = trainingOptions.optimizerModel || '';\n    const options: SessionOptions = sessionOptions || {};\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    if (backend.createTrainingSessionHandler) {\n      const handler = await backend.createTrainingSessionHandler(\n          trainingOptions.checkpointState, trainingOptions.trainModel, evalModel, optimizerModel, options);\n      return new TrainingSession(handler);\n    } else {\n      throw new Error(noBackendErrMsg);\n    }\n  }\n\n  /**\n   * Helper function for runTrainStep and future runStep methods that handles the type-narrowing conversion from\n   * the given parameters to SessionHandler.FetchesType and RunOptions.\n   *\n   * @param feeds the required input\n   * @param arg1 narrowed & converted into the SessionHandler.FetchesType or RunOptions object\n   * @param arg2 optional RunOptions object.\n   * @returns\n   */\n  typeNarrowingForRunStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions):\n      [SessionHandler.FetchesType, RunOptions] {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSession.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    return [fetches, options];\n  }\n\n  /**\n   * Helper method for runTrainStep and any other runStep methods. Takes the ReturnType result from the SessionHandler\n   * and changes it into a map of Tensors.\n   *\n   * @param results\n   * @returns\n   */\n  convertHandlerReturnTypeToMapOfTensors(results: SessionHandler.ReturnType): ReturnType {\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  runTrainStep(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  runTrainStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async runTrainStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const [fetches, options] = this.typeNarrowingForRunStep(feeds, arg1, arg2);\n    const results = await this.handler.runTrainStep(feeds, fetches, options);\n    return this.convertHandlerReturnTypeToMapOfTensors(results);\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\nvar ortWasm = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nvar d=moduleArg,aa,h;d.ready=new Promise((a,b)=>{aa=a;h=b});\"use strict\";\nd.jsepInit=(a,b,c,e,f,k,l,r)=>{d.Za=a;d.Oa=b;d.Qa=c;d.Ja=e;d.Pa=f;d.ra=k;d.Ra=l;d.Sa=r;b=(m,p,n)=>(...u)=>{const w=t,g=p?.();u=m(...u);const q=p?.();g!==q&&(m=q,n(g),p=n=null);return t!=w?ba():u};c=m=>async(...p)=>{try{if(d.Da)throw Error(\"Session already started\");const n=d.Da={Ta:p[0],errors:[]},u=await m(...p);if(d.Da!==n)throw Error(\"Session mismatch\");a.flush();const w=n.errors;if(0<w.length){let g=await Promise.all(w);g=g.filter(q=>q);if(0<g.length)throw Error(g.join(\"\\n\"));}return u}finally{d.Da=\nnull}};d._OrtRun=c(b(d._OrtRun,()=>d._OrtRun,m=>d._OrtRun=m));d._OrtRunWithBinding=c(b(d._OrtRunWithBinding,()=>d._OrtRunWithBinding,m=>d._OrtRunWithBinding=m));d._OrtBindInput=b(d._OrtBindInput,()=>d._OrtBindInput,m=>d._OrtBindInput=m);d.jsepRegisterBuffer=(m,p,n,u)=>a.registerBuffer(m,p,n,u);d.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};d.jsepGetBuffer=m=>a.getBuffer(m);d.jsepCreateDownloader=(m,p,n)=>a.createDownloader(m,p,n)};\nvar ca=Object.assign({},d),x=\"./this.program\",y=(a,b)=>{throw b;},da=\"object\"==typeof window,z=\"function\"==typeof importScripts,ea=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,A=\"\",B,C,D;\nif(ea){var fs=require(\"fs\"),fa=require(\"path\");A=z?fa.dirname(A)+\"/\":__dirname+\"/\";B=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};D=a=>{a=B(a,!0);a.buffer||(a=new Uint8Array(a));return a};C=(a,b,c,e=!0)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);fs.readFile(a,e?void 0:\"utf8\",(f,k)=>{f?c(f):b(e?k.buffer:k)})};!d.thisProgram&&1<process.argv.length&&(x=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);y=(a,b)=>{process.exitCode=\na;throw b;};d.inspect=()=>\"[Emscripten Module object]\"}else if(da||z)z?A=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),0!==A.indexOf(\"blob:\")?A=A.substr(0,A.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):A=\"\",B=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},z&&(D=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\nC=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)};var ha=d.print||console.log.bind(console),E=d.printErr||console.error.bind(console);Object.assign(d,ca);ca=null;d.thisProgram&&(x=d.thisProgram);d.quit&&(y=d.quit);var F;d.wasmBinary&&(F=d.wasmBinary);var noExitRuntime=d.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&H(\"no native wasm support detected\");\nvar I,J,K=!1,L,M,N,O,P,ia,ja;function ka(){var a=I.buffer;d.HEAP8=M=new Int8Array(a);d.HEAP16=new Int16Array(a);d.HEAP32=O=new Int32Array(a);d.HEAPU8=N=new Uint8Array(a);d.HEAPU16=new Uint16Array(a);d.HEAPU32=P=new Uint32Array(a);d.HEAPF32=ia=new Float32Array(a);d.HEAPF64=ja=new Float64Array(a)}var la=[],ma=[],na=[];function oa(){var a=d.preRun.shift();la.unshift(a)}var Q=0,pa=null,R=null;\nfunction H(a){if(d.onAbort)d.onAbort(a);a=\"Aborted(\"+a+\")\";E(a);K=!0;L=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");h(a);throw a;}function qa(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var S;S=\"ort-wasm-simd.wasm\";if(!qa(S)){var ra=S;S=d.locateFile?d.locateFile(ra,A):A+ra}function sa(a){if(a==S&&F)return new Uint8Array(F);if(D)return D(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction ta(a){if(!F&&(da||z)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>sa(a));if(C)return new Promise((b,c)=>{C(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>sa(a))}function ua(a,b,c){return ta(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{E(\"failed to asynchronously prepare wasm: \"+e);H(e)})}\nfunction va(a,b){var c=S;return F||\"function\"!=typeof WebAssembly.instantiateStreaming||qa(c)||c.startsWith(\"file://\")||ea||\"function\"!=typeof fetch?ua(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){E(\"wasm streaming compile failed: \"+f);E(\"falling back to ArrayBuffer instantiation\");return ua(c,a,b)}))}\nvar T,wa={911200:a=>{d.ra(\"Abs\",a,void 0)},911251:a=>{d.ra(\"Neg\",a,void 0)},911302:a=>{d.ra(\"Floor\",a,void 0)},911355:a=>{d.ra(\"Ceil\",a,void 0)},911407:a=>{d.ra(\"Reciprocal\",a,void 0)},911465:a=>{d.ra(\"Sqrt\",a,void 0)},911517:a=>{d.ra(\"Exp\",a,void 0)},911568:a=>{d.ra(\"Erf\",a,void 0)},911619:a=>{d.ra(\"Sigmoid\",a,void 0)},911674:a=>{d.ra(\"Log\",a,void 0)},911725:a=>{d.ra(\"Sin\",a,void 0)},911776:a=>{d.ra(\"Cos\",a,void 0)},911827:a=>{d.ra(\"Tan\",a,void 0)},911878:a=>{d.ra(\"Asin\",a,void 0)},911930:a=>{d.ra(\"Acos\",\na,void 0)},911982:a=>{d.ra(\"Atan\",a,void 0)},912034:a=>{d.ra(\"Sinh\",a,void 0)},912086:a=>{d.ra(\"Cosh\",a,void 0)},912138:a=>{d.ra(\"Asinh\",a,void 0)},912191:a=>{d.ra(\"Acosh\",a,void 0)},912244:a=>{d.ra(\"Atanh\",a,void 0)},912297:a=>{d.ra(\"Tanh\",a,void 0)},912349:a=>{d.ra(\"Not\",a,void 0)},912400:(a,b,c)=>{d.ra(\"Clip\",a,{min:b,max:c})},912469:a=>{d.ra(\"Clip\",a,void 0)},912521:(a,b)=>{d.ra(\"Elu\",a,{alpha:b})},912579:a=>{d.ra(\"Relu\",a,void 0)},912631:(a,b)=>{d.ra(\"LeakyRelu\",a,{alpha:b})},912695:(a,b)=>{d.ra(\"ThresholdedRelu\",\na,{alpha:b})},912765:(a,b)=>{d.ra(\"Cast\",a,{to:b})},912823:a=>{d.ra(\"Add\",a,void 0)},912874:a=>{d.ra(\"Sub\",a,void 0)},912925:a=>{d.ra(\"Mul\",a,void 0)},912976:a=>{d.ra(\"Div\",a,void 0)},913027:a=>{d.ra(\"Pow\",a,void 0)},913078:a=>{d.ra(\"Equal\",a,void 0)},913131:a=>{d.ra(\"Greater\",a,void 0)},913186:a=>{d.ra(\"GreaterOrEqual\",a,void 0)},913248:a=>{d.ra(\"Less\",a,void 0)},913300:a=>{d.ra(\"LessOrEqual\",a,void 0)},913359:(a,b,c,e,f)=>{d.ra(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},913523:(a,b,c,e,f)=>{d.ra(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913686:(a,b,c,e,f)=>{d.ra(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},913849:(a,b,c,e,f)=>{d.ra(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},914013:(a,b,c,e,f)=>{d.ra(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},914176:(a,b,c,e,f)=>{d.ra(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},914338:(a,b,c,e,f)=>{d.ra(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},914500:(a,b,c,e,f)=>{d.ra(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},914666:(a,b,c,e,f)=>{d.ra(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},914835:(a,b,c,e,f)=>{d.ra(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},915004:a=>{d.ra(\"Where\",a,void 0)},915057:(a,b,c)=>{d.ra(\"Transpose\",a,{perm:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[]})},915170:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[k,l],strides:[r],wIsConst:()=>!!M[p>>>0],outputPadding:n?Array.from(O.subarray(u>>>0,\nu+n>>>0)):[],outputShape:w?Array.from(O.subarray(g>>>0,g+w>>>0)):[],activation:U(q)})},915584:(a,b,c,e,f,k,l,r,m,p,n,u,w,g)=>{d.ra(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(f>>>0,f+2>>>0)),pads:Array.from(O.subarray(k>>>0,k+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<u?Array.from(O.subarray(w>>>\n0,w+u>>>0)):[],activation:U(g)})},916141:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[k,l],strides:[r],wIsConst:()=>!!M[p>>>0],outputPadding:n?Array.from(O.subarray(u>>>0,u+n>>>0)):[],outputShape:w?Array.from(O.subarray(g>>>0,g+w>>>0)):[],activation:U(q)})},916555:(a,b,c,e,f,k,l,r,m,p,n,u,w,g)=>{d.ra(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,\nkernelShape:Array.from(O.subarray(f>>>0,f+2>>>0)),pads:Array.from(O.subarray(k>>>0,k+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<u?Array.from(O.subarray(w>>>0,w+u>>>0)):[],activation:U(g)})},917112:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},917203:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,\ndilations:[k,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},917487:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},917578:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[k,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},917862:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},917949:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,\nceil_mode:c,count_include_pad:e,storage_order:f,dilations:[k,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},918229:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},918316:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[k,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},918596:(a,b,c,e,f)=>{d.ra(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},918700:a=>{d.ra(\"MatMul\",a,void 0)},918754:(a,\nb,c,e)=>{d.ra(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},918862:(a,b,c,e)=>{d.ra(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},918970:(a,b)=>{d.ra(\"Softmax\",a,{axis:b})},919033:(a,b)=>{d.ra(\"Concat\",a,{axis:b})},919093:(a,b,c,e,f)=>{d.ra(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},919238:a=>{d.ra(\"Expand\",a,void 0)},919292:(a,b)=>{d.ra(\"Gather\",a,{axis:Number(b)})},919363:(a,b)=>{d.ra(\"GatherElements\",a,{axis:Number(b)})},919442:(a,\nb,c,e,f,k,l,r,m,p,n)=>{d.ra(\"Resize\",a,{antialias:b,axes:c?Array.from(O.subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:U(f),cubicCoeffA:k,excludeOutside:l,extrapolationValue:r,keepAspectRatioPolicy:U(m),mode:U(p),nearestMode:U(n)})},919793:(a,b,c,e,f,k,l)=>{d.ra(\"Slice\",a,{starts:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[],axes:k?Array.from(O.subarray(l>>>0,l+k>>>0)):[]})},920024:a=>{d.ra(\"Tile\",a,void 0)},920076:(a,b,c)=>{d.ra(\"LayerNormalization\",\na,{axis:Number(b),epsilon:Number(c)})},920183:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},920297:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},920411:a=>{d.ra(\"Range\",a,void 0)},920464:(a,b)=>{d.ra(\"Einsum\",a,{equation:U(b)})},920545:(a,b,c,e,f)=>{d.ra(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},920677:(a,b,c,e,f,k,l,r,m)=>{d.ra(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:k,\nqkvHiddenSizes:l?Array.from(O.subarray(Number(r)>>>0,Number(r)+l>>>0)):[],pastPresentShareBuffer:!!m})},920949:a=>{d.ra(\"Gelu\",a,void 0)},921001:(a,b,c,e,f,k)=>{d.ra(\"MultiHeadAttention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:k})},921160:a=>{d.ra(\"BiasAdd\",a,void 0)},921215:a=>{d.ra(\"BiasSplitGelu\",a,void 0)},921276:(a,b)=>{d.ra(\"SkipLayerNormalization\",a,{epsilon:b})},921357:(a,b,c,e,f,k,l,r,m,p,n,u,w)=>{d.ra(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],\ngroup:e,kernel_shape:[f],pads:k?Array.from(O.subarray(l>>>0,l+k>>>0)):[],strides:[r],w_is_const:()=>!!M[p>>>0],activation:U(n),activation_params:u?Array.from(ia.subarray(w>>>0,w+u>>>0)):[]})},921738:(a,b,c,e,f,k,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"Conv\",a,{format:u?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[k,l],pads:r?Array.from(O.subarray(m>>>0,m+r>>>0)):[],strides:[p,n],w_is_const:()=>!!M[w>>>0],activation:U(g),activation_params:q?Array.from(ia.subarray(v>>>0,v+q>>>0)):[]})},922140:a=>\n{d.Ra(a)},922174:(a,b)=>d.Sa(a,b,d.Da.Ta,d.Da.errors),922286:a=>d.Oa(a),922319:a=>d.Qa(a),922351:(a,b,c)=>{d.Ja(a,b,c,!0)},922390:(a,b,c)=>{d.Ja(a,b,c)}};function xa(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var ya=a=>{for(;0<a.length;)a.shift()(d)};\nfunction za(a){this.Ha=a-24;this.Ma=function(b){P[this.Ha+4>>2>>>0]=b};this.La=function(b){P[this.Ha+8>>2>>>0]=b};this.Ya=function(b,c){this.Ka();this.Ma(b);this.La(c)};this.Ka=function(){P[this.Ha+16>>2>>>0]=0}}\nvar Aa=0,Ba=0,Ca=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Da=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ca)return Ca.decode(a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var k=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|k);else{var l=a[b++]&63;f=224==(f&240)?(f&15)<<12|k<<6|l:(f&7)<<18|k<<12|l<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},\nU=(a,b)=>(a>>>=0)?Da(N,a,b):\"\",Ea=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},Fa=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var k=0;k<a.length;++k){var l=a.charCodeAt(k);if(55296<=l&&57343>=l){var r=a.charCodeAt(++k);l=65536+((l&1023)<<10)|r&1023}if(127>=l){if(c>=e)break;b[c++>>>0]=l}else{if(2047>=l){if(c+1>=e)break;b[c++>>>0]=192|l>>6}else{if(65535>=l){if(c+2>=e)break;b[c++>>>0]=224|l>>12}else{if(c+\n3>=e)break;b[c++>>>0]=240|l>>18;b[c++>>>0]=128|l>>12&63}b[c++>>>0]=128|l>>6&63}b[c++>>>0]=128|l&63}}b[c>>>0]=0;return c-f},V=a=>0===a%4&&(0!==a%100||0===a%400),Ga=[0,31,60,91,121,152,182,213,244,274,305,335],Ha=[0,31,59,90,120,151,181,212,243,273,304,334],Ja=a=>{var b=Ea(a)+1,c=Ia(b);c&&Fa(a,N,c,b);return c},Ka=[],La=(a,b)=>{Ka.length=0;var c;for(b>>=2;c=N[a++>>>0];)b+=105!=c&b,Ka.push(105==c?O[b>>>0]:ja[b++>>>1]),++b;return Ka},Na={},Pa=()=>{if(!Oa){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",\nPWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:x||\"./this.program\"},b;for(b in Na)void 0===Na[b]?delete a[b]:a[b]=Na[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Oa=c}return Oa},Oa,Qa=[null,[],[]],Ra=[31,29,31,30,31,30,31,31,30,31,30,31],Sa=[31,28,31,30,31,30,31,31,30,31,30,31];function Ta(a){var b=Array(Ea(a)+1);Fa(a,b,0,b.length);return b}\nfunction Ua(a,b,c,e){function f(g,q,v){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<q;)g=v[0]+g;return g}function k(g,q){return f(g,q,\"0\")}function l(g,q){function v(Ma){return 0>Ma?-1:0<Ma?1:0}var G;0===(G=v(g.getFullYear()-q.getFullYear()))&&0===(G=v(g.getMonth()-q.getMonth()))&&(G=v(g.getDate()-q.getDate()));return G}function r(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var q=g.Ba;for(g=new Date((new Date(g.Ca+1900,0,1)).getTime());0<q;){var v=g.getMonth(),G=(V(g.getFullYear())?Ra:Sa)[v];if(q>G-g.getDate())q-=G-g.getDate()+1,g.setDate(1),11>v?g.setMonth(v+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+q);break}}v=new Date(g.getFullYear()+1,0,4);q=r(new Date(g.getFullYear(),\n0,4));v=r(v);return 0>=l(q,g)?0>=l(v,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var p=O[e+40>>2>>>0];e={Wa:O[e>>2>>>0],Va:O[e+4>>2>>>0],Ea:O[e+8>>2>>>0],Ia:O[e+12>>2>>>0],Fa:O[e+16>>2>>>0],Ca:O[e+20>>2>>>0],wa:O[e+24>>2>>>0],Ba:O[e+28>>2>>>0],$a:O[e+32>>2>>>0],Ua:O[e+36>>2>>>0],Xa:p?U(p):\"\"};c=U(c);p={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var n in p)c=c.replace(new RegExp(n,\"g\"),p[n]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),w=\"January February March April May June July August September October November December\".split(\" \");p={\"%a\":g=>u[g.wa].substring(0,3),\"%A\":g=>u[g.wa],\"%b\":g=>w[g.Fa].substring(0,\n3),\"%B\":g=>w[g.Fa],\"%C\":g=>k((g.Ca+1900)/100|0,2),\"%d\":g=>k(g.Ia,2),\"%e\":g=>f(g.Ia,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>k(g.Ea,2),\"%I\":g=>{g=g.Ea;0==g?g=12:12<g&&(g-=12);return k(g,2)},\"%j\":g=>{for(var q=0,v=0;v<=g.Fa-1;q+=(V(g.Ca+1900)?Ra:Sa)[v++]);return k(g.Ia+q,3)},\"%m\":g=>k(g.Fa+1,2),\"%M\":g=>k(g.Va,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.Ea&&12>g.Ea?\"AM\":\"PM\",\"%S\":g=>k(g.Wa,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.wa||7,\"%U\":g=>k(Math.floor((g.Ba+7-g.wa)/7),2),\"%V\":g=>{var q=Math.floor((g.Ba+\n7-(g.wa+6)%7)/7);2>=(g.wa+371-g.Ba-2)%7&&q++;if(q)53==q&&(v=(g.wa+371-g.Ba)%7,4==v||3==v&&V(g.Ca)||(q=1));else{q=52;var v=(g.wa+7-g.Ba-1)%7;(4==v||5==v&&V(g.Ca%400-1))&&q++}return k(q,2)},\"%w\":g=>g.wa,\"%W\":g=>k(Math.floor((g.Ba+7-(g.wa+6)%7)/7),2),\"%y\":g=>(g.Ca+1900).toString().substring(2),\"%Y\":g=>g.Ca+1900,\"%z\":g=>{g=g.Ua;var q=0<=g;g=Math.abs(g)/60;return(q?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Xa,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(n in p)c.includes(n)&&(c=c.replace(new RegExp(n,\n\"g\"),p[n](e)));c=c.replace(/\\0\\0/g,\"%\");n=Ta(c);if(n.length>b)return 0;M.set(n,a>>>0);return n.length-1}function W(a){try{a()}catch(b){H(b)}}function Va(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){X.push(e);try{return f.apply(null,arguments)}finally{K||(X.pop()===e||H(),t&&1===Y&&0===X.length&&(Y=0,W(Wa),\"undefined\"!=typeof Fibers&&Fibers.ab()))}}:f})(c);return b}var Y=0,t=null,Xa=0,X=[],Ya={},Za={},$a=0,ab=null,bb=[];\nfunction ba(){return new Promise((a,b)=>{ab={resolve:a,reject:b}})}function cb(){var a=Ia(65548),b=a+12;P[a>>2>>>0]=b;P[a+4>>2>>>0]=b+65536;b=X[0];var c=Ya[b];void 0===c&&(c=$a++,Ya[b]=c,Za[c]=b);O[a+8>>2>>>0]=c;return a}\nfunction db(a){if(!K){if(0===Y){var b=!1,c=!1;a((e=0)=>{if(!K&&(Xa=e,b=!0,c)){Y=2;W(()=>eb(t));\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.resume();e=!1;try{var f=(0,J[Za[O[t+8>>2>>>0]]])()}catch(r){f=r,e=!0}var k=!1;if(!t){var l=ab;l&&(ab=null,(e?l.reject:l.resolve)(f),k=!0)}if(e&&!k)throw f;}});c=!0;b||(Y=1,t=cb(),\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.pause(),W(()=>fb(t)))}else 2===Y?(Y=0,W(gb),hb(t),t=null,bb.forEach(e=>{if(!K)try{if(e(),!noExitRuntime)try{L=L=e=L;if(!noExitRuntime){if(d.onExit)d.onExit(e);\nK=!0}y(e,new xa(e))}catch(f){f instanceof xa||\"unwind\"==f||y(1,f)}}catch(f){f instanceof xa||\"unwind\"==f||y(1,f)}})):H(`invalid state: ${Y}`);return Xa}}function ib(a){return db(b=>{a().then(b)})}\nvar kb={n:function(a,b,c){return ib(async()=>{await d.Pa(a,b,c)})},a:function(a,b,c){a>>>=0;(new za(a)).Ya(b>>>0,c>>>0);Aa=a;Ba++;throw Aa;},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getUTCSeconds();O[c+4>>2>>>0]=\na.getUTCMinutes();O[c+8>>2>>>0]=a.getUTCHours();O[c+12>>2>>>0]=a.getUTCDate();O[c+16>>2>>>0]=a.getUTCMonth();O[c+20>>2>>>0]=a.getUTCFullYear()-1900;O[c+24>>2>>>0]=a.getUTCDay();O[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},r:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getSeconds();O[c+4>>2>>>0]=a.getMinutes();O[c+8>>2>>>0]=a.getHours();O[c+12>>2>>>0]=a.getDate();O[c+16>>2>>>0]=a.getMonth();O[c+20>>2>>>\n0]=a.getFullYear()-1900;O[c+24>>2>>>0]=a.getDay();O[c+28>>2>>>0]=(V(a.getFullYear())?Ga:Ha)[a.getMonth()]+a.getDate()-1|0;O[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();O[c+32>>2>>>0]=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0},s:function(a){a>>>=0;var b=new Date(O[a+20>>2>>>0]+1900,O[a+16>>2>>>0],O[a+12>>2>>>0],O[a+8>>2>>>0],O[a+4>>2>>>0],O[a>>2>>>0],0),c=O[a+32>>2>>>0],e=b.getTimezoneOffset(),\nf=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),k=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),l=Math.min(k,f);0>c?O[a+32>>2>>>0]=Number(f!=k&&l==e):0<c!=(l==e)&&(f=Math.max(k,f),b.setTime(b.getTime()+6E4*((0<c?l:f)-e)));O[a+24>>2>>>0]=b.getDay();O[a+28>>2>>>0]=(V(b.getFullYear())?Ga:Ha)[b.getMonth()]+b.getDate()-1|0;O[a>>2>>>0]=b.getSeconds();O[a+4>>2>>>0]=b.getMinutes();O[a+8>>2>>>0]=b.getHours();O[a+12>>2>>>0]=b.getDate();O[a+16>>2>>>0]=b.getMonth();O[a+20>>2>>>0]=b.getYear();a=b.getTime()/\n1E3;return jb((T=a,1<=+Math.abs(T)?0<T?+Math.floor(T/4294967296)>>>0:~~+Math.ceil((T-+(~~T>>>0))/4294967296)>>>0:0)),a>>>0},o:function(){return-52},p:function(){},v:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}c>>>=0;var f=(new Date).getFullYear(),k=new Date(f,0,1),l=new Date(f,6,1);f=k.getTimezoneOffset();var r=l.getTimezoneOffset();P[a>>>0>>2>>>0]=60*Math.max(f,r);O[b>>>0>>2>>>0]=Number(f!=r);a=e(k);b=e(l);a=Ja(a);b=Ja(b);r<f?(P[c>>2>>>0]=a,P[c+\n4>>2>>>0]=b):(P[c>>2>>>0]=b,P[c+4>>2>>>0]=a)},e:()=>{H(\"\")},b:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},i:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(a,b,c){b>>>=0;return N.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},u:function(a){a>>>=0;var b=N.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;\ne=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-I.buffer.byteLength+65535>>>16;try{I.grow(f);ka();var k=1;break a}catch(l){}k=void 0}if(k)return!0}return!1},D:function(a,b){a>>>=0;b>>>=0;var c=0;Pa().forEach(function(e,f){var k=b+c;f=P[a+4*f>>2>>>0]=k;for(k=0;k<e.length;++k)M[f++>>0>>>0]=e.charCodeAt(k);M[f>>0>>>0]=0;c+=e.length+1});return 0},E:function(a,b){a>>>=0;b>>>=0;var c=Pa();P[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});P[b>>2>>>0]=e;return 0},f:()=>\n52,k:function(){return 52},t:function(){return 70},j:function(a,b,c,e){b>>>=0;c>>>=0;e>>>=0;for(var f=0,k=0;k<c;k++){var l=P[b>>2>>>0],r=P[b+4>>2>>>0];b+=8;for(var m=0;m<r;m++){var p=N[l+m>>>0],n=Qa[a];0===p||10===p?((1===a?ha:E)(Da(n,0)),n.length=0):n.push(p)}f+=r}P[e>>2>>>0]=f;return 0},F:Ua,d:function(a,b,c,e){return Ua(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c){c=c.exports;c=Va(c);J=c=lb(c);I=J.M;ka();ma.unshift(J.N);Q--;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(0==Q&&(null!==pa&&(clearInterval(pa),pa=null),R)){var e=R;R=null;e()}return c}var b={a:kb};Q++;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(d.instantiateWasm)try{return d.instantiateWasm(b,a)}catch(c){E(\"Module.instantiateWasm callback failed with error: \"+c),h(c)}va(b,function(c){a(c.instance)}).catch(h);return{}})();\nd._OrtInit=(a,b)=>(d._OrtInit=J.O)(a,b);d._OrtGetLastError=(a,b)=>(d._OrtGetLastError=J.P)(a,b);d._OrtCreateSessionOptions=(a,b,c,e,f,k,l,r,m,p)=>(d._OrtCreateSessionOptions=J.Q)(a,b,c,e,f,k,l,r,m,p);d._OrtAppendExecutionProvider=(a,b)=>(d._OrtAppendExecutionProvider=J.R)(a,b);d._OrtAddFreeDimensionOverride=(a,b,c)=>(d._OrtAddFreeDimensionOverride=J.S)(a,b,c);d._OrtAddSessionConfigEntry=(a,b,c)=>(d._OrtAddSessionConfigEntry=J.T)(a,b,c);d._OrtReleaseSessionOptions=a=>(d._OrtReleaseSessionOptions=J.U)(a);\nd._OrtCreateSession=(a,b,c)=>(d._OrtCreateSession=J.V)(a,b,c);d._OrtReleaseSession=a=>(d._OrtReleaseSession=J.W)(a);d._OrtGetInputOutputCount=(a,b,c)=>(d._OrtGetInputOutputCount=J.X)(a,b,c);d._OrtGetInputName=(a,b)=>(d._OrtGetInputName=J.Y)(a,b);d._OrtGetOutputName=(a,b)=>(d._OrtGetOutputName=J.Z)(a,b);d._OrtFree=a=>(d._OrtFree=J._)(a);d._OrtCreateTensor=(a,b,c,e,f,k)=>(d._OrtCreateTensor=J.$)(a,b,c,e,f,k);d._OrtGetTensorData=(a,b,c,e,f)=>(d._OrtGetTensorData=J.aa)(a,b,c,e,f);\nd._OrtReleaseTensor=a=>(d._OrtReleaseTensor=J.ba)(a);d._OrtCreateRunOptions=(a,b,c,e)=>(d._OrtCreateRunOptions=J.ca)(a,b,c,e);d._OrtAddRunConfigEntry=(a,b,c)=>(d._OrtAddRunConfigEntry=J.da)(a,b,c);d._OrtReleaseRunOptions=a=>(d._OrtReleaseRunOptions=J.ea)(a);d._OrtCreateBinding=a=>(d._OrtCreateBinding=J.fa)(a);d._OrtBindInput=(a,b,c)=>(d._OrtBindInput=J.ga)(a,b,c);d._OrtBindOutput=(a,b,c,e)=>(d._OrtBindOutput=J.ha)(a,b,c,e);d._OrtClearBoundOutputs=a=>(d._OrtClearBoundOutputs=J.ia)(a);\nd._OrtReleaseBinding=a=>(d._OrtReleaseBinding=J.ja)(a);d._OrtRunWithBinding=(a,b,c,e,f)=>(d._OrtRunWithBinding=J.ka)(a,b,c,e,f);d._OrtRun=(a,b,c,e,f,k,l,r)=>(d._OrtRun=J.la)(a,b,c,e,f,k,l,r);d._OrtEndProfiling=a=>(d._OrtEndProfiling=J.ma)(a);d._JsepOutput=(a,b,c)=>(d._JsepOutput=J.na)(a,b,c);d._JsepGetNodeName=a=>(d._JsepGetNodeName=J.oa)(a);\nvar Ia=d._malloc=a=>(Ia=d._malloc=J.pa)(a),hb=d._free=a=>(hb=d._free=J.qa)(a),jb=a=>(jb=J.sa)(a),mb=()=>(mb=J.ta)(),nb=a=>(nb=J.ua)(a),ob=a=>(ob=J.va)(a),fb=a=>(fb=J.xa)(a),Wa=()=>(Wa=J.ya)(),eb=a=>(eb=J.za)(a),gb=()=>(gb=J.Aa)();d.___start_em_js=922423;d.___stop_em_js=922584;function lb(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}d.stackAlloc=ob;\nd.stackSave=mb;d.stackRestore=nb;d.UTF8ToString=U;d.stringToUTF8=(a,b,c)=>Fa(a,N,b,c);d.lengthBytesUTF8=Ea;var Z;R=function pb(){Z||qb();Z||(R=pb)};\nfunction qb(){function a(){if(!Z&&(Z=!0,d.calledRun=!0,!K)){ya(ma);aa(d);if(d.onRuntimeInitialized)d.onRuntimeInitialized();if(d.postRun)for(\"function\"==typeof d.postRun&&(d.postRun=[d.postRun]);d.postRun.length;){var b=d.postRun.shift();na.unshift(b)}ya(na)}}if(!(0<Q)){if(d.preRun)for(\"function\"==typeof d.preRun&&(d.preRun=[d.preRun]);d.preRun.length;)oa();ya(la);0<Q||(d.setStatus?(d.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){d.setStatus(\"\")},1);a()},1)):a())}}\nif(d.preInit)for(\"function\"==typeof d.preInit&&(d.preInit=[d.preInit]);0<d.preInit.length;)d.preInit.pop()();qb();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasm;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasm);\n", "", "", "export const cpus = undefined;", "\nvar ortWasmThreaded = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nfunction d(){l.buffer!=p.buffer&&u();return p}function v(){l.buffer!=p.buffer&&u();return aa}function z(){l.buffer!=p.buffer&&u();return ba}function A(){l.buffer!=p.buffer&&u();return ca}function da(){l.buffer!=p.buffer&&u();return ea}function fa(){l.buffer!=p.buffer&&u();return ha}var B=moduleArg,ia,C;B.ready=new Promise((a,b)=>{ia=a;C=b});\"use strict\";\nB.jsepInit=(a,b,c,e,f,h,k,q)=>{B.Qb=a;B.wb=b;B.yb=c;B.jb=e;B.xb=f;B.Ea=h;B.zb=k;B.Ab=q;b=(m,n,r)=>(...w)=>{const y=D,g=n?.();w=m(...w);const t=n?.();g!==t&&(m=t,r(g),n=r=null);return D!=y?ja():w};c=m=>async(...n)=>{try{if(B.bb)throw Error(\"Session already started\");const r=B.bb={Fb:n[0],errors:[]},w=await m(...n);if(B.bb!==r)throw Error(\"Session mismatch\");a.flush();const y=r.errors;if(0<y.length){let g=await Promise.all(y);g=g.filter(t=>t);if(0<g.length)throw Error(g.join(\"\\n\"));}return w}finally{B.bb=\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,m=>B._OrtRun=m));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,m=>B._OrtRunWithBinding=m));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,m=>B._OrtBindInput=m);B.jsepRegisterBuffer=(m,n,r,w)=>a.registerBuffer(m,n,r,w);B.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};B.jsepGetBuffer=m=>a.getBuffer(m);B.jsepCreateDownloader=(m,n,r)=>a.createDownloader(m,n,r)};\nvar ka=Object.assign({},B),la=\"./this.program\",E=(a,b)=>{throw b;},ma=\"object\"==typeof window,F=\"function\"==typeof importScripts,G=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,H=B.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function na(a){return B.locateFile?B.locateFile(a,I):I+a}var oa,J,pa;\nif(G){var fs=require(\"fs\"),qa=require(\"path\");I=F?qa.dirname(I)+\"/\":__dirname+\"/\";oa=(b,c)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};pa=b=>{b=oa(b,!0);b.buffer||(b=new Uint8Array(b));return b};J=(b,c,e,f=!0)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(h,k)=>{h?e(h):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(la=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);E=(b,c)=>{process.exitCode=\nb;throw c;};B.inspect=()=>\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(ma||F)F?I=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(I=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(I=_scriptDir),0!==I.indexOf(\"blob:\")?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",G||(oa=a=>{var b=\nnew XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},F&&(pa=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),J=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)});G&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);\nvar ra=console.log.bind(console),sa=console.error.bind(console);G&&(ra=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),sa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var ta=B.print||ra,K=B.printErr||sa;Object.assign(B,ka);ka=null;B.thisProgram&&(la=B.thisProgram);B.quit&&(E=B.quit);var L;B.wasmBinary&&(L=B.wasmBinary);var noExitRuntime=B.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&M(\"no native wasm support detected\");var l,N,ua,P=!1,Q,p,aa,ba,ca,ea,ha;\nfunction u(){var a=l.buffer;B.HEAP8=p=new Int8Array(a);B.HEAP16=new Int16Array(a);B.HEAP32=ba=new Int32Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=new Uint16Array(a);B.HEAPU32=ca=new Uint32Array(a);B.HEAPF32=ea=new Float32Array(a);B.HEAPF64=ha=new Float64Array(a)}var va=B.INITIAL_MEMORY||16777216;5242880<=va||M(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+va+\"! (STACK_SIZE=5242880)\");\nif(H)l=B.wasmMemory;else if(B.wasmMemory)l=B.wasmMemory;else if(l=new WebAssembly.Memory({initial:va/65536,maximum:65536,shared:!0}),!(l.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),G&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),\nError(\"bad memory\");u();va=l.buffer.byteLength;var wa=[],xa=[],ya=[],za=0;function Aa(){return noExitRuntime||0<za}var R=0,Ba=null,S=null;function Ca(){R++;B.monitorRunDependencies&&B.monitorRunDependencies(R)}function Da(){R--;B.monitorRunDependencies&&B.monitorRunDependencies(R);if(0==R&&(null!==Ba&&(clearInterval(Ba),Ba=null),S)){var a=S;S=null;a()}}\nfunction M(a){if(B.onAbort)B.onAbort(a);a=\"Aborted(\"+a+\")\";K(a);P=!0;Q=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");C(a);throw a;}function Ea(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var T;T=\"ort-wasm-simd-threaded.wasm\";Ea(T)||(T=na(T));function Fa(a){if(a==T&&L)return new Uint8Array(L);if(pa)return pa(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction Ga(a){if(!L&&(ma||F)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Fa(a));if(J)return new Promise((b,c)=>{J(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>Fa(a))}function Ha(a,b,c){return Ga(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{K(\"failed to asynchronously prepare wasm: \"+e);M(e)})}\nfunction Ia(a,b){var c=T;return L||\"function\"!=typeof WebAssembly.instantiateStreaming||Ea(c)||c.startsWith(\"file://\")||G||\"function\"!=typeof fetch?Ha(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){K(\"wasm streaming compile failed: \"+f);K(\"falling back to ArrayBuffer instantiation\");return Ha(c,a,b)}))}\nvar U,Ja={1425328:a=>{B.Ea(\"Abs\",a,void 0)},1425379:a=>{B.Ea(\"Neg\",a,void 0)},1425430:a=>{B.Ea(\"Floor\",a,void 0)},1425483:a=>{B.Ea(\"Ceil\",a,void 0)},1425535:a=>{B.Ea(\"Reciprocal\",a,void 0)},1425593:a=>{B.Ea(\"Sqrt\",a,void 0)},1425645:a=>{B.Ea(\"Exp\",a,void 0)},1425696:a=>{B.Ea(\"Erf\",a,void 0)},1425747:a=>{B.Ea(\"Sigmoid\",a,void 0)},1425802:a=>{B.Ea(\"Log\",a,void 0)},1425853:a=>{B.Ea(\"Sin\",a,void 0)},1425904:a=>{B.Ea(\"Cos\",a,void 0)},1425955:a=>{B.Ea(\"Tan\",a,void 0)},1426006:a=>{B.Ea(\"Asin\",a,void 0)},\n1426058:a=>{B.Ea(\"Acos\",a,void 0)},1426110:a=>{B.Ea(\"Atan\",a,void 0)},1426162:a=>{B.Ea(\"Sinh\",a,void 0)},1426214:a=>{B.Ea(\"Cosh\",a,void 0)},1426266:a=>{B.Ea(\"Asinh\",a,void 0)},1426319:a=>{B.Ea(\"Acosh\",a,void 0)},1426372:a=>{B.Ea(\"Atanh\",a,void 0)},1426425:a=>{B.Ea(\"Tanh\",a,void 0)},1426477:a=>{B.Ea(\"Not\",a,void 0)},1426528:(a,b,c)=>{B.Ea(\"Clip\",a,{min:b,max:c})},1426597:a=>{B.Ea(\"Clip\",a,void 0)},1426649:(a,b)=>{B.Ea(\"Elu\",a,{alpha:b})},1426707:a=>{B.Ea(\"Relu\",a,void 0)},1426759:(a,b)=>{B.Ea(\"LeakyRelu\",\na,{alpha:b})},1426823:(a,b)=>{B.Ea(\"ThresholdedRelu\",a,{alpha:b})},1426893:a=>{B.zb(a)},1426927:(a,b)=>B.Ab(a,b,B.bb.Fb,B.bb.errors),1427039:(a,b)=>{B.Ea(\"Cast\",a,{to:b})},1427097:a=>{B.Ea(\"Add\",a,void 0)},1427148:a=>{B.Ea(\"Sub\",a,void 0)},1427199:a=>{B.Ea(\"Mul\",a,void 0)},1427250:a=>{B.Ea(\"Div\",a,void 0)},1427301:a=>{B.Ea(\"Pow\",a,void 0)},1427352:a=>{B.Ea(\"Equal\",a,void 0)},1427405:a=>{B.Ea(\"Greater\",a,void 0)},1427460:a=>{B.Ea(\"GreaterOrEqual\",a,void 0)},1427522:a=>{B.Ea(\"Less\",a,void 0)},1427574:a=>\n{B.Ea(\"LessOrEqual\",a,void 0)},1427633:(a,b,c,e,f)=>{B.Ea(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1427797:(a,b,c,e,f)=>{B.Ea(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1427960:(a,b,c,e,f)=>{B.Ea(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428123:(a,b,c,e,f)=>{B.Ea(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?\nArray.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428287:(a,b,c,e,f)=>{B.Ea(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428450:(a,b,c,e,f)=>{B.Ea(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428612:(a,b,c,e,f)=>{B.Ea(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428774:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1428940:(a,b,c,e,f)=>{B.Ea(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1429109:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1429278:a=>{B.Ea(\"Where\",a,void 0)},1429331:(a,b,c)=>{B.Ea(\"Transpose\",a,{perm:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[]})},1429444:(a,b,c,e,f,h,k,q,m,n,r,w,y)=>{B.Ea(\"Conv\",\na,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[],strides:[q],w_is_const:()=>!!d()[n>>>0],activation:V(r),activation_params:w?Array.from(da().subarray(y>>>0,y+w>>>0)):[]})},1429825:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"Conv\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,k],pads:q?Array.from(z().subarray(m>>>0,m+q>>>0)):[],strides:[n,r],w_is_const:()=>!!d()[y>>>0],activation:V(g),activation_params:t?\nArray.from(da().subarray(x>>>0,x+t>>>0)):[]})},1430227:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},1430641:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>\n0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},1431198:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>\n!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},1431612:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>\n0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},1432169:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1432260:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},1432544:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1432635:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"AveragePool\",\na,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},1432919:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1433006:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},1433286:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1433373:(a,\nb,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},1433653:(a,b,c,e,f)=>{B.Ea(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},1433757:a=>{B.Ea(\"MatMul\",a,void 0)},1433811:(a,b,c,e)=>{B.Ea(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},1433919:(a,b,c,e)=>{B.Ea(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},1434027:(a,b)=>{B.Ea(\"Softmax\",\na,{axis:b})},1434090:(a,b)=>{B.Ea(\"Concat\",a,{axis:b})},1434150:(a,b,c,e,f)=>{B.Ea(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1434295:a=>{B.Ea(\"Expand\",a,void 0)},1434349:(a,b)=>{B.Ea(\"Gather\",a,{axis:Number(b)})},1434420:(a,b)=>{B.Ea(\"GatherElements\",a,{axis:Number(b)})},1434499:(a,b,c,e,f,h,k,q,m,n,r)=>{B.Ea(\"Resize\",a,{antialias:b,axes:c?Array.from(z().subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:V(f),cubicCoeffA:h,excludeOutside:k,extrapolationValue:q,\nkeepAspectRatioPolicy:V(m),mode:V(n),nearestMode:V(r)})},1434850:(a,b,c,e,f,h,k)=>{B.Ea(\"Slice\",a,{starts:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[]})},1435081:a=>{B.Ea(\"Tile\",a,void 0)},1435133:(a,b,c)=>{B.Ea(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},1435240:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1435354:(a,b,c)=>{B.Ea(\"InstanceNormalization\",\na,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1435468:a=>{B.Ea(\"Range\",a,void 0)},1435521:(a,b)=>{B.Ea(\"Einsum\",a,{equation:V(b)})},1435602:(a,b,c,e,f)=>{B.Ea(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},1435734:(a,b,c,e,f,h,k,q,m)=>{B.Ea(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h,qkvHiddenSizes:k?Array.from(z().subarray(Number(q)>>>0,Number(q)+k>>>0)):[],pastPresentShareBuffer:!!m})},1436006:a=>{B.Ea(\"Gelu\",a,void 0)},1436058:(a,b,c,\ne,f,h)=>{B.Ea(\"MultiHeadAttention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h})},1436217:a=>{B.Ea(\"BiasAdd\",a,void 0)},1436272:a=>{B.Ea(\"BiasSplitGelu\",a,void 0)},1436333:(a,b)=>{B.Ea(\"SkipLayerNormalization\",a,{epsilon:b})},1436414:a=>B.wb(a),1436447:a=>B.yb(a),1436479:(a,b,c)=>{B.jb(a,b,c,!0)},1436518:(a,b,c)=>{B.jb(a,b,c)}};function Ka(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}\nfunction La(a){a.terminate();a.onmessage=()=>{}}function Ma(a){(a=W.Qa[a])||M();W.Eb(a)}function Na(a){var b=W.tb();if(!b)return 6;W.Ya.push(b);W.Qa[a.Xa]=b;b.Xa=a.Xa;var c={cmd:\"run\",start_routine:a.Gb,arg:a.rb,pthread_ptr:a.Xa};G&&b.unref();b.postMessage(c,a.Mb);return 0}\nvar Oa=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Pa=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Oa)return Oa.decode(a.buffer instanceof SharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|k:(f&7)<<18|h<<12|k<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>\n10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},V=(a,b)=>(a>>>=0)?Pa(v(),a,b):\"\";function Qa(a){if(H)return X(1,1,a);Q=a;if(!Aa()){W.Hb();if(B.onExit)B.onExit(a);P=!0}E(a,new Ka(a))}\nvar Sa=a=>{Q=a;if(H)throw Ra(a),\"unwind\";Qa(a)},W={ab:[],Ya:[],mb:[],Qa:{},gb:function(){H?W.vb():W.ub()},ub:function(){wa.unshift(()=>{Ca();W.Bb(()=>Da())})},vb:function(){W.receiveObjectTransfer=W.Db;W.threadInitTLS=W.lb;W.setExitStatus=W.kb;noExitRuntime=!1},kb:function(a){Q=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of W.Ya)La(a);for(a of W.ab)La(a);W.ab=[];W.Ya=[];W.Qa=[]},Eb:function(a){var b=a.Xa;delete W.Qa[b];W.ab.push(a);W.Ya.splice(W.Ya.indexOf(a),1);a.Xa=0;Ta(b)},Db:function(){},\nlb:function(){W.mb.forEach(a=>a())},Cb:a=>new Promise(b=>{a.onmessage=h=>{h=h.data;var k=h.cmd;if(h.targetThread&&h.targetThread!=Ua()){var q=W.Qa[h.Rb];q?q.postMessage(h,h.transferList):K('Internal error! Worker sent a message \"'+k+'\" to target pthread '+h.targetThread+\", but that thread no longer exists!\")}else if(\"checkMailbox\"===k)Va();else if(\"spawnThread\"===k)Na(h);else if(\"cleanupThread\"===k)Ma(h.thread);else if(\"killThread\"===k)h=h.thread,k=W.Qa[h],delete W.Qa[h],La(k),Ta(h),W.Ya.splice(W.Ya.indexOf(k),\n1),k.Xa=0;else if(\"cancelThread\"===k)W.Qa[h.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,b(a);else if(\"alert\"===k)alert(\"Thread \"+h.threadId+\": \"+h.text);else if(\"setimmediate\"===h.target)a.postMessage(h);else if(\"callHandler\"===k)B[h.handler](...h.args);else k&&K(\"worker sent an unknown command \"+k)};a.onerror=h=>{K(\"worker sent an error! \"+h.filename+\":\"+h.lineno+\": \"+h.message);throw h;};G&&(a.on(\"message\",function(h){a.onmessage({data:h})}),a.on(\"error\",function(h){a.onerror(h)}));\nvar c=[],e=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],f;for(f of e)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:l,wasmModule:ua})}),Bb:function(a){a()},qb:function(){var a=na(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a);W.ab.push(a)},tb:function(){0==W.ab.length&&(W.qb(),W.Cb(W.ab[0]));return W.ab.pop()}};B.PThread=W;var Wa=a=>{for(;0<a.length;)a.shift()(B)};\nB.establishStackSpace=function(){var a=Ua(),b=z()[a+52>>2>>>0];a=z()[a+56>>2>>>0];Xa(b,b-a);Ya(b)};function Ra(a){if(H)return X(2,0,a);Sa(a)}B.invokeEntryPoint=function(a,b){a=Za.apply(null,[a,b]);Aa()?W.kb(a):$a(a)};function ab(a){this.fb=a-24;this.pb=function(b){A()[this.fb+4>>2>>>0]=b};this.ob=function(b){A()[this.fb+8>>2>>>0]=b};this.gb=function(b,c){this.nb();this.pb(b);this.ob(c)};this.nb=function(){A()[this.fb+16>>2>>>0]=0}}var bb=0,cb=0;\nfunction db(a,b,c,e){return H?X(3,1,a,b,c,e):eb(a,b,c,e)}function eb(a,b,c,e){a>>>=0;b>>>=0;c>>>=0;e>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(H&&0===f.length)return db(a,b,c,e);a={Gb:c,Xa:a,rb:e,Mb:f};return H?(a.Ob=\"spawnThread\",postMessage(a,f),0):Na(a)}function fb(a,b,c){return H?X(4,1,a,b,c):0}function gb(a,b){if(H)return X(5,1,a,b)}\nvar hb=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},ib=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var k=a.charCodeAt(h);if(55296<=k&&57343>=k){var q=a.charCodeAt(++h);k=65536+((k&1023)<<10)|q&1023}if(127>=k){if(c>=e)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=e)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=e)break;b[c++>>>0]=224|k>>12}else{if(c+3>=e)break;b[c++>>>0]=240|k>>\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},jb=(a,b,c)=>ib(a,v(),b,c);function kb(a,b){if(H)return X(6,1,a,b)}function lb(a,b,c){if(H)return X(7,1,a,b,c)}function mb(a,b,c){return H?X(8,1,a,b,c):0}function nb(a,b){if(H)return X(9,1,a,b)}function ob(a,b,c){if(H)return X(10,1,a,b,c)}function pb(a,b,c,e){if(H)return X(11,1,a,b,c,e)}function qb(a,b,c,e){if(H)return X(12,1,a,b,c,e)}function rb(a,b,c,e){if(H)return X(13,1,a,b,c,e)}\nfunction sb(a){if(H)return X(14,1,a)}function tb(a,b){if(H)return X(15,1,a,b)}function ub(a,b,c){if(H)return X(16,1,a,b,c)}var vb=a=>{if(!P)try{if(a(),!Aa())try{H?$a(Q):Sa(Q)}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}};function wb(a){a>>>=0;\"function\"===typeof Atomics.Nb&&(Atomics.Nb(z(),a>>2,a).value.then(Va),a+=128,Atomics.store(z(),a>>2,1))}B.__emscripten_thread_mailbox_await=wb;function Va(){var a=Ua();a&&(wb(a),vb(()=>xb()))}B.checkMailbox=Va;\nvar Y=a=>0===a%4&&(0!==a%100||0===a%400),yb=[0,31,60,91,121,152,182,213,244,274,305,335],zb=[0,31,59,90,120,151,181,212,243,273,304,334];function Ab(a,b,c,e,f,h,k,q){return H?X(17,1,a,b,c,e,f,h,k,q):-52}function Bb(a,b,c,e,f,h,k){if(H)return X(18,1,a,b,c,e,f,h,k)}var Db=a=>{var b=hb(a)+1,c=Cb(b);c&&jb(a,c,b);return c},Eb=[],Fb=(a,b)=>{Eb.length=0;var c;for(b>>=2;c=v()[a++>>>0];)b+=105!=c&b,Eb.push(105==c?z()[b>>>0]:fa()[b++>>>1]),++b;return Eb},Hb=a=>{var b=Gb();a=a();Ya(b);return a};\nfunction X(a,b){var c=arguments.length-2,e=arguments;return Hb(()=>{for(var f=Ib(8*c),h=f>>3,k=0;k<c;k++){var q=e[2+k];fa()[h+k>>>0]=q}return Jb(a,c,f,b)})}\nvar Kb=[],Lb={},Nb=()=>{if(!Mb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:la||\"./this.program\"},b;for(b in Lb)void 0===Lb[b]?delete a[b]:a[b]=Lb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Mb=c}return Mb},Mb;\nfunction Ob(a,b){if(H)return X(19,1,a,b);a>>>=0;b>>>=0;var c=0;Nb().forEach(function(e,f){var h=b+c;f=A()[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)d()[f++>>0>>>0]=e.charCodeAt(h);d()[f>>0>>>0]=0;c+=e.length+1});return 0}function Pb(a,b){if(H)return X(20,1,a,b);a>>>=0;b>>>=0;var c=Nb();A()[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});A()[b>>2>>>0]=e;return 0}function Qb(a){return H?X(21,1,a):52}function Rb(a,b,c,e){return H?X(22,1,a,b,c,e):52}\nfunction Sb(a,b,c,e,f){return H?X(23,1,a,b,c,e,f):70}var Tb=[null,[],[]];function Vb(a,b,c,e){if(H)return X(24,1,a,b,c,e);b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var k=A()[b>>2>>>0],q=A()[b+4>>2>>>0];b+=8;for(var m=0;m<q;m++){var n=v()[k+m>>>0],r=Tb[a];0===n||10===n?((1===a?ta:K)(Pa(r,0)),r.length=0):r.push(n)}f+=q}A()[e>>2>>>0]=f;return 0}var Wb=[31,29,31,30,31,30,31,31,30,31,30,31],Xb=[31,28,31,30,31,30,31,31,30,31,30,31];function Yb(a){var b=Array(hb(a)+1);ib(a,b,0,b.length);return b}\nvar Zb=(a,b)=>{d().set(a,b>>>0)};\nfunction $b(a,b,c,e){function f(g,t,x){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<t;)g=x[0]+g;return g}function h(g,t){return f(g,t,\"0\")}function k(g,t){function x(Ub){return 0>Ub?-1:0<Ub?1:0}var O;0===(O=x(g.getFullYear()-t.getFullYear()))&&0===(O=x(g.getMonth()-t.getMonth()))&&(O=x(g.getDate()-t.getDate()));return O}function q(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var t=g.Za;for(g=new Date((new Date(g.$a+1900,0,1)).getTime());0<t;){var x=g.getMonth(),O=(Y(g.getFullYear())?Wb:Xb)[x];if(t>O-g.getDate())t-=O-g.getDate()+1,g.setDate(1),11>x?g.setMonth(x+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+t);break}}x=new Date(g.getFullYear()+1,0,4);t=q(new Date(g.getFullYear(),\n0,4));x=q(x);return 0>=k(t,g)?0>=k(x,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var n=z()[e+40>>2>>>0];e={Kb:z()[e>>2>>>0],Jb:z()[e+4>>2>>>0],cb:z()[e+8>>2>>>0],ib:z()[e+12>>2>>>0],eb:z()[e+16>>2>>>0],$a:z()[e+20>>2>>>0],Wa:z()[e+24>>2>>>0],Za:z()[e+28>>2>>>0],Tb:z()[e+32>>2>>>0],Ib:z()[e+36>>2>>>0],Lb:n?V(n):\"\"};c=V(c);n={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\n\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var r in n)c=c.replace(new RegExp(r,\"g\"),n[r]);var w=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),y=\"January February March April May June July August September October November December\".split(\" \");n={\"%a\":g=>w[g.Wa].substring(0,3),\"%A\":g=>w[g.Wa],\"%b\":g=>\ny[g.eb].substring(0,3),\"%B\":g=>y[g.eb],\"%C\":g=>h((g.$a+1900)/100|0,2),\"%d\":g=>h(g.ib,2),\"%e\":g=>f(g.ib,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.cb,2),\"%I\":g=>{g=g.cb;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var t=0,x=0;x<=g.eb-1;t+=(Y(g.$a+1900)?Wb:Xb)[x++]);return h(g.ib+t,3)},\"%m\":g=>h(g.eb+1,2),\"%M\":g=>h(g.Jb,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.cb&&12>g.cb?\"AM\":\"PM\",\"%S\":g=>h(g.Kb,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Wa||7,\"%U\":g=>h(Math.floor((g.Za+7-g.Wa)/7),2),\"%V\":g=>\n{var t=Math.floor((g.Za+7-(g.Wa+6)%7)/7);2>=(g.Wa+371-g.Za-2)%7&&t++;if(t)53==t&&(x=(g.Wa+371-g.Za)%7,4==x||3==x&&Y(g.$a)||(t=1));else{t=52;var x=(g.Wa+7-g.Za-1)%7;(4==x||5==x&&Y(g.$a%400-1))&&t++}return h(t,2)},\"%w\":g=>g.Wa,\"%W\":g=>h(Math.floor((g.Za+7-(g.Wa+6)%7)/7),2),\"%y\":g=>(g.$a+1900).toString().substring(2),\"%Y\":g=>g.$a+1900,\"%z\":g=>{g=g.Ib;var t=0<=g;g=Math.abs(g)/60;return(t?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Lb,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(r in n)c.includes(r)&&\n(c=c.replace(new RegExp(r,\"g\"),n[r](e)));c=c.replace(/\\0\\0/g,\"%\");r=Yb(c);if(r.length>b)return 0;Zb(r,a);return r.length-1}function ac(a){try{a()}catch(b){M(b)}}function bc(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){cc.push(e);try{return f.apply(null,arguments)}finally{P||(cc.pop()===e||M(),D&&1===Z&&0===cc.length&&(Z=0,za+=1,ac(dc),\"undefined\"!=typeof Fibers&&Fibers.Ub()))}}:f})(c);return b}var Z=0,D=null,ec=0,cc=[],fc={},gc={},hc=0,ic=null,jc=[];\nfunction ja(){return new Promise((a,b)=>{ic={resolve:a,reject:b}})}function kc(){var a=Cb(65548),b=a+12;A()[a>>2>>>0]=b;A()[a+4>>2>>>0]=b+65536;b=cc[0];var c=fc[b];void 0===c&&(c=hc++,fc[b]=c,gc[c]=b);b=c;z()[a+8>>2>>>0]=b;return a}function lc(){var a=z()[D+8>>2>>>0];a=N[gc[a]];--za;return a()}\nfunction mc(a){if(!P){if(0===Z){var b=!1,c=!1;a((e=0)=>{if(!P&&(ec=e,b=!0,c)){Z=2;ac(()=>nc(D));\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.resume();e=!1;try{var f=lc()}catch(q){f=q,e=!0}var h=!1;if(!D){var k=ic;k&&(ic=null,(e?k.reject:k.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Z=1,D=kc(),\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.pause(),ac(()=>oc(D)))}else 2===Z?(Z=0,ac(pc),qc(D),D=null,jc.forEach(e=>vb(e))):M(`invalid state: ${Z}`);return ec}}\nfunction rc(a){return mc(b=>{a().then(b)})}W.gb();\nvar sc=[null,Qa,Ra,db,fb,gb,kb,lb,mb,nb,ob,pb,qb,rb,sb,tb,ub,Ab,Bb,Ob,Pb,Qb,Rb,Sb,Vb],vc={r:function(a,b,c){return rc(async()=>{await B.xb(a,b,c)})},b:function(a,b,c){a>>>=0;(new ab(a)).gb(b>>>0,c>>>0);bb=a;cb++;throw bb;},P:function(a){tc(a>>>0,!F,1,!ma,131072,!1);W.lb()},n:function(a){a>>>=0;H?postMessage({cmd:\"cleanupThread\",thread:a}):Ma(a)},K:eb,g:fb,V:gb,F:kb,H:lb,y:mb,T:nb,L:ob,S:pb,p:qb,G:rb,D:sb,U:tb,E:ub,q:()=>!0,B:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>Va()):H?postMessage({targetThread:a,\ncmd:\"checkMailbox\"}):(a=W.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},N:function(){return-1},O:wb,X:function(a){G&&W.Qa[a>>>0].ref()},u:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getUTCSeconds();z()[c+4>>2>>>0]=a.getUTCMinutes();z()[c+8>>2>>>0]=a.getUTCHours();z()[c+12>>2>>>0]=a.getUTCDate();z()[c+16>>2>>>0]=a.getUTCMonth();z()[c+20>>2>>>0]=a.getUTCFullYear()-1900;z()[c+24>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),\n0,1,0,0,0,0))/864E5|0;z()[c+28>>2>>>0]=a},v:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getSeconds();z()[c+4>>2>>>0]=a.getMinutes();z()[c+8>>2>>>0]=a.getHours();z()[c+12>>2>>>0]=a.getDate();z()[c+16>>2>>>0]=a.getMonth();z()[c+20>>2>>>0]=a.getFullYear()-1900;z()[c+24>>2>>>0]=a.getDay();b=(Y(a.getFullYear())?yb:zb)[a.getMonth()]+a.getDate()-1|0;z()[c+28>>2>>>0]=b;z()[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),\n6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0;z()[c+32>>2>>>0]=a},w:function(a){a>>>=0;var b=new Date(z()[a+20>>2>>>0]+1900,z()[a+16>>2>>>0],z()[a+12>>2>>>0],z()[a+8>>2>>>0],z()[a+4>>2>>>0],z()[a>>2>>>0],0),c=z()[a+32>>2>>>0],e=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(h,f);0>c?z()[a+32>>2>>>0]=Number(f!=h&&k==e):\n0<c!=(k==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-e)));z()[a+24>>2>>>0]=b.getDay();c=(Y(b.getFullYear())?yb:zb)[b.getMonth()]+b.getDate()-1|0;z()[a+28>>2>>>0]=c;z()[a>>2>>>0]=b.getSeconds();z()[a+4>>2>>>0]=b.getMinutes();z()[a+8>>2>>>0]=b.getHours();z()[a+12>>2>>>0]=b.getDate();z()[a+16>>2>>>0]=b.getMonth();z()[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return uc((U=a,1<=+Math.abs(U)?0<U?+Math.floor(U/4294967296)>>>0:~~+Math.ceil((U-+(~~U>>>0))/4294967296)>>>0:0)),a>>>0},s:Ab,t:Bb,\nA:function(a,b,c){function e(n){return(n=n.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?n[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),k=new Date(f,6,1);f=h.getTimezoneOffset();var q=k.getTimezoneOffset(),m=Math.max(f,q);A()[a>>2>>>0]=60*m;z()[b>>2>>>0]=Number(f!=q);a=e(h);b=e(k);a=Db(a);b=Db(b);q<f?(A()[c>>2>>>0]=a,A()[c+4>>2>>>0]=b):(A()[c>>2>>>0]=b,A()[c+4>>2>>>0]=a)},e:()=>{M(\"\")},c:function(a,b,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},l:function(a,\nb,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},o:function(){},k:function(){return Date.now()},W:()=>{za+=1;throw\"unwind\";},C:function(){return 4294901760},d:()=>performance.timeOrigin+performance.now(),i:function(){return G?require(\"os\").cpus().length:navigator.hardwareConcurrency},M:function(a,b,c,e){W.Pb=b>>>0;Kb.length=c;b=e>>>0>>3;for(e=0;e<c;e++)Kb[e]=fa()[b+e>>>0];return(0>a?Ja[-a-1]:sc[a]).apply(null,Kb)},z:function(a){a>>>=0;var b=v().length;if(a<=b||4294901760<a)return!1;for(var c=\n1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;e=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-l.buffer.byteLength+65535>>>16;try{l.grow(f);u();var h=1;break a}catch(k){}h=void 0}if(h)return!0}return!1},Q:Ob,R:Pb,J:Sa,h:Qb,m:Rb,x:Sb,j:Vb,a:l||B.wasmMemory,I:$b,f:function(a,b,c,e){return $b(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c,e){c=c.exports;c=bc(c);N=c=wc(c);W.mb.push(N.Da);xa.unshift(N.Y);ua=e;Da();return c}var b={a:vc};Ca();if(B.instantiateWasm)try{return B.instantiateWasm(b,a)}catch(c){K(\"Module.instantiateWasm callback failed with error: \"+c),C(c)}Ia(b,function(c){a(c.instance,c.module)}).catch(C);return{}})();B._OrtInit=(a,b)=>(B._OrtInit=N.Z)(a,b);B._OrtGetLastError=(a,b)=>(B._OrtGetLastError=N._)(a,b);\nB._OrtCreateSessionOptions=(a,b,c,e,f,h,k,q,m,n)=>(B._OrtCreateSessionOptions=N.$)(a,b,c,e,f,h,k,q,m,n);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=N.aa)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=N.ba)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=N.ca)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=N.da)(a);B._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=N.ea)(a,b,c);\nB._OrtReleaseSession=a=>(B._OrtReleaseSession=N.fa)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=N.ga)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=N.ha)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=N.ia)(a,b);B._OrtFree=a=>(B._OrtFree=N.ja)(a);B._OrtCreateTensor=(a,b,c,e,f,h)=>(B._OrtCreateTensor=N.ka)(a,b,c,e,f,h);B._OrtGetTensorData=(a,b,c,e,f)=>(B._OrtGetTensorData=N.la)(a,b,c,e,f);B._OrtReleaseTensor=a=>(B._OrtReleaseTensor=N.ma)(a);\nB._OrtCreateRunOptions=(a,b,c,e)=>(B._OrtCreateRunOptions=N.na)(a,b,c,e);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=N.oa)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=N.pa)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=N.qa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=N.ra)(a,b,c);B._OrtBindOutput=(a,b,c,e)=>(B._OrtBindOutput=N.sa)(a,b,c,e);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=N.ta)(a);B._OrtReleaseBinding=a=>(B._OrtReleaseBinding=N.ua)(a);\nB._OrtRunWithBinding=(a,b,c,e,f)=>(B._OrtRunWithBinding=N.va)(a,b,c,e,f);B._OrtRun=(a,b,c,e,f,h,k,q)=>(B._OrtRun=N.wa)(a,b,c,e,f,h,k,q);B._OrtEndProfiling=a=>(B._OrtEndProfiling=N.xa)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=N.ya)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=N.za)(a);var Ua=B._pthread_self=()=>(Ua=B._pthread_self=N.Aa)(),Cb=B._malloc=a=>(Cb=B._malloc=N.Ba)(a),qc=B._free=a=>(qc=B._free=N.Ca)(a);B.__emscripten_tls_init=()=>(B.__emscripten_tls_init=N.Da)();\nvar tc=B.__emscripten_thread_init=(a,b,c,e,f,h)=>(tc=B.__emscripten_thread_init=N.Fa)(a,b,c,e,f,h);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=N.Ga)();\nvar Jb=(a,b,c,e)=>(Jb=N.Ha)(a,b,c,e),Ta=a=>(Ta=N.Ia)(a),$a=B.__emscripten_thread_exit=a=>($a=B.__emscripten_thread_exit=N.Ja)(a),xb=B.__emscripten_check_mailbox=()=>(xb=B.__emscripten_check_mailbox=N.Ka)(),uc=a=>(uc=N.La)(a),Xa=(a,b)=>(Xa=N.Ma)(a,b),Gb=()=>(Gb=N.Na)(),Ya=a=>(Ya=N.Oa)(a),Ib=a=>(Ib=N.Pa)(a),Za=B.dynCall_ii=(a,b)=>(Za=B.dynCall_ii=N.Ra)(a,b),oc=a=>(oc=N.Sa)(a),dc=()=>(dc=N.Ta)(),nc=a=>(nc=N.Ua)(a),pc=()=>(pc=N.Va)();B.___start_em_js=1436551;B.___stop_em_js=1436712;\nfunction wc(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.pthread_self=b(a.pthread_self);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}B.keepRuntimeAlive=Aa;B.wasmMemory=l;B.stackAlloc=Ib;B.stackSave=Gb;B.stackRestore=Ya;B.UTF8ToString=V;B.stringToUTF8=jb;B.lengthBytesUTF8=hb;B.ExitStatus=Ka;B.PThread=W;var xc;S=function yc(){xc||zc();xc||(S=yc)};\nfunction zc(){function a(){if(!xc&&(xc=!0,B.calledRun=!0,!P)){H||Wa(xa);ia(B);if(B.onRuntimeInitialized)B.onRuntimeInitialized();if(!H){if(B.postRun)for(\"function\"==typeof B.postRun&&(B.postRun=[B.postRun]);B.postRun.length;){var b=B.postRun.shift();ya.unshift(b)}Wa(ya)}}}if(!(0<R))if(H)ia(B),H||Wa(xa),startWorker(B);else{if(B.preRun)for(\"function\"==typeof B.preRun&&(B.preRun=[B.preRun]);B.preRun.length;)wa.unshift(B.preRun.shift());Wa(wa);0<R||(B.setStatus?(B.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){B.setStatus(\"\")},\n1);a()},1)):a())}}if(B.preInit)for(\"function\"==typeof B.preInit&&(B.preInit=[B.preInit]);0<B.preInit.length;)B.preInit.pop()();zc();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasmThreaded;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasmThreaded);\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.numThreads) {\n                let numThreads = webnnOptions.numThreads;\n                // Just ignore invalid webnnOptions.numThreads.\n                if (typeof numThreads != 'number' || !Number.isInteger(numThreads) || numThreads < 0) {\n                  numThreads = 0;\n                }\n                const keyDataOffset = allocWasmString('numThreads', allocs);\n                const valueDataOffset = allocWasmString(numThreads.toString(), allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'numThreads' - ${webnnOptions.numThreads}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private key: string;\n  public get cacheKey(): string {\n    if (!this.key) {\n      this.key =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this.key;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input or an output) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input or an output.\n   */\n  readonly usage: 'input'|'output';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]): ProgramUniform[] =>\n    dims.length === 0 ? [] : [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}f(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param isInput - whether the helper is for an input or an output.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], isInput: boolean,\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${strides}[${i}];\n    let rest${i} = current % ${strides}[${i}];\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${strides}[${i}] * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${varIndices}[${idx}]`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${varIndices}[${idx}]=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        if (!useUniform) {\n          impls.push(`const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`);\n          impls.push(`const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage: isInput ? 'input' : 'output',\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, true, components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, false, components);\n\nexport type UniformsArrayType = Array<{name: string; type: string}>;\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   */\n  registerUniform(name: string, type: string): ShaderHelper;\n  registerUniforms(nameToTypeMap: UniformsArrayType): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x;' :\n        `let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_index;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    this.indicesHelpers.push(variable);\n    if (variable.rank !== 0) {\n      if (variable.shape.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: variable.type.indices});\n      }\n      if (variable.strides.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: variable.type.indices});\n      }\n    }\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  registerUniform(name: string, type: string): ShaderHelper {\n    this.uniforms.push({name, type});\n    return this;\n  }\n\n  registerUniforms(additionalUniforms: UniformsArrayType): ShaderHelper {\n    this.uniforms = this.uniforms.concat(additionalUniforms);\n    return this;\n  }\n\n  private indicesHelpers: IndicesHelper[] = [];\n  private uniforms: UniformsArrayType = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type} of this.uniforms) {\n      uniformSnippets.push(`${name}:${type}`);\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.indicesHelpers.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n\n// TODO: remove this limitation once >4D dims are supported by uniform.\nexport const enableShapesUniforms = (rank: number): boolean => rank <= 4;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const useShapesUniforms = enableShapesUniforms(inputRank);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  const outShapeOrRank = useShapesUniforms ? outputShape.length : outputShape;\n  const inShapeOrRank = useShapesUniforms ? inputRank : inputTensor.dims;\n  const output = outputVariable('output', inputDataType, outShapeOrRank);\n  const input = inputVariable('a', inputDataType, inShapeOrRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  return {\n    name: 'Transpose',\n    shaderCache: {hint: `${permAttr}`, inputDependencies: useShapesUniforms ? ['rank'] : ['dims']},\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n        dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        programUniforms: useShapesUniforms ?\n            [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ] :\n            [\n              {type: 'uint32', data: outputSize},\n            ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {createReduceAttributesFromInputs, ReduceAttributes} from './reduce';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst reduceOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceSharedOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceInitValues: {[key: string]: string} = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0'\n};\n\nconst reduceOutputValues: {[key: string]: string} = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)'\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach(axis => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceType: string,\n     outputDataType: DataType, outputShape: number[], reduceShape: number[]): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const reduceSize = ShapeUtil.size(reduceShape);\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n\n      const workgroupSize = 32;\n\n      const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<${output.type.storage}, ${workgroupSize}>;\n       `;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${output.type.storage}(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = ${output.type.storage}(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${\n          output.setByOffset(\n              'outputIndex',\n              `${\n                  reduceType === 'mean' ? `bestValue / ${output.type.storage}(uniforms.reduceSize)` :\n                                          `${reduceOutputValues[reduceType]}`}`)};\n         }\n        }`;\n\n      // One work group is responsible for only one element of output.\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: outputSize},\n          programUniforms: [{type: 'uint32', data: reduceSize}]\n        }),\n      };\n    };\n\nconst reduceCommon =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes,\n     reduceType: 'sum'|'sumSquare'|'prod'|'min'|'max'|'mean'|'logSumExp'|'l1'|'l2'|'logSum'): void => {\n      const updatedAttributes: ReduceAttributes =\n          context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n      let updatedAxes = updatedAttributes.axes;\n      if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n        updatedAxes = context.inputs[0].dims.map((_dim, i) => i);\n      }\n      const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n      let axes = normalizeAxes;\n      let input = context.inputs[0];\n      const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n      if (permutedAxes.length > 0) {\n        input = context.compute(\n            createTransposeProgramInfo(context.inputs[0], permutedAxes), {inputs: [0], outputs: [-1]})[0];\n        axes = getInnerMostAxes(axes.length, input.dims.length);\n      }\n\n      const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n      let finalOutputShape = outputShape;\n      if (updatedAttributes.keepDims) {\n        finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n      }\n\n      context.compute(\n          createReduceSharedProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['type']}, [input], reduceType,\n              context.inputs[0].dataType, finalOutputShape, reduceShape),\n          {inputs: [input]});\n    };\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\nimport {reduceL1Shared, reduceL2Shared, reduceLogSumExpShared, reduceLogSumShared, reduceMaxShared, reduceMeanShared, reduceMinShared, reduceProdShared, reduceSumShared, reduceSumSquareShared} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByOffset('inputOffset')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputs[0].dims.length);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n\n      const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n      const ops = reduceOp(input, output, axes);\n      const inputOffsetAssignment = `inputOffset = ${input.indicesToOffset('inputIndices')};`;\n      const initinputOffsetLet = `let ${inputOffsetAssignment};`;\n      const initinputOffsetVar = `var ${inputOffsetAssignment};`;\n      const initinputOffset = (ops[1] === '') ? '' : initinputOffsetVar;\n      let reduceOps = ((ops[1] === '') ? initinputOffsetLet : inputOffsetAssignment) + '\\n' + ops[2];\n\n      for (let k = 0, l = 0; k < inputs[0].dims.length; k++) {\n        // if this axis is reduced\n        if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n          if (keepDims) {\n            l++;\n          }\n          // loop over the d-th axis\n          reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputs[0].dims[k]}; j${k}++) {\n                ${ops[2].includes('lastIndex') ? `let lastIndex = j${k};` : ''}\n                ${input.indicesSet('inputIndices', k, `j${k}`)}\n                ${reduceOps}\n              }`;\n        } else {\n          idxCopy.push(`${input.indicesSet('inputIndices', k, output.indicesGet('outputIndices', l))};`);\n          l++;\n        }\n      }\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          var inputIndices: ${input.type.indices};\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${initinputOffset}\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n      };\n    };\n\nexport const createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByOffset('inputOffset')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByOffset('inputOffset')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('inputIndices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = max(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByOffset('inputOffset')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = min(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod =\n    (shape: readonly number[], axes: readonly number[], noopWithEmptyAxes: boolean): boolean => {\n      if (axes.length === 0) {\n        return noopWithEmptyAxes ? true : false;\n      }\n\n      let outputSize = 1;\n      let reduceSize = 1;\n      for (let dim = 0; dim < axes.length; dim++) {\n        if (axes.indexOf(dim) === -1) {\n          outputSize *= shape[dim];\n        } else {\n          reduceSize *= shape[dim];\n        }\n      }\n\n      // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n      // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n      // on some machines.\n      return reduceSize < 32 && outputSize > 1024 ? true : false;\n    };\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n\nexport const parseReduceAttributes = (attributes: Record<string, unknown>): ReduceAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ReduceAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: attributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [attributes.axis], DataType.int64,\n          attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: attributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [attributes.axis], DataType.int64,\n          attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, GpuDataType} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nexport const enum AttentionQkvFormat {\n  unknown,          // enum value not set, or depends on qkv projection implementation details\n  qkvBNSH,          // for non-packed qkv, permuted\n  qkvBSNH,          // for non-packed qkv, not permuted, used by memory efficient attention or MultiHeadAttention\n  qkvBSN3H,         // for TRT fused attention, qkv are packed\n  qkvBNSHqkvBS3NH,  // for TRT fused causal attention, data has two formats (qkv is 3BNSH, gemm_buffer is BS3NH)\n  qKvBSNHxBSN2H,    // for TRT fused cross attention, kv are packed\n  qkvTNH,           // for memory efficient attention, qkv are not packed, and paddings are removed.\n  qkvTN3H,          // for TRT fused attention, qkv are packed and paddings are removed\n}\n\nexport const enum AttentionMaskType {\n  none,                  // No mask\n  mask1dKeySeqLen,       // [batch_size], key sequence length\n  mask1dEndStart,        // [2 * batch_size] with end positions and start positions\n  mask1DKeySeqLenStart,  // [3 * batch_size + 2] with [key_len[0], ..., key_len[batch_size - 1], query_start[0],\n                         // ..., query_start[batch_size - 1], query_end[batch_size - 1], key_start[0], ...,\n                         // key_start[batch_size - 1], key_end[batch_size - 1]]\n  mask2dDummy,           // dummy mask with shape [1, 1] or [batch_size, 1]. It has same effect as no mask.\n  mask2dKeyPadding,      // [batch_size, total_sequence_length]\n  mask3dAttention,       // [batch_size, sequence_length, total_sequence_length]\n  mask4dMegatron,        // Megatron causal mask with shape [batch_size, 1, max_sequence_length, max_sequence_length]\n  maskUnknown\n}\n\nexport interface AttentionParameters {\n  batchSize: number;\n  sequenceLength: number;\n  pastSequenceLength: number;\n  kvSequenceLength: number;\n  totalSequenceLength: number;\n  maxSequenceLength: number;\n  inputHiddenSize: number;\n  hiddenSize: number;\n  vHiddenSize: number;\n  headSize: number;\n  vHeadSize: number;\n  numHeads: number;\n  isUnidirectional: boolean;\n  pastPresentShareBuffer: boolean;\n  maskFilterValue: number;\n  maskType: AttentionMaskType;\n  scale: number;\n  broadcastResPosBias: boolean;\n  passPastInKv: boolean;\n  qkvFormat: AttentionQkvFormat;\n}\n\nexport interface AttentionAttrs {\n  numHeads: number;\n  isUnidirectional: number;\n  maskFilterValue: number;\n  scale: number;\n  doRotary: number;\n  qkvHiddenSizes: number[];\n  pastPresentShareBuffer: boolean;\n}\n\nconst validateAttentionInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  // When past state is used, Q, K and V should have same hidden size (unless we split it into past_key and past_value).\n\n  // Input shapes:\n  //   input        (Q/K/V)    : (B, S, D_i)\n  //   weights      (Q/K/V)    : (D_i, D + D + D_v)\n  //   bias         (Q/K/V)    : (D + D + D_v)\n  //   mask_index              : see below\n  //   past         (K/V)      : (2, B, N, P, H) or NULL\n  //   relative_position_bias            : (B, N, S, T) or NULL\n\n  // For mask_index, the following shapes are supported:\n  //     NULL, (B, 1), (1, 1)\n  //     (B), (2 * B), (3 * B + 2)\n  //     (B, T)\n  //     (B, S, T)\n  //     (B, 1, M, M)\n  //\n  // When a model is pruned (like some attention heads are removed in Q/K/V), input_hidden_size could be larger\n  // than hidden dimension of Q, K and V.\n\n  const input = inputs[0];\n  const weights = inputs[1];\n  const bias = inputs[2];\n  const maskIndex = inputs[3];\n  const past = inputs[4];\n  const relativePositionBias = inputs[5];\n\n  if (past && relativePositionBias) {\n    throw new Error('Attention cannot have both past and relative_position_bias');\n  }\n\n  if (input.dims.length !== 3) {\n    throw new Error('Input \"input\" must have 3 dimensions');\n  }\n\n  const batchSize = input.dims[0];\n  const sequenceLength = input.dims[1];\n  const inputHiddenSize = input.dims[2];\n\n  if (bias.dims.length !== 1) {\n    throw new Error('Input \"bias\" is expected to have 1 dimensions');\n  }\n\n  if (weights.dims.length !== 2) {\n    throw new Error('Input \"weights\" is expected to have 2 dimensions');\n  }\n\n  if (weights.dims[0] !== inputHiddenSize) {\n    throw new Error('Input 1 dimension 0 should have same length as dimension 2 of input 0');\n  }\n\n  if (bias.dims[0] !== weights.dims[1]) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');\n  }\n\n  let qHiddenSize = bias.dims[0] / 3;\n  let kHiddenSize = qHiddenSize;\n  let vHiddenSize = kHiddenSize;\n  if (attributes.qkvHiddenSizes.length > 0) {\n    if (attributes.qkvHiddenSizes.length !== 3) {\n      throw new Error('qkv_hidden_sizes attribute should have 3 elements');\n    }\n    for (const sz of attributes.qkvHiddenSizes) {\n      if (sz % attributes.numHeads !== 0) {\n        throw new Error('qkv_hidden_sizes should be divisible by num_heads');\n      }\n    }\n\n    qHiddenSize = attributes.qkvHiddenSizes[0];\n    kHiddenSize = attributes.qkvHiddenSizes[1];\n    vHiddenSize = attributes.qkvHiddenSizes[2];\n  }\n\n  const kvSequenceLength = sequenceLength;\n\n  if (qHiddenSize !== kHiddenSize) {\n    throw new Error('qkv_hidden_sizes first element should be same as the second');\n  }\n\n  if (bias.dims[0] !== qHiddenSize + kHiddenSize + vHiddenSize) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');\n  }\n\n  let pastSequenceLength = 0;\n  if (past) {\n    if (kHiddenSize !== vHiddenSize) {\n      throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');\n    }\n    if (past.dims.length !== 5) {\n      throw new Error('Input \"past\" must have 5 dimensions');\n    }\n    if (past.dims[0] !== 2) {\n      throw new Error('Input \"past\" first dimension must be 2');\n    }\n    if (past.dims[1] !== batchSize) {\n      throw new Error('Input \"past\" second dimension must be batch_size');\n    }\n    if (past.dims[2] !== attributes.numHeads) {\n      throw new Error('Input \"past\" third dimension must be num_heads');\n    }\n    if (past.dims[4] !== kHiddenSize / attributes.numHeads) {\n      throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');\n    }\n\n    if (!attributes.pastPresentShareBuffer) {\n      pastSequenceLength = past.dims[3];\n    }\n    // TODO: handle past_seq_len\n  }\n\n  const totalSequenceLength = kvSequenceLength + pastSequenceLength;\n  const maxSequenceLength = -1;\n\n  const maskType = AttentionMaskType.none;\n  if (maskIndex) {\n    // maskType = AttentionMaskType.MASK_UNKNOWN;\n    // TODO: handle mask\n    throw new Error('Mask not supported');\n  }\n\n  if (past) {\n    throw new Error('past is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('relativePositionBias is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize,\n    hiddenSize: qHiddenSize,\n    vHiddenSize,\n    headSize: Math.floor(qHiddenSize / attributes.numHeads),\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias: false,\n    passPastInKv: false,\n    qkvFormat: AttentionQkvFormat.qkvBNSH,\n  };\n};\n\nexport const parseAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n    createAttributeWithCacheKey({...attributes});\n\nexport const computeInPlaceSoftmax = (context: ComputeContext, input: TensorView, n: number, d: number) => {\n  const components = getMaxComponents(d);\n  const inputHelper = outputVariable('x', input.dataType, input.dims, components);\n\n  let threadMaxValue = 'threadMaxVector';\n  if (components === 2) {\n    threadMaxValue = 'max(threadMaxVector.x, threadMaxVector.y)';\n  } else if (components === 4) {\n    threadMaxValue = 'max(max(threadMaxVector.x, threadMaxVector.y), max(threadMaxVector.z, threadMaxVector.w))';\n  }\n  const dataType = tensorTypeToWsglStorageType(input.dataType);\n  let WG = 64;\n  const dComp = d / components;\n  if (dComp < WG) {\n    WG = 1;\n  } else if (dComp / 8 < 64) {\n    WG = Math.ceil(dComp / 8);\n  }\n  const elementsPerWG = Math.ceil(d / components / WG);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dInv: ${dataType} = 1 / ${d};\n  const dComp = ${d / components};\n  var<workgroup> wgMax: array<f32, ${WG}>;\n  var<workgroup> wgSum: array<f32, ${WG}>;\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @compute @workgroup_size(${WG}, 1, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_index : u32) {\n    let localOffset = local_index * ${elementsPerWG};\n    let offset: u32 = workgroup_id.x * dComp + localOffset;\n\n    var threadMaxVector = ${fillVector('f32', components, '-3.402823e+38f')};\n    for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n      threadMaxVector = max(${castToF32(dataType, components, 'x[offset + i]')}, threadMaxVector);\n    }\n    wgMax[local_index] = ${threadMaxValue};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${WG}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${fillVector('f32', components, '0')};\n    for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n      sumVector += exp(${castToF32(dataType, components, 'x[offset + i]')} - maxValue);\n    }\n    wgSum[local_index] = ${sumVector('sumVector', components)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${WG}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n        x[offset + i] = ${fillVector(dataType, components, 'dInv')};\n      }\n    } else {\n      for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n        let f32input = ${castToF32(dataType, components, 'x[offset + i]')};\n        x[offset + i] = ${inputHelper.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`;\n\n  context.compute(\n      {\n        name: 'AttentionProbsSoftmax',\n        shaderCache: {hint: `${d}`},\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [],\n          dispatchGroup: {x: n},\n        }),\n      },\n      {inputs: [input], outputs: []});\n};\n\nconst computeAttentionProbs =\n    (context: ComputeContext, q: TensorView, key: TensorView, _bias: TensorView|undefined,\n     parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probsShape = [\n        parameters.batchSize, parameters.numHeads, parameters.sequenceLength,\n        parameters.kvSequenceLength + parameters.pastSequenceLength\n      ];\n      // TODO: handle mask\n\n      const alpha = attributes.scale === 0 ? 1.0 / Math.sqrt(parameters.headSize) : attributes.scale;\n\n      const dataType = tensorTypeToWsglStorageType(q.dataType);\n\n      const components = getMaxComponents(parameters.headSize);\n      const qInput = inputVariable('q', q.dataType, q.dims, components);\n      const kInput = inputVariable('key', key.dataType, key.dims, components);\n      const output = outputVariable('output', q.dataType, probsShape);\n\n      const vectorizedHeadSize = parameters.headSize / components;\n      const M = parameters.sequenceLength;\n      const N = parameters.totalSequenceLength;\n      const K = vectorizedHeadSize;\n\n      const TILE_SIZE = 12;\n\n      const dispatch = {\n        x: Math.ceil(parameters.totalSequenceLength / TILE_SIZE),\n        y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n        z: parameters.batchSize * parameters.numHeads\n      };\n\n      const inputs = [q, key];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha: ${dataType} = ${alpha};\n  const beta: ${dataType} = 1.0;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n\n  ${shaderHelper.declareVariables(qInput, kInput, output)}\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = ${parameters.sequenceLength * vectorizedHeadSize} * headIdx + m * K;\n    let kOffset = ${parameters.kvSequenceLength * vectorizedHeadSize} * headIdx + n * K;\n\n    var value = ${fillVector(dataType, components)};\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m + local_id.y < M && w + local_id.x < K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * K + w + local_id.x];\n      }\n      if (n + local_id.y < N && w + local_id.x < K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * M * N;\n    if (lm < M && ln < N) {\n      let outputIdx = headOffset + lm * N + ln;\n      output[outputIdx] = ${sumVector('value', components)} * alpha;\n    }\n  }`;\n\n      const probs = context.compute(\n          {\n            name: 'AttentionProbs',\n            shaderCache: {hint: JSON.stringify(parameters)},\n            getRunData: () => ({\n              outputs: [{dims: probsShape, dataType: q.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n            }),\n            getShaderSource,\n          },\n          {inputs, outputs: [-1]})[0];\n\n      computeInPlaceSoftmax(\n          context, probs, parameters.batchSize * parameters.numHeads * parameters.sequenceLength,\n          parameters.totalSequenceLength);\n\n      return probs;\n    };\n\nconst computeVxAttentionScore =\n    (context: ComputeContext, probs: TensorView, v: TensorView, params: AttentionParameters) => {\n      const outputShape = [params.batchSize, params.sequenceLength, params.vHiddenSize];\n\n      const probsHelper = inputVariable('probs', probs.dataType, probs.dims);\n      const vHelper = inputVariable('v', v.dataType, v.dims);\n      const output = outputVariable('output', probs.dataType, outputShape);\n\n      const dataType = tensorTypeToWsglStorageType(probs.dataType);\n\n      const TILE_SIZE = 12;\n      const dispatch = {\n        x: Math.ceil(params.vHeadSize / TILE_SIZE),\n        y: Math.ceil(params.sequenceLength / TILE_SIZE),\n        z: params.batchSize * params.numHeads\n      };\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${params.sequenceLength}u;\n  const N: u32 = ${params.vHeadSize}u;\n  const K: u32 = ${params.totalSequenceLength}u;\n  const numHeads: u32 = ${params.numHeads}u;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${probsHelper.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${probsHelper.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n\n  ${shaderHelper.declareVariables(probsHelper, vHelper, output)}\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (M * K) + m * K;\n   let offsetB = headIdx * (N * K) + n;\n\n   var value = ${dataType}(0);\n   for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n     if (m < M && w + local_id.x < K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < N && w + local_id.y < K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / ${params.numHeads};\n   let currentBatchHeadNumber = workgroup_id.z % ${params.numHeads};\n   let headOffset = (batchIdx * M * ${params.numHeads} + currentBatchHeadNumber) * ${params.vHeadSize};\n   if (m < M && n < N) {\n     let outputIdx = batchIdx * ${params.sequenceLength * params.vHiddenSize} + m * ${params.vHiddenSize}\n       + currentBatchHeadNumber * ${params.vHeadSize} + n;\n     output[outputIdx] = value;\n   }\n  }`;\n\n      return context.compute(\n          {\n            name: 'AttentionScore',\n            shaderCache: {hint: JSON.stringify(params)},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: probs.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n            }),\n            getShaderSource,\n          },\n          {inputs: [probs, v], outputs: [0]})[0];\n    };\n\nexport const applyAttention =\n    (context: ComputeContext, q: TensorView, k: TensorView, v: TensorView, _maskIndex: TensorView|undefined,\n     _past: TensorView|undefined, _pastKey: TensorView|undefined, _pastValue: TensorView|undefined,\n     relativePositionBias: TensorView|undefined, parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probs = computeAttentionProbs(context, q, k, relativePositionBias, parameters, attributes);\n\n      computeVxAttentionScore(context, probs, v, parameters);\n    };\n\nconst prepare = (context: ComputeContext, parameters: AttentionParameters) => {\n  const outputShape = [\n    parameters.batchSize,\n    parameters.numHeads,\n    parameters.sequenceLength,\n    parameters.headSize,\n  ];\n\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n\n  const M = parameters.sequenceLength;\n  const K = parameters.inputHiddenSize;\n  const N = parameters.headSize;\n\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(parameters.headSize / TILE_SIZE),\n    y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n    z: parameters.batchSize * parameters.numHeads\n  };\n\n  const getShaderSource = () => `\n  const M: u32 = ${M}u;\n  const K: u32 = ${K}u;\n  const N: u32 = ${N}u;\n  const numHeads: u32 = ${parameters.numHeads};\n  const ldb = ${parameters.hiddenSize + parameters.hiddenSize + parameters.vHiddenSize}u;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileInput: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightQ: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightK: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightV: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n\n  @group(0) @binding(0) var<storage, read> input: array<${dataType}>;\n  @group(0) @binding(1) var<storage, read> weight: array<${dataType}>;\n  @group(0) @binding(2) var<storage, read> bias: array<${dataType}>;\n  @group(0) @binding(3) var<storage, read_write> outputQ: array<${dataType}>;\n  @group(0) @binding(4) var<storage, read_write> outputK: array<${dataType}>;\n  @group(0) @binding(5) var<storage, read_write> outputV: array<${dataType}>;\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n    let batchIndex = workgroup_id.z / ${parameters.numHeads};\n    let headNumber = workgroup_id.z % ${parameters.numHeads};\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (M * K) + m * K;\n    let biasOffsetQ = headNumber * ${parameters.headSize};\n    let biasOffsetK = ${parameters.hiddenSize} + biasOffsetQ;\n    let biasOffsetV = ${parameters.hiddenSize} + biasOffsetK;\n\n    var valueQ = ${dataType}(0);\n    var valueK = ${dataType}(0);\n    var valueV = ${dataType}(0);\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m < M && w + local_id.x < K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < N && w + local_id.y < K) {\n        let offset = n + (w + local_id.y) * ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * N + n) % ${parameters.headSize};\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * M * N;\n    if (m < M && n < N) {\n      let outputIdx = offset + m * N + n;\n      outputQ[outputIdx] = valueQ;\n      outputK[outputIdx] = valueK;\n      outputV[outputIdx] = valueV;\n    }\n  }`;\n\n  const inputs = [context.inputs[0], context.inputs[1], context.inputs[2]];\n\n  return context.compute(\n      {\n        name: 'AttentionPrepare',\n        shaderCache: {hint: JSON.stringify(parameters)},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n          ],\n          dispatchGroup: dispatch,\n        }),\n        getShaderSource,\n      },\n      {inputs, outputs: [-1, -1, -1]});\n};\n\nexport const attention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateAttentionInputs(context.inputs, attributes);\n\n  const [q, k, v] = prepare(context, params);\n\n  return applyAttention(\n      context, q, k, v, context.inputs[4], undefined, undefined, undefined, context.inputs[5], params, attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n      ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey, inputDependencies: ['type']},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)},\n        programUniforms: [\n          {type: 'uint32', data: Math.ceil(ShapeUtil.size(input.dims) / 4)},\n        ],\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext, clipAttributes: ClipAttributes): void => {\n  const attributes = context.inputs.length === 1 ? clipAttributes : generateClipAttributesFromInputs(context.inputs);\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_: f32 = f32(${attributes.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<f32>(0.0))`,\n      `const leaky_relu_alpha_: f32 = f32(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<f32>(0.0), ${a}, ${a} > vec4<f32>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<f32>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl('vec4f')}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, sharedDimensionDivisibleBy4: boolean, funcCall: BinaryFunctionCall,\n     typeA: number, typeB: number, typeOutput: number, useShapesUniforms: boolean,\n     additionalImplementation?: string) => {\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      const inputAShapeOrRank = useShapesUniforms ? dimsA.length : dimsA;\n      const inputBShapeOrRank = useShapesUniforms ? dimsB.length : dimsB;\n      const outputShapeOrRank = useShapesUniforms ? dimsOutput.length : dimsOutput;\n      const output = outputVariable('outputData', typeOutput, outputShapeOrRank, 4);\n      const a = inputVariable('aData', typeA, inputAShapeOrRank, 4);\n      const b = inputVariable('bData', typeB, inputBShapeOrRank, 4);\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          const aLastDimDivisibleBy4 = dimsA.length > 0 && dimsA[dimsA.length - 1] % 4 === 0;\n          const bLastDimDivisibleBy4 = dimsB.length > 0 && dimsB[dimsB.length - 1] % 4 === 0;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = ${a.broadcastedIndicesToOffset('outputIndices', output)};\n            let offsetB = ${b.broadcastedIndicesToOffset('outputIndices', output)};\n            ${\n                output.setByOffset(\n                    'global_idx',\n                    expressionVector(\n                        sharedDimensionDivisibleBy4 || aLastDimDivisibleBy4 ?\n                            a.getByOffset('offsetA / 4u') :\n                            `${a.type.value}(${a.getByOffset('offsetA / 4u')}[offsetA % 4u])`,\n                        sharedDimensionDivisibleBy4 || bLastDimDivisibleBy4 ?\n                            b.getByOffset('offsetB / 4u') :\n                            `${b.type.value}(${b.getByOffset('offsetB / 4u')}[offsetB % 4u])`))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n      let sharedDimensionDivisibleBy4 = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n      const cacheKeyAux = [isBroadcast];\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n        const aLastDimDivisibleBy4 = a.dims.length > 0 && a.dims[a.dims.length - 1] % 4 === 0;\n        const bLastDimDivisibleBy4 = b.dims.length > 0 && b.dims[b.dims.length - 1] % 4 === 0;\n        cacheKeyAux.push(isAOneElement);\n        cacheKeyAux.push(isBOneElement);\n        cacheKeyAux.push(aLastDimDivisibleBy4);\n        cacheKeyAux.push(bLastDimDivisibleBy4);\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0) {\n          sharedDimensionDivisibleBy4 = true;\n          vectorize = true;\n        } else if (isAOneElement || isBOneElement || aLastDimDivisibleBy4 || bLastDimDivisibleBy4) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n      cacheKeyAux.push(vectorize);\n      const useShapesUniforms = enableShapesUniforms(a.dims.length) && enableShapesUniforms(b.dims.length) &&\n          enableShapesUniforms(outputShape.length);\n      return {\n        name,\n        shaderCache: {\n          hint: cacheKey + cacheKeyAux.map((x) => x.toString()).join('_'),\n          inputDependencies: useShapesUniforms ? ['rank', 'rank'] : ['dims', 'dims'],\n        },\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, sharedDimensionDivisibleBy4, funcCall,\n            a.dataType, b.dataType, outputDataType, useShapesUniforms, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n                ...createTensorShapeVariables(a.dims),\n                ...createTensorShapeVariables(b.dims),\n                ...createTensorShapeVariables(outputShape),\n              ] :\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n              ],\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number, sizeInConcatAxisStr: string): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${numberOfTensors}u>(${sizeInConcatAxisStr});\n    for (var i: u32 = 0u; i < ${numberOfTensors}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  const inputShapeOrRanks = [];\n  const enableInputShapesUniforms = [];\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n    enableInputShapesUniforms.push(enableShapesUniforms(inputs[i].dims.length));\n    inputShapeOrRanks.push(enableInputShapesUniforms[i] ? inputs[i].dims.length : inputs[i].dims);\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputShapeOrRanks[i]);\n    inputDependencies.push(enableInputShapesUniforms[i] ? 'rank' : 'dims');\n    programUniforms.push({type: 'uint32', data: sizeInConcatAxis[i]});\n  }\n  for (let i = 0; i < inputs.length; ++i) {\n    if (enableInputShapesUniforms[i]) {\n      programUniforms.push(...createTensorShapeVariables(inputs[i].dims));\n    }\n  }\n\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n  const output = outputVariable('output', dataType, outputShapeOrRank);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const sizeInConcatAxisStr =\n      Array.from(Array(sizeInConcatAxis.length).keys()).map(i => `uniforms.sizeInConcatAxis${i}`).join(',');\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  ${(() => {\n    shaderHelper.registerUniform('outputSize', 'u32');\n    for (let i = 0; i < inputs.length; i++) {\n      shaderHelper.registerUniform(`sizeInConcatAxis${i}`, 'u32');\n    }\n    return shaderHelper.declareVariables(...inputVars, output);\n  })()}\n\n  ${calculateInputIndexImpl(sizeInConcatAxis.length, sizeInConcatAxisStr)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}u>(${sizeInConcatAxisStr});\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActivationSnippet = (attributes: InternalActivationAttributes, valueType: string):\n    {activationFunction: string; applyActivation: string} => {\n      switch (attributes.activation) {\n        case 'Relu':\n          return {activationFunction: '', applyActivation: `value = max(value, ${valueType}(0.0));`};\n        case 'Sigmoid':\n          return {\n            activationFunction: '',\n            applyActivation: `value = (${valueType}(1.0) / (${valueType}(1.0) + exp(-value)));`\n          };\n        case 'Clip':\n          return {\n            activationFunction: `const clip_min_=${valueType}(${attributes.clipMin!});const clip_max_=${valueType}(${\n                attributes.clipMax!});`,\n            applyActivation: 'value = clamp(value, clip_min_, clip_max_);'\n          };\n          // TODO: adding other activations that can be fused.\n        default:\n          return {activationFunction: '', applyActivation: ''};\n      }\n    };\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const biasSnippet = (hasBias: boolean): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = `\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`;\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {getBroadcastDims, IndicesHelper, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActivationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const batchAShape = batchShapes[0];\n      const batchBShape = batchShapes[1];\n      const batchShape = batchShapes[2];\n      const batchVariable = variables[0];\n      const aVariable = variables[1];\n      const bVariable = variables[2];\n      const outputVariable = variables[3];\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const batchDims = inputVariable('batchDims', inputs[0].dataType, outerDims);\n      const variables = [batchDims];\n      const batchShapes = [outerDimsA, outerDimsB, outerDims];\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n      const A = inputVariable('a', inputs[0].dataType, [...outerDimsA, dimAOuter, dimInner / components], components);\n      const B = inputVariable('b', inputs[1].dataType, [...outerDimsB, dimInner, dimBOuter / components], components);\n      const output =\n          outputVariable('result', inputs[0].dataType, [batchSize, dimAOuter, dimBOuter / components], components);\n      variables.push(A);\n      variables.push(B);\n      variables.push(output);\n      const inputVariables = [A, B];\n      const hasBias = inputs.length > 2;\n      const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, output.type.value);\n      const declareFunctions =\n          matMulReadWriteFnSource(components, hasBias, applyActivation, variables, batchShapes, isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims, biasComponents));\n      }\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dimAOuter: i32 = ${dimAOuter};\n  const dimBOuter: i32 = ${dimBOuter};\n  const dimInner: i32 = ${dimInner};\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${declareFunctions}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   ${batchDims.impl()}`;\n      return {\n        name: 'MatMul',\n        shaderCache: {hint: activationAttributes.activationCacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     attributes: ConvAttributes, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4,\n     dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * wShape[3] + colIn];';\n          case 4:\n            return 'return w[row * wShape[3] / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'xShape[1]' : 'xShape[2]';\n      const xWidth = isChannelsLast ? 'xShape[2]' : 'xShape[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = wShape[2];\n    let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimAOuter && col < dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimInner && col < dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, resType);\n      const userCode = `\n    ${activationFunction}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : elementsPerThread[0];\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 && innerElementSize === 4 ? `vec4<${t}>` : t}>;`,\n        `@group(0) @binding(1) var<storage, read> w: array<${isVec4 ? `vec4<${t}>` : t}>;`\n      ];\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? `vec4<${t}>` : t}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${declareInputs.join('')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? `vec4<${t}>` : t}>;\n        //@group(0) @binding(${declareInputs.length + 1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias, attributes, elementsSize[0], elementsSize[1],\n                elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActivationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, output.type.value);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    context.compute(\n        createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n        {inputs: matmulInputs});\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {ConvTransposeAttributes} from '../conv-transpose';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, attributes: ConvTransposeAttributes, innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return W[getIndexFromCoords4D(coord, wShape)];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, xShape)/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < dimInner && col < dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < dimInner && col < dimBOuter' :\n                           'row < dimInner && col < dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, type);\n      const userCode = `\n      ${activationFunction}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      result[getIndexFromCoords4D(coords, outShape)/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`,\n        '@group(0) @binding(1) var<storage, read> W: array<f32>;'\n      ];\n      let declareFunctions = '';\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        ${declareInputs.join('\\n')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? 'vec4<f32>' : 'f32'}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${conv2dTransposeCommonSnippet(isChannelsLast, hasBias, attributes, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : '0.0'};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : '0.0'};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const hasBias = inputs.length === 3;\n      if (adjustedAttributes.group !== 1) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outputShape = adjustedAttributes.outputShape;\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, true, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + i);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i);\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst createEinsumProgramInfo = (inputs: readonly TensorView[], einsumEquation: EinsumEquation): ProgramInfo => {\n  const dataType = inputs[0].dataType;\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  for (let i = 0; i < inputs.length; ++i) {\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n  const outputShape = einsumEquation.outputDims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', dataType, outputShape);\n  const idxCopy: string[] = [];\n  const rhsSymbols = Array.from(einsumEquation.rhs.symbolToIndices.keys());\n  const initProd = 'var prod = 1.0;';\n  const initSum = 'var sum = 0.0;';\n  const updateSum = 'sum += prod;';\n  const reduceOpsSetIndices: string[] = [];\n  const reduceOpsLoopHeaders: string[] = [];\n  const reduceOpsLoopFooters: string[] = [];\n  const reduceOpCompute: string[] = [];\n  const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === rhsSymbols.length;\n  einsumEquation.symbolToInfo.forEach((info, symbol) => {\n    if (rhsSymbols.includes(symbol)) {\n      const outputIndex = rhsSymbols.indexOf(symbol);\n      einsumEquation.lhs.forEach((term, i) => {\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            idxCopy.push(`${\n                inputVars[i].indicesSet(`input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n          });\n        }\n      });\n    } else {\n      einsumEquation.lhs.forEach((term, i) => {\n        const info = einsumEquation.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid symbol error');\n        }\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n          });\n          reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n        }\n      });\n      reduceOpsLoopHeaders.push(`for(var ${symbol}: u32 = 0; ${symbol} < ${\n          einsumEquation.symbolToInfo.get(symbol)?.dimValue}; ${symbol}++) {`);\n      reduceOpsLoopFooters.push('}');\n    }\n  });\n  const reduceOps = isReduceOpsWithoutLoop ?\n      [\n        ...idxCopy,\n        `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n      ] :\n      [\n        ...idxCopy,\n        initSum,\n        ...reduceOpsLoopHeaders,\n        ...reduceOpsSetIndices,\n        initProd,\n        ...reduceOpCompute,\n        updateSum,\n        ...reduceOpsLoopFooters,\n      ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(...inputVars, output)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        var outputIndices = ${output.offsetToIndices('global_idx')};\n        ${inputVars.map((_var, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n        ${reduceOps.join('\\n')};\n        ${output.setByOffset('global_idx', 'sum')};\n      }`;\n  return {\n    name: 'Einsum',\n    shaderCache: {hint: einsumEquation.equation},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  context.compute(createEinsumProgramInfo(context.inputs, einsumEquation));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const inputShape = ${input.indices(...inputShape)};\n  ${shaderHelper.declareVariables(input, output)}\n  ${shaderHelper.mainStart()}\n  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    var inputIndices: ${input.type.indices};\n    for (var i = 0; i < ${inputShape.length}; i++) {\n      if (${input.indicesGet('inputShape', 'i')} == 1) {\n        ${input.indicesSet('inputIndices', 'i', 0)}\n      } else {\n        ${\n      input.indicesSet(\n          'inputIndices', 'i', output.indicesGet('outputIndices', `i + ${outputShape.length - inputShape.length}`))}\n      }\n    }\n    ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n  }`;\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const enableInputShapesUniforms = enableShapesUniforms(inputs[0].dims.length);\n  const inputShapeOrRank = enableInputShapesUniforms ? inputs[0].dims.length : inputs[0].dims;\n  const enableIndicesShapesUniforms = enableShapesUniforms(inputs[1].dims.length);\n  const indicesShapeOrRank = enableIndicesShapesUniforms ? inputs[1].dims.length : inputs[1].dims;\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n\n  const data = inputVariable('data', inputs[0].dataType, inputShapeOrRank);\n  const indices = inputVariable('inputIndices', inputs[1].dataType, indicesShapeOrRank);\n  const output = outputVariable('output', inputs[0].dataType, outputShapeOrRank);\n\n  const programUniforms: ProgramUniform[] =\n      [{type: 'uint32', data: outputSize}, {type: 'int32', data: axisDimLimit}, {type: 'uint32', data: axis}];\n  if (enableInputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n  }\n  if (enableIndicesShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n  }\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  inputDependencies.push(enableInputShapesUniforms ? 'rank' : 'dims');\n  inputDependencies.push(enableIndicesShapesUniforms ? 'rank' : 'dims');\n\n  const calcDataIndices = (): string => {\n    const indicesRank = indicesShape.length;\n    let calcStr = `var indicesIndices  = ${indices.type.indices}(0);`;\n    for (let i = 0; i < indicesRank; i++) {\n      calcStr += `${indicesRank > 1 ? `indicesIndices[${i}]` : 'indicesIndices'} = ${\n          outputShape.length > 1 ? `outputIndices[uniforms.axis + ${i}]` : 'outputIndices'};`;\n    }\n    calcStr += `\n        var idx = ${indices.getByIndices('indicesIndices')};\n        if (idx < 0) {\n          idx = idx + uniforms.axisDimLimit;\n        }\n        var dataIndices = ${data.type.indices}(0);\n      `;\n    for (let i = 0, j = 0; i < inputRank; i++) {\n      if (i === axis) {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = u32(idx);`;\n        j += indicesRank;\n      } else {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = ${\n            outputShape.length > 1 ? `outputIndices[${j}]` : 'outputIndices'};`;\n        j++;\n      }\n    }\n    return calcStr;\n  };\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${\n      shaderHelper.registerUniform('outputSize', 'u32')\n          .registerUniform('axisDimLimit', 'i32')\n          .registerUniform('axis', 'u32')\n          .declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        ${calcDataIndices()};\n        let value = ${data.getByIndices('dataIndices')};\n        ${output.setByOffset('global_idx', 'value')};\n      }`;\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey, inputDependencies},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n      const inputStrides = ShapeUtil.computeStrides(inputShape);\n      const inputSize = ShapeUtil.size(inputShape);\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const indicesSize = ShapeUtil.size(indicesShape);\n\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputShape);\n      const indices = inputVariable('indices', indicesDataType, [indicesSize]);\n      const output = outputVariable('output', inputOutputDataType, outputShape);\n\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputStrides = array<u32, ${inputStrides.length}>(${inputStrides.map(i => `${i}u`).join(',')});\n      ${shaderHelper.declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + ${axisDimLimit};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        if (i == ${axis}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${output.indicesGet('outputIndices', 'i')} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${inputSize}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst offsetC = (m: number, n: number, dims: readonly number[]): string => {\n  if (dims.length === 0) {\n    return '0u';\n  }\n\n  const broadcastM = (dims.length === 1 && m !== 1) || (dims.length === 2 && dims[0] !== m);\n  const broadcastN = dims[dims.length - 1] !== n;\n\n  let offset = '0u';\n  if (!broadcastM) {\n    offset += `+ m * ${dims[dims.length - 1]}u`;\n  }\n  if (!broadcastN) {\n    offset += '+n';\n  }\n\n  return offset;\n};\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  let line = '';\n  if (attributes.transA && attributes.transB) {\n    line = 'value += a[k * M + m] * b[n * K + k];';\n  } else if (attributes.transA && !attributes.transB) {\n    line = 'value += a[k * M + m] * b[k * N + n];';\n  } else if (!attributes.transA && attributes.transB) {\n    line = 'value += a[m * K + k] * b[n * K + k];';\n  } else if (!attributes.transA && !attributes.transB) {\n    line = 'value += a[m * K + k] * b[k * N + n];';\n  }\n\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n  const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= alpha;';\n  const calculateC = inputs.length === 3 ? `value += beta * c[${offsetC(M, N, inputs[2].dims)}];` : '';\n  const inputStorageBuffersDeclarations = [\n    `@group(0) @binding(0) var<storage, read> a : array<${dataType}>;`,\n    `@group(0) @binding(1) var<storage, read> b : array<${dataType}>;`\n  ];\n  if (inputs.length === 3) {\n    inputStorageBuffersDeclarations.push(`@group(0) @binding(2) var<storage, read> c : array<${dataType}>;`);\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha = ${dataType}(${attributes.alpha});\n  const beta = ${dataType}(${attributes.beta});\n\n  ${inputStorageBuffersDeclarations.join('\\n')}\n  @group(0) @binding(${inputs.length}) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k<${K}u; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${calculateC}\n    output[global_id.x] = value;\n\n  }`;\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<GemmAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface InstanceNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst metadata = {\n  name: 'InstanceNormalization'\n};\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const C = xShape[1];\n      const x = inputVariable('x', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n      const output = outputVariable('output', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const variables = [x, scale, bias, output];\n      const dataType = x.type.value;\n      const workgroupSize = 64;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  const C: u32 = ${C};\n  const normSize: u32 = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n  var<workgroup> meanShared : ${dataType};\n  var<workgroup> squaredNormShared : ${dataType};\n  var<workgroup> workgroupShared : array<${dataType}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${dataType} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${x.get('batch', 'channel', 'h')};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${dataType}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${x.get('batch', 'channel', 'h')} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${dataType}(normSize) + epsilon);\n    let channelScale = invStdDev * ${scale.getByOffset('channel')};\n    let channelShift = ${bias.getByOffset('channel')} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * channelScale + channelShift;\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount}\n        }),\n        getShaderSource,\n      };\n    };\n\nconst computeMean =\n    (context: ComputeContext, input: TensorView, scale: TensorView, bias: TensorView, n: number, h: number, c: number,\n     epsilon: number) => {\n      const components = getMaxComponents(c);\n      const inputHelper = inputVariable('input', input.dataType, input.dims, components);\n      const scaleHelper = inputVariable('scale', scale.dataType, scale.dims, components);\n      const biasHelper = inputVariable('bias', bias.dataType, bias.dims, components);\n\n      const WG = 64;\n      // we will store channel scale and channel shift in [2, components] matrix\n      // or in vec2 when components == 1\n      const outputType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const sumCastType = components === 1 ? 'f32' : `vec${components}f`;\n      const setOutputValue = (var1: string, var2: string) => `${outputType}(${var1}, ${var2})`;\n      const unitsOfWork = n * c / components;\n      const wgSize = Math.ceil(h / WG);\n\n      const getMeanShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${h * c / components};\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart(WG)}\n    let currentImageNumber = global_idx / ${WG} / C;\n    let currentChannelNumber = (global_idx / ${WG}) % C;\n    let wgId = global_idx % ${WG};\n    let wgOffset = wgId * ${wgSize};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${wgSize}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${sumCastType}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${setOutputValue('sum', 'squaredSum')};\n  }`;\n\n      const meanValues = context.compute(\n          {\n            name: 'InstanceNormComputeMean',\n            shaderCache: {hint: JSON.stringify({components, n, h, c})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, WG, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: n * c / components},\n            }),\n            getShaderSource: getMeanShaderSource,\n          },\n          {inputs: [input], outputs: [-1]})[0];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${WG * c / components};\n  const epsilon: f32 = ${epsilon};\n\n  @group(0) @binding(0) var<storage, read> input : array<${outputType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${scaleHelper.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${biasHelper.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(unitsOfWork)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = 0; i < ${WG}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${WG}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${sumCastType}(scale[currentChannelNumber]);\n    let channelShift = ${sumCastType}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${setOutputValue('channelScale', 'channelShift')};\n  }`;\n\n      return context.compute(\n          {\n            name: 'InstanceNormComputeChannelScaleShift',\n            shaderCache: {hint: JSON.stringify({components, n, h, c, epsilon})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: Math.ceil(unitsOfWork / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [meanValues, scale, bias], outputs: [-1]})[0];\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: InstanceNormAttributes) => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n\n      const components = getMaxComponents(C);\n      const outputSize = ShapeUtil.size(outputShape) / components;\n      const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n      const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const scaleType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const scaleCastType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n      // first compute mean\n      const channelScaleShift = computeMean(context, inputs[0], inputs[1], inputs[2], N, H, C, attributes.epsilon);\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${H};\n  const C: u32 = ${C / components};\n\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${scaleCastType}(scale[0]), ${scaleCastType}(scale[1]));\n  }`;\n      context.compute(\n          {\n            name: 'InstanceNormalization',\n            shaderCache: {hint: `${attributes.cacheKey}`},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n            }),\n            getShaderSource,\n          },\n          {inputs: [inputs[0], channelScaleShift]});\n    };\n\nexport const parseInstanceNormAttributes = (attributes: InstanceNormAttributes): InstanceNormAttributes =>\n    createAttributeWithCacheKey({epsilon: attributes.epsilon, format: attributes.format});\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface LayerNormAttributes extends AttributeWithCacheKey {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n\n      const components = getMaxComponents(normSize);\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const variables = [\n        inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n        inputVariable('scale', scale.dataType, scale.dims, components),\n      ];\n      if (bias) {\n        variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n      }\n      variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n\n      if (hasMeanDataOutput) {\n        variables.push(outputVariable('meanDataOutput', DataType.float, meanInvStdDevDim));\n      }\n      if (hasInvStdOutput) {\n        variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const normSize: f32 = ${normSize};\n  const normSizeVectorized: u32 = ${normSize / components};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(normCount)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${fillVector('f32', components)};\n    var meanSquareVector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${sumVector('meanVector', components)} / normSize;\n    let meanSquare = sqrt(${sumVector('meanSquareVector', components)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'meanDataOutput[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'invStdOutput[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n      if (hasInvStdOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${attributes.cacheKey}|${outputCount}|${inputs.length}`},\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}}),\n        getShaderSource,\n      };\n    };\n\nexport const parseLayerNormAttributes = (attributes: LayerNormAttributes): LayerNormAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis, epsilon: attributes.epsilon});\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil} from '../../util';\nimport {ComputeContext} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, GpuDataType} from '../types';\n\nimport {applyAttention, AttentionAttrs, AttentionMaskType, AttentionParameters, AttentionQkvFormat} from './attention';\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\nimport {createTransposeProgramInfo, TransposeAttributes} from './transpose';\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  const query = inputs[0];\n  const key = inputs[1];\n  const value = inputs[2];\n  const bias = inputs[3];\n  const keyPaddingMask = inputs[4];\n  const relativePositionBias = inputs[5];\n  const pastKey = inputs[6];\n  const pastValue = inputs[7];\n\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  //     key_padding_mask (K/V)     : (B) or (2*B + 1) or (B, L) or None\n  //     relative_position_bias     : (B, 1, S, L)\n  //     past_key                   : (B, N, S*, H)\n  //     past_value                 : (B, N, S*, H)\n  // When no packing for q/k/v:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, D) or (B, N, S*, H)\n  //     value            (V)       : (B, L, D_v) or (B, N, S*, H)\n  //     bias             (Q/K/V)   : (D + D + D_v)\n  // When packed kv is used:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, N, 2, H)\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None\n  // When packed qkv is used:\n  //     query            (Q)       : (B, L, N, 3, H) or (B, S, 3*D)\n  //     key              (K)       : None\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None or (D + D + D_v)\n\n  if (query.dims.length !== 3 && query.dims.length !== 5) {\n    throw new Error('Input query is expected to have 3 or 5 dimensions');\n  }\n\n  const dmmhaPacking = false;\n  const batchSize = query.dims[0];\n  const sequenceLength = query.dims[1];\n  const hiddenSize = query.dims.length === 3 ? (dmmhaPacking ? query.dims[2] / 3 : query.dims[2]) :\n                                               attributes.numHeads * query.dims[4];\n  let kvSequenceLength = sequenceLength;\n\n  let pastSequenceLength = 0;\n  let maxSequenceLength = 0;\n  const headSize = Math.floor(hiddenSize / attributes.numHeads);\n  if (pastKey && pastValue) {\n    if (pastKey.dims.length !== 4) {\n      throw new Error('Input \"past_key\" is expected to have 4 dimensions');\n    }\n    if (pastValue.dims.length !== 4) {\n      throw new Error('Input \"past_value\" is expected to have 4 dimensions');\n    }\n    pastSequenceLength = pastKey.dims[2];\n    maxSequenceLength = pastKey.dims[2];\n  } else if (pastKey || pastValue) {\n    throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');\n  }\n\n  let qkvFormat: AttentionQkvFormat;\n  if (key) {\n    if (query.dims.length !== 3) {\n      throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');\n    }\n    if (key.dims.length < 3 || key.dims.length > 5) {\n      throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');\n    }\n    if (query.dims[0] !== key.dims[0]) {\n      throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');\n    }\n\n    if (key.dims.length === 3) {\n      if (key.dims[2] !== query.dims[2]) {\n        throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');\n      }\n      qkvFormat = AttentionQkvFormat.qkvBSNH;\n      kvSequenceLength = key.dims[1];\n    } else if (key.dims.length === 5) {\n      if (key.dims[2] !== attributes.numHeads || key.dims[3] !== 2 || key.dims[4] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');\n      }\n      if (value) {\n        throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');\n      }\n      qkvFormat = AttentionQkvFormat.qKvBSNHxBSN2H;\n      kvSequenceLength = key.dims[1];\n    } else {  // key_dims.size() == 4 (cross-attention with past_key)\n      if (key.dims[1] !== attributes.numHeads || key.dims[3] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');\n      }\n\n      qkvFormat = AttentionQkvFormat.unknown;\n      kvSequenceLength = key.dims[2];\n    }\n  } else {  // packed QKV\n    if (query.dims.length !== 3 && query.dims.length !== 5) {\n      throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');\n    }\n    if (query.dims.length === 5 && (query.dims[2] !== attributes.numHeads || query.dims[3] !== 3)) {\n      throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');\n    }\n\n    qkvFormat = AttentionQkvFormat.qkvBSN3H;\n  }\n\n  if (bias) {\n    if (bias.dims.length !== 1) {\n      throw new Error('Input \"bias\" is expected to have 1 dimension');\n    }\n\n    if (value) {\n      if (query.dims.length === 5 && query.dims[3] === 2) {\n        throw new Error('bias is not allowed for packed kv.');\n      }\n    }\n  }\n\n  let maskType: AttentionMaskType = AttentionMaskType.none;\n  if (keyPaddingMask) {\n    maskType = AttentionMaskType.maskUnknown;\n    const maskDims = keyPaddingMask.dims;\n    if (maskDims.length === 1) {\n      if (maskDims[0] === batchSize) {\n        maskType = AttentionMaskType.mask1dKeySeqLen;\n      } else if (maskDims[0] === 3 * batchSize + 2) {\n        maskType = AttentionMaskType.mask1DKeySeqLenStart;\n      }\n    } else if (maskDims.length === 2 && maskDims[0] === batchSize && maskDims[1] === kvSequenceLength) {\n      maskType = AttentionMaskType.mask2dKeyPadding;\n    }\n    if (maskType === AttentionMaskType.maskUnknown) {\n      throw new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)');\n    }\n    throw new Error('Mask not supported');\n  }\n\n  let passPastInKv = false;\n  let vHiddenSize = hiddenSize;\n  if (value) {\n    if (value.dims.length !== 3 && value.dims.length !== 4) {\n      throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');\n    }\n\n    if (query.dims[0] !== value.dims[0]) {\n      throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');\n    }\n\n    if (value.dims.length === 3) {\n      if (kvSequenceLength !== value.dims[1]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[2];\n    } else {\n      if (kvSequenceLength !== value.dims[2]) {\n        throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[1] * value.dims[3];\n      passPastInKv = true;\n    }\n  }\n\n  const totalSequenceLength = pastSequenceLength + kvSequenceLength;\n  const broadcastResPosBias = false;\n  // if (extraAddQk) {\n  //   if (extraAddQk.dims[0] === 1) {\n  //     broadcastResPosBias = true;\n  //   }\n  // }\n\n  if (keyPaddingMask) {\n    throw new Error('Key padding mask is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('extraAddQk is not supported');\n  }\n  if (pastKey) {\n    throw new Error('pastKey is not supported');\n  }\n  if (pastValue) {\n    throw new Error('pastValue is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize: 0,\n    hiddenSize,\n    vHiddenSize,\n    headSize,\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias,\n    passPastInKv,\n    qkvFormat,\n  };\n};\n\n\nexport const parseMultiHeadAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n    createAttributeWithCacheKey({...attributes});\n\nconst weightTransposeAttribute: TransposeAttributes = createAttributeWithCacheKey({perm: [0, 2, 1, 3]});\n\nconst addBiasTranspose =\n    (context: ComputeContext, qkv: TensorView, bias: TensorView, batchSize: number, sequenceLength: number,\n     hiddenSize: number, biasOffset: number) => {\n      const outputShape = [batchSize, sequenceLength, hiddenSize];\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const dataType = tensorTypeToWsglStorageType(qkv.dataType);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const biasOffset = ${biasOffset}u;\n  const hiddenSize = ${hiddenSize}u;\n\n  @group(0) @binding(0) var<storage, read> qkv: array<${dataType}>;\n  @group(0) @binding(1) var<storage, read> bias: array<${dataType}>;\n  @group(0) @binding(2) var<storage, read_write> qkv_with_bias: array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasOffsetIdx = (global_idx % hiddenSize) + biasOffset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[biasOffsetIdx];\n  }`;\n\n      return context.compute(\n          {\n            name: 'MultiHeadAttentionAddBias',\n            shaderCache: {hint: JSON.stringify({batchSize, sequenceLength, hiddenSize, biasOffset})},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: qkv.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [qkv, bias], outputs: [-1]})[0];\n    };\n\nconst maybeTransposeToBNSHAndAddBias =\n    (context: ComputeContext, batchSize: number, numHeads: number, sequenceLength: number, headSize: number,\n     input: TensorView, bias?: TensorView, biasOffset?: number) => {\n      // const newDims = [];\n\n      let reshapedInput = input;\n      if (!bias) {\n        if (input.dims.length === 3) {\n          reshapedInput = input.reshape([batchSize, sequenceLength, numHeads, headSize]);\n        }\n        return context.compute(\n            createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n            {inputs: [reshapedInput], outputs: [-1]})[0];\n      } else {\n        if (sequenceLength === 1) {\n          throw new Error('AddBiasReshape is not implemented. Please export your model with packed QKV or KV');\n        } else {\n          reshapedInput =\n              addBiasTranspose(context, input, bias, batchSize, sequenceLength, numHeads * headSize, biasOffset!);\n          reshapedInput = reshapedInput.reshape([batchSize, sequenceLength, numHeads, headSize]);\n          return context.compute(\n              createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n              {inputs: [reshapedInput], outputs: [-1]})[0];\n        }\n      }\n    };\n\nexport const multiHeadAttention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateInputs(context.inputs, attributes);\n\n  if (context.inputs[0].dims.length === 5) {\n    throw new Error('Packed QKV is not implemented');\n  }\n\n  if (context.inputs[1]?.dims.length === 5) {\n    throw new Error('Packed KV is not implemented');\n  }\n\n  // applyAttention expects BNSH inputs\n  const kvBNSH = context.inputs[1] && context.inputs[2] && context.inputs[1].dims.length === 4 &&\n      context.inputs[2].dims.length === 4;\n\n  const Q = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.sequenceLength, params.headSize, context.inputs[0],\n      context.inputs[3], 0);\n\n  if (kvBNSH) {\n    return applyAttention(\n        context, Q, context.inputs[1], context.inputs[2], context.inputs[4], undefined, undefined, undefined,\n        context.inputs[5], params, attributes);\n  }\n\n  const K = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.headSize, context.inputs[1],\n      context.inputs[3], params.hiddenSize);\n\n  const V = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.vHeadSize, context.inputs[2],\n      context.inputs[3], 2 * params.hiddenSize);\n\n  applyAttention(\n      context, Q, K, V, context.inputs[4], undefined, context.inputs[6], context.inputs[7], context.inputs[5], params,\n      attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface PadAttributes extends AttributeWithCacheKey {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[],\n     dataType: string, constantValue: number): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${inputDims[i]}) {\n              break;\n            }\n            offset += k * ${inputStrides[i]};\n        `;\n      }\n\n      return `\n          value = ${dataType}(${constantValue});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n    };\n\nconst getPadReflect =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2 * (inputDims[i] - 1)};\n                  k = k % _2n_1;\n                  if(k >= ${inputDims[i]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadEdge =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${inputDims[i]}) {\n                  k = ${inputDims[i] - 1};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadWrap =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0)  {\n                  k += ${inputDims[i]};\n                }\n                if (k >= ${inputDims[i]}) {\n                  k -= ${inputDims[i]};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadSnippet =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], attributes: PadAttributes,\n     dataType: string): string => {\n      switch (attributes.mode) {\n        case 0:\n          return getPadConstant(output, inputDims, inputStrides, attributes.pads, dataType, attributes.value);\n        case 1:\n          return getPadReflect(output, inputDims, inputStrides, attributes.pads);\n        case 2:\n          return getPadEdge(output, inputDims, inputStrides, attributes.pads);\n        case 3:\n          return getPadWrap(output, inputDims, inputStrides, attributes.pads);\n        default:\n          throw new Error('Invalid mode');\n      }\n    };\n\nconst generatePadCode =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: PadAttributes, dataType: string):\n        string => {\n          const inputDims = inputs[0].dims;\n          const outputDims = ShapeUtil.padShape(inputDims.slice(), attributes.pads);\n          const outputSize = ShapeUtil.size(outputDims);\n          const inputStrides = ShapeUtil.computeStrides(inputDims);\n\n          const output = outputVariable('output', inputs[0].dataType, outputDims);\n          const input = inputVariable('x', inputs[0].dataType, inputDims);\n\n          const padSnippet = getPadSnippet(output, inputDims, inputStrides, attributes, dataType);\n          const padCode = `\n              ${shaderHelper.declareVariables(input, output)}\n              ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(0);\n              ${padSnippet}\n              output[global_idx] = value;\n          }`;\n          return padCode;\n        };\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  return {\n    name: 'Pad',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n    }),\n    getShaderSource: shaderHelper => generatePadCode(shaderHelper, inputs, attributes, 'f32'),\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return createAttributeWithCacheKey({mode: attributes.mode, value, pads});\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parsePadAttributes = (attributes: Record<string, unknown>): PadAttributes => {\n  const mode = attributes.mode as number;\n  const value = attributes.value as number;\n  const pads = attributes.pads as number[];\n  return createAttributeWithCacheKey({mode, value, pads});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('Pool ops supports 1-D or 2-D inputs only for now.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!);  // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, xShape: readonly number[], outputShape: readonly number[],\n    attributes: AttributeType, op1: string, op2: string, start: string): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputDims = xShape;\n  const dataType = x.type.value;\n  const rank = inputDims.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', x.type.tensor, outputShape);\n\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    if (pwStart + pwEnd !== 0) {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}] >= ${inputDims[dimIdxW]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      const dimH = inputDims[dimIdxH];\n      if (phStart + phEnd !== 0) {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= ${dimH}) {\n                    pad+= ${kw};\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value: ${dataType} = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelSize = ShapeUtil.size(attributes.kernelShape);\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    const stridesRank = kernelStrides.length;\n    const padsRank = attributes.pads.length;\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            const pads = array<u32, ${padsRank}>(${attributes.pads.map(i => `${i}u`).join(',')});\n            const inputDims = array<u32, ${rank}>(${inputDims.map(i => `${i}u`).join(',')});\n            const kernelStrides = array<u32, ${stridesRank}>(${kernelStrides.map(i => `${i}u`).join(',')});\n            const strides = array<u32, ${stridesRank}>(${attributes.strides.map(i => `${i}u`).join(',')});\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              let xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${output.type.value}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${kernelSize}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${rank - stridesRank}u]\n                    + offsets[j - ${rank - stridesRank}u] - pads[j - 2u];\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const kernelSize = ShapeUtil.size(adjustedAttributes.kernelShape);\n\n      const x = inputVariable('x', input.dataType, input.dims);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(${kernelSize});`;\n      } else {\n        op2 += `value /= ${dataType}(${kernelSize} - pad);`;\n      }\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '0.0'),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n\n  return createAttributeWithCacheKey({countIncludePad, ...attr});\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n  cacheKey: ''\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims);\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '-1e5'),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n\n  return createAttributeWithCacheKey({storageOrder, dilations, ...attr});\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {outputVariable, ShaderHelper} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n\n  const output = outputVariable('output', dataType, outputShape);\n  const wgslType = output.type.storage;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        output[global_idx] = ${wgslType}(${start}) + ${wgslType}(global_idx) * ${wgslType}(${delta});\n      }`;\n  return {\n    name: 'Range',\n    shaderCache: {hint: [start, limit, delta].map(x => x.toString()).join('_')},\n    getShaderSource,\n    getRunData: () => (\n        {outputs: [{dims: outputShape, dataType}],\n         dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}})\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for linear mode');\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate = (coordinateTransferMode: CoordinateTransformMode): string =>\n    'fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,\\\n    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { ' +\n    (() => {\n      switch (coordinateTransferMode) {\n        case 'asymmetric':\n          return 'return xResized / xScale;';\n        case 'pytorch_half_pixel':\n          return 'if (lengthResized > 1) { \\\n                    return (xResized + 0.5) / xScale - 0.5; \\\n                  } else { \\\n                    return 0.0; \\\n                  }';\n        case 'tf_half_pixel_for_nn':\n          return 'return (xResized + 0.5) / xScale;';\n        case 'align_corners':\n          return 'if (lengthResized == 1) { \\\n                    return 0.0; \\\n                  } else { \\\n                    return xResized * (lengthOriginal - 1) / (lengthResized - 1); \\\n                  }';\n        case 'tf_crop_and_resize':\n          return 'if (lengthResized > 1) { \\\n                    return roiStart * (lengthOriginal - 1) + \\\n                          (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1); \\\n                  } else { \\\n                    return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1); \\\n                  }';\n        case 'half_pixel_symmetric':\n          return [\n            'const outputWidth = xScale * lengthResized;', 'const adjustment = lengthResized / outputWidth;',\n            'const center = lengthOriginal / 2;', 'const offset = center * (1 - adjustment);',\n            'return offset + ((xResized + 0.5) / xScale) - 0.5;'\n          ].join('\\n');\n        case 'half_pixel':\n          return 'return ((xResized + 0.5) / xScale) - 0.5;';\n        default:\n          throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number): string =>\n    'fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {' + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape = (inputShape: readonly number[], scales: number[], attributes: ResizeAttributes): number[] => {\n  const scaleInPolicy = (() => {\n    switch (attributes.keepAspectRatioPolicy) {\n      case 'not_larger':\n        return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                            Math.min(...scales, Number.MAX_VALUE);\n      case 'not_smaller':\n        return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                            Math.max(...scales, Number.MIN_VALUE);\n      default:\n        throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n    }\n  })();\n  scales.fill(1.0, 0, scales.length);\n  const adjustedOutputShape = inputShape.slice();\n  if (attributes.axes.length > 0) {\n    attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n    attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n  } else {\n    scales.fill(scaleInPolicy, 0, scales.length);\n    adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n  }\n  return adjustedOutputShape;\n};\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scales: readonly number[],\n     roi: readonly number[]): string => `\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> array<f32, ${\n        outputShape.length}> {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n      const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n      const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n      var originalIndices: array<f32, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n        }\n      }\n      return originalIndices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n        const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n        const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n        const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n        var inputIndices: ${input.type.indices};\n        for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n          var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n            if (!${useExtrapolation} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${input.indicesSet('inputIndices', 'i', 'inputIndex')}\n        }\n        return inputIndices;\n    }`;\n\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(inputIndices: ${input.type.indices}) -> bool {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var inputIndex = ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], scales: readonly number[],\n     useExtrapolation: boolean, extrapolationValue: number): string => {\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (scales[1] === 1.0 ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${input.type.indices};\n      inputIndices[${heightIdx}] = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      inputIndices[${widthIdx}] = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      if (${inputShape.length} > 2) {\n        inputIndices[${channelIdx}] = channel;\n        inputIndices[${batchIdx}] = batch;\n      };\n      return input[${input.indicesToOffset('inputIndices')}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${heightIdx}];\n      var col:f32 = originalIndices[${widthIdx}];\n      if (${useExtrapolation} && (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > ${\n          inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${inputShape.length > 2}) {\n        channel = u32(originalIndices[${channelIdx}]);\n        batch = u32(originalIndices[${batchIdx}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const [heightIdx, widthIdx] = inputShape.length === 2 ? [0, 1] : (scales[1] === 1.0) ? [2, 3] : [1, 2];\n\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(inputIndices: ${input.type.indices}, outputIndices: ${\n            output.type.indices}) -> f32 {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : `outputIndices[${idx}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${scales[idx]},\n        f32(${outputShape[idx]}), f32(${inputShape[idx]}), ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: f32 = originalIdx + f32(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            if (${excludeOutside}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${useExtrapolation}) {\n              return ${extrapolationValue};\n            } else {\n              ${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${input.type.indices} = inputIndices;\n          inputIndicesCopy[${idx}] = u32(${direction});\n          data[i + 1] = ${idx === heightIdx ? `input[${input.indicesToOffset('inputIndicesCopy')}];` : `\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n    var inputIndices: ${input.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape);\n      const input = inputVariable('input', inputTensor.dataType, inputShape);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${noScale ? '' : `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales, roi, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales, roi)};\n              ${\n                bilinearInterpolation(\n                    input, output, inputShape, scales, useExtrapolation, attributes.extrapolationValue)};\n              `;\n          case 'cubic':\n            return `\n            ${\n                bicubicInterpolation(\n                    input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                    attributes.extrapolationValue, attributes.excludeOutside)};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      `}\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        ${noScale ? 'output[global_idx] = input[global_idx];' : `\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        var inputIndices: ${input.type.indices};\n        ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${input.indicesToOffset('inputIndices')}];\n                } else {\n                  output[global_idx] = ${attributes.extrapolationValue};\n                }`;\n          case 'linear':\n            return 'output[global_idx] = bilinearInterpolation(outputIndices);';\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(outputIndices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n        `}\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}|${noScale}`\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number, isTraining: boolean):\n        ProgramInfo => {\n          const inputShape = inputs[0].dims;\n          const inputSize = ShapeUtil.size(inputShape);\n          const outputShape = inputShape;\n          const outputSize = inputSize;\n          const hiddenSize = inputShape.slice(-1)[0];\n          const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n          const hasBetaInput = inputs.length > 3;\n          const hasBiasInput = inputs.length > 4;\n          const hasMeanOutput = isTraining && outputCount > 1;\n          const hasInvStdDevOutput = isTraining && outputCount > 2;\n          const hasInputSkipBiasSumOutput = outputCount > 3;\n\n          const components = getMaxComponents(hiddenSize);\n          const variables = [\n            inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n            inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n            inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n          ];\n          if (hasBetaInput) {\n            variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n          }\n          if (hasBiasInput) {\n            variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n          }\n          variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n          if (hasMeanOutput) {\n            variables.push(outputVariable('meanOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInvStdDevOutput) {\n            variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInputSkipBiasSumOutput) {\n            variables.push(outputVariable('inputSkipBiasSum', inputs[0].dataType, outputShape, components));\n          }\n          const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n          const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: f32 = ${hiddenSize};\n      const hiddenSizeVectorized: u32 = ${hiddenSize / components};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      ${shaderHelper.declareVariables(...variables)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${fillVector('f32', components)};\n        var squareSum = ${fillVector('f32', components)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32Value = ${castToF32(dataType, components, 'value')};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${sumVector('sum', components)} / hiddenSize;\n        let variance = sqrt(${sumVector('squareSum', components)} / hiddenSize - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${dataType}(mean)) / ${dataType}(variance) * gamma[i]\n           + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n          const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n          if (outputCount > 1) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 2) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 3) {\n            outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n          }\n\n          return {\n            name: 'SkipLayerNormalization',\n            shaderCache: {hint: attributes.cacheKey},\n            getShaderSource,\n            getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n          };\n        };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform, TensorInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     enableInputShapeUniforms: boolean): string =>\n        `fn calculateInputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n          var inputIndices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            let input_shape_i = ${\n            enableInputShapeUniforms ? `uniforms.input_shape${inputShape.length > 1 ? '[i]' : ''}` : 'inputShape[i]'};\n            let steps_i  = ${\n            enableInputShapeUniforms ? `uniforms.steps${inputShape.length > 1 ? '[i]' : ''}` : 'steps[i]'};\n            let signs_i  = ${\n            enableInputShapeUniforms ? `uniforms.signs${inputShape.length > 1 ? '[i]' : ''}` : 'signs[i]'};\n            let starts_i  = ${\n            enableInputShapeUniforms ? `uniforms.starts${inputShape.length > 1 ? '[i]' : ''}` : 'starts[i]'};\n            var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n            var inputIndex = outputIndex * steps_i + starts_i + carry;\n            carry = inputIndex / input_shape_i;\n            inputIndex = inputIndex % input_shape_i;\n            if (signs_i < 0) {\n              inputIndex = input_shape_i - inputIndex - 1u + starts_i;\n            }\n            ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'} = inputIndex;\n          }\n          return inputIndices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== starts.length || axes.length !== ends.length) {\n    throw new Error('start, ends and axes should have the same number of elements');\n  }\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n  // Output rank is expected to be less than or equal to the input rank.\n  const enableShapeUniforms = enableShapesUniforms(inputs[0].dims.length);\n  const inputShapeOrRank = enableShapeUniforms ? inputs[0].dims.length : inputs[0].dims;\n\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n  const outputShapeOrRank = enableShapeUniforms ? outputShape.length : outputShape;\n\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShapeOrRank);\n  const input = inputVariable('input', inputs[0].dataType, inputShapeOrRank);\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [];\n  const uniforms: UniformsArrayType = [];\n  if (enableShapeUniforms) {\n    uniforms.push({name: 'starts', type: starts.length > 1 ? `vec${starts.length}<u32>` : 'u32'});\n    uniforms.push({name: 'signs', type: signs.length > 1 ? `vec${signs.length}<i32>` : 'i32'});\n    uniforms.push({name: 'steps', type: steps.length > 1 ? `vec${steps.length}<u32>` : 'u32'});\n    programUniforms.push({type: 'uint32', data: starts});\n    programUniforms.push({type: 'int32', data: signs});\n    programUniforms.push({type: 'uint32', data: steps});\n  }\n  uniforms.push({name: 'outputSize', type: 'u32'});\n  programUniforms.push({type: 'uint32', data: outputSize});\n  if (enableShapeUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n        ${enableShapeUniforms ? '' : [\n    `const signs = array<i32, ${signs.length}>(${signs.map(i => `${i}i`).join(',')});`,\n    `const starts = array<u32, ${starts.length}>(${starts.map(i => `${i}u`).join(',')});`,\n    `const steps = array<u32, ${steps.length}>(${steps.map(i => `${i}u`).join(',')});`,\n    `const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});`\n  ].join('\\n')}\n\n        ${calculateInputIndicesImpl(input, output, inputShape, outputShape, enableShapeUniforms)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {\n      hint: enableShapeUniforms ? `${signs.length}_${starts.length}_${steps.length}` :\n                                  `${attributes.cacheKey} | ${inputs[4]?.dims ?? ''}`,\n      inputDependencies: [enableShapeUniforms ? 'rank' : 'dims']\n    },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n  const x = inputVariable('x', input.dataType, input.dims, components);\n  const output = outputVariable('result', input.dataType, input.dims, components);\n  const valueType = x.type.value;\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl = tensorTypeToWsglStorageType(input.dataType) === 'f32' ?\n      `var threadMax = ${valueType}(-3.402823e+38f);` :\n      `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${shaderHelper.registerUniform('packedCols', 'i32').declareVariables(x, output)}\n      ${shaderHelper.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    shaderCache: {hint: `${components}`, inputDependencies: ['type']},\n    getRunData: () => ({\n      outputs: [{dims: shape, dataType: input.dataType}],\n      dispatchGroup: {x: rows},\n      programUniforms: [{type: 'uint32', data: packedCols}]\n    }),\n    getShaderSource,\n  };\n};\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (outputNumber == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (outputNumber == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(outputNumber: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const rank = inputShape.length;\n  const axis = attributes.axis;\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInConcatAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInConcatAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShapes[i]);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  const indicesAxis = rank < 2 ? 'indices' : `indices[${adjustedAxis}]`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(input, ...outputs)}\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateOutputIndexImpl(sizeInConcatAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(inputSize)}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    let outputNumber = calculateOutputIndex(${indicesAxis});\n    if (outputNumber != 0) {\n        ${indicesAxis} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      var inputIndices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let inputDimValue = ${output.indicesGet('outputIndices', 'i')}  % ${input.indicesGet('inputShape', 'i')};\n\n        ${input.indicesSet('inputIndices', 'i', 'inputDimValue')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', inputs[1].dataType, inputs[1].dims, 4);\n      const b = inputVariable('bData', inputs[2].dataType, inputs[2].dims, 4);\n      const c = inputVariable('cData', inputs[0].dataType, inputs[0].dims, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(cData[indexC${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)}\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {attention, parseAttentionAttributes} from './ops/attention';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm, parseInstanceNormAttributes} from './ops/instance-norm';\nimport {layerNorm, parseLayerNormAttributes} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {multiHeadAttention, parseMultiHeadAttentionAttributes} from './ops/multi-head-attentiion';\nimport {pad, parsePadAttributes} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {parseReduceAttributes, reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  ['Attention', [attention, parseAttentionAttributes]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm, parseInstanceNormAttributes]],\n  ['LayerNormalization', [layerNorm, parseLayerNormAttributes]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['MultiHeadAttention', [multiHeadAttention, parseMultiHeadAttentionAttributes]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad, parsePadAttributes]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin, parseReduceAttributes]],\n  ['ReduceMean', [reduceMean, parseReduceAttributes]],\n  ['ReduceMax', [reduceMax, parseReduceAttributes]],\n  ['ReduceSum', [reduceSum, parseReduceAttributes]],\n  ['ReduceProd', [reduceProd, parseReduceAttributes]],\n  ['ReduceL1', [reduceL1, parseReduceAttributes]],\n  ['ReduceL2', [reduceL2, parseReduceAttributes]],\n  ['ReduceLogSum', [reduceLogSum, parseReduceAttributes]],\n  ['ReduceLogSumExp', [reduceLogSumExp, parseReduceAttributes]],\n  ['ReduceSumSquare', [reduceSumSquare, parseReduceAttributes]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (this.backend.isQueryEnabled()) {\n      if (typeof this.backend.queryData === 'undefined') {\n        this.backend.queryData = this.backend.gpuDataManager.create(\n            // eslint-disable-next-line no-bitwise\n            this.backend.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      const syncData = this.backend.gpuDataManager.create(\n          // eslint-disable-next-line no-bitwise\n          this.backend.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet!, 0, 2, this.backend.queryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.queryData.buffer, 0, syncData.buffer, 0, this.backend.querySetCount * 8);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n      const kernelName = `[${kernelInfo[0]}] ${kernelInfo[1]}`;\n\n      void syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const startTimeU64 = mappedData[0];\n        const endTimeU64 = mappedData[1];\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.queryTimeBase === 'undefined') {\n          this.backend.queryTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.queryTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.queryTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        let inputShapes = '';\n        inputTensorViews.forEach((value, i) => {\n          inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        let outputShapes = '';\n        outputTensorViews.forEach((value, i) => {\n          outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        // eslint-disable-next-line no-console\n        console.log(`[profiling] kernel \"${kernelId}|${kernelName}\" ${inputShapes}${outputShapes}execution time: ${\n            endTime - startTime} ns`);\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] ${programInfo.name} shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey =\n    (programInfo: ProgramInfo, inputTensors: readonly TensorView[], is1DimensionDispatch: boolean): string => {\n      // final key format:\n      // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:is1DimensionDispatch:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n      let key = programInfo.name;\n      if (programInfo.shaderCache?.hint) {\n        key += '[' + programInfo.shaderCache.hint + ']';\n      }\n      key += ':' + is1DimensionDispatch +\n          `:${\n                 getProgramInputTensorInfoDependencyKey(\n                     inputTensors,\n                     programInfo.shaderCache?.inputDependencies ??\n                         new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n      return key;\n    };\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  private commandEncoder: GPUCommandEncoder|null = null;\n  private computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  queryData?: GpuData;\n  querySet?: GPUQuerySet;\n  querySetCount = 2;\n  queryTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env): Promise<void> {\n    if (!navigator.gpu) {\n      // WebGPU is not available.\n      throw new Error('WebGpuBackend: WebGPU is not available.');\n    }\n\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error('WebGpuBackend: Failed to get GPU adapter.');\n    }\n\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n      if (this.isQueryEnabled()) {\n        if (typeof this.querySet === 'undefined') {\n          this.querySet = this.device.createQuerySet({\n            type: 'timestamp',\n            count: this.querySetCount,\n          });\n        }\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: 0,\n          endOfPassWriteIndex: 1,\n        };\n      }\n\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  isQueryEnabled(): boolean {\n    if (this.device.features.has('timestamp-query') && this.env.webgpu.profilingMode === 'default') {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      let preLength = 0;\n      const offsets: number[] = [];\n      let maxAlignmentOfField = 1;\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (data.length === 0) {\n          return;\n        }\n        // https://www.w3.org/TR/WGSL/#alignof\n        let baseAlignment: number;\n        switch (data.length) {\n          case 1:\n            baseAlignment = 4;\n            break;\n          case 2:\n            baseAlignment = 8;\n            break;\n          case 3:\n            baseAlignment = 16;\n            break;\n          case 4:\n            baseAlignment = 16;\n            break;\n          case 5:\n            baseAlignment = 16;\n            break;\n          case 6:\n            baseAlignment = 16;\n            break;\n          default:\n            throw new Error(`unsupported data length: ${data.length}`);\n        }\n\n        if (preLength === 5 || preLength === 6) {\n          baseAlignment = 16;\n        }\n        if (baseAlignment > maxAlignmentOfField) {\n          maxAlignmentOfField = baseAlignment;\n        }\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        preLength = data.length;\n        offsets.push(currentOffset);\n        currentOffset += data.length * 4;\n      });\n\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n    const is1DimensionDispatch = normalizedDispatchGroup[1] === 1 && normalizedDispatchGroup[2] === 1;\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews, is1DimensionDispatch);\n    let artifact = this.programManager.getArtifact(key);\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\nexport const init = async(module: OrtWasmModule, env: Env): Promise<void> => {\n  const init = module.jsepInit;\n  if (init && navigator.gpu) {\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP');\n    }\n    const backend = new WebGpuBackend();\n    await backend.initialize(env);\n\n    init(\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(size),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n            backend.memcpy(src, dst);\n          } else {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n            const data = module.HEAPU8.subarray(src, src + size);\n            backend.upload(dst, data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async(gpuDataId: number, dataOffset: number, size: number):\n            Promise<void> => {\n              LOG_DEBUG(\n                  'verbose',\n                  () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n              await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n            },\n\n        // jsepCreateKernel\n        (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n            name, kernel, attribute,\n            env.debug || env.webgpu.profilingMode === 'default' ? module.UTF8ToString(module._JsepGetNodeName(kernel)) :\n                                                                  `${kernel}`),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n          LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                  contextDataOffset}`);\n          const context = new ComputeContextImpl(module, backend, contextDataOffset);\n          return backend.computeKernel(kernel, context, errors);\n        });\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\nlet ortEnvInitialized = false;\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * initialize ORT environment.\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env);\n  }\n\n  ortEnvInitialized = true;\n};\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\nexport const isOrtEnvInitialized = (): boolean => ortEnvInitialized;\n\n/**\n * allocate the memory and memcpy the model bytes, preparing for creating an instance of InferenceSession.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const createSessionAllocate = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session using the prepared buffer containing the model data.\n * @param modelData a 2-elements tuple containing the pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSessionFinalize =\n    (modelData: SerializableModeldata, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const wasm = getInstance();\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelData[0], modelData[1], sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelData[0]);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\n\n/**\n * create an instance of InferenceSession.\n * @returns the metadata of InferenceSession. 0-value handle for failure.\n */\nexport const createSession =\n    (model: Uint8Array, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const modelData: SerializableModeldata = createSessionAllocate(model);\n      return createSessionFinalize(modelData, options);\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var un=Object.defineProperty;var Ou=Object.getOwnPropertyDescriptor;var ku=Object.getOwnPropertyNames;var Pu=Object.prototype.hasOwnProperty;var F=(e,t)=>()=>(e&&(t=e(e=0)),t);var rr=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),Er=(e,t)=>{for(var r in t)un(e,r,{get:t[r],enumerable:!0})},Ru=(e,t,r,o)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let n of ku(t))!Pu.call(e,n)&&n!==r&&un(e,n,{get:()=>t[n],enumerable:!(o=Ou(t,n))||o.enumerable});return e};var zt=e=>Ru(un({},\"__esModule\",{value:!0}),e);var ln={};Er(ln,{readFile:()=>Bu});var Bu,dn=F(()=>{Bu=void 0});var cn={};Er(cn,{join:()=>Mu});var Mu,pn=F(()=>{Mu=void 0});var po=rr((co,fn)=>{\"use strict\";var lo=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){var r=t,o,n;r.ready=new Promise((l,f)=>{o=l,n=f}),r.jsepInit=(l,f,g,x,O,H,U,se)=>{r.Za=l,r.Oa=f,r.Qa=g,r.Ja=x,r.Pa=O,r.ra=H,r.Ra=U,r.Sa=se,f=(Z,ee,X)=>(...ce)=>{let he=Ke,k=ee?.();ce=Z(...ce);let ne=ee?.();return k!==ne&&(Z=ne,X(k),ee=X=null),Ke!=he?wr():ce},g=Z=>async(...ee)=>{try{if(r.Da)throw Error(\"Session already started\");let X=r.Da={Ta:ee[0],errors:[]},ce=await Z(...ee);if(r.Da!==X)throw Error(\"Session mismatch\");l.flush();let he=X.errors;if(0<he.length){let k=await Promise.all(he);if(k=k.filter(ne=>ne),0<k.length)throw Error(k.join(`\n`))}return ce}finally{r.Da=null}},r._OrtRun=g(f(r._OrtRun,()=>r._OrtRun,Z=>r._OrtRun=Z)),r._OrtRunWithBinding=g(f(r._OrtRunWithBinding,()=>r._OrtRunWithBinding,Z=>r._OrtRunWithBinding=Z)),r._OrtBindInput=f(r._OrtBindInput,()=>r._OrtBindInput,Z=>r._OrtBindInput=Z),r.jsepRegisterBuffer=(Z,ee,X,ce)=>l.registerBuffer(Z,ee,X,ce),r.jsepUnregisterBuffers=Z=>{l.unregisterBuffers(Z)},r.jsepGetBuffer=Z=>l.getBuffer(Z),r.jsepCreateDownloader=(Z,ee,X)=>l.createDownloader(Z,ee,X)};var s=Object.assign({},r),u=\"./this.program\",d=(l,f)=>{throw f},a=typeof window==\"object\",p=typeof importScripts==\"function\",h=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",v=\"\",y,b,w;if(h){var S=(dn(),zt(ln)),C=(pn(),zt(cn));v=p?C.dirname(v)+\"/\":__dirname+\"/\",y=(l,f)=>(l=l.startsWith(\"file://\")?new URL(l):C.normalize(l),S.readFileSync(l,f?void 0:\"utf8\")),w=l=>(l=y(l,!0),l.buffer||(l=new Uint8Array(l)),l),b=(l,f,g,x=!0)=>{l=l.startsWith(\"file://\")?new URL(l):C.normalize(l),S.readFile(l,x?void 0:\"utf8\",(O,H)=>{O?g(O):f(x?H.buffer:H)})},!r.thisProgram&&1<process.argv.length&&(u=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),d=(l,f)=>{throw process.exitCode=l,f},r.inspect=()=>\"[Emscripten Module object]\"}else(a||p)&&(p?v=self.location.href:typeof document<\"u\"&&document.currentScript&&(v=document.currentScript.src),e&&(v=e),v.indexOf(\"blob:\")!==0?v=v.substr(0,v.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):v=\"\",y=l=>{var f=new XMLHttpRequest;return f.open(\"GET\",l,!1),f.send(null),f.responseText},p&&(w=l=>{var f=new XMLHttpRequest;return f.open(\"GET\",l,!1),f.responseType=\"arraybuffer\",f.send(null),new Uint8Array(f.response)}),b=(l,f,g)=>{var x=new XMLHttpRequest;x.open(\"GET\",l,!0),x.responseType=\"arraybuffer\",x.onload=()=>{x.status==200||x.status==0&&x.response?f(x.response):g()},x.onerror=g,x.send(null)});var A=r.print||console.log.bind(console),I=r.printErr||console.error.bind(console);Object.assign(r,s),s=null,r.thisProgram&&(u=r.thisProgram),r.quit&&(d=r.quit);var B;r.wasmBinary&&(B=r.wasmBinary);var _=r.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&je(\"no native wasm support detected\");var R,E,W=!1,V,Y,ae,M,K,Se,ue;function ve(){var l=R.buffer;r.HEAP8=Y=new Int8Array(l),r.HEAP16=new Int16Array(l),r.HEAP32=M=new Int32Array(l),r.HEAPU8=ae=new Uint8Array(l),r.HEAPU16=new Uint16Array(l),r.HEAPU32=K=new Uint32Array(l),r.HEAPF32=Se=new Float32Array(l),r.HEAPF64=ue=new Float64Array(l)}var j=[],xe=[],Pe=[];function _e(){var l=r.preRun.shift();j.unshift(l)}var Ce=0,ht=null,Le=null;function je(l){throw r.onAbort&&r.onAbort(l),l=\"Aborted(\"+l+\")\",I(l),W=!0,V=1,l=new WebAssembly.RuntimeError(l+\". Build with -sASSERTIONS for more info.\"),n(l),l}function L(l){return l.startsWith(\"data:application/octet-stream;base64,\")}var de;if(de=\"ort-wasm-simd.wasm\",!L(de)){var pe=de;de=r.locateFile?r.locateFile(pe,v):v+pe}function We(l){if(l==de&&B)return new Uint8Array(B);if(w)return w(l);throw\"both async and sync fetching of the wasm failed\"}function Fe(l){if(!B&&(a||p)){if(typeof fetch==\"function\"&&!l.startsWith(\"file://\"))return fetch(l,{credentials:\"same-origin\"}).then(f=>{if(!f.ok)throw\"failed to load wasm binary file at '\"+l+\"'\";return f.arrayBuffer()}).catch(()=>We(l));if(b)return new Promise((f,g)=>{b(l,x=>f(new Uint8Array(x)),g)})}return Promise.resolve().then(()=>We(l))}function Oe(l,f,g){return Fe(l).then(x=>WebAssembly.instantiate(x,f)).then(x=>x).then(g,x=>{I(\"failed to asynchronously prepare wasm: \"+x),je(x)})}function Me(l,f){var g=de;return B||typeof WebAssembly.instantiateStreaming!=\"function\"||L(g)||g.startsWith(\"file://\")||h||typeof fetch!=\"function\"?Oe(g,l,f):fetch(g,{credentials:\"same-origin\"}).then(x=>WebAssembly.instantiateStreaming(x,l).then(f,function(O){return I(\"wasm streaming compile failed: \"+O),I(\"falling back to ArrayBuffer instantiation\"),Oe(g,l,f)}))}var He,rt={911200:l=>{r.ra(\"Abs\",l,void 0)},911251:l=>{r.ra(\"Neg\",l,void 0)},911302:l=>{r.ra(\"Floor\",l,void 0)},911355:l=>{r.ra(\"Ceil\",l,void 0)},911407:l=>{r.ra(\"Reciprocal\",l,void 0)},911465:l=>{r.ra(\"Sqrt\",l,void 0)},911517:l=>{r.ra(\"Exp\",l,void 0)},911568:l=>{r.ra(\"Erf\",l,void 0)},911619:l=>{r.ra(\"Sigmoid\",l,void 0)},911674:l=>{r.ra(\"Log\",l,void 0)},911725:l=>{r.ra(\"Sin\",l,void 0)},911776:l=>{r.ra(\"Cos\",l,void 0)},911827:l=>{r.ra(\"Tan\",l,void 0)},911878:l=>{r.ra(\"Asin\",l,void 0)},911930:l=>{r.ra(\"Acos\",l,void 0)},911982:l=>{r.ra(\"Atan\",l,void 0)},912034:l=>{r.ra(\"Sinh\",l,void 0)},912086:l=>{r.ra(\"Cosh\",l,void 0)},912138:l=>{r.ra(\"Asinh\",l,void 0)},912191:l=>{r.ra(\"Acosh\",l,void 0)},912244:l=>{r.ra(\"Atanh\",l,void 0)},912297:l=>{r.ra(\"Tanh\",l,void 0)},912349:l=>{r.ra(\"Not\",l,void 0)},912400:(l,f,g)=>{r.ra(\"Clip\",l,{min:f,max:g})},912469:l=>{r.ra(\"Clip\",l,void 0)},912521:(l,f)=>{r.ra(\"Elu\",l,{alpha:f})},912579:l=>{r.ra(\"Relu\",l,void 0)},912631:(l,f)=>{r.ra(\"LeakyRelu\",l,{alpha:f})},912695:(l,f)=>{r.ra(\"ThresholdedRelu\",l,{alpha:f})},912765:(l,f)=>{r.ra(\"Cast\",l,{to:f})},912823:l=>{r.ra(\"Add\",l,void 0)},912874:l=>{r.ra(\"Sub\",l,void 0)},912925:l=>{r.ra(\"Mul\",l,void 0)},912976:l=>{r.ra(\"Div\",l,void 0)},913027:l=>{r.ra(\"Pow\",l,void 0)},913078:l=>{r.ra(\"Equal\",l,void 0)},913131:l=>{r.ra(\"Greater\",l,void 0)},913186:l=>{r.ra(\"GreaterOrEqual\",l,void 0)},913248:l=>{r.ra(\"Less\",l,void 0)},913300:l=>{r.ra(\"LessOrEqual\",l,void 0)},913359:(l,f,g,x,O)=>{r.ra(\"ReduceMean\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},913523:(l,f,g,x,O)=>{r.ra(\"ReduceMax\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},913686:(l,f,g,x,O)=>{r.ra(\"ReduceMin\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},913849:(l,f,g,x,O)=>{r.ra(\"ReduceProd\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914013:(l,f,g,x,O)=>{r.ra(\"ReduceSum\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914176:(l,f,g,x,O)=>{r.ra(\"ReduceL1\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914338:(l,f,g,x,O)=>{r.ra(\"ReduceL2\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914500:(l,f,g,x,O)=>{r.ra(\"ReduceLogSum\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914666:(l,f,g,x,O)=>{r.ra(\"ReduceSumSquare\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},914835:(l,f,g,x,O)=>{r.ra(\"ReduceLogSumExp\",l,{keepDims:!!f,noopWithEmptyAxes:!!g,axes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},915004:l=>{r.ra(\"Where\",l,void 0)},915057:(l,f,g)=>{r.ra(\"Transpose\",l,{perm:f?Array.from(M.subarray(g>>>0,g+f>>>0)):[]})},915170:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne)=>{r.ra(\"ConvTranspose\",l,{format:Z?\"NHWC\":\"NCHW\",autoPad:f,dilations:[g],group:x,kernel_shape:[O],pads:[H,U],strides:[se],wIsConst:()=>!!Y[ee>>>0],outputPadding:X?Array.from(M.subarray(ce>>>0,ce+X>>>0)):[],outputShape:he?Array.from(M.subarray(k>>>0,k+he>>>0)):[],activation:Re(ne)})},915584:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k)=>{r.ra(\"ConvTranspose\",l,{format:se?\"NHWC\":\"NCHW\",autoPad:f,dilations:Array.from(M.subarray(g>>>0,g+2>>>0)),group:x,kernelShape:Array.from(M.subarray(O>>>0,O+2>>>0)),pads:Array.from(M.subarray(H>>>0,H+4>>>0)),strides:Array.from(M.subarray(U>>>0,U+2>>>0)),wIsConst:()=>!!Y[Z>>>0],outputPadding:0<ee?Array.from(M.subarray(X>>>0,X+ee>>>0)):[],outputShape:0<ce?Array.from(M.subarray(he>>>0,he+ce>>>0)):[],activation:Re(k)})},916141:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne)=>{r.ra(\"ConvTranspose\",l,{format:Z?\"NHWC\":\"NCHW\",autoPad:f,dilations:[g],group:x,kernel_shape:[O],pads:[H,U],strides:[se],wIsConst:()=>!!Y[ee>>>0],outputPadding:X?Array.from(M.subarray(ce>>>0,ce+X>>>0)):[],outputShape:he?Array.from(M.subarray(k>>>0,k+he>>>0)):[],activation:Re(ne)})},916555:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k)=>{r.ra(\"ConvTranspose\",l,{format:se?\"NHWC\":\"NCHW\",autoPad:f,dilations:Array.from(M.subarray(g>>>0,g+2>>>0)),group:x,kernelShape:Array.from(M.subarray(O>>>0,O+2>>>0)),pads:Array.from(M.subarray(H>>>0,H+4>>>0)),strides:Array.from(M.subarray(U>>>0,U+2>>>0)),wIsConst:()=>!!Y[Z>>>0],outputPadding:0<ee?Array.from(M.subarray(X>>>0,X+ee>>>0)):[],outputShape:0<ce?Array.from(M.subarray(he>>>0,he+ce>>>0)):[],activation:Re(k)})},917112:(l,f)=>{r.ra(\"GlobalAveragePool\",l,{format:f?\"NHWC\":\"NCHW\"})},917203:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne,fe)=>{r.ra(\"AveragePool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:f,ceil_mode:g,count_include_pad:x,storage_order:O,dilations:[H,U],kernel_shape:[se,Z],pads:[ee,X,ce,he],strides:[k,ne]})},917487:(l,f)=>{r.ra(\"GlobalAveragePool\",l,{format:f?\"NHWC\":\"NCHW\"})},917578:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne,fe)=>{r.ra(\"AveragePool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:f,ceil_mode:g,count_include_pad:x,storage_order:O,dilations:[H,U],kernel_shape:[se,Z],pads:[ee,X,ce,he],strides:[k,ne]})},917862:(l,f)=>{r.ra(\"GlobalMaxPool\",l,{format:f?\"NHWC\":\"NCHW\"})},917949:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne,fe)=>{r.ra(\"MaxPool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:f,ceil_mode:g,count_include_pad:x,storage_order:O,dilations:[H,U],kernel_shape:[se,Z],pads:[ee,X,ce,he],strides:[k,ne]})},918229:(l,f)=>{r.ra(\"GlobalMaxPool\",l,{format:f?\"NHWC\":\"NCHW\"})},918316:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne,fe)=>{r.ra(\"MaxPool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:f,ceil_mode:g,count_include_pad:x,storage_order:O,dilations:[H,U],kernel_shape:[se,Z],pads:[ee,X,ce,he],strides:[k,ne]})},918596:(l,f,g,x,O)=>{r.ra(\"Gemm\",l,{alpha:f,beta:g,transA:x,transB:O})},918700:l=>{r.ra(\"MatMul\",l,void 0)},918754:(l,f,g,x)=>{r.ra(\"ArgMax\",l,{keepDims:!!f,selectLastIndex:!!g,axis:x})},918862:(l,f,g,x)=>{r.ra(\"ArgMin\",l,{keepDims:!!f,selectLastIndex:!!g,axis:x})},918970:(l,f)=>{r.ra(\"Softmax\",l,{axis:f})},919033:(l,f)=>{r.ra(\"Concat\",l,{axis:f})},919093:(l,f,g,x,O)=>{r.ra(\"Split\",l,{axis:f,numOutputs:g,splitSizes:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},919238:l=>{r.ra(\"Expand\",l,void 0)},919292:(l,f)=>{r.ra(\"Gather\",l,{axis:Number(f)})},919363:(l,f)=>{r.ra(\"GatherElements\",l,{axis:Number(f)})},919442:(l,f,g,x,O,H,U,se,Z,ee,X)=>{r.ra(\"Resize\",l,{antialias:f,axes:g?Array.from(M.subarray(x>>>0,x+g>>>0)):[],coordinateTransformMode:Re(O),cubicCoeffA:H,excludeOutside:U,extrapolationValue:se,keepAspectRatioPolicy:Re(Z),mode:Re(ee),nearestMode:Re(X)})},919793:(l,f,g,x,O,H,U)=>{r.ra(\"Slice\",l,{starts:f?Array.from(M.subarray(g>>>0,g+f>>>0)):[],ends:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[],axes:H?Array.from(M.subarray(U>>>0,U+H>>>0)):[]})},920024:l=>{r.ra(\"Tile\",l,void 0)},920076:(l,f,g)=>{r.ra(\"LayerNormalization\",l,{axis:Number(f),epsilon:Number(g)})},920183:(l,f,g)=>{r.ra(\"InstanceNormalization\",l,{epsilon:f,format:g?\"NHWC\":\"NCHW\"})},920297:(l,f,g)=>{r.ra(\"InstanceNormalization\",l,{epsilon:f,format:g?\"NHWC\":\"NCHW\"})},920411:l=>{r.ra(\"Range\",l,void 0)},920464:(l,f)=>{r.ra(\"Einsum\",l,{equation:Re(f)})},920545:(l,f,g,x,O)=>{r.ra(\"Pad\",l,{mode:f,value:g,pads:x?Array.from(M.subarray(O>>>0,O+x>>>0)):[]})},920677:(l,f,g,x,O,H,U,se,Z)=>{r.ra(\"Attention\",l,{numHeads:f,isUnidirectional:g,maskFilterValue:x,scale:O,doRotary:H,qkvHiddenSizes:U?Array.from(M.subarray(Number(se)>>>0,Number(se)+U>>>0)):[],pastPresentShareBuffer:!!Z})},920949:l=>{r.ra(\"Gelu\",l,void 0)},921001:(l,f,g,x,O,H)=>{r.ra(\"MultiHeadAttention\",l,{numHeads:f,isUnidirectional:g,maskFilterValue:x,scale:O,doRotary:H})},921160:l=>{r.ra(\"BiasAdd\",l,void 0)},921215:l=>{r.ra(\"BiasSplitGelu\",l,void 0)},921276:(l,f)=>{r.ra(\"SkipLayerNormalization\",l,{epsilon:f})},921357:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he)=>{r.ra(\"Conv\",l,{format:Z?\"NHWC\":\"NCHW\",auto_pad:f,dilations:[g],group:x,kernel_shape:[O],pads:H?Array.from(M.subarray(U>>>0,U+H>>>0)):[],strides:[se],w_is_const:()=>!!Y[ee>>>0],activation:Re(X),activation_params:ce?Array.from(Se.subarray(he>>>0,he+ce>>>0)):[]})},921738:(l,f,g,x,O,H,U,se,Z,ee,X,ce,he,k,ne,fe)=>{r.ra(\"Conv\",l,{format:ce?\"NHWC\":\"NCHW\",auto_pad:f,dilations:[g,x],group:O,kernel_shape:[H,U],pads:se?Array.from(M.subarray(Z>>>0,Z+se>>>0)):[],strides:[ee,X],w_is_const:()=>!!Y[he>>>0],activation:Re(k),activation_params:ne?Array.from(Se.subarray(fe>>>0,fe+ne>>>0)):[]})},922140:l=>{r.Ra(l)},922174:(l,f)=>r.Sa(l,f,r.Da.Ta,r.Da.errors),922286:l=>r.Oa(l),922319:l=>r.Qa(l),922351:(l,f,g)=>{r.Ja(l,f,g,!0)},922390:(l,f,g)=>{r.Ja(l,f,g)}};function qe(l){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${l})`,this.status=l}var $t=l=>{for(;0<l.length;)l.shift()(r)};function St(l){this.Ha=l-24,this.Ma=function(f){K[this.Ha+4>>2>>>0]=f},this.La=function(f){K[this.Ha+8>>2>>>0]=f},this.Ya=function(f,g){this.Ka(),this.Ma(f),this.La(g)},this.Ka=function(){K[this.Ha+16>>2>>>0]=0}}var Vt=0,pr=0,Xe=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,Nt=(l,f,g)=>{f>>>=0;var x=f+g;for(g=f;l[g]&&!(g>=x);)++g;if(16<g-f&&l.buffer&&Xe)return Xe.decode(l.subarray(f,g));for(x=\"\";f<g;){var O=l[f++];if(O&128){var H=l[f++]&63;if((O&224)==192)x+=String.fromCharCode((O&31)<<6|H);else{var U=l[f++]&63;O=(O&240)==224?(O&15)<<12|H<<6|U:(O&7)<<18|H<<12|U<<6|l[f++]&63,65536>O?x+=String.fromCharCode(O):(O-=65536,x+=String.fromCharCode(55296|O>>10,56320|O&1023))}}else x+=String.fromCharCode(O)}return x},Re=(l,f)=>(l>>>=0)?Nt(ae,l,f):\"\",Ot=l=>{for(var f=0,g=0;g<l.length;++g){var x=l.charCodeAt(g);127>=x?f++:2047>=x?f+=2:55296<=x&&57343>=x?(f+=4,++g):f+=3}return f},Ut=(l,f,g,x)=>{if(g>>>=0,!(0<x))return 0;var O=g;x=g+x-1;for(var H=0;H<l.length;++H){var U=l.charCodeAt(H);if(55296<=U&&57343>=U){var se=l.charCodeAt(++H);U=65536+((U&1023)<<10)|se&1023}if(127>=U){if(g>=x)break;f[g++>>>0]=U}else{if(2047>=U){if(g+1>=x)break;f[g++>>>0]=192|U>>6}else{if(65535>=U){if(g+2>=x)break;f[g++>>>0]=224|U>>12}else{if(g+3>=x)break;f[g++>>>0]=240|U>>18,f[g++>>>0]=128|U>>12&63}f[g++>>>0]=128|U>>6&63}f[g++>>>0]=128|U&63}}return f[g>>>0]=0,g-O},ct=l=>l%4===0&&(l%100!==0||l%400===0),fr=[0,31,60,91,121,152,182,213,244,274,305,335],pt=[0,31,59,90,120,151,181,212,243,273,304,334],kt=l=>{var f=Ot(l)+1,g=Mt(f);return g&&Ut(l,ae,g,f),g},gt=[],Pt=(l,f)=>{gt.length=0;var g;for(f>>=2;g=ae[l++>>>0];)f+=g!=105&f,gt.push(g==105?M[f>>>0]:ue[f++>>>1]),++f;return gt},Rt={},Ht=()=>{if(!Bt){var l={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:u||\"./this.program\"},f;for(f in Rt)Rt[f]===void 0?delete l[f]:l[f]=Rt[f];var g=[];for(f in l)g.push(`${f}=${l[f]}`);Bt=g}return Bt},Bt,mr=[null,[],[]],Ve=[31,29,31,30,31,30,31,31,30,31,30,31],Gt=[31,28,31,30,31,30,31,31,30,31,30,31];function Lt(l){var f=Array(Ot(l)+1);return Ut(l,f,0,f.length),f}function ie(l,f,g,x){function O(k,ne,fe){for(k=typeof k==\"number\"?k.toString():k||\"\";k.length<ne;)k=fe[0]+k;return k}function H(k,ne){return O(k,ne,\"0\")}function U(k,ne){function fe(tr){return 0>tr?-1:0<tr?1:0}var mt;return(mt=fe(k.getFullYear()-ne.getFullYear()))===0&&(mt=fe(k.getMonth()-ne.getMonth()))===0&&(mt=fe(k.getDate()-ne.getDate())),mt}function se(k){switch(k.getDay()){case 0:return new Date(k.getFullYear()-1,11,29);case 1:return k;case 2:return new Date(k.getFullYear(),0,3);case 3:return new Date(k.getFullYear(),0,2);case 4:return new Date(k.getFullYear(),0,1);case 5:return new Date(k.getFullYear()-1,11,31);case 6:return new Date(k.getFullYear()-1,11,30)}}function Z(k){var ne=k.Ba;for(k=new Date(new Date(k.Ca+1900,0,1).getTime());0<ne;){var fe=k.getMonth(),mt=(ct(k.getFullYear())?Ve:Gt)[fe];if(ne>mt-k.getDate())ne-=mt-k.getDate()+1,k.setDate(1),11>fe?k.setMonth(fe+1):(k.setMonth(0),k.setFullYear(k.getFullYear()+1));else{k.setDate(k.getDate()+ne);break}}return fe=new Date(k.getFullYear()+1,0,4),ne=se(new Date(k.getFullYear(),0,4)),fe=se(fe),0>=U(ne,k)?0>=U(fe,k)?k.getFullYear()+1:k.getFullYear():k.getFullYear()-1}l>>>=0,f>>>=0,g>>>=0,x>>>=0;var ee=M[x+40>>2>>>0];x={Wa:M[x>>2>>>0],Va:M[x+4>>2>>>0],Ea:M[x+8>>2>>>0],Ia:M[x+12>>2>>>0],Fa:M[x+16>>2>>>0],Ca:M[x+20>>2>>>0],wa:M[x+24>>2>>>0],Ba:M[x+28>>2>>>0],$a:M[x+32>>2>>>0],Ua:M[x+36>>2>>>0],Xa:ee?Re(ee):\"\"},g=Re(g),ee={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var X in ee)g=g.replace(new RegExp(X,\"g\"),ee[X]);var ce=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),he=\"January February March April May June July August September October November December\".split(\" \");ee={\"%a\":k=>ce[k.wa].substring(0,3),\"%A\":k=>ce[k.wa],\"%b\":k=>he[k.Fa].substring(0,3),\"%B\":k=>he[k.Fa],\"%C\":k=>H((k.Ca+1900)/100|0,2),\"%d\":k=>H(k.Ia,2),\"%e\":k=>O(k.Ia,2,\" \"),\"%g\":k=>Z(k).toString().substring(2),\"%G\":k=>Z(k),\"%H\":k=>H(k.Ea,2),\"%I\":k=>(k=k.Ea,k==0?k=12:12<k&&(k-=12),H(k,2)),\"%j\":k=>{for(var ne=0,fe=0;fe<=k.Fa-1;ne+=(ct(k.Ca+1900)?Ve:Gt)[fe++]);return H(k.Ia+ne,3)},\"%m\":k=>H(k.Fa+1,2),\"%M\":k=>H(k.Va,2),\"%n\":()=>`\n`,\"%p\":k=>0<=k.Ea&&12>k.Ea?\"AM\":\"PM\",\"%S\":k=>H(k.Wa,2),\"%t\":()=>\"\t\",\"%u\":k=>k.wa||7,\"%U\":k=>H(Math.floor((k.Ba+7-k.wa)/7),2),\"%V\":k=>{var ne=Math.floor((k.Ba+7-(k.wa+6)%7)/7);if(2>=(k.wa+371-k.Ba-2)%7&&ne++,ne)ne==53&&(fe=(k.wa+371-k.Ba)%7,fe==4||fe==3&&ct(k.Ca)||(ne=1));else{ne=52;var fe=(k.wa+7-k.Ba-1)%7;(fe==4||fe==5&&ct(k.Ca%400-1))&&ne++}return H(ne,2)},\"%w\":k=>k.wa,\"%W\":k=>H(Math.floor((k.Ba+7-(k.wa+6)%7)/7),2),\"%y\":k=>(k.Ca+1900).toString().substring(2),\"%Y\":k=>k.Ca+1900,\"%z\":k=>{k=k.Ua;var ne=0<=k;return k=Math.abs(k)/60,(ne?\"+\":\"-\")+(\"0000\"+(k/60*100+k%60)).slice(-4)},\"%Z\":k=>k.Xa,\"%%\":()=>\"%\"},g=g.replace(/%%/g,\"\\0\\0\");for(X in ee)g.includes(X)&&(g=g.replace(new RegExp(X,\"g\"),ee[X](x)));return g=g.replace(/\\0\\0/g,\"%\"),X=Lt(g),X.length>f?0:(Y.set(X,l>>>0),X.length-1)}function ft(l){try{l()}catch(f){je(f)}}function hr(l){var f={},g;for(g in l)(function(x){var O=l[x];f[x]=typeof O==\"function\"?function(){xt.push(x);try{return O.apply(null,arguments)}finally{W||(xt.pop()===x||je(),Ke&&nt===1&&xt.length===0&&(nt=0,ft(Jt),typeof Fibers<\"u\"&&Fibers.ab()))}}:O})(g);return f}var nt=0,Ke=null,gr=0,xt=[],Ft={},jt={},yr=0,Ct=null,br=[];function wr(){return new Promise((l,f)=>{Ct={resolve:l,reject:f}})}function vr(){var l=Mt(65548),f=l+12;K[l>>2>>>0]=f,K[l+4>>2>>>0]=f+65536,f=xt[0];var g=Ft[f];return g===void 0&&(g=yr++,Ft[f]=g,jt[g]=f),M[l+8>>2>>>0]=g,l}function $r(l){if(!W){if(nt===0){var f=!1,g=!1;l((x=0)=>{if(!W&&(gr=x,f=!0,g)){nt=2,ft(()=>Dt(Ke)),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.resume(),x=!1;try{var O=(0,E[jt[M[Ke+8>>2>>>0]]])()}catch(se){O=se,x=!0}var H=!1;if(!Ke){var U=Ct;U&&(Ct=null,(x?U.reject:U.resolve)(O),H=!0)}if(x&&!H)throw O}}),g=!0,f||(nt=1,Ke=vr(),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.pause(),ft(()=>Qt(Ke)))}else nt===2?(nt=0,ft(It),qt(Ke),Ke=null,br.forEach(x=>{if(!W)try{if(x(),!_)try{V=V=x=V,_||(r.onExit&&r.onExit(x),W=!0),d(x,new qe(x))}catch(O){O instanceof qe||O==\"unwind\"||d(1,O)}}catch(O){O instanceof qe||O==\"unwind\"||d(1,O)}})):je(`invalid state: ${nt}`);return gr}}function Sr(l){return $r(f=>{l().then(f)})}var xr={n:function(l,f,g){return Sr(async()=>{await r.Pa(l,f,g)})},a:function(l,f,g){throw l>>>=0,new St(l).Ya(f>>>0,g>>>0),Vt=l,pr++,Vt},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(l,f,g){l=f+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*f:NaN,g>>>=0,l=new Date(1e3*l),M[g>>2>>>0]=l.getUTCSeconds(),M[g+4>>2>>>0]=l.getUTCMinutes(),M[g+8>>2>>>0]=l.getUTCHours(),M[g+12>>2>>>0]=l.getUTCDate(),M[g+16>>2>>>0]=l.getUTCMonth(),M[g+20>>2>>>0]=l.getUTCFullYear()-1900,M[g+24>>2>>>0]=l.getUTCDay(),M[g+28>>2>>>0]=(l.getTime()-Date.UTC(l.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},r:function(l,f,g){l=f+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*f:NaN,g>>>=0,l=new Date(1e3*l),M[g>>2>>>0]=l.getSeconds(),M[g+4>>2>>>0]=l.getMinutes(),M[g+8>>2>>>0]=l.getHours(),M[g+12>>2>>>0]=l.getDate(),M[g+16>>2>>>0]=l.getMonth(),M[g+20>>2>>>0]=l.getFullYear()-1900,M[g+24>>2>>>0]=l.getDay(),M[g+28>>2>>>0]=(ct(l.getFullYear())?fr:pt)[l.getMonth()]+l.getDate()-1|0,M[g+36>>2>>>0]=-(60*l.getTimezoneOffset()),f=new Date(l.getFullYear(),6,1).getTimezoneOffset();var x=new Date(l.getFullYear(),0,1).getTimezoneOffset();M[g+32>>2>>>0]=(f!=x&&l.getTimezoneOffset()==Math.min(x,f))|0},s:function(l){l>>>=0;var f=new Date(M[l+20>>2>>>0]+1900,M[l+16>>2>>>0],M[l+12>>2>>>0],M[l+8>>2>>>0],M[l+4>>2>>>0],M[l>>2>>>0],0),g=M[l+32>>2>>>0],x=f.getTimezoneOffset(),O=new Date(f.getFullYear(),6,1).getTimezoneOffset(),H=new Date(f.getFullYear(),0,1).getTimezoneOffset(),U=Math.min(H,O);return 0>g?M[l+32>>2>>>0]=+(O!=H&&U==x):0<g!=(U==x)&&(O=Math.max(H,O),f.setTime(f.getTime()+6e4*((0<g?U:O)-x))),M[l+24>>2>>>0]=f.getDay(),M[l+28>>2>>>0]=(ct(f.getFullYear())?fr:pt)[f.getMonth()]+f.getDate()-1|0,M[l>>2>>>0]=f.getSeconds(),M[l+4>>2>>>0]=f.getMinutes(),M[l+8>>2>>>0]=f.getHours(),M[l+12>>2>>>0]=f.getDate(),M[l+16>>2>>>0]=f.getMonth(),M[l+20>>2>>>0]=f.getYear(),l=f.getTime()/1e3,Kt((He=l,1<=+Math.abs(He)?0<He?+Math.floor(He/4294967296)>>>0:~~+Math.ceil((He-+(~~He>>>0))/4294967296)>>>0:0)),l>>>0},o:function(){return-52},p:function(){},v:function(l,f,g){function x(Z){return(Z=Z.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?Z[1]:\"GMT\"}g>>>=0;var O=new Date().getFullYear(),H=new Date(O,0,1),U=new Date(O,6,1);O=H.getTimezoneOffset();var se=U.getTimezoneOffset();K[l>>>0>>2>>>0]=60*Math.max(O,se),M[f>>>0>>2>>>0]=+(O!=se),l=x(H),f=x(U),l=kt(l),f=kt(f),se<O?(K[g>>2>>>0]=l,K[g+4>>2>>>0]=f):(K[g>>2>>>0]=f,K[g+4>>2>>>0]=l)},e:()=>{je(\"\")},b:function(l,f,g){return l>>>=0,f=Pt(f>>>0,g>>>0),rt[l].apply(null,f)},i:function(l,f,g){return l>>>=0,f=Pt(f>>>0,g>>>0),rt[l].apply(null,f)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(l,f,g){return f>>>=0,ae.copyWithin(l>>>0>>>0,f>>>0,f+(g>>>0)>>>0)},u:function(l){l>>>=0;var f=ae.length;if(4294901760<l)return!1;for(var g=1;4>=g;g*=2){var x=f*(1+.2/g);x=Math.min(x,l+100663296);var O=Math;x=Math.max(l,x);e:{O=O.min.call(O,4294901760,x+(65536-x%65536)%65536)-R.buffer.byteLength+65535>>>16;try{R.grow(O),ve();var H=1;break e}catch{}H=void 0}if(H)return!0}return!1},D:function(l,f){l>>>=0,f>>>=0;var g=0;return Ht().forEach(function(x,O){var H=f+g;for(O=K[l+4*O>>2>>>0]=H,H=0;H<x.length;++H)Y[O++>>0>>>0]=x.charCodeAt(H);Y[O>>0>>>0]=0,g+=x.length+1}),0},E:function(l,f){l>>>=0,f>>>=0;var g=Ht();K[l>>2>>>0]=g.length;var x=0;return g.forEach(function(O){x+=O.length+1}),K[f>>2>>>0]=x,0},f:()=>52,k:function(){return 52},t:function(){return 70},j:function(l,f,g,x){f>>>=0,g>>>=0,x>>>=0;for(var O=0,H=0;H<g;H++){var U=K[f>>2>>>0],se=K[f+4>>2>>>0];f+=8;for(var Z=0;Z<se;Z++){var ee=ae[U+Z>>>0],X=mr[l];ee===0||ee===10?((l===1?A:I)(Nt(X,0)),X.length=0):X.push(ee)}O+=se}return K[x>>2>>>0]=O,0},F:ie,d:function(l,f,g,x){return ie(l>>>0,f>>>0,g>>>0,x>>>0)}};(function(){function l(g){if(g=g.exports,g=hr(g),E=g=yt(g),R=E.M,ve(),xe.unshift(E.N),Ce--,r.monitorRunDependencies&&r.monitorRunDependencies(Ce),Ce==0&&(ht!==null&&(clearInterval(ht),ht=null),Le)){var x=Le;Le=null,x()}return g}var f={a:xr};if(Ce++,r.monitorRunDependencies&&r.monitorRunDependencies(Ce),r.instantiateWasm)try{return r.instantiateWasm(f,l)}catch(g){I(\"Module.instantiateWasm callback failed with error: \"+g),n(g)}return Me(f,function(g){l(g.instance)}).catch(n),{}})(),r._OrtInit=(l,f)=>(r._OrtInit=E.O)(l,f),r._OrtGetLastError=(l,f)=>(r._OrtGetLastError=E.P)(l,f),r._OrtCreateSessionOptions=(l,f,g,x,O,H,U,se,Z,ee)=>(r._OrtCreateSessionOptions=E.Q)(l,f,g,x,O,H,U,se,Z,ee),r._OrtAppendExecutionProvider=(l,f)=>(r._OrtAppendExecutionProvider=E.R)(l,f),r._OrtAddFreeDimensionOverride=(l,f,g)=>(r._OrtAddFreeDimensionOverride=E.S)(l,f,g),r._OrtAddSessionConfigEntry=(l,f,g)=>(r._OrtAddSessionConfigEntry=E.T)(l,f,g),r._OrtReleaseSessionOptions=l=>(r._OrtReleaseSessionOptions=E.U)(l),r._OrtCreateSession=(l,f,g)=>(r._OrtCreateSession=E.V)(l,f,g),r._OrtReleaseSession=l=>(r._OrtReleaseSession=E.W)(l),r._OrtGetInputOutputCount=(l,f,g)=>(r._OrtGetInputOutputCount=E.X)(l,f,g),r._OrtGetInputName=(l,f)=>(r._OrtGetInputName=E.Y)(l,f),r._OrtGetOutputName=(l,f)=>(r._OrtGetOutputName=E.Z)(l,f),r._OrtFree=l=>(r._OrtFree=E._)(l),r._OrtCreateTensor=(l,f,g,x,O,H)=>(r._OrtCreateTensor=E.$)(l,f,g,x,O,H),r._OrtGetTensorData=(l,f,g,x,O)=>(r._OrtGetTensorData=E.aa)(l,f,g,x,O),r._OrtReleaseTensor=l=>(r._OrtReleaseTensor=E.ba)(l),r._OrtCreateRunOptions=(l,f,g,x)=>(r._OrtCreateRunOptions=E.ca)(l,f,g,x),r._OrtAddRunConfigEntry=(l,f,g)=>(r._OrtAddRunConfigEntry=E.da)(l,f,g),r._OrtReleaseRunOptions=l=>(r._OrtReleaseRunOptions=E.ea)(l),r._OrtCreateBinding=l=>(r._OrtCreateBinding=E.fa)(l),r._OrtBindInput=(l,f,g)=>(r._OrtBindInput=E.ga)(l,f,g),r._OrtBindOutput=(l,f,g,x)=>(r._OrtBindOutput=E.ha)(l,f,g,x),r._OrtClearBoundOutputs=l=>(r._OrtClearBoundOutputs=E.ia)(l),r._OrtReleaseBinding=l=>(r._OrtReleaseBinding=E.ja)(l),r._OrtRunWithBinding=(l,f,g,x,O)=>(r._OrtRunWithBinding=E.ka)(l,f,g,x,O),r._OrtRun=(l,f,g,x,O,H,U,se)=>(r._OrtRun=E.la)(l,f,g,x,O,H,U,se),r._OrtEndProfiling=l=>(r._OrtEndProfiling=E.ma)(l),r._JsepOutput=(l,f,g)=>(r._JsepOutput=E.na)(l,f,g),r._JsepGetNodeName=l=>(r._JsepGetNodeName=E.oa)(l);var Mt=r._malloc=l=>(Mt=r._malloc=E.pa)(l),qt=r._free=l=>(qt=r._free=E.qa)(l),Kt=l=>(Kt=E.sa)(l),Yt=()=>(Yt=E.ta)(),Zt=l=>(Zt=E.ua)(l),Xt=l=>(Xt=E.va)(l),Qt=l=>(Qt=E.xa)(l),Jt=()=>(Jt=E.ya)(),Dt=l=>(Dt=E.za)(l),It=()=>(It=E.Aa)();r.___start_em_js=922423,r.___stop_em_js=922584;function yt(l){l=Object.assign({},l);var f=x=>()=>x()>>>0,g=x=>O=>x(O)>>>0;return l.__errno_location=f(l.__errno_location),l.malloc=g(l.malloc),l.stackSave=f(l.stackSave),l.stackAlloc=g(l.stackAlloc),l}r.stackAlloc=Xt,r.stackSave=Yt,r.stackRestore=Zt,r.UTF8ToString=Re,r.stringToUTF8=(l,f,g)=>Ut(l,ae,f,g),r.lengthBytesUTF8=Ot;var At;Le=function l(){At||er(),At||(Le=l)};function er(){function l(){if(!At&&(At=!0,r.calledRun=!0,!W)){if($t(xe),o(r),r.onRuntimeInitialized&&r.onRuntimeInitialized(),r.postRun)for(typeof r.postRun==\"function\"&&(r.postRun=[r.postRun]);r.postRun.length;){var f=r.postRun.shift();Pe.unshift(f)}$t(Pe)}}if(!(0<Ce)){if(r.preRun)for(typeof r.preRun==\"function\"&&(r.preRun=[r.preRun]);r.preRun.length;)_e();$t(j),0<Ce||(r.setStatus?(r.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){r.setStatus(\"\")},1),l()},1)):l())}}if(r.preInit)for(typeof r.preInit==\"function\"&&(r.preInit=[r.preInit]);0<r.preInit.length;)r.preInit.pop()();return er(),t.ready}})();typeof co==\"object\"&&typeof fn==\"object\"?fn.exports=lo:typeof define==\"function\"&&define.amd&&define([],()=>lo)});var fo=rr(()=>{});var mo=rr(()=>{});var ho={};Er(ho,{cpus:()=>Du});var Du,go=F(()=>{Du=void 0});var wo=rr((bo,mn)=>{\"use strict\";var yo=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){function r(){return ve.buffer!=Ce.buffer&&pe(),Ce}function o(){return ve.buffer!=Ce.buffer&&pe(),ht}function n(){return ve.buffer!=Ce.buffer&&pe(),Le}function s(){return ve.buffer!=Ce.buffer&&pe(),je}function u(){return ve.buffer!=Ce.buffer&&pe(),L}function d(){return ve.buffer!=Ce.buffer&&pe(),de}var a=t,p,h;a.ready=new Promise((i,c)=>{p=i,h=c}),a.jsepInit=(i,c,m,$,T,D,N,te)=>{a.Qb=i,a.wb=c,a.yb=m,a.jb=$,a.xb=T,a.Ea=D,a.zb=N,a.Ab=te,c=(Q,J,oe)=>(...ge)=>{let we=ot,P=J?.();ge=Q(...ge);let le=J?.();return P!==le&&(Q=le,oe(P),J=oe=null),ot!=we?Su():ge},m=Q=>async(...J)=>{try{if(a.bb)throw Error(\"Session already started\");let oe=a.bb={Fb:J[0],errors:[]},ge=await Q(...J);if(a.bb!==oe)throw Error(\"Session mismatch\");i.flush();let we=oe.errors;if(0<we.length){let P=await Promise.all(we);if(P=P.filter(le=>le),0<P.length)throw Error(P.join(`\n`))}return ge}finally{a.bb=null}},a._OrtRun=m(c(a._OrtRun,()=>a._OrtRun,Q=>a._OrtRun=Q)),a._OrtRunWithBinding=m(c(a._OrtRunWithBinding,()=>a._OrtRunWithBinding,Q=>a._OrtRunWithBinding=Q)),a._OrtBindInput=c(a._OrtBindInput,()=>a._OrtBindInput,Q=>a._OrtBindInput=Q),a.jsepRegisterBuffer=(Q,J,oe,ge)=>i.registerBuffer(Q,J,oe,ge),a.jsepUnregisterBuffers=Q=>{i.unregisterBuffers(Q)},a.jsepGetBuffer=Q=>i.getBuffer(Q),a.jsepCreateDownloader=(Q,J,oe)=>i.createDownloader(Q,J,oe)};var v=Object.assign({},a),y=\"./this.program\",b=(i,c)=>{throw c},w=typeof window==\"object\",S=typeof importScripts==\"function\",C=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",A=a.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function B(i){return a.locateFile?a.locateFile(i,I):I+i}var _,R,E;if(C){var W=(dn(),zt(ln)),V=(pn(),zt(cn));I=S?V.dirname(I)+\"/\":__dirname+\"/\",_=(c,m)=>(c=c.startsWith(\"file://\")?new URL(c):V.normalize(c),W.readFileSync(c,m?void 0:\"utf8\")),E=c=>(c=_(c,!0),c.buffer||(c=new Uint8Array(c)),c),R=(c,m,$,T=!0)=>{c=c.startsWith(\"file://\")?new URL(c):V.normalize(c),W.readFile(c,T?void 0:\"utf8\",(D,N)=>{D?$(D):m(T?N.buffer:N)})},!a.thisProgram&&1<process.argv.length&&(y=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),b=(c,m)=>{throw process.exitCode=c,m},a.inspect=()=>\"[Emscripten Module object]\";let i;try{i=fo()}catch(c){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),c}global.Worker=i.Worker}else(w||S)&&(S?I=self.location.href:typeof document<\"u\"&&document.currentScript&&(I=document.currentScript.src),typeof e<\"u\"&&e&&(I=e),I.indexOf(\"blob:\")!==0?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",C||(_=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.send(null),c.responseText},S&&(E=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.responseType=\"arraybuffer\",c.send(null),new Uint8Array(c.response)}),R=(i,c,m)=>{var $=new XMLHttpRequest;$.open(\"GET\",i,!0),$.responseType=\"arraybuffer\",$.onload=()=>{$.status==200||$.status==0&&$.response?c($.response):m()},$.onerror=m,$.send(null)}));C&&typeof performance>\"u\"&&(global.performance=mo().performance);var Y=console.log.bind(console),ae=console.error.bind(console);C&&(Y=(...i)=>W.writeSync(1,i.join(\" \")+`\n`),ae=(...i)=>W.writeSync(2,i.join(\" \")+`\n`));var M=a.print||Y,K=a.printErr||ae;Object.assign(a,v),v=null,a.thisProgram&&(y=a.thisProgram),a.quit&&(b=a.quit);var Se;a.wasmBinary&&(Se=a.wasmBinary);var ue=a.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&Xe(\"no native wasm support detected\");var ve,j,xe,Pe=!1,_e,Ce,ht,Le,je,L,de;function pe(){var i=ve.buffer;a.HEAP8=Ce=new Int8Array(i),a.HEAP16=new Int16Array(i),a.HEAP32=Le=new Int32Array(i),a.HEAPU8=ht=new Uint8Array(i),a.HEAPU16=new Uint16Array(i),a.HEAPU32=je=new Uint32Array(i),a.HEAPF32=L=new Float32Array(i),a.HEAPF64=de=new Float64Array(i)}var We=a.INITIAL_MEMORY||16777216;if(5242880<=We||Xe(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+We+\"! (STACK_SIZE=5242880)\"),A)ve=a.wasmMemory;else if(a.wasmMemory)ve=a.wasmMemory;else if(ve=new WebAssembly.Memory({initial:We/65536,maximum:65536,shared:!0}),!(ve.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),C&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");pe(),We=ve.buffer.byteLength;var Fe=[],Oe=[],Me=[],He=0;function rt(){return ue||0<He}var qe=0,$t=null,St=null;function Vt(){qe++,a.monitorRunDependencies&&a.monitorRunDependencies(qe)}function pr(){if(qe--,a.monitorRunDependencies&&a.monitorRunDependencies(qe),qe==0&&($t!==null&&(clearInterval($t),$t=null),St)){var i=St;St=null,i()}}function Xe(i){throw a.onAbort&&a.onAbort(i),i=\"Aborted(\"+i+\")\",K(i),Pe=!0,_e=1,i=new WebAssembly.RuntimeError(i+\". Build with -sASSERTIONS for more info.\"),h(i),i}function Nt(i){return i.startsWith(\"data:application/octet-stream;base64,\")}var Re;Re=\"ort-wasm-simd-threaded.wasm\",Nt(Re)||(Re=B(Re));function Ot(i){if(i==Re&&Se)return new Uint8Array(Se);if(E)return E(i);throw\"both async and sync fetching of the wasm failed\"}function Ut(i){if(!Se&&(w||S)){if(typeof fetch==\"function\"&&!i.startsWith(\"file://\"))return fetch(i,{credentials:\"same-origin\"}).then(c=>{if(!c.ok)throw\"failed to load wasm binary file at '\"+i+\"'\";return c.arrayBuffer()}).catch(()=>Ot(i));if(R)return new Promise((c,m)=>{R(i,$=>c(new Uint8Array($)),m)})}return Promise.resolve().then(()=>Ot(i))}function ct(i,c,m){return Ut(i).then($=>WebAssembly.instantiate($,c)).then($=>$).then(m,$=>{K(\"failed to asynchronously prepare wasm: \"+$),Xe($)})}function fr(i,c){var m=Re;return Se||typeof WebAssembly.instantiateStreaming!=\"function\"||Nt(m)||m.startsWith(\"file://\")||C||typeof fetch!=\"function\"?ct(m,i,c):fetch(m,{credentials:\"same-origin\"}).then($=>WebAssembly.instantiateStreaming($,i).then(c,function(T){return K(\"wasm streaming compile failed: \"+T),K(\"falling back to ArrayBuffer instantiation\"),ct(m,i,c)}))}var pt,kt={1425328:i=>{a.Ea(\"Abs\",i,void 0)},1425379:i=>{a.Ea(\"Neg\",i,void 0)},1425430:i=>{a.Ea(\"Floor\",i,void 0)},1425483:i=>{a.Ea(\"Ceil\",i,void 0)},1425535:i=>{a.Ea(\"Reciprocal\",i,void 0)},1425593:i=>{a.Ea(\"Sqrt\",i,void 0)},1425645:i=>{a.Ea(\"Exp\",i,void 0)},1425696:i=>{a.Ea(\"Erf\",i,void 0)},1425747:i=>{a.Ea(\"Sigmoid\",i,void 0)},1425802:i=>{a.Ea(\"Log\",i,void 0)},1425853:i=>{a.Ea(\"Sin\",i,void 0)},1425904:i=>{a.Ea(\"Cos\",i,void 0)},1425955:i=>{a.Ea(\"Tan\",i,void 0)},1426006:i=>{a.Ea(\"Asin\",i,void 0)},1426058:i=>{a.Ea(\"Acos\",i,void 0)},1426110:i=>{a.Ea(\"Atan\",i,void 0)},1426162:i=>{a.Ea(\"Sinh\",i,void 0)},1426214:i=>{a.Ea(\"Cosh\",i,void 0)},1426266:i=>{a.Ea(\"Asinh\",i,void 0)},1426319:i=>{a.Ea(\"Acosh\",i,void 0)},1426372:i=>{a.Ea(\"Atanh\",i,void 0)},1426425:i=>{a.Ea(\"Tanh\",i,void 0)},1426477:i=>{a.Ea(\"Not\",i,void 0)},1426528:(i,c,m)=>{a.Ea(\"Clip\",i,{min:c,max:m})},1426597:i=>{a.Ea(\"Clip\",i,void 0)},1426649:(i,c)=>{a.Ea(\"Elu\",i,{alpha:c})},1426707:i=>{a.Ea(\"Relu\",i,void 0)},1426759:(i,c)=>{a.Ea(\"LeakyRelu\",i,{alpha:c})},1426823:(i,c)=>{a.Ea(\"ThresholdedRelu\",i,{alpha:c})},1426893:i=>{a.zb(i)},1426927:(i,c)=>a.Ab(i,c,a.bb.Fb,a.bb.errors),1427039:(i,c)=>{a.Ea(\"Cast\",i,{to:c})},1427097:i=>{a.Ea(\"Add\",i,void 0)},1427148:i=>{a.Ea(\"Sub\",i,void 0)},1427199:i=>{a.Ea(\"Mul\",i,void 0)},1427250:i=>{a.Ea(\"Div\",i,void 0)},1427301:i=>{a.Ea(\"Pow\",i,void 0)},1427352:i=>{a.Ea(\"Equal\",i,void 0)},1427405:i=>{a.Ea(\"Greater\",i,void 0)},1427460:i=>{a.Ea(\"GreaterOrEqual\",i,void 0)},1427522:i=>{a.Ea(\"Less\",i,void 0)},1427574:i=>{a.Ea(\"LessOrEqual\",i,void 0)},1427633:(i,c,m,$,T)=>{a.Ea(\"ReduceMean\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1427797:(i,c,m,$,T)=>{a.Ea(\"ReduceMax\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1427960:(i,c,m,$,T)=>{a.Ea(\"ReduceMin\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428123:(i,c,m,$,T)=>{a.Ea(\"ReduceProd\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428287:(i,c,m,$,T)=>{a.Ea(\"ReduceSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428450:(i,c,m,$,T)=>{a.Ea(\"ReduceL1\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428612:(i,c,m,$,T)=>{a.Ea(\"ReduceL2\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428774:(i,c,m,$,T)=>{a.Ea(\"ReduceLogSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1428940:(i,c,m,$,T)=>{a.Ea(\"ReduceSumSquare\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1429109:(i,c,m,$,T)=>{a.Ea(\"ReduceLogSumExp\",i,{keepDims:!!c,noopWithEmptyAxes:!!m,axes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1429278:i=>{a.Ea(\"Where\",i,void 0)},1429331:(i,c,m)=>{a.Ea(\"Transpose\",i,{perm:c?Array.from(n().subarray(m>>>0,m+c>>>0)):[]})},1429444:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we)=>{a.Ea(\"Conv\",i,{format:Q?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[m],group:$,kernel_shape:[T],pads:D?Array.from(n().subarray(N>>>0,N+D>>>0)):[],strides:[te],w_is_const:()=>!!r()[J>>>0],activation:Ve(oe),activation_params:ge?Array.from(u().subarray(we>>>0,we+ge>>>0)):[]})},1429825:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le,ye)=>{a.Ea(\"Conv\",i,{format:ge?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[m,$],group:T,kernel_shape:[D,N],pads:te?Array.from(n().subarray(Q>>>0,Q+te>>>0)):[],strides:[J,oe],w_is_const:()=>!!r()[we>>>0],activation:Ve(P),activation_params:le?Array.from(u().subarray(ye>>>0,ye+le>>>0)):[]})},1430227:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le)=>{a.Ea(\"ConvTranspose\",i,{format:Q?\"NHWC\":\"NCHW\",autoPad:c,dilations:[m],group:$,kernel_shape:[T],pads:[D,N],strides:[te],wIsConst:()=>!!r()[J>>>0],outputPadding:oe?Array.from(n().subarray(ge>>>0,ge+oe>>>0)):[],outputShape:we?Array.from(n().subarray(P>>>0,P+we>>>0)):[],activation:Ve(le)})},1430641:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P)=>{a.Ea(\"ConvTranspose\",i,{format:te?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(m>>>0,m+2>>>0)),group:$,kernelShape:Array.from(n().subarray(T>>>0,T+2>>>0)),pads:Array.from(n().subarray(D>>>0,D+4>>>0)),strides:Array.from(n().subarray(N>>>0,N+2>>>0)),wIsConst:()=>!!r()[Q>>>0],outputPadding:0<J?Array.from(n().subarray(oe>>>0,oe+J>>>0)):[],outputShape:0<ge?Array.from(n().subarray(we>>>0,we+ge>>>0)):[],activation:Ve(P)})},1431198:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le)=>{a.Ea(\"ConvTranspose\",i,{format:Q?\"NHWC\":\"NCHW\",autoPad:c,dilations:[m],group:$,kernel_shape:[T],pads:[D,N],strides:[te],wIsConst:()=>!!r()[J>>>0],outputPadding:oe?Array.from(n().subarray(ge>>>0,ge+oe>>>0)):[],outputShape:we?Array.from(n().subarray(P>>>0,P+we>>>0)):[],activation:Ve(le)})},1431612:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P)=>{a.Ea(\"ConvTranspose\",i,{format:te?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(m>>>0,m+2>>>0)),group:$,kernelShape:Array.from(n().subarray(T>>>0,T+2>>>0)),pads:Array.from(n().subarray(D>>>0,D+4>>>0)),strides:Array.from(n().subarray(N>>>0,N+2>>>0)),wIsConst:()=>!!r()[Q>>>0],outputPadding:0<J?Array.from(n().subarray(oe>>>0,oe+J>>>0)):[],outputShape:0<ge?Array.from(n().subarray(we>>>0,we+ge>>>0)):[],activation:Ve(P)})},1432169:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},1432260:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le,ye)=>{a.Ea(\"AveragePool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:m,count_include_pad:$,storage_order:T,dilations:[D,N],kernel_shape:[te,Q],pads:[J,oe,ge,we],strides:[P,le]})},1432544:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},1432635:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le,ye)=>{a.Ea(\"AveragePool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:m,count_include_pad:$,storage_order:T,dilations:[D,N],kernel_shape:[te,Q],pads:[J,oe,ge,we],strides:[P,le]})},1432919:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},1433006:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le,ye)=>{a.Ea(\"MaxPool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:m,count_include_pad:$,storage_order:T,dilations:[D,N],kernel_shape:[te,Q],pads:[J,oe,ge,we],strides:[P,le]})},1433286:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},1433373:(i,c,m,$,T,D,N,te,Q,J,oe,ge,we,P,le,ye)=>{a.Ea(\"MaxPool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:m,count_include_pad:$,storage_order:T,dilations:[D,N],kernel_shape:[te,Q],pads:[J,oe,ge,we],strides:[P,le]})},1433653:(i,c,m,$,T)=>{a.Ea(\"Gemm\",i,{alpha:c,beta:m,transA:$,transB:T})},1433757:i=>{a.Ea(\"MatMul\",i,void 0)},1433811:(i,c,m,$)=>{a.Ea(\"ArgMax\",i,{keepDims:!!c,selectLastIndex:!!m,axis:$})},1433919:(i,c,m,$)=>{a.Ea(\"ArgMin\",i,{keepDims:!!c,selectLastIndex:!!m,axis:$})},1434027:(i,c)=>{a.Ea(\"Softmax\",i,{axis:c})},1434090:(i,c)=>{a.Ea(\"Concat\",i,{axis:c})},1434150:(i,c,m,$,T)=>{a.Ea(\"Split\",i,{axis:c,numOutputs:m,splitSizes:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1434295:i=>{a.Ea(\"Expand\",i,void 0)},1434349:(i,c)=>{a.Ea(\"Gather\",i,{axis:Number(c)})},1434420:(i,c)=>{a.Ea(\"GatherElements\",i,{axis:Number(c)})},1434499:(i,c,m,$,T,D,N,te,Q,J,oe)=>{a.Ea(\"Resize\",i,{antialias:c,axes:m?Array.from(n().subarray($>>>0,$+m>>>0)):[],coordinateTransformMode:Ve(T),cubicCoeffA:D,excludeOutside:N,extrapolationValue:te,keepAspectRatioPolicy:Ve(Q),mode:Ve(J),nearestMode:Ve(oe)})},1434850:(i,c,m,$,T,D,N)=>{a.Ea(\"Slice\",i,{starts:c?Array.from(n().subarray(m>>>0,m+c>>>0)):[],ends:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[],axes:D?Array.from(n().subarray(N>>>0,N+D>>>0)):[]})},1435081:i=>{a.Ea(\"Tile\",i,void 0)},1435133:(i,c,m)=>{a.Ea(\"LayerNormalization\",i,{axis:Number(c),epsilon:Number(m)})},1435240:(i,c,m)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:m?\"NHWC\":\"NCHW\"})},1435354:(i,c,m)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:m?\"NHWC\":\"NCHW\"})},1435468:i=>{a.Ea(\"Range\",i,void 0)},1435521:(i,c)=>{a.Ea(\"Einsum\",i,{equation:Ve(c)})},1435602:(i,c,m,$,T)=>{a.Ea(\"Pad\",i,{mode:c,value:m,pads:$?Array.from(n().subarray(T>>>0,T+$>>>0)):[]})},1435734:(i,c,m,$,T,D,N,te,Q)=>{a.Ea(\"Attention\",i,{numHeads:c,isUnidirectional:m,maskFilterValue:$,scale:T,doRotary:D,qkvHiddenSizes:N?Array.from(n().subarray(Number(te)>>>0,Number(te)+N>>>0)):[],pastPresentShareBuffer:!!Q})},1436006:i=>{a.Ea(\"Gelu\",i,void 0)},1436058:(i,c,m,$,T,D)=>{a.Ea(\"MultiHeadAttention\",i,{numHeads:c,isUnidirectional:m,maskFilterValue:$,scale:T,doRotary:D})},1436217:i=>{a.Ea(\"BiasAdd\",i,void 0)},1436272:i=>{a.Ea(\"BiasSplitGelu\",i,void 0)},1436333:(i,c)=>{a.Ea(\"SkipLayerNormalization\",i,{epsilon:c})},1436414:i=>a.wb(i),1436447:i=>a.yb(i),1436479:(i,c,m)=>{a.jb(i,c,m,!0)},1436518:(i,c,m)=>{a.jb(i,c,m)}};function gt(i){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${i})`,this.status=i}function Pt(i){i.terminate(),i.onmessage=()=>{}}function Rt(i){(i=ie.Qa[i])||Xe(),ie.Eb(i)}function Ht(i){var c=ie.tb();if(!c)return 6;ie.Ya.push(c),ie.Qa[i.Xa]=c,c.Xa=i.Xa;var m={cmd:\"run\",start_routine:i.Gb,arg:i.rb,pthread_ptr:i.Xa};return C&&c.unref(),c.postMessage(m,i.Mb),0}var Bt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,mr=(i,c,m)=>{c>>>=0;var $=c+m;for(m=c;i[m]&&!(m>=$);)++m;if(16<m-c&&i.buffer&&Bt)return Bt.decode(i.buffer instanceof SharedArrayBuffer?i.slice(c,m):i.subarray(c,m));for($=\"\";c<m;){var T=i[c++];if(T&128){var D=i[c++]&63;if((T&224)==192)$+=String.fromCharCode((T&31)<<6|D);else{var N=i[c++]&63;T=(T&240)==224?(T&15)<<12|D<<6|N:(T&7)<<18|D<<12|N<<6|i[c++]&63,65536>T?$+=String.fromCharCode(T):(T-=65536,$+=String.fromCharCode(55296|T>>10,56320|T&1023))}}else $+=String.fromCharCode(T)}return $},Ve=(i,c)=>(i>>>=0)?mr(o(),i,c):\"\";function Gt(i){if(A)return U(1,1,i);_e=i,rt()||(ie.Hb(),a.onExit&&a.onExit(i),Pe=!0),b(i,new gt(i))}var Lt=i=>{if(_e=i,A)throw hr(i),\"unwind\";Gt(i)},ie={ab:[],Ya:[],mb:[],Qa:{},gb:function(){A?ie.vb():ie.ub()},ub:function(){Fe.unshift(()=>{Vt(),ie.Bb(()=>pr())})},vb:function(){ie.receiveObjectTransfer=ie.Db,ie.threadInitTLS=ie.lb,ie.setExitStatus=ie.kb,ue=!1},kb:function(i){_e=i},Sb:[\"$terminateWorker\"],Hb:function(){for(var i of ie.Ya)Pt(i);for(i of ie.ab)Pt(i);ie.ab=[],ie.Ya=[],ie.Qa=[]},Eb:function(i){var c=i.Xa;delete ie.Qa[c],ie.ab.push(i),ie.Ya.splice(ie.Ya.indexOf(i),1),i.Xa=0,nn(c)},Db:function(){},lb:function(){ie.mb.forEach(i=>i())},Cb:i=>new Promise(c=>{i.onmessage=D=>{D=D.data;var N=D.cmd;if(D.targetThread&&D.targetThread!=Ar()){var te=ie.Qa[D.Rb];te?te.postMessage(D,D.transferList):K('Internal error! Worker sent a message \"'+N+'\" to target pthread '+D.targetThread+\", but that thread no longer exists!\")}else N===\"checkMailbox\"?It():N===\"spawnThread\"?Ht(D):N===\"cleanupThread\"?Rt(D.thread):N===\"killThread\"?(D=D.thread,N=ie.Qa[D],delete ie.Qa[D],Pt(N),nn(D),ie.Ya.splice(ie.Ya.indexOf(N),1),N.Xa=0):N===\"cancelThread\"?ie.Qa[D.thread].postMessage({cmd:\"cancel\"}):N===\"loaded\"?(i.loaded=!0,c(i)):N===\"alert\"?alert(\"Thread \"+D.threadId+\": \"+D.text):D.target===\"setimmediate\"?i.postMessage(D):N===\"callHandler\"?a[D.handler](...D.args):N&&K(\"worker sent an unknown command \"+N)},i.onerror=D=>{throw K(\"worker sent an error! \"+D.filename+\":\"+D.lineno+\": \"+D.message),D},C&&(i.on(\"message\",function(D){i.onmessage({data:D})}),i.on(\"error\",function(D){i.onerror(D)}));var m=[],$=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],T;for(T of $)a.hasOwnProperty(T)&&m.push(T);i.postMessage({cmd:\"load\",handlers:m,urlOrBlob:a.mainScriptUrlOrBlob||e,wasmMemory:ve,wasmModule:xe})}),Bb:function(i){i()},qb:function(){var i=B(\"ort-wasm-simd-threaded.worker.js\");i=new Worker(i),ie.ab.push(i)},tb:function(){return ie.ab.length==0&&(ie.qb(),ie.Cb(ie.ab[0])),ie.ab.pop()}};a.PThread=ie;var ft=i=>{for(;0<i.length;)i.shift()(a)};a.establishStackSpace=function(){var i=Ar(),c=n()[i+52>>2>>>0];i=n()[i+56>>2>>>0],to(c,c-i),_r(c)};function hr(i){if(A)return U(2,0,i);Lt(i)}a.invokeEntryPoint=function(i,c){i=ro.apply(null,[i,c]),rt()?ie.kb(i):on(i)};function nt(i){this.fb=i-24,this.pb=function(c){s()[this.fb+4>>2>>>0]=c},this.ob=function(c){s()[this.fb+8>>2>>>0]=c},this.gb=function(c,m){this.nb(),this.pb(c),this.ob(m)},this.nb=function(){s()[this.fb+16>>2>>>0]=0}}var Ke=0,gr=0;function xt(i,c,m,$){return A?U(3,1,i,c,m,$):Ft(i,c,m,$)}function Ft(i,c,m,$){if(i>>>=0,c>>>=0,m>>>=0,$>>>=0,typeof SharedArrayBuffer>\"u\")return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var T=[];return A&&T.length===0?xt(i,c,m,$):(i={Gb:m,Xa:i,rb:$,Mb:T},A?(i.Ob=\"spawnThread\",postMessage(i,T),0):Ht(i))}function jt(i,c,m){return A?U(4,1,i,c,m):0}function yr(i,c){if(A)return U(5,1,i,c)}var Ct=i=>{for(var c=0,m=0;m<i.length;++m){var $=i.charCodeAt(m);127>=$?c++:2047>=$?c+=2:55296<=$&&57343>=$?(c+=4,++m):c+=3}return c},br=(i,c,m,$)=>{if(m>>>=0,!(0<$))return 0;var T=m;$=m+$-1;for(var D=0;D<i.length;++D){var N=i.charCodeAt(D);if(55296<=N&&57343>=N){var te=i.charCodeAt(++D);N=65536+((N&1023)<<10)|te&1023}if(127>=N){if(m>=$)break;c[m++>>>0]=N}else{if(2047>=N){if(m+1>=$)break;c[m++>>>0]=192|N>>6}else{if(65535>=N){if(m+2>=$)break;c[m++>>>0]=224|N>>12}else{if(m+3>=$)break;c[m++>>>0]=240|N>>18,c[m++>>>0]=128|N>>12&63}c[m++>>>0]=128|N>>6&63}c[m++>>>0]=128|N&63}}return c[m>>>0]=0,m-T},wr=(i,c,m)=>br(i,o(),c,m);function vr(i,c){if(A)return U(6,1,i,c)}function $r(i,c,m){if(A)return U(7,1,i,c,m)}function Sr(i,c,m){return A?U(8,1,i,c,m):0}function xr(i,c){if(A)return U(9,1,i,c)}function Mt(i,c,m){if(A)return U(10,1,i,c,m)}function qt(i,c,m,$){if(A)return U(11,1,i,c,m,$)}function Kt(i,c,m,$){if(A)return U(12,1,i,c,m,$)}function Yt(i,c,m,$){if(A)return U(13,1,i,c,m,$)}function Zt(i){if(A)return U(14,1,i)}function Xt(i,c){if(A)return U(15,1,i,c)}function Qt(i,c,m){if(A)return U(16,1,i,c,m)}var Jt=i=>{if(!Pe)try{if(i(),!rt())try{A?on(_e):Lt(_e)}catch(c){c instanceof gt||c==\"unwind\"||b(1,c)}}catch(c){c instanceof gt||c==\"unwind\"||b(1,c)}};function Dt(i){i>>>=0,typeof Atomics.Nb==\"function\"&&(Atomics.Nb(n(),i>>2,i).value.then(It),i+=128,Atomics.store(n(),i>>2,1))}a.__emscripten_thread_mailbox_await=Dt;function It(){var i=Ar();i&&(Dt(i),Jt(()=>Jn()))}a.checkMailbox=It;var yt=i=>i%4===0&&(i%100!==0||i%400===0),At=[0,31,60,91,121,152,182,213,244,274,305,335],er=[0,31,59,90,120,151,181,212,243,273,304,334];function l(i,c,m,$,T,D,N,te){return A?U(17,1,i,c,m,$,T,D,N,te):-52}function f(i,c,m,$,T,D,N){if(A)return U(18,1,i,c,m,$,T,D,N)}var g=i=>{var c=Ct(i)+1,m=rn(c);return m&&wr(i,m,c),m},x=[],O=(i,c)=>{x.length=0;var m;for(c>>=2;m=o()[i++>>>0];)c+=m!=105&c,x.push(m==105?n()[c>>>0]:d()[c++>>>1]),++c;return x},H=i=>{var c=an();return i=i(),_r(c),i};function U(i,c){var m=arguments.length-2,$=arguments;return H(()=>{for(var T=sn(8*m),D=T>>3,N=0;N<m;N++){var te=$[2+N];d()[D+N>>>0]=te}return Qn(i,m,T,c)})}var se=[],Z={},ee=()=>{if(!X){var i={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:y||\"./this.program\"},c;for(c in Z)Z[c]===void 0?delete i[c]:i[c]=Z[c];var m=[];for(c in i)m.push(`${c}=${i[c]}`);X=m}return X},X;function ce(i,c){if(A)return U(19,1,i,c);i>>>=0,c>>>=0;var m=0;return ee().forEach(function($,T){var D=c+m;for(T=s()[i+4*T>>2>>>0]=D,D=0;D<$.length;++D)r()[T++>>0>>>0]=$.charCodeAt(D);r()[T>>0>>>0]=0,m+=$.length+1}),0}function he(i,c){if(A)return U(20,1,i,c);i>>>=0,c>>>=0;var m=ee();s()[i>>2>>>0]=m.length;var $=0;return m.forEach(function(T){$+=T.length+1}),s()[c>>2>>>0]=$,0}function k(i){return A?U(21,1,i):52}function ne(i,c,m,$){return A?U(22,1,i,c,m,$):52}function fe(i,c,m,$,T){return A?U(23,1,i,c,m,$,T):70}var mt=[null,[],[]];function tr(i,c,m,$){if(A)return U(24,1,i,c,m,$);c>>>=0,m>>>=0,$>>>=0;for(var T=0,D=0;D<m;D++){var N=s()[c>>2>>>0],te=s()[c+4>>2>>>0];c+=8;for(var Q=0;Q<te;Q++){var J=o()[N+Q>>>0],oe=mt[i];J===0||J===10?((i===1?M:K)(mr(oe,0)),oe.length=0):oe.push(J)}T+=te}return s()[$>>2>>>0]=T,0}var Ln=[31,29,31,30,31,30,31,31,30,31,30,31],Fn=[31,28,31,30,31,30,31,31,30,31,30,31];function yu(i){var c=Array(Ct(i)+1);return br(i,c,0,c.length),c}var bu=(i,c)=>{r().set(i,c>>>0)};function jn(i,c,m,$){function T(P,le,ye){for(P=typeof P==\"number\"?P.toString():P||\"\";P.length<le;)P=ye[0]+P;return P}function D(P,le){return T(P,le,\"0\")}function N(P,le){function ye(uo){return 0>uo?-1:0<uo?1:0}var _t;return(_t=ye(P.getFullYear()-le.getFullYear()))===0&&(_t=ye(P.getMonth()-le.getMonth()))===0&&(_t=ye(P.getDate()-le.getDate())),_t}function te(P){switch(P.getDay()){case 0:return new Date(P.getFullYear()-1,11,29);case 1:return P;case 2:return new Date(P.getFullYear(),0,3);case 3:return new Date(P.getFullYear(),0,2);case 4:return new Date(P.getFullYear(),0,1);case 5:return new Date(P.getFullYear()-1,11,31);case 6:return new Date(P.getFullYear()-1,11,30)}}function Q(P){var le=P.Za;for(P=new Date(new Date(P.$a+1900,0,1).getTime());0<le;){var ye=P.getMonth(),_t=(yt(P.getFullYear())?Ln:Fn)[ye];if(le>_t-P.getDate())le-=_t-P.getDate()+1,P.setDate(1),11>ye?P.setMonth(ye+1):(P.setMonth(0),P.setFullYear(P.getFullYear()+1));else{P.setDate(P.getDate()+le);break}}return ye=new Date(P.getFullYear()+1,0,4),le=te(new Date(P.getFullYear(),0,4)),ye=te(ye),0>=N(le,P)?0>=N(ye,P)?P.getFullYear()+1:P.getFullYear():P.getFullYear()-1}i>>>=0,c>>>=0,m>>>=0,$>>>=0;var J=n()[$+40>>2>>>0];$={Kb:n()[$>>2>>>0],Jb:n()[$+4>>2>>>0],cb:n()[$+8>>2>>>0],ib:n()[$+12>>2>>>0],eb:n()[$+16>>2>>>0],$a:n()[$+20>>2>>>0],Wa:n()[$+24>>2>>>0],Za:n()[$+28>>2>>>0],Tb:n()[$+32>>2>>>0],Ib:n()[$+36>>2>>>0],Lb:J?Ve(J):\"\"},m=Ve(m),J={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var oe in J)m=m.replace(new RegExp(oe,\"g\"),J[oe]);var ge=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),we=\"January February March April May June July August September October November December\".split(\" \");J={\"%a\":P=>ge[P.Wa].substring(0,3),\"%A\":P=>ge[P.Wa],\"%b\":P=>we[P.eb].substring(0,3),\"%B\":P=>we[P.eb],\"%C\":P=>D((P.$a+1900)/100|0,2),\"%d\":P=>D(P.ib,2),\"%e\":P=>T(P.ib,2,\" \"),\"%g\":P=>Q(P).toString().substring(2),\"%G\":P=>Q(P),\"%H\":P=>D(P.cb,2),\"%I\":P=>(P=P.cb,P==0?P=12:12<P&&(P-=12),D(P,2)),\"%j\":P=>{for(var le=0,ye=0;ye<=P.eb-1;le+=(yt(P.$a+1900)?Ln:Fn)[ye++]);return D(P.ib+le,3)},\"%m\":P=>D(P.eb+1,2),\"%M\":P=>D(P.Jb,2),\"%n\":()=>`\n`,\"%p\":P=>0<=P.cb&&12>P.cb?\"AM\":\"PM\",\"%S\":P=>D(P.Kb,2),\"%t\":()=>\"\t\",\"%u\":P=>P.Wa||7,\"%U\":P=>D(Math.floor((P.Za+7-P.Wa)/7),2),\"%V\":P=>{var le=Math.floor((P.Za+7-(P.Wa+6)%7)/7);if(2>=(P.Wa+371-P.Za-2)%7&&le++,le)le==53&&(ye=(P.Wa+371-P.Za)%7,ye==4||ye==3&&yt(P.$a)||(le=1));else{le=52;var ye=(P.Wa+7-P.Za-1)%7;(ye==4||ye==5&&yt(P.$a%400-1))&&le++}return D(le,2)},\"%w\":P=>P.Wa,\"%W\":P=>D(Math.floor((P.Za+7-(P.Wa+6)%7)/7),2),\"%y\":P=>(P.$a+1900).toString().substring(2),\"%Y\":P=>P.$a+1900,\"%z\":P=>{P=P.Ib;var le=0<=P;return P=Math.abs(P)/60,(le?\"+\":\"-\")+(\"0000\"+(P/60*100+P%60)).slice(-4)},\"%Z\":P=>P.Lb,\"%%\":()=>\"%\"},m=m.replace(/%%/g,\"\\0\\0\");for(oe in J)m.includes(oe)&&(m=m.replace(new RegExp(oe,\"g\"),J[oe]($)));return m=m.replace(/\\0\\0/g,\"%\"),oe=yu(m),oe.length>c?0:(bu(oe,i),oe.length-1)}function Cr(i){try{i()}catch(c){Xe(c)}}function wu(i){var c={},m;for(m in i)(function($){var T=i[$];c[$]=typeof T==\"function\"?function(){Ir.push($);try{return T.apply(null,arguments)}finally{Pe||(Ir.pop()===$||Xe(),ot&&bt===1&&Ir.length===0&&(bt=0,He+=1,Cr(oo),typeof Fibers<\"u\"&&Fibers.Ub()))}}:T})(m);return c}var bt=0,ot=null,qn=0,Ir=[],Kn={},Yn={},vu=0,tn=null,$u=[];function Su(){return new Promise((i,c)=>{tn={resolve:i,reject:c}})}function xu(){var i=rn(65548),c=i+12;s()[i>>2>>>0]=c,s()[i+4>>2>>>0]=c+65536,c=Ir[0];var m=Kn[c];return m===void 0&&(m=vu++,Kn[c]=m,Yn[m]=c),c=m,n()[i+8>>2>>>0]=c,i}function Cu(){var i=n()[ot+8>>2>>>0];return i=j[Yn[i]],--He,i()}function Iu(i){if(!Pe){if(bt===0){var c=!1,m=!1;i(($=0)=>{if(!Pe&&(qn=$,c=!0,m)){bt=2,Cr(()=>ao(ot)),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.resume(),$=!1;try{var T=Cu()}catch(te){T=te,$=!0}var D=!1;if(!ot){var N=tn;N&&(tn=null,($?N.reject:N.resolve)(T),D=!0)}if($&&!D)throw T}}),m=!0,c||(bt=1,ot=xu(),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.pause(),Cr(()=>no(ot)))}else bt===2?(bt=0,Cr(io),Zn(ot),ot=null,$u.forEach($=>Jt($))):Xe(`invalid state: ${bt}`);return qn}}function Au(i){return Iu(c=>{i().then(c)})}ie.gb();var _u=[null,Gt,hr,xt,jt,yr,vr,$r,Sr,xr,Mt,qt,Kt,Yt,Zt,Xt,Qt,l,f,ce,he,k,ne,fe,tr],Tu={r:function(i,c,m){return Au(async()=>{await a.xb(i,c,m)})},b:function(i,c,m){throw i>>>=0,new nt(i).gb(c>>>0,m>>>0),Ke=i,gr++,Ke},P:function(i){Xn(i>>>0,!S,1,!w,131072,!1),ie.lb()},n:function(i){i>>>=0,A?postMessage({cmd:\"cleanupThread\",thread:i}):Rt(i)},K:Ft,g:jt,V:yr,F:vr,H:$r,y:Sr,T:xr,L:Mt,S:qt,p:Kt,G:Yt,D:Zt,U:Xt,E:Qt,q:()=>!0,B:function(i,c){i>>>=0,i==c>>>0?setTimeout(()=>It()):A?postMessage({targetThread:i,cmd:\"checkMailbox\"}):(i=ie.Qa[i])&&i.postMessage({cmd:\"checkMailbox\"})},N:function(){return-1},O:Dt,X:function(i){C&&ie.Qa[i>>>0].ref()},u:function(i,c,m){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,m>>>=0,i=new Date(1e3*i),n()[m>>2>>>0]=i.getUTCSeconds(),n()[m+4>>2>>>0]=i.getUTCMinutes(),n()[m+8>>2>>>0]=i.getUTCHours(),n()[m+12>>2>>>0]=i.getUTCDate(),n()[m+16>>2>>>0]=i.getUTCMonth(),n()[m+20>>2>>>0]=i.getUTCFullYear()-1900,n()[m+24>>2>>>0]=i.getUTCDay(),i=(i.getTime()-Date.UTC(i.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,n()[m+28>>2>>>0]=i},v:function(i,c,m){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,m>>>=0,i=new Date(1e3*i),n()[m>>2>>>0]=i.getSeconds(),n()[m+4>>2>>>0]=i.getMinutes(),n()[m+8>>2>>>0]=i.getHours(),n()[m+12>>2>>>0]=i.getDate(),n()[m+16>>2>>>0]=i.getMonth(),n()[m+20>>2>>>0]=i.getFullYear()-1900,n()[m+24>>2>>>0]=i.getDay(),c=(yt(i.getFullYear())?At:er)[i.getMonth()]+i.getDate()-1|0,n()[m+28>>2>>>0]=c,n()[m+36>>2>>>0]=-(60*i.getTimezoneOffset()),c=new Date(i.getFullYear(),6,1).getTimezoneOffset();var $=new Date(i.getFullYear(),0,1).getTimezoneOffset();i=(c!=$&&i.getTimezoneOffset()==Math.min($,c))|0,n()[m+32>>2>>>0]=i},w:function(i){i>>>=0;var c=new Date(n()[i+20>>2>>>0]+1900,n()[i+16>>2>>>0],n()[i+12>>2>>>0],n()[i+8>>2>>>0],n()[i+4>>2>>>0],n()[i>>2>>>0],0),m=n()[i+32>>2>>>0],$=c.getTimezoneOffset(),T=new Date(c.getFullYear(),6,1).getTimezoneOffset(),D=new Date(c.getFullYear(),0,1).getTimezoneOffset(),N=Math.min(D,T);return 0>m?n()[i+32>>2>>>0]=+(T!=D&&N==$):0<m!=(N==$)&&(T=Math.max(D,T),c.setTime(c.getTime()+6e4*((0<m?N:T)-$))),n()[i+24>>2>>>0]=c.getDay(),m=(yt(c.getFullYear())?At:er)[c.getMonth()]+c.getDate()-1|0,n()[i+28>>2>>>0]=m,n()[i>>2>>>0]=c.getSeconds(),n()[i+4>>2>>>0]=c.getMinutes(),n()[i+8>>2>>>0]=c.getHours(),n()[i+12>>2>>>0]=c.getDate(),n()[i+16>>2>>>0]=c.getMonth(),n()[i+20>>2>>>0]=c.getYear(),i=c.getTime()/1e3,eo((pt=i,1<=+Math.abs(pt)?0<pt?+Math.floor(pt/4294967296)>>>0:~~+Math.ceil((pt-+(~~pt>>>0))/4294967296)>>>0:0)),i>>>0},s:l,t:f,A:function(i,c,m){function $(J){return(J=J.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?J[1]:\"GMT\"}i>>>=0,c>>>=0,m>>>=0;var T=new Date().getFullYear(),D=new Date(T,0,1),N=new Date(T,6,1);T=D.getTimezoneOffset();var te=N.getTimezoneOffset(),Q=Math.max(T,te);s()[i>>2>>>0]=60*Q,n()[c>>2>>>0]=+(T!=te),i=$(D),c=$(N),i=g(i),c=g(c),te<T?(s()[m>>2>>>0]=i,s()[m+4>>2>>>0]=c):(s()[m>>2>>>0]=c,s()[m+4>>2>>>0]=i)},e:()=>{Xe(\"\")},c:function(i,c,m){return i>>>=0,c=O(c>>>0,m>>>0),kt[i].apply(null,c)},l:function(i,c,m){return i>>>=0,c=O(c>>>0,m>>>0),kt[i].apply(null,c)},o:function(){},k:function(){return Date.now()},W:()=>{throw He+=1,\"unwind\"},C:function(){return 4294901760},d:()=>performance.timeOrigin+performance.now(),i:function(){return C?(go(),zt(ho)).cpus().length:navigator.hardwareConcurrency},M:function(i,c,m,$){for(ie.Pb=c>>>0,se.length=m,c=$>>>0>>3,$=0;$<m;$++)se[$]=d()[c+$>>>0];return(0>i?kt[-i-1]:_u[i]).apply(null,se)},z:function(i){i>>>=0;var c=o().length;if(i<=c||4294901760<i)return!1;for(var m=1;4>=m;m*=2){var $=c*(1+.2/m);$=Math.min($,i+100663296);var T=Math;$=Math.max(i,$);e:{T=T.min.call(T,4294901760,$+(65536-$%65536)%65536)-ve.buffer.byteLength+65535>>>16;try{ve.grow(T),pe();var D=1;break e}catch{}D=void 0}if(D)return!0}return!1},Q:ce,R:he,J:Lt,h:k,m:ne,x:fe,j:tr,a:ve||a.wasmMemory,I:jn,f:function(i,c,m,$){return jn(i>>>0,c>>>0,m>>>0,$>>>0)}};(function(){function i(m,$){return m=m.exports,m=wu(m),j=m=Eu(m),ie.mb.push(j.Da),Oe.unshift(j.Y),xe=$,pr(),m}var c={a:Tu};if(Vt(),a.instantiateWasm)try{return a.instantiateWasm(c,i)}catch(m){K(\"Module.instantiateWasm callback failed with error: \"+m),h(m)}return fr(c,function(m){i(m.instance,m.module)}).catch(h),{}})(),a._OrtInit=(i,c)=>(a._OrtInit=j.Z)(i,c),a._OrtGetLastError=(i,c)=>(a._OrtGetLastError=j._)(i,c),a._OrtCreateSessionOptions=(i,c,m,$,T,D,N,te,Q,J)=>(a._OrtCreateSessionOptions=j.$)(i,c,m,$,T,D,N,te,Q,J),a._OrtAppendExecutionProvider=(i,c)=>(a._OrtAppendExecutionProvider=j.aa)(i,c),a._OrtAddFreeDimensionOverride=(i,c,m)=>(a._OrtAddFreeDimensionOverride=j.ba)(i,c,m),a._OrtAddSessionConfigEntry=(i,c,m)=>(a._OrtAddSessionConfigEntry=j.ca)(i,c,m),a._OrtReleaseSessionOptions=i=>(a._OrtReleaseSessionOptions=j.da)(i),a._OrtCreateSession=(i,c,m)=>(a._OrtCreateSession=j.ea)(i,c,m),a._OrtReleaseSession=i=>(a._OrtReleaseSession=j.fa)(i),a._OrtGetInputOutputCount=(i,c,m)=>(a._OrtGetInputOutputCount=j.ga)(i,c,m),a._OrtGetInputName=(i,c)=>(a._OrtGetInputName=j.ha)(i,c),a._OrtGetOutputName=(i,c)=>(a._OrtGetOutputName=j.ia)(i,c),a._OrtFree=i=>(a._OrtFree=j.ja)(i),a._OrtCreateTensor=(i,c,m,$,T,D)=>(a._OrtCreateTensor=j.ka)(i,c,m,$,T,D),a._OrtGetTensorData=(i,c,m,$,T)=>(a._OrtGetTensorData=j.la)(i,c,m,$,T),a._OrtReleaseTensor=i=>(a._OrtReleaseTensor=j.ma)(i),a._OrtCreateRunOptions=(i,c,m,$)=>(a._OrtCreateRunOptions=j.na)(i,c,m,$),a._OrtAddRunConfigEntry=(i,c,m)=>(a._OrtAddRunConfigEntry=j.oa)(i,c,m),a._OrtReleaseRunOptions=i=>(a._OrtReleaseRunOptions=j.pa)(i),a._OrtCreateBinding=i=>(a._OrtCreateBinding=j.qa)(i),a._OrtBindInput=(i,c,m)=>(a._OrtBindInput=j.ra)(i,c,m),a._OrtBindOutput=(i,c,m,$)=>(a._OrtBindOutput=j.sa)(i,c,m,$),a._OrtClearBoundOutputs=i=>(a._OrtClearBoundOutputs=j.ta)(i),a._OrtReleaseBinding=i=>(a._OrtReleaseBinding=j.ua)(i),a._OrtRunWithBinding=(i,c,m,$,T)=>(a._OrtRunWithBinding=j.va)(i,c,m,$,T),a._OrtRun=(i,c,m,$,T,D,N,te)=>(a._OrtRun=j.wa)(i,c,m,$,T,D,N,te),a._OrtEndProfiling=i=>(a._OrtEndProfiling=j.xa)(i),a._JsepOutput=(i,c,m)=>(a._JsepOutput=j.ya)(i,c,m),a._JsepGetNodeName=i=>(a._JsepGetNodeName=j.za)(i);var Ar=a._pthread_self=()=>(Ar=a._pthread_self=j.Aa)(),rn=a._malloc=i=>(rn=a._malloc=j.Ba)(i),Zn=a._free=i=>(Zn=a._free=j.Ca)(i);a.__emscripten_tls_init=()=>(a.__emscripten_tls_init=j.Da)();var Xn=a.__emscripten_thread_init=(i,c,m,$,T,D)=>(Xn=a.__emscripten_thread_init=j.Fa)(i,c,m,$,T,D);a.__emscripten_thread_crashed=()=>(a.__emscripten_thread_crashed=j.Ga)();var Qn=(i,c,m,$)=>(Qn=j.Ha)(i,c,m,$),nn=i=>(nn=j.Ia)(i),on=a.__emscripten_thread_exit=i=>(on=a.__emscripten_thread_exit=j.Ja)(i),Jn=a.__emscripten_check_mailbox=()=>(Jn=a.__emscripten_check_mailbox=j.Ka)(),eo=i=>(eo=j.La)(i),to=(i,c)=>(to=j.Ma)(i,c),an=()=>(an=j.Na)(),_r=i=>(_r=j.Oa)(i),sn=i=>(sn=j.Pa)(i),ro=a.dynCall_ii=(i,c)=>(ro=a.dynCall_ii=j.Ra)(i,c),no=i=>(no=j.Sa)(i),oo=()=>(oo=j.Ta)(),ao=i=>(ao=j.Ua)(i),io=()=>(io=j.Va)();a.___start_em_js=1436551,a.___stop_em_js=1436712;function Eu(i){i=Object.assign({},i);var c=$=>()=>$()>>>0,m=$=>T=>$(T)>>>0;return i.__errno_location=c(i.__errno_location),i.pthread_self=c(i.pthread_self),i.malloc=m(i.malloc),i.stackSave=c(i.stackSave),i.stackAlloc=m(i.stackAlloc),i}a.keepRuntimeAlive=rt,a.wasmMemory=ve,a.stackAlloc=sn,a.stackSave=an,a.stackRestore=_r,a.UTF8ToString=Ve,a.stringToUTF8=wr,a.lengthBytesUTF8=Ct,a.ExitStatus=gt,a.PThread=ie;var Tr;St=function i(){Tr||so(),Tr||(St=i)};function so(){function i(){if(!Tr&&(Tr=!0,a.calledRun=!0,!Pe)&&(A||ft(Oe),p(a),a.onRuntimeInitialized&&a.onRuntimeInitialized(),!A)){if(a.postRun)for(typeof a.postRun==\"function\"&&(a.postRun=[a.postRun]);a.postRun.length;){var c=a.postRun.shift();Me.unshift(c)}ft(Me)}}if(!(0<qe))if(A)p(a),A||ft(Oe),startWorker(a);else{if(a.preRun)for(typeof a.preRun==\"function\"&&(a.preRun=[a.preRun]);a.preRun.length;)Fe.unshift(a.preRun.shift());ft(Fe),0<qe||(a.setStatus?(a.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){a.setStatus(\"\")},1),i()},1)):i())}}if(a.preInit)for(typeof a.preInit==\"function\"&&(a.preInit=[a.preInit]);0<a.preInit.length;)a.preInit.pop()();return so(),t.ready}})();typeof bo==\"object\"&&typeof mn==\"object\"?mn.exports=yo:typeof define==\"function\"&&define.amd&&define([],()=>yo)});var vo=rr((Tc,zu)=>{zu.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var yn,or,ar,kr,ir,Ao,bn,De=F(()=>{\"use strict\";yn=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},or=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},ar=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],kr=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},ir=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},Ao=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",bn=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var ju,qu,_o,To,Eo,Ku,Te,wt=F(()=>{\"use strict\";De();ju=[\"V\",\"I\",\"W\",\"E\",\"F\"],qu=(e,t)=>{console.log(`[${ju[e]},${new Date().toISOString()}]${t}`)},Eo=(e,t)=>{_o=e,To=t},Ku=(e,t)=>{let r=ir(e),o=ir(_o);r>=o&&qu(r,typeof t==\"function\"?t():t)},Te=(...e)=>{To&&Ku(...e)}});var Oo,ko=F(()=>{\"use strict\";De();Oo=(e,t)=>new(kr(t))(e)});var Pr=F(()=>{\"use strict\"});var Rr,Yu,Po,vn,wn,Bo,Mo=F(()=>{\"use strict\";wt();Pr();Rr=e=>Math.ceil(e/16)*16,Yu=1,Po=()=>Yu++,vn=async(e,t,r,o)=>{let n=Rr(r),s=e.device.createBuffer({size:n,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let u=e.getCommandEncoder();e.endComputePass(),u.copyBufferToBuffer(t,0,s,0,n),e.flush(),await s.mapAsync(GPUMapMode.READ);let d=s.getMappedRange();if(o){let a=o();return a.set(new Uint8Array(d,0,r)),a}else return new Uint8Array(d.slice(0,r))}finally{s.destroy()}},wn=class{constructor(t){this.backend=t;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(t,r){let o=r.buffer,n=r.byteOffset,s=r.byteLength,u=Rr(s),d=this.storageCache.get(t);if(!d)throw new Error(\"gpu data for uploading does not exist\");if(d.originalSize!==s)throw new Error(`inconsistent data size. gpu data size=${d.originalSize}, data size=${s}`);let a=this.backend.device.createBuffer({mappedAtCreation:!0,size:u,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),p=a.getMappedRange();new Uint8Array(p).set(new Uint8Array(o,n,s)),a.unmap();let h=this.backend.getCommandEncoder();this.backend.endComputePass(),h.copyBufferToBuffer(a,0,d.gpuData.buffer,0,u),Te(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${t})`),this.buffersForUploadingPending.push(a)}memcpy(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"source gpu data for memcpy does not exist\");let n=this.storageCache.get(r);if(!n)throw new Error(\"destination gpu data for memcpy does not exist\");if(o.originalSize!==n.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let s=Rr(o.originalSize),u=this.backend.getCommandEncoder();this.backend.endComputePass(),u.copyBufferToBuffer(o.gpuData.buffer,0,n.gpuData.buffer,0,s)}registerExternalBuffer(t,r,o){let n;if(o){if(n=this.externalBuffers.get(o),n===void 0)throw new Error(\"previous buffer is not registered\");if(t===o)return Te(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, buffer is the same, skip.`),n;this.externalBuffers.delete(o)}else n=Po();return this.storageCache.set(n,{gpuData:{id:n,type:0,buffer:t},originalSize:r}),this.externalBuffers.set(t,n),Te(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, registered.`),n}unregisterExternalBuffer(t){let r=this.externalBuffers.get(t);r!==void 0&&(this.storageCache.delete(r),this.externalBuffers.delete(t),Te(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${r}`))}create(t,r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let o=Rr(t),n,s=(r&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,u=(r&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(s||u){let a=s?this.freeBuffers:this.freeUniformBuffers,p=a.get(o);p||(p=[],a.set(o,p)),p.length>0?n=p.pop():n=this.backend.device.createBuffer({size:o,usage:r})}else n=this.backend.device.createBuffer({size:o,usage:r});let d={id:Po(),type:0,buffer:n};return this.storageCache.set(d.id,{gpuData:d,originalSize:t}),Te(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${t}) => id=${d.id}`),d}get(t){return this.storageCache.get(t)?.gpuData}release(t){let r=this.storageCache.get(t);if(!r)throw new Error(\"releasing data does not exist\");return Te(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${r.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(r.gpuData.buffer),r.originalSize}async download(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"data does not exist\");await vn(this.backend,o.gpuData.buffer,o.originalSize,r)}refreshPendingBuffers(){for(let t of this.buffersForUploadingPending)t.destroy();this.buffersForUploadingPending=[];for(let t of this.buffersPending)(t.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(t.size).push(t):(t.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(t.size).push(t):t.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.freeUniformBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.storageCache.forEach(t=>{t.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},Bo=(...e)=>new wn(...e)});var $n,re,Ee=F(()=>{\"use strict\";$n=class{constructor(t){Object.assign(this,t)}get cacheKey(){return this.key||(this.key=Object.getOwnPropertyNames(this).sort().map(t=>`${this[t]}`).join(\";\")),this.key}},re=e=>new $n(e)});var Sn,at,z,Tt,Br,Mr,Dr,me=F(()=>{\"use strict\";Sn=class{static calcMatMulShape(t,r){return t[1]!==r[0]?void 0:[t[0],r[1]]}},at=class{static calcShape(t,r,o=!1){let n=t.length,s=r.length;if(n===0)return r;if(s===0)return t;let u=Math.max(t.length,r.length),d=new Array(u);if(o){if(n<2||s<2)return;let a=Sn.calcMatMulShape([t[n-2],t[n-1]],[r[s-2],r[s-1]]);if(a===void 0)return;[d[u-2],d[u-1]]=a}for(let a=o?3:1;a<=u;a++){let p=n-a<0?1:t[n-a],h=s-a<0?1:r[s-a];if(p!==h&&p>1&&h>1)return;d[u-a]=Math.max(p,h)}return d}static isValidBroadcast(t,r){let o=t.length,n=r.length;if(o>n)return!1;for(let s=1;s<=o;s++)if(t[o-s]!==1&&t[o-s]!==r[n-s])return!1;return!0}},z=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,r,t.length)}static sizeToDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,r)}static getSizeFromDimensionRange(t,r,o){let n=1;for(let s=r;s<o;s++){if(t[s]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");n*=t[s]}return n}static computeStrides(t){let r=t.length;if(r===0)return[];if(r===1)return[1];let o=new Array(r);o[r-1]=1,o[r-2]=t[r-1];for(let n=r-3;n>=0;--n)o[n]=o[n+1]*t[n+1];return o}static normalizeAxis(t,r){if(t<-r&&t>=r)throw new Error(\"unsupported axis for this operation.\");return t<0?t+r:t}static normalizeAxes(t,r){return t.map(o=>this.normalizeAxis(o,r??t.length))}static sortBasedOnPerm(t,r){return r?r.map(o=>t[o]):t.slice().reverse()}static padShape(t,r){let o=t.length;return t.map((n,s)=>n+r[s]+r[s+o])}static areEqual(t,r){return t.length!==r.length?!1:t.every((o,n)=>o===r[n])}},Tt=class e{static adjustPoolAttributes(t,r,o,n,s,u){if(!t&&o.length!==r.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let d=0;d<r.length-2;d++)d>=o.length?o.push(r[d+2]):o[d]=r[d+2];for(let d=0;d<o.length;d++)if(d<n.length){if(n[d]<0)throw new Error(\"strides should be greater than or equal to 1\")}else n.push(1);for(let d=0;d<o.length;d++)if(d<s.length){if(s[d]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else s.push(1);for(let d=0;d<o.length*2;d++)if(d<u.length){if(u[d]<0)throw new Error(\"pad should be greater than or equal to 1\")}else u.push(0);for(let d=0;d<o.length;d++){if(o[d]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(u[d]>=o[d]||u[d+o.length]>=o[d])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,r,o,n,s,u,d){if(d){if(s.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(n.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let a=0;a<t.length-2;a++)e.adjustPadAndReturnShape(t[a+(u?1:2)],r[a],o[a],n[a],s,a,a+t.length-2,d)}}static computePoolOutputShape(t,r,o,n,s,u,d){if(r.length<=0)throw new Error(\"input shape must be of size greater than 0\");let a=[r[0],r[1]];return e.computeShapeHelper(t,r,a,o,n,s,u,d),a}static computeConvOutputShape(t,r,o,n,s,u,d){if(t.length<=0||r.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let a=[t[0],r[0]];return e.computeShapeHelper(!1,t,a,o,n,s,u,d),a}static computeShapeHelper(t,r,o,n,s,u,d,a){if(t)for(let p=0;p<r.length-2;p++)o.push(1);else for(let p=0;p<r.length-2;p++)o.push(e.adjustPadAndReturnShape(r[p+2],n[p],s[p],u[p],d,p,p+r.length-2,a))}static adjustPadAndReturnShape(t,r,o,n,s,u,d,a){let p=o*(n-1)+1;if(a&&a!==\"NOTSET\")switch(a){case\"VALID\":return s[u]=0,s[d]=0,Math.floor((t-p)/r+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(o!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let v=((t+r-1)/r-1)*r+n-t;return s[u]=Math.floor(a===\"SAME_LOWER\"?(v+1)/2:v/2),s[d]=v-s[u],Math.floor((t+v-n)/r+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((t+s[u]+s[d]-p)/r+1)}},Br=class{static getShapeOfGemmResult(t,r,o,n,s){if(t.length!==2||o.length!==2)throw new Error(\"shape need to be of size 2\");let u,d,a;r?(u=t[1],d=t[0]):(u=t[0],d=t[1]);let p=-1;if(n?(a=o[0],p=1):(a=o[1],p=0),o[p]!==d)throw new Error(\"dimension mismatch\");if(u<=0||a<=0||d<=0)throw new Error(\"invalid shape specified\");if(s&&!at.isValidBroadcast(s,[u,a]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[u,a,d]}},Mr=-34028234663852886e22,Dr=34028234663852886e22});var Zu,Do,Ie,Ne,Ze,Ue,Qe,Je,zo,G,q,xn,Wo,Cn,Ge,be=F(()=>{\"use strict\";De();me();Zu=64,Do=(e,t)=>{if(t===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return t>1?`vec${t}<f16>`:\"f16\";case 1:return t>1?`vec${t}<f32>`:\"f32\";case 6:return t>1?`vec${t}<i32>`:\"i32\";case 12:return t>1?`vec${t}<u32>`:\"u32\";case 7:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(t!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},Ie=(e,t=1)=>{let r=Do(e,t);return typeof r==\"string\"?r:r[0]},Ne=e=>e.length===0?[]:[{type:\"uint32\",data:e},{type:\"uint32\",data:z.computeStrides(e)}],Ze=e=>e%4===0?4:e%2===0?2:1,Ue=(e=\"f32\",t,r=\"0\")=>!t||t===1?`${e}(${r})`:`vec${t}<${e}>(${r})`,Qe=(e,t,r)=>e===\"f32\"?r:t===1?`f32(${r})`:`vec${t}f(${r})`,Je=(e,t)=>t===4?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:t===2?`(${e}.x + ${e}.y)`:t===3?`(${e}.x + ${e}.y + ${e}.z)`:e,zo=(e,t,r,o,n)=>{let s=typeof r==\"number\",u=s?r:r.length,d=[...new Array(u).keys()],a=u<2?\"u32\":u<=4?`vec${u}<u32>`:`array<u32, ${u}>`,p=Do(t,n),h=typeof p==\"string\"?p:p[1],v=typeof p==\"string\"?p:p[0],y={indices:a,value:h,storage:v,tensor:t},b=L=>typeof L==\"string\"?L:`${L}u`,w={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},S=s?\"uniforms.\":\"\",C=`${S}${e}_shape`,A=`${S}${e}_strides`,I=\"\";for(let L=0;L<u-1;L++)I+=`\n    let dim${L} = current / ${A}[${L}];\n    let rest${L} = current % ${A}[${L}];\n    indices[${L}] = dim${L};\n    current = rest${L};\n    `;I+=`indices[${u-1}] = current;`;let B=u<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${y.indices} {\n    var indices: ${y.indices};\n    var current = offset;\n    ${I}\n    return indices;\n  }`,_=L=>(w.offsetToIndices=!0,u<2?L:`o2i_${e}(${L})`),R=[];if(u>=2)for(let L=u-1;L>=0;L--)R.push(`${A}[${L}] * (indices[${L}])`);let E=u<2?\"\":`\n  fn i2o_${e}(indices: ${y.indices}) -> u32 {\n    return ${R.join(\"+\")};\n  }`,W=L=>(w.indicesToOffset=!0,u<2?L:`i2o_${e}(${L})`),V=(...L)=>u===0?\"0u\":`${y.indices}(${L.map(b).join(\",\")})`,Y=(L,de)=>u<2?`${L}`:`${L}[${de}]`,ae=(L,de,pe)=>u<2?`${L}=${pe};`:`${L}[${de}]=${pe};`,M={},K=(L,de)=>{w.broadcastedIndicesToOffset=!0;let pe=`${de.name}broadcastedIndicesTo${e}Offset`;if(pe in M)return`${pe}(${L})`;let We=[];for(let Fe=u-1;Fe>=0;Fe--){let Oe=de.indicesGet(\"outputIndices\",Fe+de.rank-u);We.push(`${Y(A,Fe)} * (${Oe} % ${Y(C,Fe)})`)}return M[pe]=`fn ${pe}(outputIndices: ${de.type.indices}) -> u32 {\n             return ${We.length>0?We.join(\"+\"):\"0u\"};\n           }`,`${pe}(${L})`},Se=(L,de)=>(()=>{if(y.storage===y.value)return`${e}[${L}]=${de};`;if(y.storage===\"vec2<u32>\"&&y.value===\"i32\")return`${e}[${L}]=vec2<u32>(u32(${de}), select(0u, 0xFFFFFFFFu, ${de} < 0));`;if(y.storage===\"vec2<u32>\"&&y.value===\"u32\")return`${e}[${L}]=vec2<u32>(u32(${de}), 0u);`;if(y.storage===\"u32\"&&y.value===\"vec4<bool>\")return`${e}[${L}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${de}));`;throw new Error(`not supported combination of storage type ${y.storage} and value type ${y.value} yet`)})(),ue=L=>(()=>{if(y.storage===y.value)return`${e}[${L}]`;if(y.storage===\"vec2<u32>\"&&y.value===\"i32\")return`i32(${e}[${L}].x)`;if(y.storage===\"vec2<u32>\"&&y.value===\"u32\")return`u32(${e}[${L}].x)`;if(y.storage===\"u32\"&&y.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${L}] & 0xFFu), bool(${e}[${L}] & 0xFF00u), bool(${e}[${L}] & 0xFF0000u), bool(${e}[${L}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${y.storage} and value type ${y.value} yet`)})(),ve=u<2?\"\":`\n  fn get_${e}ByIndices(indices: ${y.indices}) -> ${h} {\n    return ${ue(`i2o_${e}(indices)`)};\n  }`,j=u<2?\"\":(()=>{let L=d.map(pe=>`d${pe}: u32`).join(\", \"),de=d.map(pe=>`d${pe}`).join(\", \");return`\n  fn get_${e}(${L}) -> ${h} {\n    return get_${e}ByIndices(${V(de)});\n  }`})(),xe=(...L)=>{if(L.length!==u)throw new Error(`indices length must be ${u}`);let de=L.map(b).join(\",\");return u===0?ue(\"0u\"):u===1?ue(de[0]):(w.get=!0,w.getByIndices=!0,w.indicesToOffset=!0,`get_${e}(${de})`)},Pe=L=>u<2?ue(L):(w.getByIndices=!0,w.indicesToOffset=!0,`get_${e}ByIndices(${L})`),_e=u<2?\"\":`\n  fn set_${e}ByIndices(indices: ${y.indices}, value: ${h}) {\n    ${Se(`i2o_${e}(indices)`,\"value\")}\n  }`,Ce=u<2?\"\":(()=>{let L=d.map(pe=>`d${pe}: u32`).join(\", \"),de=d.map(pe=>`d${pe}`).join(\", \");return`\n  fn set_${e}(${L}, value: ${h}) {\n    set_${e}ByIndices(${V(de)}, value);\n  }`})();return{impl:()=>{let L=[];return s||(L.push(`const ${C} = ${y.indices}(${r.join(\",\")});`),L.push(`const ${A} = ${y.indices}(${z.computeStrides(r).join(\",\")});`)),w.offsetToIndices&&L.push(B),w.indicesToOffset&&L.push(E),w.broadcastedIndicesToOffset&&Object.values(M).forEach(de=>L.push(de)),w.set&&L.push(Ce),w.setByIndices&&L.push(_e),w.get&&L.push(j),w.getByIndices&&L.push(ve),L.join(`\n`)},type:y,offsetToIndices:_,indicesToOffset:W,broadcastedIndicesToOffset:K,indices:V,indicesGet:Y,indicesSet:ae,set:(...L)=>{if(L.length!==u+1)throw new Error(`indices length must be ${u}`);let de=L[u];if(typeof de!=\"string\")throw new Error(\"value must be string\");let pe=L.slice(0,u).map(b).join(\",\");return u===0?Se(\"0u\",de):u===1?Se(pe[0],de):(w.set=!0,w.setByIndices=!0,w.indicesToOffset=!0,`set_${e}(${pe}, ${de})`)},setByOffset:Se,setByIndices:(L,de)=>u<2?Se(L,de):(w.setByIndices=!0,w.indicesToOffset=!0,`set_${e}ByIndices(${L}, ${de});`),get:xe,getByOffset:ue,getByIndices:Pe,usage:o?\"input\":\"output\",name:e,strides:A,shape:C,rank:u}},G=(e,t,r,o=1)=>zo(e,t,r,!0,o),q=(e,t,r,o=1)=>zo(e,t,r,!1,o),xn=class{constructor(t){this.normalizedDispatchGroup=t;this.indicesHelpers=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(t){return`if (global_idx >= ${typeof t==\"number\"?`${t}u`:t}) { return; }`}mainStart(t=Zu){let r=typeof t==\"number\"?t:t[0],o=typeof t==\"number\"?1:t[1],n=typeof t==\"number\"?1:t[2],s=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,u=s?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`,d=s?\"let global_idx = global_id.x;\":`let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${r*o*n}u + local_index;`;return`@compute @workgroup_size(${r}, ${o}, ${n})\n  fn main(${u}) {\n    ${d}\n  `}declareVariable(t,r){this.indicesHelpers.push(t),t.rank!==0&&(t.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.shape.replace(\"uniforms.\",\"\"),type:t.type.indices}),t.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.strides.replace(\"uniforms.\",\"\"),type:t.type.indices}));let o=t.usage===\"input\"?\"read\":\"read_write\",n=t.type.storage;return`@group(0) @binding(${r}) var<storage, ${o}> ${t.name}: array<${n}>;`}declareVariables(...t){return t.map(r=>this.declareVariable(r,this.variableIndex++)).join(`\n`)}registerUniform(t,r){return this.uniforms.push({name:t,type:r}),this}registerUniforms(t){return this.uniforms=this.uniforms.concat(t),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let t=[];for(let{name:r,type:o}of this.uniforms)t.push(`${r}:${o}`);return`\n      struct Uniforms { ${t.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.indicesHelpers.map(t=>t.impl()).join(`\n`)}},Wo=e=>new xn(e),Cn=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;n++){let s=r-1-n,u=e[s]||1;(t[t.length-1-n]||1)>1&&u===1&&o.unshift(s)}return o},Ge=e=>e<=4});var Xu,Vo,Qu,Ju,et,No,Uo,Wt=F(()=>{\"use strict\";me();Ee();be();Xu=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},Vo=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,Qu=(e,t)=>z.sortBasedOnPerm(e,Vo(e.length,t)),Ju=(e,t,r,o)=>{let n=[];n.push(`fn perm(i: ${o.type.indices}) -> ${r.type.indices} {\n    var a: ${r.type.indices};`);for(let s=0;s<t;++s)n.push(r.indicesSet(\"a\",e[s],`i[${s}]`));return n.push(\"return a;}\"),n.join(`\n`)},et=(e,t)=>{let r=e.dataType,o=e.dims.length,n=Vo(o,t),s=Ge(o),u=Qu(e.dims,n),d=s?u.length:u,a=s?o:e.dims,p=q(\"output\",r,d),h=G(\"a\",r,a),v=y=>`\n  ${y.registerUniform(\"output_size\",\"u32\").declareVariables(h,p)}\n\n  ${Ju(n,o,h,p)}\n\n  ${y.mainStart()}\n    ${y.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${p.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${p.setByOffset(\"global_idx\",h.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${t}`,inputDependencies:s?[\"rank\"]:[\"dims\"]},getRunData:y=>{let b=z.size(u);return{outputs:[{dims:u,dataType:y[0].dataType}],dispatchGroup:{x:Math.ceil(b/64)},programUniforms:s?[{type:\"uint32\",data:b},...Ne(y[0].dims),...Ne(u)]:[{type:\"uint32\",data:b}]}},getShaderSource:v}},No=(e,t)=>{Xu(e.inputs),e.compute(et(e.inputs[0],t.perm))},Uo=e=>re({perm:e.perm})});var el,tl,rl,nl,ol,al,il,sl,ul,ll,it,Ho,Go,Lo,Fo,jo,qo,Ko,Yo,Zo,Xo,Qo=F(()=>{\"use strict\";me();be();zr();Wt();el={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate * candidate\",logSumExp:\"bestValue + exp(candidate)\",l1:\"bestValue + abs(candidate)\",l2:\"bestValue + candidate * candidate\",logSum:\"bestValue + candidate\"},tl={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate\",logSumExp:\"bestValue + candidate\",l1:\"bestValue + candidate\",l2:\"bestValue + candidate\",logSum:\"bestValue + candidate\"},rl={max:\"_A[offset]\",min:\"_A[offset]\",mean:\"0\",sum:\"0\",prod:\"1\",sumSquare:\"0\",logSumExp:\"0\",l1:\"0\",l2:\"0\",logSum:\"0\"},nl={max:\"bestValue\",min:\"bestValue\",sum:\"bestValue\",prod:\"bestValue\",sumSquare:\"bestValue\",logSumExp:\"log(bestValue)\",l1:\"bestValue\",l2:\"sqrt(bestValue)\",logSum:\"log(bestValue)\"},ol=(e,t)=>{let r=[];for(let o=t-e;o<t;++o)r.push(o);return r},al=(e,t)=>{let r=[],o=e.length;for(let s=0;s<o;s++)t.indexOf(s)===-1&&r.push(e[s]);let n=t.map(s=>e[s]);return[r,n]},il=(e,t)=>{let r=e.length+t.length,o=[],n=0;for(let s=0;s<r;s++)t.indexOf(s)===-1?o.push(e[n++]):o.push(1);return o},sl=(e,t)=>{for(let r=0;r<e.length;++r)if(e[e.length-r-1]!==t-1-r)return!1;return!0},ul=(e,t)=>{let r=[];if(!sl(e,t)){for(let o=0;o<t;++o)e.indexOf(o)===-1&&r.push(o);e.forEach(o=>r.push(o))}return r},ll=(e,t,r,o,n,s,u)=>{let d=r[0].dims,a=z.size(s),p=z.size(u),h=G(\"_A\",r[0].dataType,d),v=q(\"output\",n,s),y=32,b=`\n          var<workgroup> aBestValues : array<${v.type.storage}, ${y}>;\n       `;return{name:e,shaderCache:t,getShaderSource:S=>`\n        ${S.registerUniform(\"reduceSize\",\"u32\").declareVariables(h,v)}\n        ${b}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${S.mainStart(y)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${y};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${v.type.storage}(${rl[o]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${y}) {\n           let candidate = ${v.type.storage}(${h.getByOffset(\"offset + k\")});\n           bestValue = ${el[o]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${y}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${tl[o]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${v.setByOffset(\"outputIndex\",`${o===\"mean\"?`bestValue / ${v.type.storage}(uniforms.reduceSize)`:`${nl[o]}`}`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:s,dataType:n}],dispatchGroup:{x:a},programUniforms:[{type:\"uint32\",data:p}]})}},it=(e,t,r,o)=>{let n=e.inputs.length===1?r:In(e.inputs,r),s=n.axes;s.length===0&&!n.noopWithEmptyAxes&&(s=e.inputs[0].dims.map((b,w)=>w));let u=z.normalizeAxes(s,e.inputs[0].dims.length),d=u,a=e.inputs[0],p=ul(d,e.inputs[0].dims.length);p.length>0&&(a=e.compute(et(e.inputs[0],p),{inputs:[0],outputs:[-1]})[0],d=ol(d.length,a.dims.length));let[h,v]=al(a.dims,d),y=h;n.keepDims&&(y=il(h,u)),e.compute(ll(t,{hint:n.cacheKey,inputDependencies:[\"type\"]},[a],o,e.inputs[0].dataType,y,v),{inputs:[a]})},Ho=(e,t)=>{it(e,\"ReduceMeanShared\",t,\"mean\")},Go=(e,t)=>{it(e,\"ReduceL1Shared\",t,\"l1\")},Lo=(e,t)=>{it(e,\"ReduceL2Shared\",t,\"l2\")},Fo=(e,t)=>{it(e,\"ReduceLogSumExpShared\",t,\"logSumExp\")},jo=(e,t)=>{it(e,\"ReduceMaxShared\",t,\"max\")},qo=(e,t)=>{it(e,\"ReduceMinShared\",t,\"min\")},Ko=(e,t)=>{it(e,\"ReduceProdShared\",t,\"prod\")},Yo=(e,t)=>{it(e,\"ReduceSumShared\",t,\"sum\")},Zo=(e,t)=>{it(e,\"ReduceSumSquareShared\",t,\"sumSquare\")},Xo=(e,t)=>{it(e,\"ReduceLogSumShared\",t,\"logSum\")}});var st,dl,Wr,In,ut,cl,pl,fl,ml,hl,gl,yl,bl,wl,vl,lt,Jo,ea,ta,ra,na,oa,aa,ia,sa,ua,tt,zr=F(()=>{\"use strict\";me();Ee();be();Qo();st=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},dl=e=>[\"\",\"\",`var value = ${e.getByOffset(\"inputOffset\")};`,\"\"],Wr=(e,t,r,o,n,s,u=!1,d=!1)=>{let a=[],p=r[0].dims,h=z.normalizeAxes(n,r[0].dims.length),v=!d&&h.length===0;p.forEach((W,V)=>{v||h.indexOf(V)>=0?u&&a.push(1):a.push(W)});let y=[],b=G(\"_A\",r[0].dataType,p),w=q(\"output\",s,a),S=o(b,w,h),C=`inputOffset = ${b.indicesToOffset(\"inputIndices\")};`,A=`let ${C};`,I=`var ${C};`,B=S[1]===\"\"?\"\":I,_=(S[1]===\"\"?A:C)+`\n`+S[2];for(let W=0,V=0;W<r[0].dims.length;W++)v||h.indexOf(W)>=0?(u&&V++,_=`for(var j${W}: u32 = 0; j${W} < ${r[0].dims[W]}; j${W}++) {\n                ${S[2].includes(\"lastIndex\")?`let lastIndex = j${W};`:\"\"}\n                ${b.indicesSet(\"inputIndices\",W,`j${W}`)}\n                ${_}\n              }`):(y.push(`${b.indicesSet(\"inputIndices\",W,w.indicesGet(\"outputIndices\",V))};`),V++);let R=z.size(a);return{name:e,shaderCache:t,getShaderSource:W=>`\n        ${W.declareVariables(b,w)}\n\n        ${W.mainStart()}\n          ${W.guardAgainstOutOfBoundsWorkgroupSizes(R)}\n          var inputIndices: ${b.type.indices};\n          let outputIndices = ${w.offsetToIndices(\"global_idx\")};\n\n          ${y.join(`\n`)}\n          ${S[0]}       // init ops for reduce max/min\n          ${B}\n          ${S[1]}\n          ${_}\n          ${S[3]}\n          ${S.length===4?w.setByOffset(\"global_idx\",\"value\"):S.slice(4).join(`\n`)}\n        }`,getRunData:()=>({outputs:[{dims:a,dataType:s}],dispatchGroup:{x:Math.ceil(R/64)}})}},In=(e,t)=>{let r=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(o=>r.push(Number(o))),re({axes:r,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},ut=(e,t,r,o)=>{let n=e.inputs,s=n.length===1?r:In(n,r);e.compute(Wr(t,{hint:s.cacheKey},[n[0]],s.noopWithEmptyAxes&&s.axes.length===0?dl:o,s.axes,n[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},cl=(e,t)=>{st(e.inputs),ut(e,\"ReduceLogSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"value = log(value);\"])},pl=(e,t)=>{st(e.inputs),ut(e,\"ReduceL1\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += abs(${o.getByOffset(\"inputOffset\")});`,\"\"])},fl=(e,t)=>{st(e.inputs),ut(e,\"ReduceL2\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += (t * t);`,\"value = sqrt(value);\"])},ml=(e,t)=>{st(e.inputs),ut(e,\"ReduceLogSumExp\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += exp(${o.getByOffset(\"inputOffset\")});`,\"value = log(value);\"])},hl=(e,t)=>{st(e.inputs),ut(e,\"ReduceMax\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(o.indicesSet(\"inputIndices\",d,0));return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = max(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},gl=(e,t)=>{st(e.inputs),ut(e,\"ReduceMean\",t,(o,n,s)=>{let u=1;for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&(u*=e.inputs[0].dims[d]);return[\"var sum = f32(0);\",\"\",`sum += f32(${o.getByOffset(\"inputOffset\")});`,`let value = ${n.type.value}(sum / ${u});`]})},yl=(e,t)=>{st(e.inputs),ut(e,\"ReduceMin\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`inputIndices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = min(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},bl=(e,t)=>{st(e.inputs),ut(e,\"ReduceProd\",t,(o,n)=>[`var value = ${n.type.storage}(1);`,\"\",`value *= ${o.getByOffset(\"inputOffset\")};`,\"\"])},wl=(e,t)=>{st(e.inputs),ut(e,\"ReduceSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"\"])},vl=(e,t)=>{st(e.inputs),ut(e,\"ReduceSumSquare\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += t * t;`,\"\"])},lt=(e,t,r)=>{if(t.length===0)return!!r;let o=1,n=1;for(let s=0;s<t.length;s++)t.indexOf(s)===-1?o*=e[s]:n*=e[s];return n<32&&o>1024},Jo=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?gl(e,t):Ho(e,t)},ea=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?pl(e,t):Go(e,t)},ta=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?fl(e,t):Lo(e,t)},ra=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ml(e,t):Fo(e,t)},na=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?hl(e,t):jo(e,t)},oa=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?yl(e,t):qo(e,t)},aa=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?bl(e,t):Ko(e,t)},ia=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?wl(e,t):Yo(e,t)},sa=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?vl(e,t):Zo(e,t)},ua=(e,t)=>{lt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?cl(e,t):Xo(e,t)},tt=e=>re(e)});var la,da,ca,An,pa=F(()=>{\"use strict\";De();Ee();zr();la=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},da=(e,t)=>{la(e.inputs);let r=(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`inputIndices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${o.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${o.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",n.setByOffset(\"global_idx\",\"bestIndex\")]};e.compute(Wr(\"ArgMin\",{hint:t.cacheKey},[e.inputs[0]],r,[t.axis],7,t.keepDims),{inputs:[0]})},ca=(e,t)=>{la(e.inputs);let r=(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`inputIndices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${o.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${o.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",n.setByOffset(\"global_idx\",\"bestIndex\")]};e.compute(Wr(\"argMax\",{hint:t.cacheKey},[e.inputs[0]],r,[t.axis],7,t.keepDims),{inputs:[0]})},An=e=>re(e)});var $l,fa,Sl,xl,Cl,Vr,Il,ma,_n=F(()=>{\"use strict\";Ee();Pr();be();$l=(e,t)=>{let r=e[0],o=e[1],n=e[2],s=e[3],u=e[4],d=e[5];if(u&&d)throw new Error(\"Attention cannot have both past and relative_position_bias\");if(r.dims.length!==3)throw new Error('Input \"input\" must have 3 dimensions');let a=r.dims[0],p=r.dims[1],h=r.dims[2];if(n.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimensions');if(o.dims.length!==2)throw new Error('Input \"weights\" is expected to have 2 dimensions');if(o.dims[0]!==h)throw new Error(\"Input 1 dimension 0 should have same length as dimension 2 of input 0\");if(n.dims[0]!==o.dims[1])throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');let v=n.dims[0]/3,y=v,b=y;if(t.qkvHiddenSizes.length>0){if(t.qkvHiddenSizes.length!==3)throw new Error(\"qkv_hidden_sizes attribute should have 3 elements\");for(let B of t.qkvHiddenSizes)if(B%t.numHeads!==0)throw new Error(\"qkv_hidden_sizes should be divisible by num_heads\");v=t.qkvHiddenSizes[0],y=t.qkvHiddenSizes[1],b=t.qkvHiddenSizes[2]}let w=p;if(v!==y)throw new Error(\"qkv_hidden_sizes first element should be same as the second\");if(n.dims[0]!==v+y+b)throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');let S=0;if(u){if(y!==b)throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');if(u.dims.length!==5)throw new Error('Input \"past\" must have 5 dimensions');if(u.dims[0]!==2)throw new Error('Input \"past\" first dimension must be 2');if(u.dims[1]!==a)throw new Error('Input \"past\" second dimension must be batch_size');if(u.dims[2]!==t.numHeads)throw new Error('Input \"past\" third dimension must be num_heads');if(u.dims[4]!==y/t.numHeads)throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');t.pastPresentShareBuffer||(S=u.dims[3])}let C=w+S,A=-1,I=0;if(s)throw new Error(\"Mask not supported\");if(u)throw new Error(\"past is not supported\");if(d)throw new Error(\"relativePositionBias is not supported\");return{batchSize:a,sequenceLength:p,pastSequenceLength:S,kvSequenceLength:w,totalSequenceLength:C,maxSequenceLength:A,inputHiddenSize:h,hiddenSize:v,vHiddenSize:b,headSize:Math.floor(v/t.numHeads),vHeadSize:Math.floor(b/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:I,scale:t.scale,broadcastResPosBias:!1,passPastInKv:!1,qkvFormat:1}},fa=e=>re({...e}),Sl=(e,t,r,o)=>{let n=Ze(o),s=q(\"x\",t.dataType,t.dims,n),u=\"threadMaxVector\";n===2?u=\"max(threadMaxVector.x, threadMaxVector.y)\":n===4&&(u=\"max(max(threadMaxVector.x, threadMaxVector.y), max(threadMaxVector.z, threadMaxVector.w))\");let d=Ie(t.dataType),a=64,p=o/n;p<a?a=1:p/8<64&&(a=Math.ceil(p/8));let h=Math.ceil(o/n/a),v=y=>`\n  const dInv: ${d} = 1 / ${o};\n  const dComp = ${o/n};\n  var<workgroup> wgMax: array<f32, ${a}>;\n  var<workgroup> wgSum: array<f32, ${a}>;\n\n  ${y.declareVariables(s)}\n  @compute @workgroup_size(${a}, 1, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_index : u32) {\n    let localOffset = local_index * ${h};\n    let offset: u32 = workgroup_id.x * dComp + localOffset;\n\n    var threadMaxVector = ${Ue(\"f32\",n,\"-3.402823e+38f\")};\n    for (var i: u32 = 0; i < ${h} && i + localOffset < dComp; i++) {\n      threadMaxVector = max(${Qe(d,n,\"x[offset + i]\")}, threadMaxVector);\n    }\n    wgMax[local_index] = ${u};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${a}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${Ue(\"f32\",n,\"0\")};\n    for (var i: u32 = 0; i < ${h} && i + localOffset < dComp; i++) {\n      sumVector += exp(${Qe(d,n,\"x[offset + i]\")} - maxValue);\n    }\n    wgSum[local_index] = ${Je(\"sumVector\",n)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${a}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < ${h} && i + localOffset < dComp; i++) {\n        x[offset + i] = ${Ue(d,n,\"dInv\")};\n      }\n    } else {\n      for (var i: u32 = 0; i < ${h} && i + localOffset < dComp; i++) {\n        let f32input = ${Qe(d,n,\"x[offset + i]\")};\n        x[offset + i] = ${s.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`;e.compute({name:\"AttentionProbsSoftmax\",shaderCache:{hint:`${o}`},getShaderSource:v,getRunData:()=>({outputs:[],dispatchGroup:{x:r}})},{inputs:[t],outputs:[]})},xl=(e,t,r,o,n,s)=>{let u=[n.batchSize,n.numHeads,n.sequenceLength,n.kvSequenceLength+n.pastSequenceLength],d=s.scale===0?1/Math.sqrt(n.headSize):s.scale,a=Ie(t.dataType),p=Ze(n.headSize),h=G(\"q\",t.dataType,t.dims,p),v=G(\"key\",r.dataType,r.dims,p),y=q(\"output\",t.dataType,u),b=n.headSize/p,w=n.sequenceLength,S=n.totalSequenceLength,C=b,A=12,I={x:Math.ceil(n.totalSequenceLength/A),y:Math.ceil(n.sequenceLength/A),z:n.batchSize*n.numHeads},B=[t,r],_=E=>`\n  const M: u32 = ${w}u;\n  const N: u32 = ${S}u;\n  const K: u32 = ${C}u;\n  const alpha: ${a} = ${d};\n  const beta: ${a} = 1.0;\n  const TILE_SIZE = ${A}u;\n\n  var<workgroup> tileQ: array<${h.type.storage}, ${A*A}>;\n  var<workgroup> tileK: array<${h.type.storage}, ${A*A}>;\n\n  ${E.declareVariables(h,v,y)}\n\n  @compute @workgroup_size(${A}, ${A}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${I.x*I.y}u +\n          workgroup_id.y * ${I.x}u + workgroup_id.x) * ${A*A}u + local_index;\n\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = ${n.sequenceLength*b} * headIdx + m * K;\n    let kOffset = ${n.kvSequenceLength*b} * headIdx + n * K;\n\n    var value = ${Ue(a,p)};\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m + local_id.y < M && w + local_id.x < K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * K + w + local_id.x];\n      }\n      if (n + local_id.y < N && w + local_id.x < K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * M * N;\n    if (lm < M && ln < N) {\n      let outputIdx = headOffset + lm * N + ln;\n      output[outputIdx] = ${Je(\"value\",p)} * alpha;\n    }\n  }`,R=e.compute({name:\"AttentionProbs\",shaderCache:{hint:JSON.stringify(n)},getRunData:()=>({outputs:[{dims:u,dataType:t.dataType,gpuDataType:0}],dispatchGroup:I}),getShaderSource:_},{inputs:B,outputs:[-1]})[0];return Sl(e,R,n.batchSize*n.numHeads*n.sequenceLength,n.totalSequenceLength),R},Cl=(e,t,r,o)=>{let n=[o.batchSize,o.sequenceLength,o.vHiddenSize],s=G(\"probs\",t.dataType,t.dims),u=G(\"v\",r.dataType,r.dims),d=q(\"output\",t.dataType,n),a=Ie(t.dataType),p=12,h={x:Math.ceil(o.vHeadSize/p),y:Math.ceil(o.sequenceLength/p),z:o.batchSize*o.numHeads},v=y=>`\n  const M: u32 = ${o.sequenceLength}u;\n  const N: u32 = ${o.vHeadSize}u;\n  const K: u32 = ${o.totalSequenceLength}u;\n  const numHeads: u32 = ${o.numHeads}u;\n  const TILE_SIZE = ${p}u;\n\n  var<workgroup> tileQ: array<${s.type.storage}, ${p*p}>;\n  var<workgroup> tileK: array<${s.type.storage}, ${p*p}>;\n\n  ${y.declareVariables(s,u,d)}\n\n  @compute @workgroup_size(${p}, ${p}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${h.x*h.y}u +\n          workgroup_id.y * ${h.x}u + workgroup_id.x) * ${p*p}u + local_index;\n\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (M * K) + m * K;\n   let offsetB = headIdx * (N * K) + n;\n\n   var value = ${a}(0);\n   for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n     if (m < M && w + local_id.x < K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < N && w + local_id.y < K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / ${o.numHeads};\n   let currentBatchHeadNumber = workgroup_id.z % ${o.numHeads};\n   let headOffset = (batchIdx * M * ${o.numHeads} + currentBatchHeadNumber) * ${o.vHeadSize};\n   if (m < M && n < N) {\n     let outputIdx = batchIdx * ${o.sequenceLength*o.vHiddenSize} + m * ${o.vHiddenSize}\n       + currentBatchHeadNumber * ${o.vHeadSize} + n;\n     output[outputIdx] = value;\n   }\n  }`;return e.compute({name:\"AttentionScore\",shaderCache:{hint:JSON.stringify(o)},getRunData:()=>({outputs:[{dims:n,dataType:t.dataType,gpuDataType:0}],dispatchGroup:h}),getShaderSource:v},{inputs:[t,r],outputs:[0]})[0]},Vr=(e,t,r,o,n,s,u,d,a,p,h)=>{let v=xl(e,t,r,a,p,h);Cl(e,v,o,p)},Il=(e,t)=>{let r=[t.batchSize,t.numHeads,t.sequenceLength,t.headSize],o=Ie(e.inputs[0].dataType),n=t.sequenceLength,s=t.inputHiddenSize,u=t.headSize,d=12,a={x:Math.ceil(t.headSize/d),y:Math.ceil(t.sequenceLength/d),z:t.batchSize*t.numHeads},p=()=>`\n  const M: u32 = ${n}u;\n  const K: u32 = ${s}u;\n  const N: u32 = ${u}u;\n  const numHeads: u32 = ${t.numHeads};\n  const ldb = ${t.hiddenSize+t.hiddenSize+t.vHiddenSize}u;\n  const TILE_SIZE = ${d}u;\n\n  var<workgroup> tileInput: array<${o}, ${d*d}>;\n  var<workgroup> tileWeightQ: array<${o}, ${d*d}>;\n  var<workgroup> tileWeightK: array<${o}, ${d*d}>;\n  var<workgroup> tileWeightV: array<${o}, ${d*d}>;\n\n  @group(0) @binding(0) var<storage, read> input: array<${o}>;\n  @group(0) @binding(1) var<storage, read> weight: array<${o}>;\n  @group(0) @binding(2) var<storage, read> bias: array<${o}>;\n  @group(0) @binding(3) var<storage, read_write> outputQ: array<${o}>;\n  @group(0) @binding(4) var<storage, read_write> outputK: array<${o}>;\n  @group(0) @binding(5) var<storage, read_write> outputV: array<${o}>;\n\n  @compute @workgroup_size(${d}, ${d}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${a.x*a.y}u +\n          workgroup_id.y * ${a.x}u + workgroup_id.x) * ${d*d}u + local_index;\n\n    let batchIndex = workgroup_id.z / ${t.numHeads};\n    let headNumber = workgroup_id.z % ${t.numHeads};\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (M * K) + m * K;\n    let biasOffsetQ = headNumber * ${t.headSize};\n    let biasOffsetK = ${t.hiddenSize} + biasOffsetQ;\n    let biasOffsetV = ${t.hiddenSize} + biasOffsetK;\n\n    var valueQ = ${o}(0);\n    var valueK = ${o}(0);\n    var valueV = ${o}(0);\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m < M && w + local_id.x < K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < N && w + local_id.y < K) {\n        let offset = n + (w + local_id.y) * ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * N + n) % ${t.headSize};\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * M * N;\n    if (m < M && n < N) {\n      let outputIdx = offset + m * N + n;\n      outputQ[outputIdx] = valueQ;\n      outputK[outputIdx] = valueK;\n      outputV[outputIdx] = valueV;\n    }\n  }`,h=[e.inputs[0],e.inputs[1],e.inputs[2]];return e.compute({name:\"AttentionPrepare\",shaderCache:{hint:JSON.stringify(t)},getRunData:()=>({outputs:[{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0}],dispatchGroup:a}),getShaderSource:p},{inputs:h,outputs:[-1,-1,-1]})},ma=(e,t)=>{let r=$l(e.inputs,t),[o,n,s]=Il(e,r);return Vr(e,o,n,s,e.inputs[4],void 0,void 0,void 0,e.inputs[5],r,t)}});var Al,_l,ha,ga=F(()=>{\"use strict\";me();be();Al=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},_l=e=>{let t=e[0].dims,r=e[0].dims[2],o=z.size(t)/4,n=e[0].dataType,s=G(\"input\",n,t,4),u=G(\"bias\",n,[r],4),d=G(\"residual\",n,t,4),a=q(\"output\",n,t,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}}),getShaderSource:h=>`\n  const channels = ${r}u / 4;\n  ${h.declareVariables(s,u,d,a)}\n\n  ${h.mainStart()}\n    ${h.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n    let value = ${s.getByOffset(\"global_idx\")}\n      + ${u.getByOffset(\"global_idx % channels\")} + ${d.getByOffset(\"global_idx\")};\n    ${a.setByOffset(\"global_idx\",\"value\")}\n  }`}},ha=e=>{Al(e.inputs),e.compute(_l(e.inputs))}});var Tl,$e,ya,ba,wa,va,$a,Sa,xa,Ca,Ia,El,Aa,_a,Ta,Ea,Nr,Oa,Ur,ka,Pa,Ra,Ba,Ma,Da,za,Wa,Va,Na,Ua,Ha,Ga,La,Fa,ja,qa,Tn=F(()=>{\"use strict\";De();me();Ee();be();Tl=(e,t,r,o,n,s)=>{let u=Math.ceil(t/4),d=\"\";typeof n==\"string\"?d=`${n}(a)`:d=n(\"a\");let a=G(\"inputData\",r,[u],4),p=q(\"outputData\",o,[u],4);return`\n      ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(a,p)}\n\n  ${s??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n\n    let a = ${a.getByOffset(\"global_idx\")};\n    ${p.setByOffset(\"global_idx\",d)}\n  }`},$e=(e,t,r,o,n,s=e.dataType)=>({name:t,shaderCache:{hint:n,inputDependencies:[\"type\"]},getShaderSource:u=>Tl(u,z.size(e.dims),e.dataType,s,r,o),getRunData:u=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(z.size(u[0].dims)/64/4)},programUniforms:[{type:\"uint32\",data:Math.ceil(z.size(e.dims)/4)}]})}),ya=e=>{e.compute($e(e.inputs[0],\"Abs\",\"abs\"))},ba=e=>{e.compute($e(e.inputs[0],\"Acos\",\"acos\"))},wa=e=>{e.compute($e(e.inputs[0],\"Acosh\",\"acosh\"))},va=e=>{e.compute($e(e.inputs[0],\"Asin\",\"asin\"))},$a=e=>{e.compute($e(e.inputs[0],\"Asinh\",\"asinh\"))},Sa=e=>{e.compute($e(e.inputs[0],\"Atan\",\"atan\"))},xa=e=>{e.compute($e(e.inputs[0],\"Atanh\",\"atanh\"))},Ca=e=>re(e),Ia=(e,t)=>{let r;switch(t.to){case 10:r=\"vec4<f16>\";break;case 1:r=\"vec4<f32>\";break;case 12:r=\"vec4<u32>\";break;case 6:r=\"vec4<i32>\";break;case 9:r=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute($e(e.inputs[0],\"Cast\",r,void 0,t.cacheKey,t.to))},El=e=>{let t=e.length>=2?e[1].getFloat32Array()[0]:Mr,r=e.length>=3?e[2].getFloat32Array()[0]:Dr;return re({min:t,max:r})},Aa=(e,t)=>{let r=e.inputs.length===1?t:El(e.inputs),o=Ie(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Clip\",n=>`clamp(${n}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${o}> = vec4(${o}(${r.min}));\n    const clip_max_: vec4<${o}> = vec4(${o}(${r.max}));\n`,r.cacheKey),{inputs:[0]})},_a=e=>{e.compute($e(e.inputs[0],\"Ceil\",\"ceil\"))},Ta=e=>{e.compute($e(e.inputs[0],\"Cos\",\"cos\"))},Ea=e=>{e.compute($e(e.inputs[0],\"Cosh\",\"cosh\"))},Nr=e=>re(e),Oa=(e,t)=>{e.compute($e(e.inputs[0],\"Elu\",r=>`elu_vf32(${r})`,`\n  const elu_alpha_: f32 = f32(${t.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Ur=(e,t=\"f32\")=>`\nconst r0: ${t} = 0.3275911;\nconst r1: ${t} = 0.254829592;\nconst r2: ${t} = -0.284496736;\nconst r3: ${t} = 1.421413741;\nconst r4: ${t} = -1.453152027;\nconst r5: ${t} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,ka=e=>{let t=Ie(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Erf\",r=>`erf_vf32(${r})`,Ur(`vec4<${t}>`,t)))},Pa=e=>{e.compute($e(e.inputs[0],\"Exp\",\"exp\"))},Ra=e=>{e.compute($e(e.inputs[0],\"Floor\",\"floor\"))},Ba=e=>{let t=Ie(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Gelu\",r=>`0.5 * ${r} * (1.0 + erf_vf32(${r} * 0.7071067811865475))`,Ur(`vec4<${t}>`,t)))},Ma=(e,t)=>{e.compute($e(e.inputs[0],\"LeakyRelu\",r=>`select(leaky_relu_alpha_ * ${r}, ${r}, ${r} >= vec4<f32>(0.0))`,`const leaky_relu_alpha_: f32 = f32(${t.alpha});`,t.cacheKey))},Da=e=>{e.compute($e(e.inputs[0],\"Not\",t=>`!${t}`))},za=e=>{e.compute($e(e.inputs[0],\"Neg\",t=>`-${t}`))},Wa=e=>{e.compute($e(e.inputs[0],\"Reciprocal\",t=>`1.0/${t}`))},Va=e=>{e.compute($e(e.inputs[0],\"Relu\",t=>`select(vec4<f32>(0.0), ${t}, ${t} > vec4<f32>(0.0))`))},Na=e=>{e.compute($e(e.inputs[0],\"Sigmoid\",t=>`(1.0 / (1.0 + exp(-${t})))`))},Ua=e=>{e.compute($e(e.inputs[0],\"Sin\",\"sin\"))},Ha=e=>{e.compute($e(e.inputs[0],\"Sinh\",\"sinh\"))},Ga=e=>{e.compute($e(e.inputs[0],\"Sqrt\",\"sqrt\"))},La=e=>{e.compute($e(e.inputs[0],\"Tan\",\"tan\"))},Fa=e=>{e.compute($e(e.inputs[0],\"Tanh\",\"tanh\"))},ja=(e,t)=>(e.compute($e(e.inputs[0],\"ThresholdedRelu\",r=>`select(vec4<f32>(0.0), ${r}, ${r} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${t.alpha});`,t.cacheKey)),0),qa=e=>{e.compute($e(e.inputs[0],\"Log\",\"log\"))}});var kl,Pl,Ka,Ya=F(()=>{\"use strict\";me();be();Tn();kl=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},Pl=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let r=G(\"input\",e[0].dataType,e[0].dims,4),o=G(\"bias\",e[0].dataType,[e[0].dims[2]],4),n=q(\"output\",e[0].dataType,t,4),s=z.size(t)/4;return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:d=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${d.declareVariables(r,o,n)}\n\n  ${Ur(\"vec4f\")}\n\n  ${d.mainStart()}\n    ${d.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${n.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},Ka=e=>{kl(e.inputs),e.compute(Pl(e.inputs))}});var Rl,Bl,dt,Za,Xa,Qa,Ja,ei,ti,ri,ni,oi,ai,ii=F(()=>{\"use strict\";De();me();be();Rl=(e,t,r,o,n,s,u,d,a,p,h,v,y)=>{let b,w;typeof d==\"string\"?b=w=(E,W)=>`${d}((${E}),(${W}))`:typeof d==\"function\"?b=w=d:(b=d.scalar,w=d.vector);let S=v?t.length:t,C=v?r.length:r,A=v?o.length:o,I=q(\"outputData\",h,A,4),B=G(\"aData\",a,S,4),_=G(\"bData\",p,C,4),R;if(n)if(s){let E=z.size(t)===1,W=z.size(r)===1,V=t.length>0&&t[t.length-1]%4===0,Y=r.length>0&&r[r.length-1]%4===0;E||W?R=I.setByOffset(\"global_idx\",w(E?`${B.type.value}(${B.getByOffset(\"0\")}.x)`:B.getByOffset(\"global_idx\"),W?`${_.type.value}(${_.getByOffset(\"0\")}.x)`:_.getByOffset(\"global_idx\"))):R=`\n            let outputIndices = ${I.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = ${B.broadcastedIndicesToOffset(\"outputIndices\",I)};\n            let offsetB = ${_.broadcastedIndicesToOffset(\"outputIndices\",I)};\n            ${I.setByOffset(\"global_idx\",w(u||V?B.getByOffset(\"offsetA / 4u\"):`${B.type.value}(${B.getByOffset(\"offsetA / 4u\")}[offsetA % 4u])`,u||Y?_.getByOffset(\"offsetB / 4u\"):`${_.type.value}(${_.getByOffset(\"offsetB / 4u\")}[offsetB % 4u])`))}\n          `}else R=I.setByOffset(\"global_idx\",w(B.getByOffset(\"global_idx\"),_.getByOffset(\"global_idx\")));else{if(!s)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let E=(W,V,Y=\"\")=>{let ae=`aData[indexA${V}][componentA${V}]`,M=`bData[indexB${V}][componentB${V}]`;return`\n            let outputIndices${V} = ${I.offsetToIndices(`global_idx * 4u + ${V}u`)};\n            let offsetA${V} = ${B.broadcastedIndicesToOffset(`outputIndices${V}`,I)};\n            let offsetB${V} = ${_.broadcastedIndicesToOffset(`outputIndices${V}`,I)};\n            let indexA${V} = offsetA${V} / 4u;\n            let indexB${V} = offsetB${V} / 4u;\n            let componentA${V} = offsetA${V} % 4u;\n            let componentB${V} = offsetB${V} % 4u;\n            ${W}[${V}] = ${Y}(${b(ae,M)});\n          `};h===9?R=`\n            var data = vec4<u32>(0);\n            ${E(\"data\",0,\"u32\")}\n            ${E(\"data\",1,\"u32\")}\n            ${E(\"data\",2,\"u32\")}\n            ${E(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:R=`\n            ${E(\"outputData[global_idx]\",0)}\n            ${E(\"outputData[global_idx]\",1)}\n            ${E(\"outputData[global_idx]\",2)}\n            ${E(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(B,_,I)}\n\n        ${y??\"\"}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n        ${R}\n      }`},Bl=(e,t,r,o,n,s,u=r.dataType)=>{let d=!z.areEqual(r.dims,o.dims),a=r.dims,p=z.size(r.dims),h=!1,v=!1,y=[d];if(d){let w=at.calcShape(r.dims,o.dims,!1);if(!w)throw new Error(\"Can't perform binary op on the given tensors\");a=w,p=z.size(a);let S=z.size(r.dims)===1,C=z.size(o.dims)===1,A=r.dims.length>0&&r.dims[r.dims.length-1]%4===0,I=o.dims.length>0&&o.dims[o.dims.length-1]%4===0;y.push(S),y.push(C),y.push(A),y.push(I);let B=1;for(let _=1;_<a.length;_++){let R=r.dims[r.dims.length-_]??1,E=o.dims[o.dims.length-_]??1;if(R===E)B*=R;else break}B%4===0?(v=!0,h=!0):(S||C||A||I)&&(h=!0)}else h=!0;y.push(h);let b=Ge(r.dims.length)&&Ge(o.dims.length)&&Ge(a.length);return{name:e,shaderCache:{hint:t+y.map(w=>w.toString()).join(\"_\"),inputDependencies:b?[\"rank\",\"rank\"]:[\"dims\",\"dims\"]},getShaderSource:w=>Rl(w,r.dims,o.dims,a,h,d,v,n,r.dataType,o.dataType,u,b,s),getRunData:()=>({outputs:[{dims:a,dataType:u}],dispatchGroup:{x:Math.ceil(p/64/4)},programUniforms:b?[{type:\"uint32\",data:Math.ceil(z.size(a)/4)},...Ne(r.dims),...Ne(o.dims),...Ne(a)]:[{type:\"uint32\",data:Math.ceil(z.size(a)/4)}]})}},dt=(e,t,r,o,n,s)=>{e.compute(Bl(t,n??\"\",e.inputs[0],e.inputs[1],r,o,s))},Za=e=>{dt(e,\"Add\",(t,r)=>`${t}+${r}`)},Xa=e=>{dt(e,\"Div\",(t,r)=>`${t}/${r}`)},Qa=e=>{dt(e,\"Equal\",{scalar:(t,r)=>`u32(${t}==${r})`,vector:(t,r)=>`vec4<u32>(${t}==${r})`},void 0,void 0,9)},Ja=e=>{dt(e,\"Mul\",(t,r)=>`${t}*${r}`)},ei=e=>{let t=G(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;dt(e,\"Pow\",{scalar:(o,n)=>`pow_custom(${o},${n})`,vector:(o,n)=>`pow_vector_custom(${o},${n})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${t===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},ti=e=>{dt(e,\"Sub\",(t,r)=>`${t}-${r}`)},ri=e=>{dt(e,\"Greater\",{scalar:(t,r)=>`u32(${t}>${r})`,vector:(t,r)=>`vec4<u32>(${t}>${r})`},void 0,void 0,9)},ni=e=>{dt(e,\"Less\",{scalar:(t,r)=>`u32(${t}<${r})`,vector:(t,r)=>`vec4<u32>(${t}<${r})`},void 0,void 0,9)},oi=e=>{dt(e,\"GreaterOrEqual\",{scalar:(t,r)=>`u32(${t}>=${r})`,vector:(t,r)=>`vec4<u32>(${t}>=${r})`},void 0,void 0,9)},ai=e=>{dt(e,\"LessOrEqual\",{scalar:(t,r)=>`u32(${t}<=${r})`,vector:(t,r)=>`vec4<u32>(${t}<=${r})`},void 0,void 0,9)}});var Dl,zl,Wl,Vl,si,ui,li=F(()=>{\"use strict\";me();Ee();be();Dl=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let t=e[0].dataType,r=e[0].dims.length;for(let o of e){if(o.dataType!==t)throw new Error(\"input tensors should be one type\");if(o.dims.length!==r)throw new Error(\"input tensors should have the same shape\")}},zl=(e,t)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${t});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,Wl=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;++n){let s=t.setByOffset(\"global_idx\",e[n].getByIndices(\"indices\"));r===1?o.push(s):n===0?o.push(`if (inputIndex == ${n}u) { ${s} }`):n===r-1?o.push(`else { ${s} }`):o.push(`else if (inputIndex == ${n}) { ${s} }`)}return o.join(`\n`)},Vl=(e,t)=>{let r=e[0].dims.slice();if(t>=r.length||t<-1*r.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let o=t<0?r.length+t:t,n=r.slice(0);for(let _=1;_<e.length;_++){let R=e[_].dims.slice();for(let E=0;E<r.length;E++)if(E===o)n[o]+=R[E];else if(r[E]!==R[E])throw new Error(\"non concat dimensions must match\")}let s=z.size(n),u=new Array(e.length),d=new Array(e.length),a=e[0].dataType,p=0,h=[],v=[],y=[],b=[{type:\"uint32\",data:s}];for(let _=0;_<e.length;++_)p+=e[_].dims[o],u[_]=p,y.push(Ge(e[_].dims.length)),v.push(y[_]?e[_].dims.length:e[_].dims),d[_]=G(`input${_}`,a,v[_]),h.push(y[_]?\"rank\":\"dims\"),b.push({type:\"uint32\",data:u[_]});for(let _=0;_<e.length;++_)y[_]&&b.push(...Ne(e[_].dims));let w=Ge(n.length);w&&b.push(...Ne(n));let S=w?n.length:n,C=q(\"output\",a,S),A=C.indicesGet(\"indices\",o),I=Array.from(Array(u.length).keys()).map(_=>`uniforms.sizeInConcatAxis${_}`).join(\",\"),B=_=>`\n\n  ${(()=>{_.registerUniform(\"outputSize\",\"u32\");for(let R=0;R<e.length;R++)_.registerUniform(`sizeInConcatAxis${R}`,\"u32\");return _.declareVariables(...d,C)})()}\n\n  ${zl(u.length,I)}\n\n  ${_.mainStart()}\n    ${_.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n    var indices = ${C.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${A});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${u.length}u>(${I});\n      ${A} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${Wl(d,C)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${t}`,inputDependencies:h},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:b}),getShaderSource:B}},si=(e,t)=>{Dl(e.inputs),e.compute(Vl(e.inputs,t.axis))},ui=e=>re({axis:e.axis})});var vt,Hr,Et=F(()=>{\"use strict\";me();vt=(e,t)=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:`value = max(value, ${t}(0.0));`};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:`value = (${t}(1.0) / (${t}(1.0) + exp(-value)));`};case\"Clip\":return{activationFunction:`const clip_min_=${t}(${e.clipMin});const clip_max_=${t}(${e.clipMax});`,applyActivation:\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},Hr=e=>{let t=e?.activation||\"\";if(t===\"Clip\"){let[r,o]=e?.activation_params||[Mr,Dr];return{activation:t,clipMax:o,clipMin:r,activationCacheKey:`${t}:${r},${o}`}}return{activation:t,activationCacheKey:t}}});var ze,Gr,Lr=F(()=>{\"use strict\";ze=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},Gr=e=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      `});var Fr,En=F(()=>{\"use strict\";Fr=`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`});var Nl,Ul,sr,di,Hl,ur,Gl,jr,lr=F(()=>{\"use strict\";me();be();Et();Lr();Nl=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `,Ul=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${t===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,sr=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32)=>{let a=t[1]*e[1],p=t[0]*e[0],h=n?a:s,v=n?s:a,y=h/t[0],b=s/t[1];if(!((n&&y===4&&e[1]===4||!n&&(y===3||y===4))&&h%t[0]===0&&s%t[1]===0&&e[0]===4))throw new Error(`If transposeA ${n} is true, innerElementSize ${y} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${y} must be 3 or 4.\n  tileAWidth ${h} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${y}<${r}>, ${h/y}>, ${v}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${r}>, ${p/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${y};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${u?\"0\":\"i32(globalId.z)\"};\n  ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${a};\n\n  let numTiles = ${u?`${Math.ceil(d/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n  var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n  var acc: array<vec4<${r}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${b};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${Nl(n,o)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${b}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${o?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${y===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${Ul(n,y)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},di=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?\", batchIndices\":\"\"});\n            `,Hl=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",ur=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32,a=!1)=>{let p=e[1]*t[1],h=e[0]*t[0],v=n?p:s,y=n?s:p;if(!(y%t[1]===0&&v%t[0]===0&&s%t[1]===0))throw new Error(`tileAHight ${y} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${v} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);let b=y/t[1],w=v/t[0],S=s/t[1],C=a?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${p};\n    let globalColStart = i32(workgroupId.x) * ${h};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${y}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${v}; inputCol = inputCol + ${t[0]}) {\n          ${di(n,o)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${h}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${o?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${r}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${n?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${p};\n\nlet tileRowA = i32(localId.y) * ${b};\nlet tileColA = i32(localId.x) * ${w};\nlet tileRowB = i32(localId.y) * ${S};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${b}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${w}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${di(n,o)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${S}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${o?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${r}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${Hl(n)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${r}, ${v}>, ${y}>;\n  var<workgroup> mm_Bsub : array<array<${r}, ${h}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${u?\"0\":\"i32(globalId.z)\"};\n    ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${u?`${Math.ceil(d/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n    var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n    var acc : array<array<${r}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${C}\n  }\n`},Gl=(e,t,r,o,n,s=!1)=>{let u=n[0],d=n[1],a=n[2],p=o[0],h=o[1],v=o[2],y=o[3],b=Cn(u,a),w=Cn(d,a),S=Ie(o[0].type.tensor),C=()=>{let B=h.rank,_=p.rank,R=`var aIndices: ${h.type.indices};`;for(let E=B-2-1,W=_-1;E>=0;E--,W--)R+=`\naIndices[${E}] = ${_>1?`batchIndices[${W}]`:\"batchIndices\"};`;return b.forEach(E=>{R+=`\naIndices[${E}] = 0;`}),R+=`\naIndices[${B-2}] = u32(row);\n                   aIndices[${B-1}] = u32(colIn);`,R},A=()=>{let B=v.rank,_=p.rank,R=`var bIndices: ${v.type.indices};`;for(let E=B-2-1,W=_-1;E>=0;E--,W--)R+=`\nbIndices[${E}] = ${_>1?`batchIndices[${W}]`:\"batchIndices\"};`;return w.forEach(E=>{R+=`\nbIndices[${E}] = 0;`}),R+=`\nbIndices[${B-2}] = u32(row);\n                   bIndices[${B-1}] = u32(colIn);`,R};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${p.type.indices}) -> ${ze(e,S)} {\n      var value = ${ze(e,S)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${C()}\n        value = ${h.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${p.type.indices}) -> ${ze(e,S)} {\n      var value = ${ze(e,S)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${A()}\n        value = ${v.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${ze(e,S)}) {\n      let col = colIn * ${e};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${s?\"bias[colIn]\":`${ze(e,S)}(bias[row])`};`:\"\"}\n        ${r}\n        ${y.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},jr=(e,t,r,o,n=!1)=>{let s=e[0].dims,u=e[1].dims,d=s.slice(0,-2),a=u.slice(0,-2),p=o?o.slice(0,-2):r.slice(0,-2),h=G(\"batchDims\",e[0].dataType,p),v=[h],y=[d,a,p],b=z.size(p),w=s[s.length-2],S=s[s.length-1],C=u[u.length-1],A=S%4===0&&C%4===0,I=w<=8?[4,1,1]:[4,4,1],B=[8,8,1],_=[Math.ceil(C/B[0]/I[0]),Math.ceil(w/B[1]/I[1]),Math.ceil(b/B[2]/I[2])],R=Ie(e[0].dataType),E=A?4:1,W=G(\"a\",e[0].dataType,[...d,w,S/E],E),V=G(\"b\",e[1].dataType,[...a,S,C/E],E),Y=q(\"result\",e[0].dataType,[b,w,C/E],E);v.push(W),v.push(V),v.push(Y);let ae=[W,V],M=e.length>2,{activationFunction:K,applyActivation:Se}=vt(t,Y.type.value),ue=Gl(E,M,Se,v,y,n);if(M){let j=n?E:1;ae.push(G(\"bias\",e[2].dataType,e[2].dims,j))}let ve=j=>`\n  const dimAOuter: i32 = ${w};\n  const dimBOuter: i32 = ${C};\n  const dimInner: i32 = ${S};\n  ${j.declareVariables(...ae,Y)}\n  ${K}\n  ${ue}\n  ${A?sr(I,B,R,h):ur(I,B,R,h)}\n                   ${h.impl()}`;return{name:\"MatMul\",shaderCache:{hint:t.activationCacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:_[0],y:_[1],z:_[2]}}),getShaderSource:ve}}});var Ll,ci,pi=F(()=>{\"use strict\";wt();me();be();Et();Lr();En();lr();Ll=(e,t,r,o,n=!1,s,u=4,d=4,a=4,p=\"f32\")=>{let h=M=>{switch(M){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${p}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${M} is not supported.`)}},v=M=>{switch(M){case 1:return\"return w[row * wShape[3] + colIn];\";case 4:return\"return w[row * wShape[3] / 4 + colIn];\";default:throw new Error(`innerElementSize ${M} is not supported.`)}},y=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,b=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,w=e?\"xShape[1]\":\"xShape[2]\",S=e?\"xShape[2]\":\"xShape[3]\",C=e?\"row\":\"col\",A=e?\"col\":\"row\",I=`\n    let inChannels = wShape[2];\n    let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n    let outRow = ${C} / outWidth;\n    let outCol = ${C} % outWidth;\n\n    let WRow = ${A} / (filterDims[1] * inChannels);\n    let WCol = ${A} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${A} % inChannels;\n    var resData = ${ze(u,p)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${w} && xCol >= 0 && xCol < ${S}) {\n      ${y}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${h(u)}\n    }\n    return resData;`,B=e?t&&o?`\n    let col = colIn * ${u};\n    ${I}`:`\n    let col = colIn * ${u};\n    if (row < dimAOuter && col < dimInner) {\n      ${I}\n    }\n    return ${ze(u,p)}(0.0);`:o&&r?`\n    let col = colIn * ${u};\n    ${I}`:`\n    let col = colIn * ${u};\n    if (row < dimInner && col < dimBOuter) {\n      ${I}\n    }\n    return ${ze(u,p)}(0.0);`,_=`${v(d)}`,R=ze(a,p),E=e?ze(u,p):ze(d,p),W=e?ze(d,p):ze(u,p),{activationFunction:V,applyActivation:Y}=vt(s,R);return`\n    ${V}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${E} {\n      ${e?B:_}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${W} {\n      ${e?_:B}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${R}) {\n      let col = colIn * ${a};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${b}\n      ${Gr(n)}\n      ${Y}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},ci=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",p=a?e[0].dims[3]:e[0].dims[1],h=r[0],v=a?r[2]:r[3],y=a?r[1]:r[2],b=a?r[3]:r[1],w=a&&(p%4===0||p%3===0)&&b%4===0,S=a?b:v*y,C=a?v*y:b,A=[8,8,1],I=o<=8?[4,1,1]:[4,4,1],B=[Math.ceil(S/A[0]/I[0]),Math.ceil(C/A[1]/I[1]),Math.ceil(h/A[2]/I[2])];Te(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${B}`);let _=w?a&&p%4!==0?3:4:I[0],R=A[1]*I[1],E=A[0]*I[0],W=Math.max(A[0]*_,A[1]),V=o%R===0,Y=n%E===0,ae=s%W===0,M=w?[_,4,4]:[1,1,1],K=Ie(e[0].dataType),Se=[`@group(0) @binding(0) var<storage, read> x: array<${w&&_===4?`vec4<${K}>`:K}>;`,`@group(0) @binding(1) var<storage, read> w: array<${w?`vec4<${K}>`:K}>;`],ue=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${w?`vec4<${K}>`:K}) {\n        result[flatIndex] = ${w?`vec4<${K}>`:K}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${w?`vec4<${K}>`:K}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${w?\"/ 4\":\"\"}, value);\n      }`;return u&&(Se.push(`@group(0) @binding(2) var<storage, read> bias: array<${w?`vec4<${K}>`:K}>;`),ue+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${w?`vec4<${K}>`:K} {\n          return bias[coords.${a?\"w\":\"y\"}${w?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:B[0],y:B[1],z:B[2]}}),getShaderSource:()=>`\n        ${Fr}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${Se.join(\"\")}\n        @group(0) @binding(${Se.length}) var<storage, read_write> result: array<${w?`vec4<${K}>`:K}>;\n        //@group(0) @binding(${Se.length+1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${z.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[0]}, ${t.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${t.pads[0]}, ${t.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${n};\n        const dimInner : i32 = ${s};\n        ${ue}\n        ${Ll(a,V,Y,ae,u,t,M[0],M[1],M[2],K)}\n            ${w?sr(I,A,K,void 0,!a,W):ur(I,A,K,void 0,!a,W,!1,void 0,d)}`}}});var On,fi=F(()=>{\"use strict\";me();be();Pn();Et();On=(e,t,r)=>{let o=e.length>2,n=o?\"value += b[output_channel];\":\"\",s=e[0].dims,u=e[1].dims,d=u[0]/t.group,a=t.format===\"NHWC\",p=kn(s,u,t.dilations,t.pads,t.strides,a),h=z.size(p),v=q(\"output\",e[0].dataType,p),{activationFunction:y,applyActivation:b}=vt(t,v.type.value),w=G(\"x\",e[0].dataType,s),S=G(\"w\",e[1].dataType,u),C=[w,S];o&&C.push(G(\"b\",e[2].dataType,e[2].dims));let A=I=>`\n  const strides: vec2<u32> = vec2(${t.strides[0]}u, ${t.strides[1]}u);\n  const pads: vec2<u32> = vec2(${t.pads[0]}u, ${t.pads[1]}u);\n\n  ${I.declareVariables(...C,v)}\n\n  ${y}\n\n  ${I.mainStart()}\n    ${I.guardAgainstOutOfBoundsWorkgroupSizes(h)}\n\n    let outputIndices = ${v.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${a?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${a?1:2}], outputIndices[${a?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${d}u;\n\n    var value: ${v.type.value} = ${v.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${u[1]}u; wInChannel++) {\n      let input_channel = group_id * ${u[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${u[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${t.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${s[a?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${u[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${t.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${s[a?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${a?w.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):w.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${S.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${n}\n    ${b}\n    ${v.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r?r(p):p,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(h/64)}}),getShaderSource:A}}});var kn,mi,Fl,hi,Rn,jl,ql,Bn,Pn=F(()=>{\"use strict\";me();Ee();pi();lr();fi();Et();Wt();kn=(e,t,r,o,n,s)=>{let u=e[0],d=e.slice(s?1:2,s?3:4),a=d.length,p=t[0],v=t.slice(2).map((w,S)=>w+(w-1)*(r[S]-1)),b=d.map((w,S)=>w+o[S]+o[S+a]).map((w,S)=>Math.floor((w-v[S]+n[S])/n[S]));return b.splice(0,0,u),b.splice(s?3:1,0,p),b},mi=[2,3,1,0],Fl=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[1]*t.group;if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let n=e[0].dims.length-2;if(t.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(t.strides.length!==n)throw new Error(`strides should be ${n}D`);if(t.pads.length!==n*2)throw new Error(`pads should be ${n*2}D`);if(t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},hi=(e,t)=>{let r=e.kernelShape.slice();for(let s=2;s<t[1].dims.length;++s)r[s-2]===0&&(r[s-2]=t[1].dims[s]);let o=e.pads.slice();Tt.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,r,o,e.format===\"NHWC\",e.autoPad);let n=Object.assign({},e);return Object.assign(n,{kernelShape:r,pads:o,cacheKey:e.cacheKey}),n},Rn=e=>{let t=Hr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],n=e.dilations,s=e.group,u=e.kernel_shape,d=e.pads,a=e.strides,p=e.w_is_const();return re({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,pads:d,strides:a,wIsConst:p,...t})},jl=(e,t,r)=>{let o=hi(r,t);if(r.group!==1){e.compute(On(t,o));return}let n=r.format===\"NHWC\",s=t.length===3,u=t[0].dims[n?1:2],d=t[0].dims[n?2:3],a=t[0].dims[n?3:1],p=t[1].dims[2],h=t[1].dims[3],v=kn(t[0].dims,t[1].dims,r.dilations,o.pads,r.strides,n),y=v[n?1:2],b=v[n?2:3],w=v[n?3:1],S=n&&p===u&&h===d&&r.pads[0]===0&&r.pads[1]===0;if(S||p===1&&h===1&&r.dilations[0]===1&&r.dilations[1]===1&&r.strides[0]===1&&r.strides[1]===1&&r.pads[0]===0&&r.pads[1]===0){let E=v[0],W,V,Y,ae=[];if(n){let M=e.kernelCustomData.wT??e.compute(et(t[1],mi),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];if(r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=M),S){let K=u*d*a;W=t[0].reshape([1,E,K]),V=M.reshape([1,K,w]),Y=[1,E,w]}else W=t[0].reshape([E,u*d,a]),V=M.reshape([1,a,w]),Y=[E,y*b,w];ae.push(W),ae.push(V)}else W=t[0].reshape([E,a,u*d]),V=t[1].reshape([1,w,a]),Y=[E,w,y*b],ae.push(V),ae.push(W);s&&ae.push(t[2]),e.compute(jr(ae,o,v,Y,n),{inputs:ae});return}let C=!0,A=e.kernelCustomData.wT??e.compute(et(t[1],mi),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=A);let I=[t[0],A];s&&I.push(t[2]);let B=n?y*b:w,_=n?w:y*b,R=p*h*a;e.compute(ci(I,o,v,B,_,R,s,C),{inputs:I})},ql=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&o.push(e.inputs[2]);let n=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),u=[1].concat(t.dilations),d=[1].concat(t.kernelShape),a=hi({...t,pads:n,strides:s,dilations:u,kernelShape:d},o);e.compute(On(o,a,p=>r?[p[0],p[2],p[3]]:[]))},Bn=(e,t)=>{Fl(e.inputs,t),e.inputs[0].dims.length===3?ql(e,t):jl(e,e.inputs,t)}});var Kl,gi,yi=F(()=>{\"use strict\";wt();me();Et();Lr();En();lr();Kl=(e,t=!1,r,o=4)=>{let n=ze(o,\"f32\"),s=I=>{switch(I){case 1:return\"return W[getIndexFromCoords4D(coord, wShape)];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${I} is not supported.`)}},u=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,d=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,a=e?\"outBackprop[1]\":\"outBackprop[2]\",p=e?\"outBackprop[2]\":\"outBackprop[3]\",h=e?\"row\":\"col\",v=e?\"col\":\"row\",y=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      let outRow = ${h} / outWidth;\n      let outCol = ${h} % outWidth;\n\n      let WRow = ${v} / (filterDims[1] * inChannels);\n      let WCol = ${v} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${a}) || fract(xR) > 0.0) {\n        return ${n}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${p}) || fract(xC) > 0.0) {\n        return ${n}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${v} % inChannels;\n      ${u}\n      return x[getIndexFromCoords4D(coord, xShape)/${o}];`,b=e?`\n      let col = colIn * ${o};\n      if (row < dimAOuter && col < dimInner) {\n        ${y}\n      }\n      return ${n}(0.0);`:`\n      let col = colIn * ${o};\n      if (row < dimInner && col < dimBOuter) {\n        ${y}\n      }\n      return ${n}(0.0);`,w=`\n      let col = colIn * ${o};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < dimInner && col < dimBOuter\":\"row < dimInner && col < dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${s(o)}\n      }\n      return ${n}(0.0);\n      `,{activationFunction:S,applyActivation:C}=vt(r,n);return`\n      ${S}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${n} {\n    ${e?b:w}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${n} {\n    ${e?w:b}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${n}) {\n    let col = colIn * ${o};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${d}\n      ${Gr(t)}\n      ${C}\n      result[getIndexFromCoords4D(coords, outShape)/${o}] = value;\n    }\n  }`},gi=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",p=a?e[0].dims[3]:e[0].dims[1],h=r[0],v=a?r[2]:r[3],y=a?r[1]:r[2],b=a?r[3]:r[1],w=a?p%4===0&&b%4===0:v%4===0&&b%4===0,S=a?b:v*y,C=a?v*y:b,A=w?[8,8,1]:[S<=4||C<=4?4:16,S>4&&C<=4?4:16,1],I=w?[4,4,1]:[S<=4?1:4,S>4&&C<=4?1:4,1],B=[Math.ceil(S/A[0]/I[0]),Math.ceil(C/A[1]/I[1]),Math.ceil(h/A[2]/I[2])];Te(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${B}`);let _=w?4:1,R=Math.max(A[0]*_,A[1]),E=[`@group(0) @binding(0) var<storage, read> x: array<${w?\"vec4<f32>\":\"f32\"}>;`,\"@group(0) @binding(1) var<storage, read> W: array<f32>;\"],W=\"\";return u&&(E.push(`@group(0) @binding(2) var<storage, read> bias: array<${w?\"vec4<f32>\":\"f32\"}>;`),W+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${w?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${a?\"w\":\"y\"}${w?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:B[0],y:B[1],z:B[2]}}),getShaderSource:()=>`\n        ${Fr}\n        ${E.join(`\n`)}\n        @group(0) @binding(${E.length}) var<storage, read_write> result: array<${w?\"vec4<f32>\":\"f32\"}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${z.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[a?1:2]}, ${t.kernelShape[a?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${t.dilations[0]<=1?0:(t.kernelShape[a?1:2]-1)*(t.dilations[0]-1)},\n              ${t.dilations[1]<=1?0:(t.kernelShape[a?2:3]-1)*(t.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${n};\n        const dimInner : i32 = ${s};\n        ${W}\n        ${Kl(a,u,t,_)}\n        ${w?sr(I,A,\"f32\",void 0,!a,R):ur(I,A,\"f32\",void 0,!a,R,!1,void 0,d)}`}}});var Yl,Mn,bi=F(()=>{\"use strict\";wt();me();be();Yl=(e,t,r,o,n,s,u=!1,d)=>{let a=r.format===\"NHWC\",p=a?1:2,h=a?2:3,v=a?3:1,y=z.size(o),b=u?2:1,w=r.group,S=t[1].dims,C=S[0]/w,A=S[1],I=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${u?`vec4<${d}>`:d}) {\n    result[flatIndex] = ${u?`vec4<${d}>`:d}(value);\n  }`;n&&(I+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${u?`vec4<${d}>`:d} {\n      return bias[coords.${a?\"w\":\"y\"}${u?\"/ 4\":\"\"}];\n    }`);let B=u?4:1,_=G(\"W\",t[1].dataType,t[1].dims,B),R=G(\"Dy\",t[0].dataType,t[0].dims,B),E=[R,_];n&&E.push(G(\"bias\",t[2].dataType,[o[v]],B));let W=q(\"result\",t[0].dataType,o,B),V=`{\n        let batch: u32 = ${s?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${s?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${s?\"global_id.y\":\"workgroup_id.y\"} * ${b};\n        let d1: u32 = ${s?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${d}>, ${b}>;\n        for (var i = 0; i < ${b}; i++) {\n          dotProd[i] = vec4<${d}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${d}(dyCorner.x) + ${d}(wR)) / ${d}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${d}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${d}(dyCorner.y) + ${d}(wC)) / ${d}(strides.y);\n            let dyC2 = (${d}(dyCorner.y) + 1.0 + ${d}(wC)) / ${d}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${d}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${d}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${R.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${R.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${d}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${v}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${R.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${_.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${R.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${b}; i = i + 1) {\n          let value = dotProd[i] + ${n?\"bias[c+i]\":\"0.0\"};\n          ${W.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,Y=`\n          let outputIndices = ${W.offsetToIndices(\"global_idx\")};\n          let batch = ${W.indicesGet(\"outputIndices\",0)};\n          let d1 = ${W.indicesGet(\"outputIndices\",v)};\n          let r = ${W.indicesGet(\"outputIndices\",p)};\n          let c = ${W.indicesGet(\"outputIndices\",h)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${A};\n          let wOutChannel = d1 - groupId * ${A};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${d}(dyRCorner) + ${d}(wR)) / ${d}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${d}(outBackprop[${p}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${d}(dyCCorner) + ${d}(wC)) / ${d}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${d}(outBackprop[${h}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${C};\n              for (var d2: u32 = 0; d2 < ${C}; d2 = d2 + 1) {\n                let xValue = ${a?R.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):R.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${_.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${n?\"bias[d1]\":\"0.0\"};\n          ${W.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(...E,W)}\n  ${I}\n  const outShape : vec4<u32> = vec4<u32>(${o.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${t[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${r.strides[0]}, ${r.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${r.kernelShape[a?1:2]}, ${r.kernelShape[a?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${r.dilations[0]}, ${r.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${r.dilations[0]<=1?0:(r.kernelShape[a?1:2]-1)*(r.dilations[0]-1)},\n          ${r.dilations[1]<=1?0:(r.kernelShape[a?2:3]-1)*(r.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(y)};\n  ${u?V:Y}}`},Mn=(e,t,r)=>{let o=e.length>2,n=t.outputShape,s=z.size(n),u=[Math.ceil(s/64),1,1];Te(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${u}`);let d=Ie(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:t.cacheKey},getRunData:()=>({dispatchGroup:{x:u[0],y:u[1],z:u[2]},outputs:[{dims:r?r(n):n,dataType:e[0].dataType}]}),getShaderSource:a=>Yl(a,e,t,n,o,u[1]===1&&u[2]===1,!1,d)}}});var Zl,Xl,Ql,wi,vi,Jl,ed,td,rd,$i,Si=F(()=>{\"use strict\";Ee();yi();bi();Et();Wt();Zl=(e,t,r,o,n,s)=>(e-1)*t+r+(o-1)*n+1-s,Xl=(e,t,r,o,n)=>{let s=Math.floor(e/2);t===\"SAME_UPPER\"?(r[o]=s,r[n]=e-s):t===\"SAME_LOWER\"&&(r[o]=e-s,r[n]=s)},Ql=(e,t,r,o,n,s,u,d,a,p)=>{let h=e.length-2,v=p.length===0;if(a.length===0)for(let w=0;w<h;++w)a.push(0);let y=e[0],b=t[d?3:1]*n;for(let w=0,S=e.length-h-(d?1:0);w<h;++w,++S){let C=e[S],A=v?C*u[w]:p[w],I=Zl(C,u[w],s[w],t[S],r[w],A);Xl(I,o,s,w,w+h),v&&p.push(u[w]*(C-1)+a[w]+(t[S]-1)*r[w]+1-s[w]-s[w+h])}p.splice(0,0,y),p.splice(d?3:1,0,b)},wi=(e,t)=>{let r=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((y,b)=>y*b,1)===0){r.length=0;for(let y=2;y<t[1].dims.length;++y)r.push(t[1].dims[y])}let o=e.format===\"NHWC\";r.splice(0,0,t[1].dims[0]),r.splice(o?3:1,0,t[1].dims[1]);let n=e.pads.slice(),s=e.outputShape.slice(),u=e.outputPadding.slice(),d=t[0].dims,a=e.dilations.slice();if(a.reduce((y,b)=>y+b,0)===0){let y=t[0].dims.length-2;a=new Array(y).fill(1)}let p=e.strides.slice();if(p.reduce((y,b)=>y+b,0)===0){let y=t[0].dims.length-2;p=new Array(y).fill(1)}Ql(d,r,a,e.autoPad,e.group,n,p,o,u,s);let h=Object.assign({},e),v=e.cacheKey+[r.join(\"n,\"),n.join(\",\"),p.join(\",\"),u.join(\",\"),s.join(\",\"),a.join(\",\")].join(\"_\");return Object.assign(h,{kernelShape:r,pads:n,outputPadding:u,outputShape:s,dilations:a,strides:p,cacheKey:v}),h},vi=e=>{let t=Hr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],n=e.dilations,s=e.group,u=e.kernelShape,d=e.pads,a=e.strides,p=e.wIsConst(),h=e.outputPadding,v=e.outputShape;return re({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,outputPadding:h,outputShape:v,pads:d,strides:a,wIsConst:p,...t})},Jl=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[0];if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let n=e[1].dims[1]*t.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==n))throw new Error(\"invalid bias\");let s=e[0].dims.length-2;if(t.dilations.reduce((h,v)=>h+v,0)>0&&t.dilations.length!==s)throw new Error(`dilations should be ${s}D`);if(t.strides.reduce((h,v)=>h+v,0)>0&&t.strides.length!==s)throw new Error(`strides should be ${s}D`);if(t.pads.reduce((h,v)=>h+v,0)>0&&t.pads.length!==s*2)throw new Error(`pads should be ${s*2}D`);if(t.outputPadding.length!==s&&t.outputPadding.length!==0)throw new Error(`output_padding should be ${s}D`);if(t.kernelShape.reduce((h,v)=>h+v,0)>0&&t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(t.outputShape.length!==0&&t.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},ed=[2,3,1,0],td=(e,t,r)=>{let o=wi(r,t),n=r.format===\"NHWC\",s=t.length===3;if(o.group!==1){e.compute(Mn(t,o));return}let u=o.outputShape,d=u[n?1:2],a=u[n?2:3],p=u[n?3:1],h=t[1].dims[2],v=t[1].dims[3],y=t[0].dims[n?3:1],b=n?d*a:p,w=n?p:d*a,S=h*v*y,C=!0,A=e.kernelCustomData.wT??e.compute(et(t[1],ed),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=A);let I=[t[0],A];s&&(!n&&t[2].dims.length===1?I.push(t[2].reshape([t[2].dims[0],1,1])):I.push(t[2])),e.compute(gi(I,o,u,b,w,S,s,C),{inputs:I})},rd=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];o.length===3&&o.push(e.inputs[2]);let n=t.kernelShape;(n.length===0||n[0]===0)&&(n=[e.inputs[1].dims[2]]);let s=t.dilations;(s.length===0||s[0]===0)&&(s=[1]);let u=t.strides;(u.length===0||u[0]===0)&&(u=[1]);let d=t.pads;d.length===0&&(d=[0,0]),d=[0,d[0],0,d[1]],u=[1].concat(u),s=[1].concat(s),n=[1].concat(n);let a=wi({...t,pads:d,strides:u,dilations:s,kernelShape:n},o);e.compute(Mn(o,a,p=>r?[p[0],p[2],p[3]]:[p[0],p[1],p[3]]))},$i=(e,t)=>{Jl(e.inputs,t),e.inputs[0].dims.length===3?rd(e,t):td(e,e.inputs,t)}});var Dn,qr,xi,nd,od,zn,Wn,ad,Ci,Ii,Ai=F(()=>{\"use strict\";me();Ee();be();Dn=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",qr=\"(\"+Dn+\")+\",xi=\"^\"+qr+\"$\",nd=\"(\"+qr+\",)*\"+qr,od=\"^\"+nd+\"$\",zn=class{constructor(t=-1){this.symbolToIndices=new Map,this.inputIndex=t}addSymbol(t,r){let o=this.symbolToIndices.get(t);o===void 0?o=[r]:o.push(r),this.symbolToIndices.set(t,o)}},Wn=class{constructor(t,r){this.equation=r;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[o,n]=r.includes(\"->\")?r.split(\"->\",2):[r,\"\"];if(!o.match(RegExp(od)))throw new Error(\"Invalid LHS term\");if(o.split(\",\").forEach((d,a)=>{let p=t[a].dims.slice();if(!d.match(RegExp(xi)))throw new Error(\"Invalid LHS term\");let h=this.processTerm(d,!0,p,a);this.lhs.push(h)}),n===\"\")n+=[...this.symbolToInfo.entries()].filter(([d,a])=>a.count===1||d===\"...\").map(([d])=>d).join(\"\");else if(!n.match(RegExp(qr)))throw new Error(\"Invalid RHS\");n.match(RegExp(Dn,\"g\"))?.forEach(d=>{if(d===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let a=this.symbolToInfo.get(d);if(a===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(a.dimValue)}}),this.rhs=this.processTerm(n,!0,this.outputDims)}addSymbol(t,r,o){let n=this.symbolToInfo.get(t);if(n!==void 0){if(n.dimValue!==r&&n.count!==1)throw new Error(\"Dimension mismatch\");n.count++,n.inputIndices.push(o)}else n={count:1,dimValue:r,inputIndices:[o]};this.symbolToInfo.set(t,n)}processTerm(t,r,o,n=-1){let s=o.length,u=!1,d=[],a=0;if(!t.match(RegExp(xi))&&!r&&t!==\"\")throw new Error(\"Invalid LHS term\");let p=t.match(RegExp(Dn,\"g\")),h=new zn(n);return p?.forEach((v,y)=>{if(v===\"...\"){if(u)throw new Error(\"Only one ellipsis is allowed per input term\");u=!0;let b=s-p.length+1;if(b<0)throw new Error(\"Ellipsis out of bounds\");if(d=o.slice(a,a+b),this.hasEllipsis){if(this.ellipsisDims.length!==d.length||this.ellipsisDims.toString()!==d.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(r)this.hasEllipsis=!0,this.ellipsisDims=d;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let w=0;w<d.length;w++){let S=String.fromCharCode(\"0\".charCodeAt(0)+y);h.addSymbol(S,y+w),this.addSymbol(S,o[a++],n)}}else h.addSymbol(v,y),this.addSymbol(v,o[a++],n)}),h}},ad=(e,t)=>{let r=e[0].dataType,o=new Array(e.length);for(let B=0;B<e.length;++B)o[B]=G(`input${B}`,r,e[B].dims);let n=t.outputDims,s=z.size(n),u=q(\"output\",r,n),d=[],a=Array.from(t.rhs.symbolToIndices.keys()),p=\"var prod = 1.0;\",h=\"var sum = 0.0;\",v=\"sum += prod;\",y=[],b=[],w=[],S=[],C=t.symbolToInfo.size===a.length;t.symbolToInfo.forEach((B,_)=>{if(a.includes(_)){let R=a.indexOf(_);t.lhs.forEach((E,W)=>{if(B.inputIndices.includes(W)){let V=E.symbolToIndices.get(_);if(V===void 0)throw new Error(\"Invalid symbol error\");V.forEach(Y=>{d.push(`${o[W].indicesSet(`input${W}Indices`,Y,u.indicesGet(\"outputIndices\",R))}`)})}})}else t.lhs.forEach((R,E)=>{let W=t.symbolToInfo.get(_);if(W===void 0)throw new Error(\"Invalid symbol error\");if(W.inputIndices.includes(E)){let V=R.symbolToIndices.get(_);if(V===void 0)throw new Error(\"Invalid symbol error\");V.forEach(Y=>{y.push(`${o[E].indicesSet(`input${E}Indices`,Y,`${_}`)}`)}),S.push(`prod *= ${o[E].getByIndices(`input${E}Indices`)};`)}}),b.push(`for(var ${_}: u32 = 0; ${_} < ${t.symbolToInfo.get(_)?.dimValue}; ${_}++) {`),w.push(\"}\")});let A=C?[...d,`let sum = ${o.map((B,_)=>B.getByIndices(`input${_}Indices`)).join(\" * \")};`]:[...d,h,...b,...y,p,...S,v,...w],I=B=>`\n      ${B.declareVariables(...o,u)}\n\n      ${B.mainStart()}\n        ${B.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n        var outputIndices = ${u.offsetToIndices(\"global_idx\")};\n        ${o.map((_,R)=>`var input${R}Indices: ${o[R].type.indices};`).join(`\n`)}\n        ${A.join(`\n`)};\n        ${u.setByOffset(\"global_idx\",\"sum\")};\n      }`;return{name:\"Einsum\",shaderCache:{hint:t.equation},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:I}},Ci=(e,t)=>{let r=new Wn(e.inputs,t.equation);e.compute(ad(e.inputs,r))},Ii=e=>{let t=e.equation.replace(/\\s+/g,\"\");return re({equation:t})}});var id,_i,sd,ud,Ti,Ei=F(()=>{\"use strict\";me();be();id=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=r.length<t.length?0:r.length-t.length,n=t.length<r.length?0:t.length-r.length;for(;o<r.length&&n<t.length;++o,++n)if(r[o]!==t[n]&&r[o]!==1&&t[n]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},_i=(e,t)=>{let r=e.length-t.length,o=[];for(let n=0;n<r;++n)o.push(e[n]);for(let n=0;n<t.length;++n)o.push(t[n]===1?e[n+r]:t[n]);return o},sd=(e,t)=>e.length>t.length?_i(e,t):_i(t,e),ud=e=>{let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=sd(t,r),n=z.size(o),s=e[0].dataType,u=G(\"input\",s,t),d=q(\"output\",s,o),a=p=>`\n  const inputShape = ${u.indices(...t)};\n  ${p.declareVariables(u,d)}\n  ${p.mainStart()}\n  ${p.guardAgainstOutOfBoundsWorkgroupSizes(n)}\n    let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n    var inputIndices: ${u.type.indices};\n    for (var i = 0; i < ${t.length}; i++) {\n      if (${u.indicesGet(\"inputShape\",\"i\")} == 1) {\n        ${u.indicesSet(\"inputIndices\",\"i\",0)}\n      } else {\n        ${u.indicesSet(\"inputIndices\",\"i\",d.indicesGet(\"outputIndices\",`i + ${o.length-t.length}`))}\n      }\n    }\n    ${d.setByOffset(\"global_idx\",u.getByIndices(\"inputIndices\"))}\n  }`;return{name:\"Expand\",shaderCache:{hint:`${o}`},getShaderSource:a,getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(n/64)}})}},Ti=e=>{id(e.inputs),e.compute(ud(e.inputs),{inputs:[0]})}});var ld,dd,Oi,ki,Pi=F(()=>{\"use strict\";me();Ee();be();ld=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},dd=(e,t)=>{let r=e[0].dims,o=e[1].dims,n=r.length,s=z.normalizeAxis(t.axis,n),u=r.slice(0);u.splice(s,1,...o);let d=r[s],a=z.size(u),p=Ge(e[0].dims.length),h=p?e[0].dims.length:e[0].dims,v=Ge(e[1].dims.length),y=v?e[1].dims.length:e[1].dims,b=Ge(u.length),w=b?u.length:u,S=G(\"data\",e[0].dataType,h),C=G(\"inputIndices\",e[1].dataType,y),A=q(\"output\",e[0].dataType,w),I=[{type:\"uint32\",data:a},{type:\"int32\",data:d},{type:\"uint32\",data:s}];p&&I.push(...Ne(e[0].dims)),v&&I.push(...Ne(e[1].dims)),b&&I.push(...Ne(u));let B=[];B.push(p?\"rank\":\"dims\"),B.push(v?\"rank\":\"dims\");let _=()=>{let E=o.length,W=`var indicesIndices  = ${C.type.indices}(0);`;for(let V=0;V<E;V++)W+=`${E>1?`indicesIndices[${V}]`:\"indicesIndices\"} = ${u.length>1?`outputIndices[uniforms.axis + ${V}]`:\"outputIndices\"};`;W+=`\n        var idx = ${C.getByIndices(\"indicesIndices\")};\n        if (idx < 0) {\n          idx = idx + uniforms.axisDimLimit;\n        }\n        var dataIndices = ${S.type.indices}(0);\n      `;for(let V=0,Y=0;V<n;V++)V===s?(W+=`${n>1?`dataIndices[${V}]`:\"dataIndices\"} = u32(idx);`,Y+=E):(W+=`${n>1?`dataIndices[${V}]`:\"dataIndices\"} = ${u.length>1?`outputIndices[${Y}]`:\"outputIndices\"};`,Y++);return W},R=E=>`\n      ${E.registerUniform(\"outputSize\",\"u32\").registerUniform(\"axisDimLimit\",\"i32\").registerUniform(\"axis\",\"u32\").declareVariables(S,C,A)}\n      ${E.mainStart()}\n        ${E.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n        let outputIndices = ${A.offsetToIndices(\"global_idx\")};\n        ${_()};\n        let value = ${S.getByIndices(\"dataIndices\")};\n        ${A.setByOffset(\"global_idx\",\"value\")};\n      }`;return{name:\"Gather\",shaderCache:{hint:t.cacheKey,inputDependencies:B},getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:I}),getShaderSource:R}},Oi=e=>re({axis:e.axis}),ki=(e,t)=>{let r=e.inputs;ld(r),e.compute(dd(e.inputs,t))}});var cd,pd,Ri,Bi,Mi=F(()=>{\"use strict\";me();Ee();be();cd=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},pd=(e,t)=>{let r=e[0].dims,o=e[0].dataType,n=r.length,s=z.computeStrides(r),u=z.size(r),d=e[1].dims,a=e[1].dataType,p=z.size(d),h=z.normalizeAxis(t.axis,n),v=r[h],y=d.slice(0),b=z.size(y),w=G(\"input\",o,r),S=G(\"indices\",a,[p]),C=q(\"output\",o,y),A=I=>`\n      const inputStrides = array<u32, ${s.length}>(${s.map(B=>`${B}u`).join(\",\")});\n      ${I.declareVariables(w,S,C)}\n      ${I.mainStart()}\n      ${I.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n      let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n\n      var idx = ${S.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + ${v};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${r.length}; i++) {\n        if (i == ${h}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${C.indicesGet(\"outputIndices\",\"i\")} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${u}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;return{name:\"GatherElements\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:y,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(b/64)}}),getShaderSource:A}},Ri=e=>re({axis:e.axis}),Bi=(e,t)=>{let r=e.inputs;cd(r),e.compute(pd(e.inputs,t))}});var fd,md,hd,Di,zi,Wi=F(()=>{\"use strict\";me();Ee();be();fd=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},md=(e,t,r)=>{if(r.length===0)return\"0u\";let o=r.length===1&&e!==1||r.length===2&&r[0]!==e,n=r[r.length-1]!==t,s=\"0u\";return o||(s+=`+ m * ${r[r.length-1]}u`),n||(s+=\"+n\"),s},hd=(e,t)=>{let r=e[0].dims.slice(),o=e[1].dims.slice(),[n,s,u]=Br.getShapeOfGemmResult(r,t.transA,o,t.transB,e.length===3?e[2].dims:void 0),d=[n,s];if(!d)throw new Error(\"Can't use gemm on the given tensors\");let a=z.size(d),p=\"\";t.transA&&t.transB?p=\"value += a[k * M + m] * b[n * K + k];\":t.transA&&!t.transB?p=\"value += a[k * M + m] * b[k * N + n];\":!t.transA&&t.transB?p=\"value += a[m * K + k] * b[n * K + k];\":!t.transA&&!t.transB&&(p=\"value += a[m * K + k] * b[k * N + n];\");let h=Ie(e[0].dataType),v=t.alpha===1?\"\":\"value *= alpha;\",y=e.length===3?`value += beta * c[${md(n,s,e[2].dims)}];`:\"\",b=[`@group(0) @binding(0) var<storage, read> a : array<${h}>;`,`@group(0) @binding(1) var<storage, read> b : array<${h}>;`];e.length===3&&b.push(`@group(0) @binding(2) var<storage, read> c : array<${h}>;`);let w=S=>`\n  const M: u32 = ${n}u;\n  const N: u32 = ${s}u;\n  const K: u32 = ${u}u;\n  const alpha = ${h}(${t.alpha});\n  const beta = ${h}(${t.beta});\n\n  ${b.join(`\n`)}\n  @group(0) @binding(${e.length}) var<storage, read_write> output : array<${h}>;\n\n  ${S.mainStart()}\n    ${S.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${h}(0);\n    for (var k: u32 = 0u; k<${u}u; k++) {\n      ${p}\n    }\n\n    ${v}\n    ${y}\n    output[global_id.x] = value;\n\n  }`;return{name:\"Gemm\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:w}},Di=(e,t)=>{fd(e.inputs),e.compute(hd(e.inputs,t))},zi=e=>re(e)});var gd,yd,bd,wd,Vi,Ni,Ui=F(()=>{\"use strict\";De();me();Ee();be();gd={name:\"InstanceNormalization\"},yd=(e,t)=>{let r=e[0].dims,o=r,n=2,s=z.sizeToDimension(r,n),u=z.sizeFromDimension(r,n),d=r[1],a=G(\"x\",e[0].dataType,[r[0],r[1],u]),p=G(\"scale\",e[1].dataType,e[1].dims),h=G(\"bias\",e[2].dataType,e[2].dims),v=q(\"output\",e[0].dataType,[r[0],r[1],u]),y=[a,p,h,v],b=a.type.value,w=64,S=C=>`\n\n  const C: u32 = ${d};\n  const normSize: u32 = ${u};\n  const epsilon: f32 = ${t.epsilon};\n  var<workgroup> meanShared : ${b};\n  var<workgroup> squaredNormShared : ${b};\n  var<workgroup> workgroupShared : array<${b}, ${w}>;\n  const workgroupSize = ${w}u;\n  ${C.declareVariables(...y)}\n  ${C.mainStart(w)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${b} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${a.get(\"batch\",\"channel\",\"h\")};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${b}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${a.get(\"batch\",\"channel\",\"h\")} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${b}(normSize) + epsilon);\n    let channelScale = invStdDev * ${p.getByOffset(\"channel\")};\n    let channelShift = ${h.getByOffset(\"channel\")} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${a.get(\"batch\",\"channel\",\"h\")} * channelScale + channelShift;\n      ${v.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`;return{...gd,shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:s}}),getShaderSource:S}},bd=(e,t,r,o,n,s,u,d)=>{let a=Ze(u),p=G(\"input\",t.dataType,t.dims,a),h=G(\"scale\",r.dataType,r.dims,a),v=G(\"bias\",o.dataType,o.dims,a),y=64,b=a===1?\"vec2f\":`mat2x${a}f`,w=a===1?\"f32\":`vec${a}f`,S=(R,E)=>`${b}(${R}, ${E})`,C=n*u/a,A=Math.ceil(s/y),I=R=>`\n  const H: u32 = ${s};\n  const C: u32 = ${u/a};\n  const imageSize: u32 = ${s*u/a};\n\n  ${R.declareVariables(p)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${b}>;\n\n  ${R.mainStart(y)}\n    let currentImageNumber = global_idx / ${y} / C;\n    let currentChannelNumber = (global_idx / ${y}) % C;\n    let wgId = global_idx % ${y};\n    let wgOffset = wgId * ${A};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${A}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${Ue(\"f32\",a)};\n    var squaredSum = ${Ue(\"f32\",a)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${w}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${S(\"sum\",\"squaredSum\")};\n  }`,B=e.compute({name:\"InstanceNormComputeMean\",shaderCache:{hint:JSON.stringify({components:a,n,h:s,c:u})},getRunData:()=>({outputs:[{dims:[n,u,y,2],dataType:1}],dispatchGroup:{x:n*u/a}}),getShaderSource:I},{inputs:[t],outputs:[-1]})[0],_=R=>`\n  const H: u32 = ${s};\n  const C: u32 = ${u/a};\n  const imageSize: u32 = ${y*u/a};\n  const epsilon: f32 = ${d};\n\n  @group(0) @binding(0) var<storage, read> input : array<${b}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${h.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${v.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${b}>;\n\n  ${R.mainStart()}\n    ${R.guardAgainstOutOfBoundsWorkgroupSizes(C)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${Ue(\"f32\",a)};\n    var squaredSum = ${Ue(\"f32\",a)};\n    for (var i: u32 = 0; i < ${y}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${y}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${w}(scale[currentChannelNumber]);\n    let channelShift = ${w}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${S(\"channelScale\",\"channelShift\")};\n  }`;return e.compute({name:\"InstanceNormComputeChannelScaleShift\",shaderCache:{hint:JSON.stringify({components:a,n,h:s,c:u,epsilon:d})},getRunData:()=>({outputs:[{dims:[n,u,2],dataType:1}],dispatchGroup:{x:Math.ceil(C/64)}}),getShaderSource:_},{inputs:[B,r,o],outputs:[-1]})[0]},wd=(e,t,r)=>{let o=t[0].dims,n=o,s=o[0],u=o[o.length-1],d=z.sizeFromDimension(o,1)/u,a=Ze(u),p=z.size(n)/a,h=G(\"input\",t[0].dataType,t[0].dims,a),v=q(\"output\",t[0].dataType,n,a),y=Ie(t[0].dataType),b=a===1?\"vec2f\":`mat2x${a}f`,w=a===1?y:`vec${a}<${y}>`,S=bd(e,t[0],t[1],t[2],s,d,u,r.epsilon),C=A=>`\n  const H: u32 = ${d};\n  const C: u32 = ${u/a};\n\n  @group(0) @binding(0) var<storage, read> input : array<${h.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${b}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${v.type.storage}>;\n\n  ${A.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${w}(scale[0]), ${w}(scale[1]));\n  }`;e.compute({name:\"InstanceNormalization\",shaderCache:{hint:`${r.cacheKey}`},getRunData:()=>({outputs:[{dims:n,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(p/64)}}),getShaderSource:C},{inputs:[t[0],S]})},Vi=e=>re({epsilon:e.epsilon,format:e.format}),Ni=(e,t)=>{t.format===\"NHWC\"?wd(e,e.inputs,t):e.compute(yd(e.inputs,t))}});var vd,$d,Hi,Gi,Li=F(()=>{\"use strict\";De();me();Ee();be();vd=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\")},$d=(e,t,r)=>{let o=e[0].dims,n=e[1],s=e[2],u=o,d=z.normalizeAxis(t.axis,o.length),a=z.sizeToDimension(o,d),p=z.sizeFromDimension(o,d),h=z.size(n.dims),v=s?z.size(s.dims):0;if(h!==p||s&&v!==p)throw new Error(`Size of X.shape()[axis:] == ${p}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${h} and bias size of ${v}`);let y=[];for(let _=0;_<o.length;++_)_<d?y.push(o[_]):y.push(1);let b=Ze(p),w=Ie(e[0].dataType),S=[G(\"x\",e[0].dataType,e[0].dims,b),G(\"scale\",n.dataType,n.dims,b)];s&&S.push(G(\"bias\",s.dataType,s.dims,b)),S.push(q(\"output\",e[0].dataType,u,b));let C=r>1,A=r>2;C&&S.push(q(\"meanDataOutput\",1,y)),A&&S.push(q(\"invStdOutput\",1,y));let I=_=>`\n  const normSize: f32 = ${p};\n  const normSizeVectorized: u32 = ${p/b};\n  const epsilon: f32 = ${t.epsilon};\n\n  ${_.declareVariables(...S)}\n  ${_.mainStart()}\n    ${_.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${Ue(\"f32\",b)};\n    var meanSquareVector = ${Ue(\"f32\",b)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${Qe(w,b,\"x[h + offset]\")};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${Je(\"meanVector\",b)} / normSize;\n    let meanSquare = sqrt(${Je(\"meanSquareVector\",b)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${Qe(w,b,\"x[j + offset]\")};\n      let f32scale = ${Qe(w,b,\"scale[j]\")};\n      output[j + offset] = ${S[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${s?`+ ${Qe(w,b,\"bias[j]\")}`:\"\"}\n      );\n    }\n\n    ${C?\"meanDataOutput[global_idx] = mean\":\"\"};\n    ${A?\"invStdOutput[global_idx] = 1 / meanSquare\":\"\"};\n  }`,B=[{dims:u,dataType:e[0].dataType}];return C&&B.push({dims:y,dataType:1}),A&&B.push({dims:y,dataType:1}),{name:\"LayerNormalization\",shaderCache:{hint:`${t.cacheKey}|${r}|${e.length}`},getRunData:()=>({outputs:B,dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:I}},Hi=e=>re({axis:e.axis,epsilon:e.epsilon}),Gi=(e,t)=>{vd(e.inputs),e.compute($d(e.inputs,t,e.outputCount))}});var Sd,Fi,ji=F(()=>{\"use strict\";me();lr();Sd=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},Fi=e=>{Sd(e.inputs);let t=at.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error(\"Can't use matmul on the given tensors\");e.compute(jr(e.inputs,{activation:\"\",activationCacheKey:\"\"},t))}});var xd,Ki,qi,Cd,Vn,Yi,Zi=F(()=>{\"use strict\";me();Ee();Pr();_n();be();Wt();xd=(e,t)=>{let r=e[0],o=e[1],n=e[2],s=e[3],u=e[4],d=e[5],a=e[6],p=e[7];if(r.dims.length!==3&&r.dims.length!==5)throw new Error(\"Input query is expected to have 3 or 5 dimensions\");let h=!1,v=r.dims[0],y=r.dims[1],b=r.dims.length===3?h?r.dims[2]/3:r.dims[2]:t.numHeads*r.dims[4],w=y,S=0,C=0,A=Math.floor(b/t.numHeads);if(a&&p){if(a.dims.length!==4)throw new Error('Input \"past_key\" is expected to have 4 dimensions');if(p.dims.length!==4)throw new Error('Input \"past_value\" is expected to have 4 dimensions');S=a.dims[2],C=a.dims[2]}else if(a||p)throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');let I;if(o){if(r.dims.length!==3)throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');if(o.dims.length<3||o.dims.length>5)throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');if(r.dims[0]!==o.dims[0])throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');if(o.dims.length===3){if(o.dims[2]!==r.dims[2])throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');I=2,w=o.dims[1]}else if(o.dims.length===5){if(o.dims[2]!==t.numHeads||o.dims[3]!==2||o.dims[4]!==A)throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(n)throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');I=5,w=o.dims[1]}else{if(o.dims[1]!==t.numHeads||o.dims[3]!==A)throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');I=0,w=o.dims[2]}}else{if(r.dims.length!==3&&r.dims.length!==5)throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');if(r.dims.length===5&&(r.dims[2]!==t.numHeads||r.dims[3]!==3))throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');I=3}if(s){if(s.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimension');if(n&&r.dims.length===5&&r.dims[3]===2)throw new Error(\"bias is not allowed for packed kv.\")}let B=0;if(u){B=8;let V=u.dims;throw V.length===1?V[0]===v?B=1:V[0]===3*v+2&&(B=3):V.length===2&&V[0]===v&&V[1]===w&&(B=5),B===8?new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)'):new Error(\"Mask not supported\")}let _=!1,R=b;if(n){if(n.dims.length!==3&&n.dims.length!==4)throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');if(r.dims[0]!==n.dims[0])throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');if(n.dims.length===3){if(w!==n.dims[1])throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');R=n.dims[2]}else{if(w!==n.dims[2])throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');R=n.dims[1]*n.dims[3],_=!0}}let E=S+w,W=!1;if(u)throw new Error(\"Key padding mask is not supported\");if(d)throw new Error(\"extraAddQk is not supported\");if(a)throw new Error(\"pastKey is not supported\");if(p)throw new Error(\"pastValue is not supported\");return{batchSize:v,sequenceLength:y,pastSequenceLength:S,kvSequenceLength:w,totalSequenceLength:E,maxSequenceLength:C,inputHiddenSize:0,hiddenSize:b,vHiddenSize:R,headSize:A,vHeadSize:Math.floor(R/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:B,scale:t.scale,broadcastResPosBias:W,passPastInKv:_,qkvFormat:I}},Ki=e=>re({...e}),qi=re({perm:[0,2,1,3]}),Cd=(e,t,r,o,n,s,u)=>{let d=[o,n,s],a=z.size(d),p=Ie(t.dataType),h=v=>`\n  const biasOffset = ${u}u;\n  const hiddenSize = ${s}u;\n\n  @group(0) @binding(0) var<storage, read> qkv: array<${p}>;\n  @group(0) @binding(1) var<storage, read> bias: array<${p}>;\n  @group(0) @binding(2) var<storage, read_write> qkv_with_bias: array<${p}>;\n\n  ${v.mainStart()}\n    ${v.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n    let biasOffsetIdx = (global_idx % hiddenSize) + biasOffset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[biasOffsetIdx];\n  }`;return e.compute({name:\"MultiHeadAttentionAddBias\",shaderCache:{hint:JSON.stringify({batchSize:o,sequenceLength:n,hiddenSize:s,biasOffset:u})},getRunData:()=>({outputs:[{dims:d,dataType:t.dataType,gpuDataType:0}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:h},{inputs:[t,r],outputs:[-1]})[0]},Vn=(e,t,r,o,n,s,u,d)=>{let a=s;if(u){if(o===1)throw new Error(\"AddBiasReshape is not implemented. Please export your model with packed QKV or KV\");return a=Cd(e,s,u,t,o,r*n,d),a=a.reshape([t,o,r,n]),e.compute(et(a,qi.perm),{inputs:[a],outputs:[-1]})[0]}else return s.dims.length===3&&(a=s.reshape([t,o,r,n])),e.compute(et(a,qi.perm),{inputs:[a],outputs:[-1]})[0]},Yi=(e,t)=>{let r=xd(e.inputs,t);if(e.inputs[0].dims.length===5)throw new Error(\"Packed QKV is not implemented\");if(e.inputs[1]?.dims.length===5)throw new Error(\"Packed KV is not implemented\");let o=e.inputs[1]&&e.inputs[2]&&e.inputs[1].dims.length===4&&e.inputs[2].dims.length===4,n=Vn(e,r.batchSize,r.numHeads,r.sequenceLength,r.headSize,e.inputs[0],e.inputs[3],0);if(o)return Vr(e,n,e.inputs[1],e.inputs[2],e.inputs[4],void 0,void 0,void 0,e.inputs[5],r,t);let s=Vn(e,r.batchSize,r.numHeads,r.kvSequenceLength,r.headSize,e.inputs[1],e.inputs[3],r.hiddenSize),u=Vn(e,r.batchSize,r.numHeads,r.kvSequenceLength,r.vHeadSize,e.inputs[2],e.inputs[3],2*r.hiddenSize);Vr(e,n,s,u,e.inputs[4],void 0,e.inputs[6],e.inputs[7],e.inputs[5],r,t)}});var Id,Ad,_d,Td,Ed,Od,kd,Pd,Rd,Xi,Qi,Ji=F(()=>{\"use strict\";De();me();Ee();be();Id=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let t=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(t=e[3].dims[0]*2===e[1].dims[0]),!t)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},Ad=(e,t,r,o,n,s)=>{let u=t.length,d=\"\";for(let a=u-1;a>=0;--a)d+=`\n            k = i32(${e.indicesGet(\"indices\",a)}) - ${o[a]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${t[a]}) {\n              break;\n            }\n            offset += k * ${r[a]};\n        `;return`\n          value = ${n}(${s});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${d}\n            value = x[offset];\n          }\n      `},_d=(e,t,r,o)=>{let n=t.length,s=\"\";for(let u=n-1;u>=0;--u)s+=`\n                k = i32(${e.indicesGet(\"indices\",u)}) - ${o[u]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2*(t[u]-1)};\n                  k = k % _2n_1;\n                  if(k >= ${t[u]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${r[u]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${s}\n              value = x[offset];\n          `},Td=(e,t,r,o)=>{let n=t.length,s=\"\";for(let u=n-1;u>=0;--u)s+=`\n                k = i32(${e.indicesGet(\"indices\",u)}) - ${o[u]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${t[u]}) {\n                  k = ${t[u]-1};\n                }\n                offset += k * ${r[u]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${s}\n              value = x[offset];\n          `},Ed=(e,t,r,o)=>{let n=t.length,s=\"\";for(let u=n-1;u>=0;--u)s+=`\n                k = i32(${e.indicesGet(\"indices\",u)}) - ${o[u]};\n                if (k < 0)  {\n                  k += ${t[u]};\n                }\n                if (k >= ${t[u]}) {\n                  k -= ${t[u]};\n                }\n                offset += k * ${r[u]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${s}\n              value = x[offset];\n          `},Od=(e,t,r,o,n)=>{switch(o.mode){case 0:return Ad(e,t,r,o.pads,n,o.value);case 1:return _d(e,t,r,o.pads);case 2:return Td(e,t,r,o.pads);case 3:return Ed(e,t,r,o.pads);default:throw new Error(\"Invalid mode\")}},kd=(e,t,r,o)=>{let n=t[0].dims,s=z.padShape(n.slice(),r.pads),u=z.size(s),d=z.computeStrides(n),a=q(\"output\",t[0].dataType,s),p=G(\"x\",t[0].dataType,n),h=Od(a,n,d,r,o);return`\n              ${e.declareVariables(p,a)}\n              ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n\n              let indices = ${a.offsetToIndices(\"global_idx\")};\n\n              var value = ${o}(0);\n              ${h}\n              output[global_idx] = value;\n          }`},Pd=(e,t)=>{let r=z.padShape(e[0].dims.slice(),t.pads);return{name:\"Pad\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(z.size(r)/64)}}),getShaderSource:o=>kd(o,e,t,\"f32\")}},Rd=(e,t)=>{if(e.length>1){let r=e[1].getBigInt64Array(),o=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,n=e[0].dims.length,s=new Int32Array(2*n).fill(0);if(e.length>=4){let d=e[3].getBigInt64Array();for(let a=0;a<d.length;a++)s[Number(d[a])]=Number(r[a]),s[Number(d[a])+n]=Number(r[a+d.length])}else r.forEach((d,a)=>s[Number(a)]=Number(d));let u=[];return s.forEach(d=>u.push(d)),re({mode:t.mode,value:o,pads:u})}else return t},Xi=(e,t)=>{Id(e.inputs);let r=Rd(e.inputs,t);e.compute(Pd(e.inputs,r),{inputs:[0]})},Qi=e=>{let t=e.mode,r=e.value,o=e.pads;return re({mode:t,value:r,pads:o})}});var Kr,es,ts,rs,ns,os,as,is,ss,us,ls,ds,cs,ps,fs,ms=F(()=>{\"use strict\";me();Ee();be();Kr=e=>{if(!e||e.length!==1)throw new Error(\"Pool ops requires 1 input.\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"Pool ops supports 1-D or 2-D inputs only for now.\")},es=(e,t,r)=>{let o=t.format===\"NHWC\",n=e.dims.slice();o&&n.splice(1,0,n.pop());let s=Object.hasOwnProperty.call(t,\"dilations\"),u=t.kernelShape.slice(),d=t.strides.slice(),a=s?t.dilations.slice():[],p=t.pads.slice();Tt.adjustPoolAttributes(r,n,u,d,a,p);let h=Tt.computePoolOutputShape(r,n,d,a,u,p,t.autoPad),v=Object.assign({},t);s?Object.assign(v,{kernelShape:u,strides:d,pads:p,dilations:a,cacheKey:t.cacheKey}):Object.assign(v,{kernelShape:u,strides:d,pads:p,cacheKey:t.cacheKey});let y=h.slice();return y.push(y.splice(1,1)[0]),[v,o?y:h]},ts=(e,t,r,o,n,s,u,d)=>{let a=n.format===\"NHWC\",p=r,h=t.type.value,v=p.length,y=z.size(o),b=q(\"output\",t.type.tensor,o);if(n.kernelShape.length<=2){let w=n.kernelShape[n.kernelShape.length-1],S=n.strides[n.strides.length-1],C=n.pads[n.pads.length/2-1],A=n.pads[n.pads.length-1],I=v-(a?2:1),B=\"\",_=\"\",R=\"\";if(C+A!==0?B=`\n                for (var i: u32 = 0u; i < ${w}u; i++) {\n                  xIndices[${I}] = indices[${I}] * ${S} - ${C} + i;\n                  if (xIndices[${I}] < 0 || xIndices[${I}] >= ${p[I]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`:B=`\n                for (var i: u32 = 0u; i < ${w}u; i++) {\n                  xIndices[${I}] = indices[${I}] * ${S} - ${C} + i;\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`,n.kernelShape.length===2){let W=n.kernelShape[n.kernelShape.length-2],V=n.strides[n.strides.length-2],Y=n.pads[n.pads.length/2-2],ae=n.pads[n.pads.length-2],M=v-(a?3:2),K=p[M];Y+ae!==0?_=`\n                for (var j: u32 = 0u; j < ${W}u; j++) {\n                  xIndices[${M}] = indices[${M}] * ${V} - ${Y} + j;\n                  if (xIndices[${M}] < 0 || xIndices[${M}] >= ${K}) {\n                    pad+= ${w};\n                    continue;\n                  }\n              `:_=`\n                for (var j: u32 = 0u; j < ${W}u; j++) {\n                  xIndices[${M}] = indices[${M}] * ${V} - ${Y} + j;\n                `,R=`\n              }\n            `}return`\n            ${e.declareVariables(t,b)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(y)}\n\n              let indices = ${b.offsetToIndices(\"global_idx\")};\n              var xIndices = ${b.offsetToIndices(\"global_idx\")};\n\n              var value: ${h} = ${h}(${d});\n              var pad = 0;\n              ${_}\n              ${B}\n              ${R}\n              ${u}\n\n              output[global_idx] = value;\n            }`}else{if(a)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let w=z.size(n.kernelShape),S=z.computeStrides(n.kernelShape),C=S.length,A=n.pads.length,I=n.pads.reduce((R,E)=>R+E),B=\"\";return I?B=`\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`:B=`\n              }\n              let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n              ${s}\n            `,`\n            ${e.declareVariables(t,b)}\n\n            const pads = array<u32, ${A}>(${n.pads.map(R=>`${R}u`).join(\",\")});\n            const inputDims = array<u32, ${v}>(${p.map(R=>`${R}u`).join(\",\")});\n            const kernelStrides = array<u32, ${C}>(${S.map(R=>`${R}u`).join(\",\")});\n            const strides = array<u32, ${C}>(${n.strides.map(R=>`${R}u`).join(\",\")});\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(y)}\n\n              let indices = ${b.offsetToIndices(\"global_idx\")};\n              let xIndices = ${b.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${C}>;\n\n              var value = ${b.type.value}(${d});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${w}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${C-1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${C-1}] = offset;\n\n                isPad = false;\n                for (var j = ${v-C}u; j < ${v}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${v-C}u]\n                    + offsets[j - ${v-C}u] - pads[j - 2u];\n                  ${B}\n              }\n              ${u}\n\n              output[global_idx] = value;\n            }`}},rs=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),ns=(e,t,r,o)=>{let[n,s]=es(t,o,r),u=z.size(n.kernelShape),d=G(\"x\",t.dataType,t.dims),a=d.type.value,p=\"value += x_val;\",h=\"\";return n.countIncludePad?h+=`value /= ${a}(${u});`:h+=`value /= ${a}(${u} - pad);`,{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(z.size(s)/64)}}),getShaderSource:v=>ts(v,d,t.dims,s,n,p,h,\"0.0\")}},os=e=>{let t=e.count_include_pad!==0,r=rs(e);if(r.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return re({countIncludePad:t,...r})},as=(e,t)=>{Kr(e.inputs),e.compute(ns(\"AveragePool\",e.inputs[0],!1,t))},is={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},ss=e=>{let t=e.format;return{format:t,...is,cacheKey:t}},us=(e,t)=>{Kr(e.inputs),e.compute(ns(\"GlobalAveragePool\",e.inputs[0],!0,t))},ls=(e,t,r,o)=>{let[n,s]=es(t,o,r),u=`\n      value = max(x_val, value);\n    `,d=\"\",a=G(\"x\",t.dataType,t.dims);return{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(z.size(s)/64)}}),getShaderSource:p=>ts(p,a,t.dims,s,n,u,d,\"-1e5\")}},ds=(e,t)=>{Kr(e.inputs),e.compute(ls(\"MaxPool\",e.inputs[0],!1,t))},cs=e=>{let t=e.storage_order,r=e.dilations,o=rs(e);if(t!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(o.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return re({storageOrder:t,dilations:r,...o})},ps=e=>{let t=e.format;return{format:t,...is,cacheKey:t}},fs=(e,t)=>{Kr(e.inputs),e.compute(ls(\"GlobalMaxPool\",e.inputs[0],!0,t))}});var Yr=F(()=>{});var hs=F(()=>{Yr()});var gs,ys=F(()=>{gs=\"1.17.0\"});var bs,Nn,ws=F(()=>{ys();bs=\"warning\",Nn={wasm:{},webgl:{},webgpu:{},versions:{common:gs},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);bs=e}},get logLevel(){return bs}};Object.defineProperty(Nn,\"logLevel\",{enumerable:!0})});var vs,$s=F(()=>{ws();vs=Nn});var Ss=F(()=>{});var xs=F(()=>{Zr()});var Is=F(()=>{});var As=F(()=>{Zr()});var Zr=F(()=>{Ss();xs();Is();As()});var Xr=F(()=>{Zr()});var _s=F(()=>{Yr();Xr()});var Ts=F(()=>{_s()});var Es=F(()=>{});var Os=F(()=>{Yr();Xr()});var ks=F(()=>{Os()});var Ps=F(()=>{hs();$s();Ts();Xr();Es();ks()});var zd,Wd,Rs,Bs=F(()=>{\"use strict\";Ps();De();be();zd=(e,t,r)=>{let o=e===t,n=e<t&&r<0,s=e>t&&r>0;if(o||n||s)throw new Error(\"Range these inputs' contents are invalid.\")},Wd=(e,t,r,o)=>{let n=Math.abs(Math.ceil((t-e)/r)),s=[n],u=n,d=q(\"output\",o,s),a=d.type.storage,p=h=>`\n        ${h.declareVariables(d)}\n        ${h.mainStart()}\n        ${h.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n        output[global_idx] = ${a}(${e}) + ${a}(global_idx) * ${a}(${r});\n      }`;return{name:\"Range\",shaderCache:{hint:[e,t,r].map(h=>h.toString()).join(\"_\")},getShaderSource:p,getRunData:()=>({outputs:[{dims:s,dataType:o}],dispatchGroup:{x:Math.ceil(u/64)}})}},Rs=e=>{let t=0,r=0,o=0;e.inputs[0].dataType===6?(t=e.inputs[0].getInt32Array()[0],r=e.inputs[1].getInt32Array()[0],o=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(t=e.inputs[0].getFloat32Array()[0],r=e.inputs[1].getFloat32Array()[0],o=e.inputs[2].getFloat32Array()[0]),vs.webgpu.validateInputContent&&zd(t,r,o),e.compute(Wd(t,r,o,e.inputs[0].dataType),{inputs:[]})}});var Vd,Nd,Ud,Hd,Gd,Ld,Fd,jd,qd,Kd,Yd,Zd,Xd,Qd,Jd,Ms,Ds,zs=F(()=>{\"use strict\";me();Ee();be();Vd=(e,t)=>{if(e.every(r=>r>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(t.mode===\"linear\"){if(!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for linear mode\")}else if(t.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},Nd=(e,t,r)=>{t.every(n=>n>=0&&n<r||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let o=new Array(r).fill(1);return t.forEach((n,s)=>o[n]=e[s]),o},Ud=(e,t,r,o,n,s)=>{let[u,d,a]=r>10?[1,2,3]:[-1,e.length>1?1:-1,-1],p=e[0].dims.length;if(u>0&&e.length>u&&e[u].dims.length>0)e[u].getFloat32Array().forEach(h=>s.push(h));else if(t.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(d>0&&e.length>d&&e[d].dims.length>0){if(e[d].getFloat32Array().forEach(h=>o.push(h)),o.length!==0&&o.length!==p&&r>=18&&o.length!==t.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");Vd(o,t),t.axes.length>0&&Nd(o,t.axes,p).forEach((h,v)=>o[v]=h)}if(a>0&&e.length>a&&(e[a].getBigInt64Array().forEach(h=>n.push(Number(h))),n.length!==p||r>=18&&n.length===t.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(t.axes.length>0){if(o.length!==t.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(n.length!==t.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof o<\"u\"&&typeof n<\"u\"&&o.length>0&&n.length>p)throw new Error(\"Resize requires only of scales or sizes to be specified\")},Hd=e=>\"fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { \"+(()=>{switch(e){case\"asymmetric\":return\"return xResized / xScale;\";case\"pytorch_half_pixel\":return\"if (lengthResized > 1) {                     return (xResized + 0.5) / xScale - 0.5;                   } else {                     return 0.0;                   }\";case\"tf_half_pixel_for_nn\":return\"return (xResized + 0.5) / xScale;\";case\"align_corners\":return\"if (lengthResized == 1) {                     return 0.0;                   } else {                     return xResized * (lengthOriginal - 1) / (lengthResized - 1);                   }\";case\"tf_crop_and_resize\":return\"if (lengthResized > 1) {                     return roiStart * (lengthOriginal - 1) +                           (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1);                   } else {                     return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1);                   }\";case\"half_pixel_symmetric\":return[\"const outputWidth = xScale * lengthResized;\",\"const adjustment = lengthResized / outputWidth;\",\"const center = lengthOriginal / 2;\",\"const offset = center * (1 - adjustment);\",\"return offset + ((xResized + 0.5) / xScale) - 0.5;\"].join(`\n`);case\"half_pixel\":return\"return ((xResized + 0.5) / xScale) - 0.5;\";default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",Gd=(e,t)=>\"fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {\"+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(t<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",Ld=(e,t,r)=>{let o=new Array(r).fill(0).concat(new Array(r).fill(1)),n=e.length===0?o:e.slice();return t.length>0?(t.forEach((s,u)=>{o[s]=n[u],o[u+r]=n[t.length+u]}),o):n},Fd=(e,t,r,o)=>{let n=[];if(r.length>0)if(o.length>0){if(e.forEach(s=>n.push(s)),Math.max(...o)>e.length)throw new Error(\"axes is out of bound\");o.forEach((s,u)=>n[s]=r[u])}else r.forEach(s=>n.push(s));else{if(t.length===0)throw new Error(\"Resize requires either scales or sizes.\");n=e.map((s,u)=>Math.round(s*t[u]))}return n},jd=(e,t,r)=>{let o=(()=>{switch(r.keepAspectRatioPolicy){case\"not_larger\":return r.axes.length>0?Math.min(...r.axes.map(s=>t[s]),Number.MAX_VALUE):Math.min(...t,Number.MAX_VALUE);case\"not_smaller\":return r.axes.length>0?Math.max(...r.axes.map(s=>t[s]),Number.MIN_VALUE):Math.max(...t,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${r.keepAspectRatioPolicy} is not supported`)}})();t.fill(1,0,t.length);let n=e.slice();return r.axes.length>0?(r.axes.forEach(s=>t[s]=o),r.axes.forEach(s=>n[s]=Math.round(e[s]*t[s]))):(t.fill(o,0,t.length),n.forEach((s,u)=>n[u]=Math.round(s*t[u]))),n},qd=(e,t,r,o,n)=>`\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${e.type.indices}) -> array<f32, ${r.length}> {\n      const inputShape = array<u32, ${t.length}>(${t.map(s=>`${s}u`).join(\",\")});\n      const outputShape = array<u32, ${r.length}>(${r.map(s=>`${s}u`).join(\",\")});\n      const scales = array<f32, ${o.length}>(${o.map(s=>`${s}f`).join(\",\")});\n      const roi = array<f32, ${n.length}>(${n.map(s=>`${s}f`).join(\",\")});\n      var originalIndices: array<f32, ${r.length}>;\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var outputIndex = ${r.length===1?\"outputIndices\":\"outputIndices[i]\"};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${t.length}]);\n        }\n      }\n      return originalIndices;\n    }`,Kd=(e,t,r,o,n,s,u)=>`\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n        const inputShape = array<u32, ${r.length}>(${r.map(d=>`${d}u`).join(\",\")});\n        const outputShape = array<u32, ${o.length}>(${o.map(d=>`${d}u`).join(\",\")});\n        const scales = array<f32, ${n.length}>(${n.map(d=>`${d}f`).join(\",\")});\n        const roi = array<f32, ${s.length}>(${s.map(d=>`${d}f`).join(\",\")});\n        var inputIndices: ${e.type.indices};\n        for (var i:u32 = 0; i < ${o.length}; i++) {\n          var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${r.length}]);\n            if (!${u} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${e.indicesSet(\"inputIndices\",\"i\",\"inputIndex\")}\n        }\n        return inputIndices;\n    }`,Yd=(e,t)=>`\n    fn checkInputIndices(inputIndices: ${e.type.indices}) -> bool {\n      const inputShape = array<u32, ${t.length}>(${t.map(r=>`${r}u`).join(\",\")});\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var inputIndex = ${t.length===1?\"inputIndices\":\"inputIndices[i]\"};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`,Zd=(e,t,r,o,n,s)=>{let[u,d,a,p]=r.length===2?[-1,0,1,-1]:o[1]===1?[0,2,3,1]:[0,1,2,3];return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${e.type.indices};\n      inputIndices[${d}] = max(0, min(row, ${r[d]} - 1));\n      inputIndices[${a}] = max(0, min(col, ${r[a]} - 1));\n      if (${r.length} > 2) {\n        inputIndices[${p}] = channel;\n        inputIndices[${u}] = batch;\n      };\n      return input[${e.indicesToOffset(\"inputIndices\")}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${d}];\n      var col:f32 = originalIndices[${a}];\n      if (${n} && (row < 0 || row > (${r[d]} - 1) || col < 0 || col > ${r[a]} - 1)) {\n        return ${s};\n      }\n      row = max(0, min(row, ${r[d]} - 1));\n      col = max(0, min(col, ${r[a]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${r.length>2}) {\n        channel = u32(originalIndices[${p}]);\n        batch = u32(originalIndices[${u}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},Xd=(e,t,r,o,n,s,u,d,a,p)=>{let[h,v]=r.length===2?[0,1]:n[1]===1?[2,3]:[1,2],y=b=>{let w=b===h?\"row\":\"col\";return`\n      fn ${w}CubicInterpolation(inputIndices: ${e.type.indices}, outputIndices: ${t.type.indices}) -> f32 {\n        var outputIndex = ${o.length===1?\"outputIndices\":`outputIndices[${b}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${n[b]},\n        f32(${o[b]}), f32(${r[b]}), ${s[b]}, ${s[b]} + ${r.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${d} && (originalIdx < 0 || originalIdx > (${r[b]} - 1))) {\n          return ${a};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${w}: f32 = originalIdx + f32(i);\n          if (${w} < 0 || ${w} >= ${r[b]}) {\n            if (${p}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${d}) {\n              return ${a};\n            } else {\n              ${w} = max(0, min(${w}, ${r[b]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${e.type.indices} = inputIndices;\n          inputIndicesCopy[${b}] = u32(${w});\n          data[i + 1] = ${b===h?`input[${e.indicesToOffset(\"inputIndicesCopy\")}];`:`\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${y(h)};\n    ${y(v)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${u} * onePlusAbsS - 5 * ${u}) * onePlusAbsS + 8 * ${u}) * onePlusAbsS - 4 * ${u};\n    coeffs[1] = ((${u} + 2) * absS - (${u} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${u} + 2) * oneMinusAbsS - (${u} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${u} * twoMinusAbsS - 5 * ${u}) * twoMinusAbsS + 8 * ${u}) * twoMinusAbsS - 4 * ${u};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n    var inputIndices: ${e.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `},Qd=(e,t,r,o,n,s)=>{let u=e.dims,d=Ld(s,t.axes,u.length),a=Fd(u,o,n,t.axes),p=o.slice();o.length===0&&(p=u.map((C,A)=>C===0?1:a[A]/C),t.keepAspectRatioPolicy!==\"stretch\"&&(a=jd(u,p,t)));let h=q(\"output\",e.dataType,a),v=G(\"input\",e.dataType,u),y=z.size(a),b=u.length===a.length&&u.every((C,A)=>C===a[A]),w=t.coordinateTransformMode===\"tf_crop_and_resize\",S=C=>`\n      ${b?\"\":`\n      ${Hd(t.coordinateTransformMode)};\n      ${(()=>{switch(t.mode){case\"nearest\":return`\n              ${Yd(v,u)};\n              ${Gd(t.nearestMode,r)};\n              ${Kd(v,h,u,a,p,d,w)};\n              `;case\"linear\":return`\n              ${qd(h,u,a,p,d)};\n              ${Zd(v,h,u,p,w,t.extrapolationValue)};\n              `;case\"cubic\":return`\n            ${Xd(v,h,u,a,p,d,t.cubicCoeffA,w,t.extrapolationValue,t.excludeOutside)};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      `}\n      ${C.declareVariables(v,h)}\n      ${C.mainStart()}\n        ${C.guardAgainstOutOfBoundsWorkgroupSizes(y)}\n        ${b?\"output[global_idx] = input[global_idx];\":`\n        let outputIndices = ${h.offsetToIndices(\"global_idx\")};\n        var inputIndices: ${v.type.indices};\n        ${(()=>{switch(t.mode){case\"nearest\":return`inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${v.indicesToOffset(\"inputIndices\")}];\n                } else {\n                  output[global_idx] = ${t.extrapolationValue};\n                }`;case\"linear\":return\"output[global_idx] = bilinearInterpolation(outputIndices);\";case\"cubic\":return\"output[global_idx] = bicubicInterpolation(outputIndices);\";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n        `}\n      }`;return{name:\"Resize\",shaderCache:{hint:`${t.cacheKey}|${r}|${p.length>0?p:\"\"}|${n.length>0?n:\"\"}|${b}`},getShaderSource:S,getRunData:()=>({outputs:[{dims:a,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(y/64)}})}},Jd=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},Ms=(e,t)=>{let r=[],o=[],n=[],s=Jd(e);Ud(e.inputs,t,s,r,o,n),e.compute(Qd(e.inputs[0],t,s,r,o,n),{inputs:[0]})},Ds=e=>{let t=e.antialias,r=e.axes,o=e.coordinateTransformMode,n=e.cubicCoeffA,s=e.excludeOutside!==0,u=e.extrapolationValue,d=e.keepAspectRatioPolicy,a=e.mode,p=e.nearestMode===\"\"?\"simple\":e.nearestMode;return re({antialias:t,axes:r,coordinateTransformMode:o,cubicCoeffA:n,excludeOutside:s,extrapolationValue:u,keepAspectRatioPolicy:d,mode:a,nearestMode:p})}});var ec,tc,Ws,Vs,Ns=F(()=>{\"use strict\";De();me();Ee();be();ec=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");let t=e[0],r=e[1],o=e[2];if(t.dataType!==r.dataType||t.dataType!==o.dataType)throw new Error(\"All inputs must have the same data type\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let n=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(r.dims[r.dims.length-1]!==n)throw new Error(\"Skip must have the same hidden size as input\");if(r.dims[r.dims.length-2]!==s)throw new Error(\"Skip must have the same sequence length as input\");if(o.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(o.dims[o.dims.length-1]!==n)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let u=e[3];if(u.dims.length!==1)throw new Error(\"Beta must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let u=e[4];if(u.dims.length!==1)throw new Error(\"Bias must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Bias must have the same hidden size as input\")}},tc=(e,t,r,o)=>{let n=e[0].dims,s=z.size(n),u=n,d=s,a=n.slice(-1)[0],p=o?n.slice(0,-1).concat(1):[],h=e.length>3,v=e.length>4,y=o&&r>1,b=o&&r>2,w=r>3,S=Ze(a),C=[G(\"x\",e[0].dataType,e[0].dims,S),G(\"skip\",e[1].dataType,e[1].dims,S),G(\"gamma\",e[2].dataType,e[2].dims,S)];h&&C.push(G(\"beta\",e[3].dataType,e[3].dims,S)),v&&C.push(G(\"bias\",e[4].dataType,e[4].dims,S)),C.push(q(\"output\",e[0].dataType,u,S)),y&&C.push(q(\"meanOutput\",1,p)),b&&C.push(q(\"invStdOutput\",1,p)),w&&C.push(q(\"inputSkipBiasSum\",e[0].dataType,u,S));let A=Ie(e[0].dataType),I=_=>`\n      const hiddenSize: f32 = ${a};\n      const hiddenSizeVectorized: u32 = ${a/S};\n      const epsilon: f32 = ${t.epsilon};\n\n      ${_.declareVariables(...C)}\n\n      ${_.mainStart()}\n        ${_.guardAgainstOutOfBoundsWorkgroupSizes(d/a)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${Ue(\"f32\",S)};\n        var squareSum = ${Ue(\"f32\",S)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${v?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${w?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          let f32Value = ${Qe(A,S,\"value\")};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${Je(\"sum\",S)} / hiddenSize;\n        let variance = sqrt(${Je(\"squareSum\",S)} / hiddenSize - mean * mean + epsilon);\n        ${y?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${b?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${A}(mean)) / ${A}(variance) * gamma[i]\n           + ${h?\"beta[i]\":\"0.0\"};\n        }\n      }`,B=[{dims:u,dataType:e[0].dataType}];return r>1&&B.push({dims:p,dataType:1}),r>2&&B.push({dims:p,dataType:1}),r>3&&B.push({dims:n,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:t.cacheKey},getShaderSource:I,getRunData:()=>({outputs:B,dispatchGroup:{x:Math.ceil(d/a/64)}})}},Ws=(e,t)=>{ec(e.inputs);let o=[0];e.outputCount>1&&o.push(-3),e.outputCount>2&&o.push(-3),e.outputCount>3&&o.push(3),e.compute(tc(e.inputs,t,e.outputCount,!1),{outputs:o})},Vs=e=>{let t=e.epsilon;return re({epsilon:t})}});var rc,Qr,nc,Us,oc,ac,Hs,Gs,Ls=F(()=>{\"use strict\";De();me();Ee();be();rc=(e,t)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(t.axes.length!==0){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(t.starts.length!==t.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((r,o)=>{if(e[o+1].dataType!==6&&e[o+1].dataType!==7)throw new Error(`Input ${o} must be an array of int32 or int64`)})},Qr=(e,t)=>{let r=[];if(e.length>t)if(e[t].dataType===7)e[t].getBigInt64Array().forEach(o=>r.push(Number(o)));else if(e[t].dataType===6)e[t].getInt32Array().forEach(o=>r.push(Number(o)));else throw new Error(`Input ${t} must be an array of int32 or int64`);return r},nc=(e,t)=>{if(e.length>1){let r=Qr(e,1),o=Qr(e,2),n=Qr(e,3);return n.length===0&&(n=[...Array(e[0].dims.length).keys()]),re({starts:r,ends:o,axes:n})}else return t},Us=(e,t,r,o,n)=>{let s=e;return e<0&&(s+=r[o[t]]),n[t]<0?Math.max(0,Math.min(s,r[o[t]]-1)):Math.max(0,Math.min(s,r[o[t]]))},oc=(e,t,r,o,n)=>`fn calculateInputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n          var inputIndices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${r.length}; i >= 0; i--) {\n            let input_shape_i = ${n?`uniforms.input_shape${r.length>1?\"[i]\":\"\"}`:\"inputShape[i]\"};\n            let steps_i  = ${n?`uniforms.steps${r.length>1?\"[i]\":\"\"}`:\"steps[i]\"};\n            let signs_i  = ${n?`uniforms.signs${r.length>1?\"[i]\":\"\"}`:\"signs[i]\"};\n            let starts_i  = ${n?`uniforms.starts${r.length>1?\"[i]\":\"\"}`:\"starts[i]\"};\n            var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n            var inputIndex = outputIndex * steps_i + starts_i + carry;\n            carry = inputIndex / input_shape_i;\n            inputIndex = inputIndex % input_shape_i;\n            if (signs_i < 0) {\n              inputIndex = input_shape_i - inputIndex - 1u + starts_i;\n            }\n            ${r.length===1?\"inputIndices\":\"inputIndices[i]\"} = inputIndex;\n          }\n          return inputIndices;\n      }`,ac=(e,t)=>{let r=e[0].dims,o=z.size(r),n=t.axes.length>0?z.normalizeAxes(t.axes,r.length):[...Array(r.length).keys()],s=Qr(e,4);s.forEach(_=>_!==0||(()=>{throw new Error(\"step cannot be 0\")})),s.length===0&&(s=Array(n.length).fill(1));let u=t.starts.map((_,R)=>Us(_,R,r,n,s)),d=t.ends.map((_,R)=>Us(_,R,r,n,s));if(n.length!==u.length||n.length!==d.length)throw new Error(\"start, ends and axes should have the same number of elements\");if(n.length!==r.length)for(let _=0;_<r.length;++_)n.includes(_)||(u.splice(_,0,0),d.splice(_,0,r[_]),s.splice(_,0,1));let a=s.map(_=>Math.sign(_));s.forEach((_,R,E)=>{if(_<0){let W=(d[R]-u[R])/_,V=u[R],Y=V+W*s[R];u[R]=Y,d[R]=V,E[R]=-_}});let p=Ge(e[0].dims.length),h=p?e[0].dims.length:e[0].dims,v=r.slice(0);n.forEach((_,R)=>{v[_]=Math.ceil((d[_]-u[_])/s[_])});let y=p?v.length:v,b={dims:v,dataType:e[0].dataType},w=q(\"output\",e[0].dataType,y),S=G(\"input\",e[0].dataType,h),C=z.size(v),A=[],I=[];p&&(I.push({name:\"starts\",type:u.length>1?`vec${u.length}<u32>`:\"u32\"}),I.push({name:\"signs\",type:a.length>1?`vec${a.length}<i32>`:\"i32\"}),I.push({name:\"steps\",type:s.length>1?`vec${s.length}<u32>`:\"u32\"}),A.push({type:\"uint32\",data:u}),A.push({type:\"int32\",data:a}),A.push({type:\"uint32\",data:s})),I.push({name:\"outputSize\",type:\"u32\"}),A.push({type:\"uint32\",data:C}),p&&(A.push(...Ne(e[0].dims)),A.push(...Ne(v)));let B=_=>`\n      ${_.registerUniforms(I).declareVariables(S,w)}\n        ${p?\"\":[`const signs = array<i32, ${a.length}>(${a.map(R=>`${R}i`).join(\",\")});`,`const starts = array<u32, ${u.length}>(${u.map(R=>`${R}u`).join(\",\")});`,`const steps = array<u32, ${s.length}>(${s.map(R=>`${R}u`).join(\",\")});`,`const inputShape = array<u32, ${r.length}>(${r.map(R=>`${R}u`).join(\",\")});`].join(`\n`)}\n\n        ${oc(S,w,r,v,p)}\n        ${_.mainStart()}\n          ${_.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n          let outputIndices = ${w.offsetToIndices(\"global_idx\")};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${w.setByOffset(\"global_idx\",S.getByIndices(\"inputIndices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:p?`${a.length}_${u.length}_${s.length}`:`${t.cacheKey} | ${e[4]?.dims??\"\"}`,inputDependencies:[p?\"rank\":\"dims\"]},getShaderSource:B,getRunData:()=>({outputs:[b],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:A})}},Hs=(e,t)=>{rc(e.inputs,t);let r=nc(e.inputs,t);e.compute(ac(e.inputs,r),{inputs:[0]})},Gs=e=>{let t=e.starts,r=e.ends,o=e.axes;return re({starts:t,ends:r,axes:o})}});var ic,sc,Fs,js,qs=F(()=>{\"use strict\";me();Ee();be();ic=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},sc=(e,t)=>{let r=e.dims,o=z.size(r),n=64,s=t.axis;if(s<0&&(s=r.length+s),s<r.length-1)throw new Error(\"softmax only supports last axis for now.\");let u=r[s],d=o/u,a=Ze(u),p=u/a,h=(C,A)=>A===4?`max(max(${C}.x, ${C}.y), max(${C}.z, ${C}.w))`:A===2?`max(${C}.x, ${C}.y)`:A===3?`max(max(${C}.x, ${C}.y), ${C}.z)`:C,v=G(\"x\",e.dataType,e.dims,a),y=q(\"result\",e.dataType,e.dims,a),b=v.type.value,w=Ie(e.dataType)===\"f32\"?`var threadMax = ${b}(-3.402823e+38f);`:`var threadMax = ${b}(-65504.0h);`,S=C=>`\n      var<workgroup> rowMaxShared : ${b};\n      var<workgroup> rowSumShared : ${b};\n      var<workgroup> threadShared : array<${b}, ${n}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${b} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${b}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${C.registerUniform(\"packedCols\",\"i32\").declareVariables(v,y)}\n      ${C.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${n};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${w}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${b}(${h(\"threadShared[0]\",a)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${b}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${b}(${Je(\"threadShared[0]\",a)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;return{name:\"Softmax\",shaderCache:{hint:`${a}`,inputDependencies:[\"type\"]},getRunData:()=>({outputs:[{dims:r,dataType:e.dataType}],dispatchGroup:{x:d},programUniforms:[{type:\"uint32\",data:p}]}),getShaderSource:S}},Fs=(e,t)=>{ic(e.inputs),e.compute(sc(e.inputs[0],t))},js=e=>re({axis:e.axis})});var uc,lc,dc,cc,pc,Ks,Ys,Zs=F(()=>{\"use strict\";me();Ee();be();uc=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},lc=(e,t)=>{let r=[],o=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(n=>r.push(Number(n))),o=r.length),re({numOutputs:o,axis:t.axis,splitSizes:r})},dc=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,cc=e=>{let t=e.length,r=[];for(let o=0;o<t;++o){let n=e[o].setByIndices(\"indices\",\"input[global_idx]\");t===1?r.push(n):o===0?r.push(`if (outputNumber == ${o}u) { ${n} }`):o===t-1?r.push(`else { ${n} }`):r.push(`else if (outputNumber == ${o}) { ${n} }`)}return`\n      fn writeBufferData(outputNumber: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${r.join(`\n`)}\n      }`},pc=(e,t)=>{let r=e[0].dims,o=z.size(r),n=e[0].dataType,s=r.length,u=t.axis,d=u<0?r.length+u:u,a=new Array(t.numOutputs),p=G(\"input\",n,r),h=new Array(t.numOutputs),v=[],y=[],b=0;for(let C=0;C<t.numOutputs;C++){b+=t.splitSizes[C],h[C]=b;let A=r.slice();A[t.axis]=t.splitSizes[C],y.push(A),a[C]=q(`output${C}`,n,y[C]),v.push({dims:y[C],dataType:e[0].dataType})}let w=s<2?\"indices\":`indices[${d}]`,S=C=>`\n  ${C.declareVariables(p,...a)}\n  const sizeInConcatAxis = array<u32, ${h.length}>(${h.map(A=>`${A}u`).join(\",\")});\n  ${dc(h.length)}\n  ${cc(a)}\n\n  ${C.mainStart()}\n    ${C.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n\n    var indices = ${p.offsetToIndices(\"global_idx\")};\n    let outputNumber = calculateOutputIndex(${w});\n    if (outputNumber != 0) {\n        ${w} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:t.cacheKey},getShaderSource:S,getRunData:()=>({outputs:v,dispatchGroup:{x:Math.ceil(o/64)}})}},Ks=(e,t)=>{uc(e.inputs);let r=e.inputs.length===1?t:lc(e.inputs,t);e.compute(pc(e.inputs,r),{inputs:[0]})},Ys=e=>{let t=e.axis,r=e.splitSizes,o=e.numOutputs<0?r.length:e.numOutputs;if(o!==r.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return re({axis:t,numOutputs:o,splitSizes:r})}});var Xs,fc,mc,hc,Qs,Js=F(()=>{\"use strict\";De();me();be();Xs=e=>Array.from(e.getBigInt64Array(),Number),fc=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(Xs(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},mc=(e,t)=>{let r=[];for(let o=0;o<e.length;++o)r.push(e[o]*t[o]);return r},hc=e=>{let t=e[0].dims,r=Xs(e[1]),o=mc(t,r),n=z.size(o),s=e[0].dataType,u=G(\"input\",s,t),d=q(\"output\",s,o),a=p=>`\n      const inputShape = ${u.indices(...t)};\n      ${p.declareVariables(u,d)}\n      ${p.mainStart()}\n      ${p.guardAgainstOutOfBoundsWorkgroupSizes(n)}\n      let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n      var inputIndices: ${u.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let inputDimValue = ${d.indicesGet(\"outputIndices\",\"i\")}  % ${u.indicesGet(\"inputShape\",\"i\")};\n\n        ${u.indicesSet(\"inputIndices\",\"i\",\"inputDimValue\")}\n      }\n      ${d.setByOffset(\"global_idx\",u.getByIndices(\"inputIndices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${r}`},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(n/64)}}),getShaderSource:a}},Qs=e=>{fc(e.inputs),e.compute(hc(e.inputs),{inputs:[0]})}});var gc,yc,eu,tu=F(()=>{\"use strict\";De();me();be();gc=(e,t,r,o,n)=>{let s=z.size(r),u=Math.ceil(s/4),d=q(\"outputData\",n,r,4),a=G(\"aData\",t[1].dataType,t[1].dims,4),p=G(\"bData\",t[2].dataType,t[2].dims,4),h=G(\"cData\",t[0].dataType,t[0].dims,4),v,y=(b,w,S)=>`select(${w}, ${b}, ${S})`;if(!o)v=d.setByOffset(\"global_idx\",y(a.getByOffset(\"global_idx\"),p.getByOffset(\"global_idx\"),h.getByOffset(\"global_idx\")));else{let b=(w,S,C=\"\")=>{let A=`aData[indexA${S}][componentA${S}]`,I=`bData[indexB${S}][componentB${S}]`,B=`bool(cData[indexC${S}] & ${4278190080>>>(3-S)*8}u)`;return`\n            let outputIndices${S} = ${d.offsetToIndices(`global_idx * 4u + ${S}u`)};\n            let offsetA${S} = ${a.broadcastedIndicesToOffset(`outputIndices${S}`,d)};\n            let offsetB${S} = ${p.broadcastedIndicesToOffset(`outputIndices${S}`,d)};\n            let offsetC${S} = ${h.broadcastedIndicesToOffset(`outputIndices${S}`,d)};\n            let indexA${S} = offsetA${S} / 4u;\n            let indexB${S} = offsetB${S} / 4u;\n            let indexC${S} = offsetC${S} / 4u;\n            let componentA${S} = offsetA${S} % 4u;\n            let componentB${S} = offsetB${S} % 4u;\n            ${w}[${S}] = ${C}(${y(A,I,B)});\n          `};n===9?v=`\n            var data = vec4<u32>(0);\n            ${b(\"data\",0,\"u32\")}\n            ${b(\"data\",1,\"u32\")}\n            ${b(\"data\",2,\"u32\")}\n            ${b(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:v=`\n            ${b(\"outputData[global_idx]\",0)}\n            ${b(\"outputData[global_idx]\",1)}\n            ${b(\"outputData[global_idx]\",2)}\n            ${b(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(h,a,p,d)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n        ${v}\n      }`},yc=e=>{let t=e[1].dims,r=e[2].dims,o=e[0].dims,n=e[1].dataType,s=!(z.areEqual(t,r)&&z.areEqual(r,o)),u=t,d=z.size(t);if(s){let a=at.calcShape(at.calcShape(t,r,!1),o,!1);if(!a)throw new Error(\"Can't perform where op on the given tensors\");u=a,d=z.size(u)}return{name:\"Where\",getShaderSource:a=>gc(a,e,u,s,n),getRunData:()=>({outputs:[{dims:u,dataType:n}],dispatchGroup:{x:Math.ceil(d/64/4)}})}},eu=e=>{e.compute(yc(e.inputs))}});var ru,nu=F(()=>{\"use strict\";pa();_n();ga();Ya();ii();li();Pn();Si();Ai();Ei();Pi();Mi();Wi();Ui();Li();ji();Zi();Ji();ms();Bs();zr();zs();Ns();Ls();qs();Zs();Js();Wt();Tn();tu();ru=new Map([[\"Abs\",[ya]],[\"Acos\",[ba]],[\"Acosh\",[wa]],[\"Add\",[Za]],[\"ArgMax\",[ca,An]],[\"ArgMin\",[da,An]],[\"Asin\",[va]],[\"Asinh\",[$a]],[\"Atan\",[Sa]],[\"Atanh\",[xa]],[\"Attention\",[ma,fa]],[\"AveragePool\",[as,os]],[\"BiasAdd\",[ha]],[\"BiasSplitGelu\",[Ka]],[\"Cast\",[Ia,Ca]],[\"Ceil\",[_a]],[\"Clip\",[Aa]],[\"Concat\",[si,ui]],[\"Conv\",[Bn,Rn]],[\"ConvTranspose\",[$i,vi]],[\"Cos\",[Ta]],[\"Cosh\",[Ea]],[\"Div\",[Xa]],[\"Einsum\",[Ci,Ii]],[\"Elu\",[Oa,Nr]],[\"Equal\",[Qa]],[\"Erf\",[ka]],[\"Exp\",[Pa]],[\"Expand\",[Ti]],[\"Floor\",[Ra]],[\"FusedConv\",[Bn,Rn]],[\"Gather\",[ki,Oi]],[\"GatherElements\",[Bi,Ri]],[\"Gelu\",[Ba]],[\"Gemm\",[Di,zi]],[\"GlobalAveragePool\",[us,ss]],[\"GlobalMaxPool\",[fs,ps]],[\"Greater\",[ri]],[\"GreaterOrEqual\",[oi]],[\"InstanceNormalization\",[Ni,Vi]],[\"LayerNormalization\",[Gi,Hi]],[\"LeakyRelu\",[Ma,Nr]],[\"Less\",[ni]],[\"LessOrEqual\",[ai]],[\"Log\",[qa]],[\"MatMul\",[Fi]],[\"MaxPool\",[ds,cs]],[\"Mul\",[Ja]],[\"MultiHeadAttention\",[Yi,Ki]],[\"Neg\",[za]],[\"Not\",[Da]],[\"Pad\",[Xi,Qi]],[\"Pow\",[ei]],[\"Range\",[Rs]],[\"Reciprocal\",[Wa]],[\"ReduceMin\",[oa,tt]],[\"ReduceMean\",[Jo,tt]],[\"ReduceMax\",[na,tt]],[\"ReduceSum\",[ia,tt]],[\"ReduceProd\",[aa,tt]],[\"ReduceL1\",[ea,tt]],[\"ReduceL2\",[ta,tt]],[\"ReduceLogSum\",[ua,tt]],[\"ReduceLogSumExp\",[ra,tt]],[\"ReduceSumSquare\",[sa,tt]],[\"Relu\",[Va]],[\"Resize\",[Ms,Ds]],[\"Sigmoid\",[Na]],[\"Sin\",[Ua]],[\"Sinh\",[Ha]],[\"Slice\",[Hs,Gs]],[\"SkipLayerNormalization\",[Ws,Vs]],[\"Split\",[Ks,Ys]],[\"Sqrt\",[Ga]],[\"Softmax\",[Fs,js]],[\"Sub\",[ti]],[\"Tan\",[La]],[\"Tanh\",[Fa]],[\"ThresholdedRelu\",[ja,Nr]],[\"Tile\",[Qs]],[\"Transpose\",[No,Uo]],[\"Where\",[eu]]])});var Jr,ou=F(()=>{\"use strict\";De();wt();be();Jr=class{constructor(t){this.backend=t;this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,r){this.repo.set(t,r)}run(t,r,o,n,s,u,d){let a=this.backend.device,p=this.backend.getComputePassEncoder();p.setPipeline(t.computePipeline);let h=[];for(let y of n)h.push({binding:h.length,resource:{buffer:y.buffer}});for(let y of s)h.push({binding:h.length,resource:{buffer:y.buffer}});d&&h.push({binding:h.length,resource:d});let v=a.createBindGroup({layout:t.computePipeline.getBindGroupLayout(0),entries:h,label:t.programInfo.name});if(p.setBindGroup(0,v),p.dispatchWorkgroups(...u),this.backend.pendingDispatchNumber++,this.backend.isQueryEnabled()){typeof this.backend.queryData>\"u\"&&(this.backend.queryData=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let y=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet,0,2,this.backend.queryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.queryData.buffer,0,y.buffer,0,this.backend.querySetCount*8),this.backend.flush();let b=this.backend.currentKernelId,w=this.backend.kernels.get(b),S=`[${w[0]}] ${w[1]}`;y.buffer.mapAsync(GPUMapMode.READ).then(()=>{let C=new BigUint64Array(y.buffer.getMappedRange()),A=C[0],I=C[1];y.buffer.unmap(),typeof this.backend.queryTimeBase>\"u\"&&(this.backend.queryTimeBase=A);let B=Number(A-this.backend.queryTimeBase),_=Number(I-this.backend.queryTimeBase);if(!Number.isSafeInteger(B)||!Number.isSafeInteger(_))throw new RangeError(\"incorrect timestamp range\");this.backend.gpuDataManager.release(y.id);let R=\"\";r.forEach((W,V)=>{R+=`input[${V}]: [${W.dims}] | ${or(W.dataType)}, `});let E=\"\";o.forEach((W,V)=>{E+=`output[${V}]: [${W.dims}] | ${or(W.dataType)}, `}),console.log(`[profiling] kernel \"${b}|${S}\" ${R}${E}execution time: ${_-B} ns`)})}this.backend.pendingDispatchNumber>=16&&this.backend.flush()}dispose(){}build(t,r){let o=this.backend.device,n=[];o.features.has(\"shader-f16\")&&n.push(\"enable f16;\");let s=Wo(r),u=t.getShaderSource(s),d=`${n.join(`\n`)}\n${s.additionalImplementations}\n${u}`,a=o.createShaderModule({code:d,label:t.name});Te(\"verbose\",()=>`[WebGPU] ${t.name} shader code: ${d}`);let p=o.createComputePipeline({compute:{module:a,entryPoint:\"main\"},layout:\"auto\",label:t.name});return{programInfo:t,computePipeline:p}}normalizeDispatchGroupSize(t){let r=typeof t==\"number\"?t:t.x,o=typeof t==\"number\"?1:t.y||1,n=typeof t==\"number\"?1:t.z||1,s=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(r<=s&&o<=s&&n<=s)return[r,o,n];let u=r*o*n,d=Math.ceil(Math.sqrt(u));if(d>s){if(d=Math.ceil(Math.cbrt(u)),d>s)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[d,d,d]}else return[d,d,1]}}});var bc,wc,en,au=F(()=>{\"use strict\";wt();ko();Mo();nu();ou();bc=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let r=[];for(let o=0;o<e.length;++o){let n=e[o].dataType;switch(t[o]){case\"none\":{r.push(\"\");break}case\"type\":{r.push(`${n}`);break}case\"rank\":{let s=e[o].dims.length;r.push(`${n};${s}`);break}case\"dims\":{let s=e[o].dims.join(\",\");r.push(`${n};${s}`);break}default:throw new Error(`unsupported input dependency: ${t[o]}`)}}return r.join(\"|\")},wc=(e,t,r)=>{let o=e.name;return e.shaderCache?.hint&&(o+=\"[\"+e.shaderCache.hint+\"]\"),o+=\":\"+r+`:${bc(t,e.shaderCache?.inputDependencies??new Array(t.length).fill(\"dims\"))}`,o},en=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.querySetCount=2;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let t=this.kernelCustomData.get(this.currentKernelId);return t||(t={},this.kernelCustomData.set(this.currentKernelId,t)),t}async initialize(t){if(!navigator.gpu)throw new Error(\"WebGpuBackend: WebGPU is not available.\");let r=await navigator.gpu.requestAdapter();if(!r)throw new Error(\"WebGpuBackend: Failed to get GPU adapter.\");this.env=t;let o=[],n={requiredLimits:{maxComputeWorkgroupStorageSize:r.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:r.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:r.limits.maxStorageBufferBindingSize,maxBufferSize:r.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:r.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:r.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:r.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:r.limits.maxComputeWorkgroupSizeZ},requiredFeatures:o};r.features.has(\"timestamp-query\")&&o.push(\"timestamp-query\"),r.features.has(\"shader-f16\")&&o.push(\"shader-f16\"),this.device=await r.requestDevice(n),this.gpuDataManager=Bo(this),this.programManager=new Jr(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,Eo(t.logLevel,!!t.debug),this.device.onuncapturederror=s=>{s.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${s.error.message}`)},Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){typeof this.querySet<\"u\"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let t={};this.isQueryEnabled()&&(typeof this.querySet>\"u\"&&(this.querySet=this.device.createQuerySet({type:\"timestamp\",count:this.querySetCount})),t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:0,endOfPassWriteIndex:1}),this.computePassEncoder=this.getCommandEncoder().beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}isQueryEnabled(){return!!(this.device.features.has(\"timestamp-query\")&&this.env.webgpu.profilingMode===\"default\")}run(t,r,o,n,s){let u=[];for(let I=0;I<r.length;++I){let B=this.gpuDataManager.get(r[I].data);if(!B)throw new Error(`no GPU data for input: ${r[I].data}`);u[I]=B}let{outputs:d,dispatchGroup:a,programUniforms:p}=t.getRunData(r),h=o.length===0?d.map((I,B)=>B):o;if(h.length!==d.length)throw new Error(`Output size ${h.length} must be equal to ${d.length}.`);let v=[],y=[];for(let I=0;I<d.length;++I){if(!Number.isInteger(h[I])||h[I]<-3||h[I]>=d.length)throw new Error(`Invalid output index: ${h[I]}`);if(h[I]===-3)continue;let B=h[I]===-1,_=h[I]===-2,R=B||_?s(d[I].dataType,d[I].dims):n(h[I],d[I].dataType,d[I].dims),E=this.gpuDataManager.get(R.data);if(!E)throw new Error(`no GPU data for output: ${R.data}`);if(B&&this.temporaryData.push(E),_){let W=this.kernelPersistentData.get(this.currentKernelId);W||(W=[],this.kernelPersistentData.set(this.currentKernelId,W)),W.push(E)}v.push(R),y.push(E)}let b;if(p){let I=0,B=0,_=[],R=1;p.forEach(V=>{let Y=typeof V.data==\"number\"?[V.data]:V.data;if(Y.length===0)return;let ae;switch(Y.length){case 1:ae=4;break;case 2:ae=8;break;case 3:ae=16;break;case 4:ae=16;break;case 5:ae=16;break;case 6:ae=16;break;default:throw new Error(`unsupported data length: ${Y.length}`)}(B===5||B===6)&&(ae=16),ae>R&&(R=ae),I=Math.ceil(I/ae)*ae,B=Y.length,_.push(I),I+=Y.length*4}),I=Math.ceil(I/R)*R;let E=new ArrayBuffer(I);p.forEach((V,Y)=>{let ae=_[Y],M=typeof V.data==\"number\"?[V.data]:V.data;V.type===\"int32\"?new Int32Array(E,ae,M.length).set(M):V.type===\"uint32\"?new Uint32Array(E,ae,M.length).set(M):new Float32Array(E,ae,M.length).set(M)});let W=this.gpuDataManager.create(I,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(W.buffer,0,E,0,I),this.gpuDataManager.release(W.id),b={offset:0,size:I,buffer:W.buffer}}let w=this.programManager.normalizeDispatchGroupSize(a),S=w[1]===1&&w[2]===1,C=wc(t,r,S),A=this.programManager.getArtifact(C);return A||(A=this.programManager.build(t,w),this.programManager.setArtifact(C,A)),Te(\"info\",()=>`[ProgramManager] run \"${t.name}\" (key=${C}) with ${w[0]}x${w[1]}x${w[2]}`),this.programManager.run(A,r,v,u,y,w,b),v}upload(t,r){this.gpuDataManager.upload(t,r)}memcpy(t,r){this.gpuDataManager.memcpy(t,r)}async download(t,r){await this.gpuDataManager.download(t,r)}alloc(t){return this.gpuDataManager.create(t).id}free(t){return this.gpuDataManager.release(t)}createKernel(t,r,o,n){let s=ru.get(t);if(!s)throw new Error(`kernel not implemented: ${t}`);this.kernels.set(r,[t,n,s[0],[s[1],o]])}releaseKernel(t){let r=this.kernelPersistentData.get(t);if(r){for(let o of r)this.gpuDataManager.release(o.id);this.kernelPersistentData.delete(t)}this.kernelCustomData.delete(t),this.kernels.delete(t)}computeKernel(t,r,o){let n=this.kernels.get(t);if(!n)throw new Error(`kernel not created: ${t}`);let[s,u,d,a]=n;if(this.currentKernelId!==null)throw new Error(`kernel \"[${s}] ${u}\" is not allowed to be called recursively`);this.currentKernelId=t,a[0]&&(a[1]=a[0](a[1]),a[0]=void 0),Te(\"info\",()=>`[WebGPU] Start to run kernel \"[${s}] ${u}\"...`);let p=this.env.debug;this.temporaryData=[];try{return p&&this.device.pushErrorScope(\"validation\"),d(r,a[1]),0}catch(h){return o.push(Promise.resolve(`[WebGPU] Kernel \"[${s}] ${u}\" failed. ${h}`)),1}finally{p&&o.push(this.device.popErrorScope().then(h=>h?`GPU validation error for kernel \"[${s}] ${u}\": ${h.message}`:null));for(let h of this.temporaryData)this.gpuDataManager.release(h.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(t,r,o,n){let s=this.sessionExternalDataMapping.get(t);s||(s=new Map,this.sessionExternalDataMapping.set(t,s));let u=s.get(r),d=this.gpuDataManager.registerExternalBuffer(o,n,u?.[1]);return s.set(r,[d,o]),d}unregisterBuffers(t){let r=this.sessionExternalDataMapping.get(t);r&&(r.forEach(o=>this.gpuDataManager.unregisterExternalBuffer(o[1])),this.sessionExternalDataMapping.delete(t))}getBuffer(t){let r=this.gpuDataManager.get(t);if(!r)throw new Error(`no GPU data for buffer: ${t}`);return r.buffer}createDownloader(t,r,o){return async()=>{let n=await vn(this,t,r);return Oo(n.buffer,o)}}}});var iu={};Er(iu,{init:()=>vc});var dr,Un,vc,su=F(()=>{\"use strict\";De();au();wt();me();dr=class e{constructor(t,r,o,n){this.module=t;this.dataType=r;this.data=o;this.dims=n}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,t)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,t)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,t)}reshape(t){if(z.size(t)!==z.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,t)}},Un=class{constructor(t,r,o){this.module=t;this.backend=r;this.customDataOffset=0;this.customDataSize=0;let n=t.HEAPU32,s=o>>2;this.opKernelContext=n[s++];let u=n[s++];this.outputCount=n[s++],this.customDataOffset=n[s++],this.customDataSize=n[s++];let d=[];for(let a=0;a<u;a++){let p=n[s++],h=n[s++],v=n[s++],y=[];for(let b=0;b<v;b++)y.push(n[s++]);d.push(new dr(t,p,h,y))}this.inputs=d}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(t,r){let o=r?.inputs?.map(d=>typeof d==\"number\"?this.inputs[d]:d)??this.inputs,n=r?.outputs??[],s=(d,a,p)=>new dr(this.module,a,this.output(d,p),p),u=(d,a)=>{let p=ar(d);if(!p)throw new Error(`Unsupported data type: ${d}`);let h=p*z.size(a);return new dr(this.module,d,this.backend.gpuDataManager.create(h).id,a)};return this.backend.run(t,o,n,s,u)}output(t,r){let o=this.module.stackSave();try{let n=this.module.stackAlloc((1+r.length)*4),s=n>>2;this.module.HEAPU32[s++]=r.length;for(let u=0;u<r.length;u++)this.module.HEAPU32[s++]=r[u];return this.module._JsepOutput(this.opKernelContext,t,n)}catch(n){throw new Error(`Failed to generate kernel's output[${t}] with dims [${r}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n}`)}finally{this.module.stackRestore(o)}}},vc=async(e,t)=>{let r=e.jsepInit;if(r&&navigator.gpu){if(!t.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP\");let o=new en;await o.initialize(t),r(o,n=>o.alloc(n),n=>o.free(n),(n,s,u,d=!1)=>{if(d)Te(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${n}, dst=${s}, size=${u}`),o.memcpy(n,s);else{Te(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${n}, gpuDataId=${s}, size=${u}`);let a=e.HEAPU8.subarray(n,n+u);o.upload(s,a)}},async(n,s,u)=>{Te(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${n}, dataOffset=${s}, size=${u}`),await o.download(n,()=>e.HEAPU8.subarray(s,s+u))},(n,s,u)=>o.createKernel(n,s,u,t.debug||t.webgpu.profilingMode===\"default\"?e.UTF8ToString(e._JsepGetNodeName(s)):`${s}`),n=>o.releaseKernel(n),(n,s,u,d)=>{Te(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${u}, kernel=${n}, contextDataOffset=${s}`);let a=new Un(e,o,s);return o.computeKernel(n,a,d)})}}});var So;So=po();var Wu=wo(),hn,gn=!1,Or=!1,$o=!1,Vu=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},Nu=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},Uu=(e,t)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":t?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",xo=async e=>{if(gn)return Promise.resolve();if(Or)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if($o)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");Or=!0;let t=e.initTimeout,r=e.numThreads,o=e.simd,n=r>1&&Vu(),s=o&&Nu(),u=e.wasmPaths,d=typeof u==\"string\"?u:void 0,a=Uu(s,n),p=typeof u==\"object\"?u[a]:void 0,h=!1,v=[];if(t>0&&v.push(new Promise(y=>{setTimeout(()=>{h=!0,y()},t)})),v.push(new Promise((y,b)=>{let w=n?Wu:So,S={locateFile:(C,A)=>{if(n&&C.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([vo()],{type:\"text/javascript\"}));if(C.endsWith(\".wasm\")){if(p)return p;let I=d??A;return a===\"ort-wasm-simd.wasm\"?I+\"ort-wasm-simd.jsep.wasm\":a===\"ort-wasm-simd-threaded.wasm\"?I+\"ort-wasm-simd-threaded.jsep.wasm\":I+a}return A+C}};if(n)if(typeof Blob>\"u\")S.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let C=`var ortWasmThreaded=${w.toString()};`;S.mainScriptUrlOrBlob=new Blob([C],{type:\"text/javascript\"})}w(S).then(C=>{Or=!1,gn=!0,hn=C,y()},C=>{Or=!1,$o=!0,b(C)})})),await Promise.race(v),h)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},ke=()=>{if(gn&&hn)return hn;throw new Error(\"WebAssembly is not initialized yet.\")};var Be=(e,t)=>{let r=ke(),o=r.lengthBytesUTF8(e)+1,n=r._malloc(o);return r.stringToUTF8(e,n,o),t.push(n),n},nr=(e,t,r,o)=>{if(typeof e==\"object\"&&e!==null){if(r.has(e))throw new Error(\"Circular reference in options\");r.add(e)}Object.entries(e).forEach(([n,s])=>{let u=t?t+n:n;if(typeof s==\"object\")nr(s,u+\".\",r,o);else if(typeof s==\"string\"||typeof s==\"number\")o(u,s.toString());else if(typeof s==\"boolean\")o(u,s?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof s}`)})},Ae=e=>{let t=ke(),r=t.stackSave();try{let o=t.stackAlloc(8);t._OrtGetLastError(o,o+4);let n=t.HEAP32[o/4],s=t.HEAPU32[o/4+1],u=s?t.UTF8ToString(s):\"\";throw new Error(`${e} ERROR_CODE: ${n}, ERROR_MESSAGE: ${u}`)}finally{t.stackRestore(r)}};var Co=e=>{let t=ke(),r=0,o=[],n=e||{};try{if(e?.logSeverityLevel===void 0)n.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)n.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(n.terminate=!1);let s=0;return e?.tag!==void 0&&(s=Be(e.tag,o)),r=t._OrtCreateRunOptions(n.logSeverityLevel,n.logVerbosityLevel,!!n.terminate,s),r===0&&Ae(\"Can't create run options.\"),e?.extra!==void 0&&nr(e.extra,\"\",new WeakSet,(u,d)=>{let a=Be(u,o),p=Be(d,o);t._OrtAddRunConfigEntry(r,a,p)!==0&&Ae(`Can't set a run config entry: ${u} - ${d}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseRunOptions(r),o.forEach(u=>t._free(u)),s}};var Hu=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Gu=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},Lu=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(r=>(typeof r==\"string\"?r:r.name)===\"webgpu\")&&(e.enableMemPattern=!1)},Fu=(e,t,r)=>{for(let o of t){let n=typeof o==\"string\"?o:o.name;switch(n){case\"xnnpack\":n=\"XNNPACK\";break;case\"webnn\":if(n=\"WEBNN\",typeof o!=\"string\"){let u=o;if(u?.deviceType){let d=Be(\"deviceType\",r),a=Be(u.deviceType,r);ke()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'deviceType' - ${u.deviceType}.`)}if(u?.numThreads){let d=u.numThreads;(typeof d!=\"number\"||!Number.isInteger(d)||d<0)&&(d=0);let a=Be(\"numThreads\",r),p=Be(d.toString(),r);ke()._OrtAddSessionConfigEntry(e,a,p)!==0&&Ae(`Can't set a session config entry: 'numThreads' - ${u.numThreads}.`)}if(u?.powerPreference){let d=Be(\"powerPreference\",r),a=Be(u.powerPreference,r);ke()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'powerPreference' - ${u.powerPreference}.`)}}break;case\"webgpu\":if(n=\"JS\",typeof o!=\"string\"){let u=o;if(u?.preferredLayout){if(u.preferredLayout!==\"NCHW\"&&u.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${u.preferredLayout}`);let d=Be(\"preferredLayout\",r),a=Be(u.preferredLayout,r);ke()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'preferredLayout' - ${u.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${n}`)}let s=Be(n,r);ke()._OrtAppendExecutionProvider(e,s)!==0&&Ae(`Can't append execution provider: ${n}.`)}},Io=e=>{let t=ke(),r=0,o=[],n=e||{};Lu(n);try{let s=Hu(n.graphOptimizationLevel??\"all\"),u=Gu(n.executionMode??\"sequential\"),d=typeof n.logId==\"string\"?Be(n.logId,o):0,a=n.logSeverityLevel??2;if(!Number.isInteger(a)||a<0||a>4)throw new Error(`log serverity level is not valid: ${a}`);let p=n.logVerbosityLevel??0;if(!Number.isInteger(p)||p<0||p>4)throw new Error(`log verbosity level is not valid: ${p}`);let h=typeof n.optimizedModelFilePath==\"string\"?Be(n.optimizedModelFilePath,o):0;if(r=t._OrtCreateSessionOptions(s,!!n.enableCpuMemArena,!!n.enableMemPattern,u,!!n.enableProfiling,0,d,a,p,h),r===0&&Ae(\"Can't create session options.\"),n.executionProviders&&Fu(r,n.executionProviders,o),n.freeDimensionOverrides)for(let[v,y]of Object.entries(n.freeDimensionOverrides)){if(typeof v!=\"string\")throw new Error(`free dimension override name must be a string: ${v}`);if(typeof y!=\"number\"||!Number.isInteger(y)||y<0)throw new Error(`free dimension override value must be a non-negative integer: ${y}`);let b=Be(v,o);t._OrtAddFreeDimensionOverride(r,b,y)!==0&&Ae(`Can't set a free dimension override: ${v} - ${y}.`)}return n.extra!==void 0&&nr(n.extra,\"\",new WeakSet,(v,y)=>{let b=Be(v,o),w=Be(y,o);t._OrtAddSessionConfigEntry(r,b,w)!==0&&Ae(`Can't set a session config entry: ${v} - ${y}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseSessionOptions(r),o.forEach(u=>t._free(u)),s}};De();var lu=!1,$c=e=>{let t=ke(),r=t.stackSave();try{let o=t.stackAlloc(8);return t._OrtGetInputOutputCount(e,o,o+4)!==0&&Ae(\"Can't get session input/output count.\"),[t.HEAP32[o/4],t.HEAP32[o/4+1]]}finally{t.stackRestore(r)}},Sc=(e,t)=>{ke()._OrtInit(e,t)!==0&&Ae(\"Can't initialize onnxruntime.\")},du=async e=>{Sc(e.wasm.numThreads,ir(e.logLevel));{let t=(su(),zt(iu)).init;await t(ke(),e)}lu=!0},cr=new Map,cu=()=>lu,Hn=e=>{let t=ke(),r=t._malloc(e.byteLength);if(r===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},Gn=(e,t)=>{let r=ke(),o=0,n=0,s=0,u=[],d=[],a=[];try{[n,u]=Io(t),o=r._OrtCreateSession(e[0],e[1],n),o===0&&Ae(\"Can't create a session.\");let[p,h]=$c(o),v=[],y=[],b=[];for(let S=0;S<p;S++){let C=r._OrtGetInputName(o,S);C===0&&Ae(\"Can't get an input name.\"),d.push(C),v.push(r.UTF8ToString(C))}for(let S=0;S<h;S++){let C=r._OrtGetOutputName(o,S);C===0&&Ae(\"Can't get an output name.\"),a.push(C);let A=r.UTF8ToString(C);y.push(A);{let I=typeof t?.preferredOutputLocation==\"string\"?t.preferredOutputLocation:t?.preferredOutputLocation?.[A]??\"cpu\";if(I!==\"cpu\"&&I!==\"cpu-pinned\"&&I!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${I}.`);b.push(I)}}let w=null;return b.some(S=>S===\"gpu-buffer\")&&(s=r._OrtCreateBinding(o),s===0&&Ae(\"Can't create IO binding.\"),w={handle:s,outputPreferredLocations:b,outputPreferredLocationsEncoded:b.map(S=>bn(S))}),cr.set(o,[o,d,a,w]),[o,v,y]}catch(p){throw d.forEach(h=>r._OrtFree(h)),a.forEach(h=>r._OrtFree(h)),s!==0&&r._OrtReleaseBinding(s),o!==0&&r._OrtReleaseSession(o),p}finally{r._free(e[0]),n!==0&&r._OrtReleaseSessionOptions(n),u.forEach(p=>r._free(p))}},pu=(e,t)=>{let r=Hn(e);return Gn(r,t)},fu=e=>{let t=ke(),r=cr.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);let[o,n,s,u]=r;u&&t._OrtReleaseBinding(u.handle),t.jsepUnregisterBuffers?.(e),n.forEach(d=>t._OrtFree(d)),s.forEach(d=>t._OrtFree(d)),t._OrtReleaseSession(o),cr.delete(e)},uu=(e,t,r,o,n)=>{if(!e){t.push(0);return}let s=ke(),u=e[0],d=e[1],a=e[3],p,h;if(u===\"string\"&&a===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(a===\"gpu-buffer\"){let b=e[2].gpuBuffer,w=ar(yn(u));h=d.reduce((S,C)=>S*C,1)*w,p=s.jsepRegisterBuffer(o,n,b,h)}else{let b=e[2];if(Array.isArray(b)){h=4*b.length,p=s._malloc(h),r.push(p);let w=p/4;for(let S=0;S<b.length;S++){if(typeof b[S]!=\"string\")throw new TypeError(`tensor data at index ${S} is not a string`);s.HEAPU32[w++]=Be(b[S],r)}}else h=b.byteLength,p=s._malloc(h),r.push(p),s.HEAPU8.set(new Uint8Array(b.buffer,b.byteOffset,h),p)}let v=s.stackSave(),y=s.stackAlloc(4*d.length);try{let b=y/4;d.forEach(S=>s.HEAP32[b++]=S);let w=s._OrtCreateTensor(yn(u),p,h,y,d.length,bn(a));w===0&&Ae(`Can't create tensor for input/output. session=${o}, index=${n}.`),t.push(w)}finally{s.stackRestore(v)}},mu=async(e,t,r,o,n,s)=>{let u=ke(),d=cr.get(e);if(!d)throw new Error(`cannot run inference. invalid session id: ${e}`);let[a,p,h,v]=d,y=t.length,b=o.length,w=0,S=[],C=[],A=[],I=[],B=u.stackSave(),_=u.stackAlloc(y*4),R=u.stackAlloc(y*4),E=u.stackAlloc(b*4),W=u.stackAlloc(b*4);try{[w,S]=Co(s);for(let ue=0;ue<y;ue++)uu(r[ue],C,I,e,t[ue]);for(let ue=0;ue<b;ue++)uu(n[ue],A,I,e,y+o[ue]);let V=_/4,Y=R/4,ae=E/4,M=W/4;for(let ue=0;ue<y;ue++)u.HEAPU32[V++]=C[ue],u.HEAPU32[Y++]=p[t[ue]];for(let ue=0;ue<b;ue++)u.HEAPU32[ae++]=A[ue],u.HEAPU32[M++]=h[o[ue]];if(v){let{handle:ue,outputPreferredLocations:ve,outputPreferredLocationsEncoded:j}=v;if(p.length!==y)throw new Error(`input count from feeds (${y}) is expected to be always equal to model's input count (${p.length}).`);for(let xe=0;xe<y;xe++){let Pe=t[xe];await u._OrtBindInput(ue,p[Pe],C[xe])!==0&&Ae(`Can't bind input[${xe}] for session=${e}.`)}for(let xe=0;xe<b;xe++){let Pe=o[xe];n[xe]?.[3]?u._OrtBindOutput(ue,h[Pe],A[xe],0)!==0&&Ae(`Can't bind pre-allocated output[${xe}] for session=${e}.`):u._OrtBindOutput(ue,h[Pe],0,j[Pe])!==0&&Ae(`Can't bind output[${xe}] to ${ve[xe]} for session=${e}.`)}}let K;v?K=await u._OrtRunWithBinding(a,v.handle,b,E,w):K=await u._OrtRun(a,R,_,y,W,b,E,w),K!==0&&Ae(\"failed to call OrtRun().\");let Se=[];for(let ue=0;ue<b;ue++){let ve=u.HEAPU32[E/4+ue];if(ve===A[ue]){Se.push(n[ue]);continue}let j=u.stackSave(),xe=u.stackAlloc(4*4),Pe=!1,_e,Ce=0;try{u._OrtGetTensorData(ve,xe,xe+4,xe+8,xe+12)!==0&&Ae(`Can't access output tensor data on index ${ue}.`);let Le=xe/4,je=u.HEAPU32[Le++];Ce=u.HEAPU32[Le++];let L=u.HEAPU32[Le++],de=u.HEAPU32[Le++],pe=[];for(let Oe=0;Oe<de;Oe++)pe.push(u.HEAPU32[L/4+Oe]);u._OrtFree(L);let We=pe.reduce((Oe,Me)=>Oe*Me,1);_e=or(je);let Fe=v?.outputPreferredLocations[o[ue]];if(_e===\"string\"){if(Fe===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Oe=[],Me=Ce/4;for(let He=0;He<We;He++){let rt=u.HEAPU32[Me++],qe=He===We-1?void 0:u.HEAPU32[Me]-rt;Oe.push(u.UTF8ToString(rt,qe))}Se.push([_e,pe,Oe,\"cpu\"])}else if(Fe===\"gpu-buffer\"&&We>0){let Oe=u.jsepGetBuffer(Ce),Me=ar(je);if(Me===void 0||!Ao(_e))throw new Error(`Unsupported data type: ${_e}`);Pe=!0,Se.push([_e,pe,{gpuBuffer:Oe,download:u.jsepCreateDownloader(Oe,We*Me,_e),dispose:()=>{u._OrtReleaseTensor(ve)}},\"gpu-buffer\"])}else{let Oe=kr(_e),Me=new Oe(We);new Uint8Array(Me.buffer,Me.byteOffset,Me.byteLength).set(u.HEAPU8.subarray(Ce,Ce+Me.byteLength)),Se.push([_e,pe,Me,\"cpu\"])}}finally{u.stackRestore(j),_e===\"string\"&&Ce&&u._free(Ce),Pe||u._OrtReleaseTensor(ve)}}return v&&u._OrtClearBoundOutputs(v.handle),Se}finally{u.stackRestore(B),C.forEach(V=>u._OrtReleaseTensor(V)),A.forEach(V=>u._OrtReleaseTensor(V)),I.forEach(V=>u._free(V)),w!==0&&u._OrtReleaseRunOptions(w),S.forEach(V=>u._free(V))}},hu=e=>{let t=ke(),r=cr.get(e);if(!r)throw new Error(\"invalid session id\");let o=r[0],n=t._OrtEndProfiling(o);n===0&&Ae(\"Can't get an profile file name.\"),t._OrtFree(n)},gu=e=>{let t=[];for(let r of e){let o=r[2];!Array.isArray(o)&&\"buffer\"in o&&t.push(o.buffer)}return t};self.onmessage=e=>{switch(e.data.type){case\"init-wasm\":try{xo(e.data.in).then(()=>postMessage({type:\"init-wasm\"}),t=>postMessage({type:\"init-wasm\",err:t}))}catch(t){postMessage({type:\"init-wasm\",err:t})}break;case\"init-ort\":try{du(e.data.in).then(()=>postMessage({type:\"init-ort\"}),t=>postMessage({type:\"init-ort\",err:t}))}catch(t){postMessage({type:\"init-ort\",err:t})}break;case\"create_allocate\":try{let{model:t}=e.data.in,r=Hn(t);postMessage({type:\"create_allocate\",out:r})}catch(t){postMessage({type:\"create_allocate\",err:t})}break;case\"create_finalize\":try{let{modeldata:t,options:r}=e.data.in,o=Gn(t,r);postMessage({type:\"create_finalize\",out:o})}catch(t){postMessage({type:\"create_finalize\",err:t})}break;case\"create\":try{let{model:t,options:r}=e.data.in,o=pu(t,r);postMessage({type:\"create\",out:o})}catch(t){postMessage({type:\"create\",err:t})}break;case\"release\":try{fu(e.data.in),postMessage({type:\"release\"})}catch(t){postMessage({type:\"release\",err:t})}break;case\"run\":try{let{sessionId:t,inputIndices:r,inputs:o,outputIndices:n,options:s}=e.data.in;mu(t,r,o,n,new Array(n.length).fill(null),s).then(u=>{u.some(d=>d[3]!==\"cpu\")?postMessage({type:\"run\",err:\"Proxy does not support non-cpu tensor location.\"}):postMessage({type:\"run\",out:u},gu(u))},u=>{postMessage({type:\"run\",err:u})})}catch(t){postMessage({type:\"run\",err:t})}break;case\"end-profiling\":try{let t=e.data.in;hu(t),postMessage({type:\"end-profiling\"})}catch(t){postMessage({type:\"end-profiling\",err:t})}break;case\"is-ort-env-initialized\":try{let t=cu();postMessage({type:\"is-ort-env-initialized\",out:t})}catch(t){postMessage({type:\"is-ort-env-initialized\",err:t})}break;default:}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\n// resolve; reject\ntype PromiseCallbacks<T = void> = [(result: T) => void, (reason: unknown) => void];\n\nlet initWasmCallbacks: PromiseCallbacks;\nlet initOrtCallbacks: PromiseCallbacks;\nconst createSessionAllocateCallbacks: Array<PromiseCallbacks<SerializableModeldata>> = [];\nconst createSessionFinalizeCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst createSessionCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst releaseSessionCallbacks: Array<PromiseCallbacks<void>> = [];\nconst runCallbacks: Array<PromiseCallbacks<SerializableTensorMetadata[]>> = [];\nconst endProfilingCallbacks: Array<PromiseCallbacks<void>> = [];\nconst isOrtEnvInitializedCallbacks: Array<PromiseCallbacks<boolean>> = [];\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ort':\n      if (ev.data.err) {\n        initOrtCallbacks[1](ev.data.err);\n      } else {\n        initOrtCallbacks[0]();\n      }\n      break;\n    case 'create_allocate':\n      if (ev.data.err) {\n        createSessionAllocateCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionAllocateCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create_finalize':\n      if (ev.data.err) {\n        createSessionFinalizeCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionFinalizeCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create':\n      if (ev.data.err) {\n        createSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'release':\n      if (ev.data.err) {\n        releaseSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        releaseSessionCallbacks.shift()![0]();\n      }\n      break;\n    case 'run':\n      if (ev.data.err) {\n        runCallbacks.shift()![1](ev.data.err);\n      } else {\n        runCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'end-profiling':\n      if (ev.data.err) {\n        endProfilingCallbacks.shift()![1](ev.data.err);\n      } else {\n        endProfilingCallbacks.shift()![0]();\n      }\n      break;\n    case 'is-ort-env-initialized':\n      if (ev.data.err) {\n        isOrtEnvInitializedCallbacks.shift()![1](ev.data.err);\n      } else {\n        isOrtEnvInitializedCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyInstance = async(): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    if (initialized) {\n      return;\n    }\n    if (initializing) {\n      throw new Error('multiple calls to \\'initWasm()\\' detected.');\n    }\n    if (aborted) {\n      throw new Error('previous call to \\'initWasm()\\' failed.');\n    }\n\n    initializing = true;\n\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env.wasm};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    return initializeWebAssembly(env.wasm);\n  }\n};\n\nexport const initializeRuntime = async(env: Env): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      initOrtCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-ort', in : env};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initRuntime(env);\n  }\n};\n\nexport const createSessionAllocate = async(model: Uint8Array): Promise<SerializableModeldata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableModeldata>((resolve, reject) => {\n      createSessionAllocateCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create_allocate', in : {model}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSessionAllocate(model);\n  }\n};\n\nexport const createSessionFinalize = async(modeldata: SerializableModeldata, options?: InferenceSession.SessionOptions):\n    Promise<SerializableSessionMetadata> => {\n      if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n        ensureWorker();\n        return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n          createSessionFinalizeCallbacks.push([resolve, reject]);\n          const message: OrtWasmMessage = {type: 'create_finalize', in : {modeldata, options}};\n          proxyWorker!.postMessage(message);\n        });\n      } else {\n        return core.createSessionFinalize(modeldata, options);\n      }\n    };\n\nexport const createSession =\n    async(model: Uint8Array, options?: InferenceSession.SessionOptions): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      createSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      releaseSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      runCallbacks.push([resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      endProfilingCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n\nexport const isOrtEnvInitialized = async(): Promise<boolean> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<boolean>((resolve, reject) => {\n      isOrtEnvInitializedCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'is-ort-env-initialized'};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    return core.isOrtEnvInitialized();\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {env, InferenceSession, InferenceSessionHandler, SessionHandler, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, TensorMetadata} from './proxy-messages';\nimport {createSession, createSessionAllocate, createSessionFinalize, endProfiling, initializeRuntime, isOrtEnvInitialized, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nlet runtimeInitializationPromise: Promise<void>|undefined;\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async createSessionAllocate(path: string): Promise<SerializableModeldata> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return createSessionAllocate(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    if (!(await isOrtEnvInitialized())) {\n      if (!runtimeInitializationPromise) {\n        runtimeInitializationPromise = initializeRuntime(env);\n      }\n      await runtimeInitializationPromise;\n      runtimeInitializationPromise = undefined;\n    }\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        const model = await readFile(pathOrBuffer);\n        [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n      } else {\n        // browser\n        // fetch model and move to wasm heap.\n        const modelData: SerializableModeldata = await this.createSessionAllocate(pathOrBuffer);\n        // create the session\n        [this.sessionId, this.inputNames, this.outputNames] = await createSessionFinalize(modelData, options);\n      }\n    } else {\n      [this.sessionId, this.inputNames, this.outputNames] = await createSession(pathOrBuffer, options);\n    }\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeWebAssemblyInstance} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  async init(): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyInstance();\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU && typeof navigator !== 'undefined' && navigator.gpu) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    registerBackend('webnn', wasmBackend, 9);\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n"],
  "mappings": ";;;;;miBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,EAAA,KAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAI,GAEpD,MAAMA,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,EAAA,KA2EAC,OC3EA,IAMaC,GANbC,GAAAC,EAAA,KAMaF,GAAU,WCNvB,IAQIG,GAESC,GAVbC,GAAAC,EAAA,KAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IAmKaM,GAnKbC,GAAAC,EAAA,KAGAC,KAgKaH,GAAWA,KCnKxB,IASaI,GA0FAC,GAnGbC,GAAAC,EAAA,KASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,GAAMnB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1E,EAAIM,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAM,EAAI,IACxEhB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEiB,EACJ,GAAIjB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAgB,EACApB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBqB,EAAWrB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBqB,EAAWrB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcoB,IAAa,GAAKpB,EAAQ,SAAW,QACrEoB,IAAa,GAAMpB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMqB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEf,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BU,EAAQjB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBmB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMP,IAC/FK,EAAM,KAAKG,CAAa,GAAMvB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKI,CAAa,GAAMxB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKK,CAAa,GAAMzB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKM,CAAa,EAAIZ,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOY,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,EAAA,KAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,EAAA,KAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,EAAA,KAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,EAAA,KAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,EAAA,KAIAC,KAoUaH,GAASA,KCxUtB,IAeaI,GAfbC,GAAAC,EAAA,KAGAC,KAIAC,KAQaJ,GAAP,MAAOK,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1E,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOJ,GAAU,UAAYA,IAAU,MAAQA,aAAiBK,IAAU,MAAM,QAAQL,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIM,EAAiB,GAErB,GAAI,OAAOL,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBI,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQJ,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DK,EAAiB,GAEjB,QAAWC,KAAQN,EAAM,CACvB,GAAI,OAAOM,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIM,EAAY,GACVC,EAAW,OAAO,oBAAoBR,CAAI,EAChD,QAAWM,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKT,EAA4DM,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDE,EAAUH,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWM,KAAQ,KAAK,WACtB,GAAI,OAAOP,EAAMO,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIX,EAAOG,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTG,EAAyCd,EAA8BC,EACvEc,EAAqB,CAEvB,IAAIC,EACAb,EAA0B,CAAA,EAE9B,GAAI,OAAOW,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7Cc,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDc,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOjB,GAAS,SAAU,CAE5B,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCZ,EAAUY,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOd,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDgB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMjB,EAAQ,oBAAsB,CAAA,GACjB,IAAIkB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DvB,EAAU,MADA,MAAMwB,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBb,CAAO,EACzF,OAAO,IAAIN,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCrNF,IAqcayB,GArcbC,GAAAC,EAAA,KAGAC,KAkcaH,GAA4CA,KCrczD,IAAAI,GAAAC,EAAA,QCAA,IAgBMC,GAGOC,GAnBbC,GAAAC,EAAA,KAGAC,KAIAC,KASML,GAA0B,gHAGnBC,GAAP,MAAOK,CAAe,CAC1B,YAAoBC,EAA+B,CACjD,KAAK,QAAUA,CACjB,CAGA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,aAAa,OAAOC,EAA+CC,EAA+B,CAEhG,IAAMC,EAA+BF,EAAgB,WAAa,GAC5DG,EAAoCH,EAAgB,gBAAkB,GACtEI,EAA0BH,GAAkB,CAAA,EAI5CI,GADMD,EAAQ,oBAAsB,CAAA,GACjB,IAAIE,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAC9DC,EAAU,MAAMC,GAAeH,CAAY,EACjD,GAAIE,EAAQ,6BAA8B,CACxC,IAAMR,EAAU,MAAMQ,EAAQ,6BAC1BP,EAAgB,gBAAiBA,EAAgB,WAAYE,EAAWC,EAAgBC,CAAO,EACnG,OAAO,IAAIN,EAAgBC,CAAO,MAElC,OAAM,IAAI,MAAMP,EAAe,CAEnC,CAWA,wBAAwBiB,EAAkBC,EAA+BC,EAAiB,CAExF,IAAMC,EAA4C,CAAA,EAC9CR,EAAsB,CAAA,EAE1B,GAAI,OAAOK,GAAU,UAAYA,IAAU,MAAQA,aAAiBI,IAAU,MAAM,QAAQJ,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIK,EAAiB,GAErB,GAAI,OAAOJ,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBG,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQH,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DI,EAAiB,GAEjB,QAAWC,KAAQL,EAAM,CACvB,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEH,EAAQG,CAAI,EAAI,KAGlB,GAAI,OAAOJ,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIK,EAAY,GACVC,EAAW,OAAO,oBAAoBP,CAAI,EAChD,QAAWK,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKR,EAAmDK,CAAI,GAC9DG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBF,EAAQG,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDP,EAAUM,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWK,KAAQ,KAAK,WACtB,GAAI,OAAON,EAAMM,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBH,EAAQG,CAAI,EAAI,KAIpB,MAAO,CAACH,EAASR,CAAO,CAC1B,CASA,uCAAuCe,EAAkC,CACvE,IAAMC,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAIA,MAAM,aAAaX,EAAkBC,EAA+BC,EAAiB,CACnF,GAAM,CAACC,EAASR,CAAO,EAAI,KAAK,wBAAwBK,EAAOC,EAAMC,CAAI,EACnEQ,EAAU,MAAM,KAAK,QAAQ,aAAaV,EAAOG,EAASR,CAAO,EACvE,OAAO,KAAK,uCAAuCe,CAAO,CAC5D,CAEA,MAAM,qBAAqBI,EAAoBC,EAAuB,CACpE,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,wBAAwBA,EAAuB,CACnD,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KC5LF,IAqIaC,GArIbC,GAAAC,EAAA,KAIAC,KAiIaH,GAA0CA,KCrIvD,IAAAI,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,WAAAC,GAAA,oBAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAAA,IAAAC,GAAAC,EAAA,KAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCxBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EAC1DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,GAAEC,IAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,KAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,KAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,EAAEI,CAAC,EAAEL,GAAEC,EAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,KAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,EAAEb,EAAE,GAAG,CAAC,GAAGY,GAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,EAAC,EAAE,GAAGZ,EAAE,KAAKa,EAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,EAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,GAAEC,EAAEC,KAAIX,EAAE,eAAeQ,EAAEC,GAAEC,EAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,GAAEC,IAAIV,EAAE,iBAAiBQ,EAAEC,GAAEC,CAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAE,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAEC,EAAEC,EAChP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAEO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAE,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAE1B,IAAIA,EAAEwB,EAAExB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAE,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SACnfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAEA,EAAEE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAExB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIK,EAAE1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GACvfwB,EAAE,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAEjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAErB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIkC,EAAElC,EAAE,aAAakC,EAAElC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,GAAE,iCAAiC,EACve,IAAIC,EAAEC,EAAEC,EAAE,GAAGC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAGC,GAAG,SAASC,IAAI,CAAC,IAAI5C,EAAEkC,EAAE,OAAOrC,EAAE,MAAMyC,EAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,GAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,EAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,EAAEH,EAAE,QAAQ8C,GAAG,IAAI,aAAa3C,CAAC,CAAC,CAAC,IAAI6C,EAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAIhD,EAAEH,EAAE,OAAO,MAAM,EAAEgD,EAAG,QAAQ7C,CAAC,CAAC,CAAC,IAAIiD,GAAE,EAAEC,GAAG,KAAKC,GAAE,KACnY,SAASlB,GAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAE9B,CAAC,EAAEoC,EAAE,GAAGC,EAAE,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASoD,EAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,GAAyB,GAAvBA,GAAE,qBAAwB,CAACD,EAAGC,EAAC,EAAE,CAAC,IAAIC,GAAGD,GAAEA,GAAExD,EAAE,WAAWA,EAAE,WAAWyD,GAAG/B,CAAC,EAAEA,EAAE+B,EAAE,CAAC,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGqD,IAAGtB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGL,EAAE,OAAOA,EAAE1B,CAAC,EAAE,KAAK,iDAAkD,CACnc,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAAC+B,IAAIX,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAGyB,EAAE,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAEzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAE,0CAA0C3B,CAAC,EAAE8B,GAAE9B,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,GAAE,OAAOtB,GAAe,OAAO,YAAY,sBAA/B,YAAqDqB,EAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAE,kCAAkC1B,CAAC,EAAE0B,EAAE,2CAA2C,EAAS2B,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,OAAOG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAC1fG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAClgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IACzf,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAC/f,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EACpfA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAAI,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KACnf,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EACnf,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAAI,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAChgB,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAC5f,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAC1fC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EACnfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,IAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,EAAC,EAAE,YAAYoD,GAAEnD,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBACpeG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,IAAI,CAACX,EAAE,GAAG,YAAYG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAC5f,eAAeC,EAAE,MAAM,KAAKkC,EAAE,SAAS,OAAOjC,EAAC,IAAI,EAAE,OAAOA,EAAC,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,CAAC,CAAC,CAAC,EAAE,OAAOR,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EACnf,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,WAAWoD,GAAEnD,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK+B,GAAG,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKiC,EAAE,SAAShC,IAAI,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,GAAEC,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC4B,EAAE1B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK2B,GAAG,SAASoB,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GACvf,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAIgE,GAAGhE,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EACxS,SAASoE,GAAGjE,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACuC,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CACnN,IAAIyB,GAAG,EAAEC,GAAG,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EACxgB0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAG9B,GAAEvC,EAAEC,CAAC,EAAE,GAAGqE,GAAGtE,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEsE,GAAG,CAACvE,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EACnf,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEoE,GAAExE,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAWyE,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG3E,GAAG,CAAC,IAAIC,EAAEqE,GAAGtE,CAAC,EAAE,EAAEE,EAAE0E,GAAG3E,CAAC,EAAE,OAAAC,GAAGqE,GAAGvE,EAAEuC,GAAErC,EAAED,CAAC,EAASC,CAAC,EAAE2E,GAAG,CAAC,EAAEC,GAAG,CAAC9E,EAAEC,IAAI,CAAC4E,GAAG,OAAO,EAAE,IAAI3E,EAAE,IAAID,IAAI,EAAEC,EAAEqC,GAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE4E,GAAG,KAAU3E,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAE0C,GAAG1C,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO4E,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAIjF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IACtf,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAG,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK8E,GAAYA,GAAG9E,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE8E,GAAG9E,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEgF,GAAG/E,CAAC,CAAC,OAAO+E,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGrF,EAAE,CAAC,IAAIC,EAAE,MAAMqE,GAAGtE,CAAC,EAAE,CAAC,EAAE,OAAAuE,GAAGvE,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACtb,SAASqF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyB,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1B,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyE,GAAE1B,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyE,GAAE1B,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyE,EAAC,CAAC,SAASjF,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0E,IAAGhB,GAAE1D,EAAE,YAAY,CAAC,EAAEqE,GAAGC,IAAItB,EAAC,EAAE,GAAG/C,GAAEyE,GAAE1E,EAAE,QAAQ,EAAEC,IAAGyE,GAAE1E,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,GAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,GAAEoD,GAAEpD,EAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,GAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,KAAKD,GAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,GAAEC,CAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,GAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAIyD,GAAE1D,EAAE,GAAG,IAAI,EAAEqE,GAAGC,IAAItB,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GACvf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,KAAKD,GAAEP,EAAE,SAASQ,CAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EACzgB,GAAG,EAAED,GAAEC,CAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,EAAE2E,GAAGnF,CAAC,EAAKQ,EAAE,OAAOT,EAAS,GAAEqC,EAAE,IAAI5B,EAAEV,IAAI,CAAC,EAASU,EAAE,OAAO,EAAC,CAAC,SAAS+E,GAAEzF,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,GAAEhC,CAAC,CAAC,CAAC,CAAC,SAASyF,GAAG1F,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuF,GAAE,KAAKxF,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAIuD,GAAE,IAAI,IAAIxF,GAAG8B,GAAE,EAAEpB,IAAO+E,KAAJ,GAAWD,GAAE,SAAN,IAAeC,GAAE,EAAEH,GAAEI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzF,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2F,GAAE,EAAE/E,GAAE,KAAKiF,GAAG,EAAEH,GAAE,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC9c,SAASnF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiG,GAAG,CAAC,QAAQlG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmG,IAAI,CAAC,IAAIpG,EAAE4E,GAAG,KAAK,EAAE3E,EAAED,EAAE,GAAGyC,EAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,EAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0F,GAAE,CAAC,EAAE,IAAIzF,EAAE6F,GAAG9F,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+F,KAAKF,GAAG9F,CAAC,EAAEC,EAAE8F,GAAG9F,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC5N,SAASqG,GAAGrG,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAOwD,KAAJ,EAAM,CAAC,IAAI3F,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAI0D,GAAG3F,EAAEF,EAAE,GAAGC,GAAG,CAAC0F,GAAE,EAAEH,GAAE,IAAIa,GAAGzF,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAE6D,GAAGxD,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE4F,GAAG5F,IAAI4F,GAAG,MAAM/F,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2F,GAAE,EAAE/E,GAAEuF,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAE,IAAIc,GAAG1F,EAAC,CAAC,EAAE,MAAU+E,KAAJ,GAAOA,GAAE,EAAEH,GAAEe,EAAE,EAAEC,GAAG5F,EAAC,EAAEA,GAAE,KAAKsF,GAAG,QAAQhG,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAEA,EAAElC,EAAEkC,EAAML,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAC7hBiC,EAAE,IAAGjB,EAAEhB,EAAE,IAAI4D,GAAG5D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,GAAE,kBAAkB2D,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAG1G,EAAE,CAAC,OAAOqG,GAAGpG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CACnM,IAAI0G,GAAG,CAAC,EAAE,SAAS3G,EAAEC,EAAEC,EAAE,CAAC,OAAOwG,GAAG,SAAS,CAAC,MAAM7G,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIiE,GAAGjE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEgE,GAAGlE,EAAEmE,KAAWD,EAAG,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,IAAI,GAAG,EAAE,SAASlE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EACnfF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAClf,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGsE,GAAExE,EAAE,YAAY,CAAC,EAAEyE,GAAGC,IAAI1E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAC5fG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAGwE,GAAEvE,EAAE,YAAY,CAAC,EAAEwE,GAAGC,IAAIzE,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAC7f,IAAW2G,IAAIjD,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEmC,EAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,EAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE2E,GAAG3E,CAAC,EAAEC,EAAE0E,GAAG1E,CAAC,EAAEM,GAAEH,GAAGqC,EAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,EAAEvC,EACnf,GAAG,IAAI,CAAC,EAAED,IAAIwC,EAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,EAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACiC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,GAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,GAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KACpfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAK9B,CAAC,EAAEwC,GAAG,EAAE,IAAIvC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAE,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA8E,GAAG,EAAE,QAAQ,SAAS7E,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,EAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,EAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,EAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE8E,GAAG,EAAEvC,EAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,EAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EAAE,EAAE,IACrf,GAAG,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,EAAExC,GAAG,IAAI,CAAC,EAAEM,GAAEkC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,GAAE8B,GAAEjC,EAAEE,IAAI,CAAC,EAAEE,EAAEwE,GAAGlF,CAAC,EAAMS,KAAJ,GAAYA,KAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAGuC,GAAG3D,EAAE,CAAC,CAAC,EAAEA,EAAE,OAAO,GAAGA,EAAE,KAAKD,EAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAkC,EAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,EAAEkF,GAAG,EAAE,SAAStF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmF,GAAGtF,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GAC7V,UAAU,CAAC,SAASH,EAAEE,EAAE,CAAoH,GAAnHA,EAAEA,EAAE,QAAQA,EAAEwF,GAAGxF,CAAC,EAAEiC,EAAEjC,EAAE2G,GAAG3G,CAAC,EAAEgC,EAAEC,EAAE,EAAES,GAAG,EAAEE,GAAG,QAAQX,EAAE,CAAC,EAAEc,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIhD,EAAEgD,GAAEA,GAAE,KAAKhD,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE0G,EAAE,EAA4D,GAA1D1D,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAKpD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAE,sDAAsD5B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAC1dF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,MAAKZ,EAAE,yBAAyBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,GAAGnC,CAAC,EAC1fH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAC/dP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACtV,IAAI4E,GAAG/E,EAAE,QAAQG,IAAI4E,GAAG/E,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAEyG,GAAG5G,EAAE,MAAMG,IAAIyG,GAAG5G,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAE4G,GAAG5G,IAAI4G,GAAGzE,EAAE,IAAInC,CAAC,EAAE8G,GAAG,KAAKA,GAAG3E,EAAE,IAAI,EAAE4E,GAAG/G,IAAI+G,GAAG5E,EAAE,IAAInC,CAAC,EAAEgH,GAAGhH,IAAIgH,GAAG7E,EAAE,IAAInC,CAAC,EAAEuG,GAAGvG,IAAIuG,GAAGpE,EAAE,IAAInC,CAAC,EAAE6F,GAAG,KAAKA,GAAG1D,EAAE,IAAI,EAAEmE,GAAGtG,IAAIsG,GAAGnE,EAAE,IAAInC,CAAC,EAAEwG,GAAG,KAAKA,GAAGrE,EAAE,IAAI,EAAEtC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAAO,SAASgH,GAAG7G,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAWmH,GAC5enH,EAAE,UAAUiH,GAAGjH,EAAE,aAAakH,GAAGlH,EAAE,aAAagE,GAAEhE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAIqE,GAAGvE,EAAEuC,GAAEtC,EAAEC,CAAC,EAAEL,EAAE,gBAAgByE,GAAG,IAAI2C,GAAE9D,GAAE,SAAS+D,GAAI,CAACD,IAAGE,GAAG,EAAEF,KAAI9D,GAAE+D,EAAG,EAClJ,SAASC,IAAI,CAAC,SAASnH,GAAG,CAAC,GAAG,CAACiH,KAAIA,GAAE,GAAGpH,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE4B,GAAGlB,EAAE,EAAEhD,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEkD,GAAG,QAAQ9C,CAAC,CAAC,CAAC+D,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGpD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQmD,GAAG,EAAEgB,GAAGnB,CAAE,EAAE,EAAEI,KAAIpD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC1e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAsH,GAAG,EAGvGvH,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IC7E1B,IAAA0H,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASE,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAL,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASI,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAP,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASM,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAT,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASQ,CAAE,CAAC,SAASC,GAAI,CAAC,OAAAX,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASU,EAAE,CAAC,IAAIC,EAAEf,EAAUgB,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EACrVJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,EAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,GAAEI,CAAC,EAAEL,EAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,GAAEC,KAAIX,EAAE,eAAeQ,EAAEC,EAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,KAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE1B,EAAE,wBAAwB,GAAG2B,EAAE,GAAG,SAASC,EAAGzB,EAAE,CAAC,OAAOH,EAAE,WAAWA,EAAE,WAAWG,EAAEwB,CAAC,EAAEA,EAAExB,CAAC,CAAC,IAAI0B,EAAGC,EAAEC,EAC7U,GAAGN,EAAE,CAAC,IAAIO,EAAG,cAAcC,EAAG,cAAgBN,EAAEH,EAAES,EAAG,QAAQN,CAAC,EAAE,IAAI,UAAU,IAAIE,EAAG,CAACzB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAS4B,EAAG,aAAa5B,EAAEC,EAAE,OAAO,MAAM,GAAG0B,EAAG3B,IAAIA,EAAEyB,EAAGzB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAG0B,EAAE,CAAC1B,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAE4B,EAAG,SAAS5B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACT,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEL,EAAE,QAAQ,IAAI,6BAA6B,IAAIG,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAEG,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAM,OAAO3C,EAAe,KAAeA,IAAc2C,EAAE3C,GAAgB2C,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGF,IAAII,EAAG1B,GAAG,CAAC,IAAIC,EAC9hB,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIO,EAAG5B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAG0B,EAAE,CAAC3B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aACrd,IAAIS,EAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,GAAG,QAAQ,MAAM,KAAK,OAAO,EAAEV,IAAIS,EAAG,IAAI/B,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAEgC,GAAG,IAAIhC,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIiC,EAAGpC,EAAE,OAAOkC,EAAG,EAAElC,EAAE,UAAUmC,GAAG,OAAO,OAAOnC,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIqC,GAAErC,EAAE,aAAaqC,GAAErC,EAAE,YAAY,IAAIsC,GAActC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BuC,GAAE,iCAAiC,EAAE,IAAIpD,GAAEqD,EAAEC,GAAGC,GAAE,GAAGC,GAAEvD,GAAEG,GAAGE,GAAGE,GAAGE,EAAGE,GAChc,SAASV,IAAG,CAAC,IAAIc,EAAEhB,GAAE,OAAOa,EAAE,MAAMZ,GAAE,IAAI,UAAUe,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAOP,GAAG,IAAI,WAAWU,CAAC,EAAEH,EAAE,OAAOT,GAAG,IAAI,WAAWY,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQL,GAAG,IAAI,YAAYQ,CAAC,EAAEH,EAAE,QAAQH,EAAG,IAAI,aAAaM,CAAC,EAAEH,EAAE,QAAQD,GAAG,IAAI,aAAaI,CAAC,CAAC,CAAC,IAAIyC,GAAG5C,EAAE,gBAAgB,SACtS,GAD+S,SAAS4C,IAAIL,GAAE,wDAAwDK,GAAG,wBAAwB,EAC9YlB,EAAEvC,GAAEa,EAAE,mBAAmBA,EAAE,WAAWb,GAAEa,EAAE,mBAAmBb,GAAE,IAAI,YAAY,OAAO,CAAC,QAAQyD,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAEzD,GAAE,kBAAkB,mBAAmB,MAAM,EAAE,6NAA6N,EAAEsC,GAAG,EAAE,2GAA2G,EACrgB,MAAM,YAAY,EAAEpC,GAAE,EAAEuD,GAAGzD,GAAE,OAAO,WAAW,IAAI0D,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAE,SAASC,IAAI,CAAC,OAAOX,IAAe,EAAEU,EAAE,CAAC,IAAIE,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAAK,SAASC,IAAI,CAACH,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,CAAC,CAAC,SAASI,IAAI,CAA2D,GAA1DJ,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIjD,EAAEiD,GAAEA,GAAE,KAAKjD,EAAE,CAAC,CAAC,CAClW,SAASoC,GAAEpC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI,EAAEA,CAAC,EAAEuC,GAAE,GAAGC,GAAE,EAAExC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASoD,GAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,GAAEA,GAAE,8BAA8BD,GAAGC,EAAC,IAAIA,GAAE5B,EAAG4B,EAAC,GAAG,SAASC,GAAGtD,EAAE,CAAC,GAAGA,GAAGqD,IAAGnB,GAAE,OAAO,IAAI,WAAWA,EAAC,EAAE,GAAGN,EAAG,OAAOA,EAAG5B,CAAC,EAAE,KAAK,iDAAkD,CACpa,SAASuD,GAAGvD,EAAE,CAAC,GAAG,CAACkC,KAAId,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIqD,GAAGtD,CAAC,CAAC,EAAE,GAAG2B,EAAE,OAAO,IAAI,QAAQ,CAAC1B,EAAEC,IAAI,CAACyB,EAAE3B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIoD,GAAGtD,CAAC,CAAC,CAAC,CAAC,SAASwD,GAAGxD,EAAEC,EAAEC,EAAE,CAAC,OAAOqD,GAAGvD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC,EAAE,0CAA0CA,CAAC,EAAEiC,GAAEjC,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASsD,GAAGzD,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,GAAE,OAAOnB,IAAe,OAAO,YAAY,sBAA/B,YAAqDkB,GAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAe,OAAO,OAAnB,WAAyBkC,GAAGtD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,SAAE,kCAAkCA,CAAC,EAAE,EAAE,2CAA2C,EAASoD,GAAGtD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC7W,IAAIyD,GAAEC,GAAG,CAAC,QAAQ3D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EACpf,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,OAAOG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YACjfG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,QAAQ,CAACG,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GACxf,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EACzf,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAChgB,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAC/eG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,WAAWmD,GAAElD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKlB,EAAG,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE8C,KAAI,CAAChE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,IAAI,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC3B,EAAE,EAAE6B,KAAI,CAAC,EAAE,WAAWgD,GAAE9C,CAAC,EAAE,kBAAkBC,GAC/f,MAAM,KAAKtB,EAAG,EAAE,SAASoE,KAAI,EAAEA,GAAE9C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWgD,GAAE7C,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IACpf,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IACpf,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWgD,GAAE7C,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KACpgB,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE8C,KAAI,CAAChE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO6D,GAAE,OAAO,OAAO,SAAS5D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE8C,KAAI,CAAChE,EAAE,GAAG,cACjfG,EAAE,CAAC,OAAO6D,GAAE,OAAO,OAAO,SAAS5D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE8C,KAAI,CAAChE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO6D,GAAE,OAAO,OAAO,SAAS5D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EACxfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE8C,KAAI,CAAChE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO6D,GAAE,OAAO,OAAO,SAAS5D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,QAAQJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAC3eG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB0D,GAAExD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAChgB,sBAAsBqD,GAAEpD,CAAC,EAAE,KAAKoD,GAAEnD,CAAC,EAAE,YAAYmD,GAAElD,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBACjeG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS4D,GAAE3D,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,IAAI,CAACX,EAAE,GAAG,YAAYG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAAE,eAAeC,EAAE,MAAM,KAAKjB,EAAE,EAAE,SAAS,OAAOkB,EAAC,IAAI,EAAE,OAAOA,EAAC,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,CAAC,CAAC,CAAC,EAAE,QAAQR,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EACpfC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,QAAQL,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQA,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAAS4D,GAAG9D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CACzc,SAAS+D,GAAG/D,EAAE,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,CAAC,SAASgE,GAAGhE,EAAE,EAAEA,EAAEiE,GAAE,GAAGjE,CAAC,IAAIoC,GAAE,EAAE6B,GAAE,GAAGjE,CAAC,CAAC,CAAC,SAASkE,GAAGlE,EAAE,CAAC,IAAIC,EAAEgE,GAAE,GAAG,EAAE,GAAG,CAAChE,EAAE,MAAO,GAAEgE,GAAE,GAAG,KAAKhE,CAAC,EAAEgE,GAAE,GAAGjE,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,CACjR,IAAImE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACpE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQmE,GAAG,OAAOA,GAAG,OAAOnE,EAAE,kBAAkB,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GACpf,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAEyD,GAAE,CAAC5D,EAAEC,KAAKD,KAAK,GAAGoE,GAAGjF,EAAE,EAAEa,EAAEC,CAAC,EAAE,GAAG,SAASoE,GAAGrE,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,CAAC,EAAEwC,GAAExC,EAAM8C,GAAG,IAAGmB,GAAE,GAAG,EAAKpE,EAAE,QAAOA,EAAE,OAAOG,CAAC,EAAEuC,GAAE,IAAGpB,EAAEnB,EAAE,IAAI8D,GAAG9D,CAAC,CAAC,CAAC,CACjM,IAAIuE,GAAGvE,GAAG,CAAK,GAAJwC,GAAExC,EAAKuB,EAAE,MAAMiD,GAAGxE,CAAC,EAAE,SAASqE,GAAGrE,CAAC,CAAC,EAAEiE,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC1C,EAAE0C,GAAE,GAAG,EAAEA,GAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAACvB,GAAG,QAAQ,IAAI,CAACQ,GAAG,EAAEe,GAAE,GAAG,IAAId,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAACc,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAG9B,GAAc,EAAE,EAAE,GAAG,SAASnC,EAAE,CAACwC,GAAExC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,UAAU,CAAC,QAAQA,KAAKiE,GAAE,GAAGF,GAAG/D,CAAC,EAAE,IAAIA,KAAKiE,GAAE,GAAGF,GAAG/D,CAAC,EAAEiE,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAASjE,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAOiE,GAAE,GAAGhE,CAAC,EAAEgE,GAAE,GAAG,KAAKjE,CAAC,EAAEiE,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQjE,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,EAAEyE,GAAGxE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,EACtf,GAAG,UAAU,CAACgE,GAAE,GAAG,QAAQjE,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,EAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcqE,GAAG,EAAE,CAAC,IAAInE,GAAE0D,GAAE,GAAG5D,EAAE,EAAE,EAAEE,GAAEA,GAAE,YAAYF,EAAEA,EAAE,YAAY,EAAE,EAAE,0CAA0CC,EAAE,uBAAuBD,EAAE,aAAa,qCAAqC,CAAC,MAA0BC,IAAjB,eAAmBqE,GAAG,EAA0BrE,IAAhB,cAAkB4D,GAAG7D,CAAC,EAA4BC,IAAlB,gBAAoB0D,GAAG3D,EAAE,MAAM,EAAyBC,IAAf,cAAiBD,EAAEA,EAAE,OAAOC,EAAE2D,GAAE,GAAG5D,CAAC,EAAE,OAAO4D,GAAE,GAAG5D,CAAC,EAAE0D,GAAGzD,CAAC,EAAEmE,GAAGpE,CAAC,EAAE4D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ3D,CAAC,EAClgB,CAAC,EAAEA,EAAE,GAAG,GAA2BA,IAAjB,eAAmB2D,GAAE,GAAG5D,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,IAAX,UAAaN,EAAE,OAAO,GAAGC,EAAED,CAAC,GAAoBM,IAAV,QAAY,MAAM,UAAUD,EAAE,SAAS,KAAKA,EAAE,IAAI,EAA2BA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,IAAhB,cAAkBT,EAAEQ,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,GAAG,EAAE,kCAAkCA,CAAC,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,QAAE,yBAAyBA,EAAE,SAAS,IAAIA,EAAE,OAAO,KAAKA,EAAE,OAAO,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAU,SAASK,EAAE,CAACL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,CAAC,EAAEL,EAAE,GAAG,QAAQ,SAASK,EAAE,CAACL,EAAE,QAAQK,CAAC,CAAC,CAAC,GAC/f,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,SAAS,UAAU,QAAQ,UAAU,EAAEC,EAAE,IAAIA,KAAKD,EAAEN,EAAE,eAAeO,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUL,EAAE,qBAAqBhB,EAAW,WAAWG,GAAE,WAAWsD,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,SAAStC,EAAE,CAACA,EAAE,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIA,EAAEyB,EAAG,kCAAkC,EAAEzB,EAAE,IAAI,OAAOA,CAAC,EAAEiE,GAAE,GAAG,KAAKjE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAGiE,GAAE,GAAG,QAAR,IAAiBA,GAAE,GAAG,EAAEA,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,GAAUA,GAAE,GAAG,IAAI,CAAC,CAAC,EAAEpE,EAAE,QAAQoE,GAAE,IAAIW,GAAG5E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EACzbA,EAAE,oBAAoB,UAAU,CAAC,IAAIG,EAAE0E,GAAG,EAAEzE,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE6E,GAAG5E,EAAEA,EAAED,CAAC,EAAE8E,GAAG7E,CAAC,CAAC,EAAE,SAASuE,GAAGxE,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,CAAC,EAAEuE,GAAGvE,CAAC,CAAC,CAACH,EAAE,iBAAiB,SAASG,EAAEC,EAAE,CAACD,EAAE+E,GAAG,MAAM,KAAK,CAAC/E,EAAEC,CAAC,CAAC,EAAE6C,GAAG,EAAEmB,GAAE,GAAGjE,CAAC,EAAEgF,GAAGhF,CAAC,CAAC,EAAE,SAASiF,GAAGjF,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACX,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI2F,GAAG,EAAEC,GAAG,EAC/b,SAASC,GAAGpF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAEkF,GAAGrF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASkF,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAO,EAAE,qFAAqF,EAAE,EAAE,IAAIC,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoBgF,GAAGpF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAG8D,GAAGlE,CAAC,EAAC,CAAC,SAASsF,GAAGtF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASqF,GAAGvF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CACrc,IAAIuF,GAAGxF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEwF,GAAG,CAACzF,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEsF,GAAG,CAAC1F,EAAEC,EAAEC,IAAIuF,GAAGzF,EAAEb,EAAE,EAAEc,EAAEC,CAAC,EAAE,SAASyF,GAAG3F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAAS2F,GAAG5F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS2F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE+C,EAAE,EAAE,EAAEtE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,EAAE,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAG/F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAGhG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS8F,GAAGjG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGlG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9d,SAASgG,GAAGnG,EAAE,CAAC,GAAGuB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,CAAC,CAAC,CAAC,SAASoG,GAAGpG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,CAAC,CAAC,SAASoG,GAAGrG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIoG,GAAGtG,GAAG,CAAC,GAAG,CAACuC,GAAE,GAAG,CAAC,GAAGvC,EAAE,EAAE,CAAC8C,GAAG,EAAE,GAAG,CAACvB,EAAEyD,GAAGxC,EAAC,EAAE+B,GAAG/B,EAAC,CAAC,OAAOvC,EAAE,CAACA,aAAa6D,IAAc7D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa6D,IAAc7D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,EAAE,SAASsG,GAAGvG,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGX,EAAE,EAAEW,GAAG,EAAEA,CAAC,EAAE,MAAM,KAAK2E,EAAE,EAAE3E,GAAG,IAAI,QAAQ,MAAMX,EAAE,EAAEW,GAAG,EAAE,CAAC,EAAE,CAACH,EAAE,kCAAkC0G,GAAG,SAAS5B,IAAI,CAAC,IAAI3E,EAAE0E,GAAG,EAAE1E,IAAIuG,GAAGvG,CAAC,EAAEsG,GAAG,IAAIE,GAAG,CAAC,EAAE,CAAC3G,EAAE,aAAa8E,GACpf,IAAI8B,GAAEzG,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW0G,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,EAAG5G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAE,CAAC,OAAOgB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAE,GAAG,CAAC,SAASsG,EAAG7G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGiB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIwG,EAAG9G,GAAG,CAAC,IAAIC,EAAEuF,GAAGxF,CAAC,EAAE,EAAEE,EAAE6G,GAAG9G,CAAC,EAAE,OAAAC,GAAGwF,GAAG1F,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAE8G,EAAG,CAAC,EAAEC,EAAG,CAACjH,EAAEC,IAAI,CAAC+G,EAAG,OAAO,EAAE,IAAI9G,EAAE,IAAID,IAAI,EAAEC,EAAEf,EAAE,EAAEa,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE+G,EAAG,KAAU9G,GAAL,IAAOb,EAAE,EAAEY,IAAI,CAAC,EAAEN,EAAG,EAAEM,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO+G,CAAE,EAAEE,EAAGlH,GAAG,CAAC,IAAIC,EAAEkH,GAAG,EAAE,OAAAnH,EAAEA,EAAE,EAAE8E,GAAG7E,CAAC,EAASD,CAAC,EACve,SAASsE,EAAEtE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAO+G,EAAG,IAAI,CAAC,QAAQ9G,EAAEgH,GAAG,EAAElH,CAAC,EAAEG,EAAED,GAAG,EAAEE,EAAE,EAAEA,EAAEJ,EAAEI,IAAI,CAAC,IAAIC,GAAEJ,EAAE,EAAEG,CAAC,EAAEX,EAAG,EAAEU,EAAEC,IAAI,CAAC,EAAEC,EAAC,CAAC,OAAO8G,GAAGrH,EAAEE,EAAEE,EAAEH,CAAC,CAAC,CAAC,CAAC,CAC3J,IAAIqH,GAAG,CAAC,EAAEC,EAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,EAAG,CAAC,IAAIzH,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKsH,EAAYA,EAAGtH,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEsH,EAAGtH,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEwH,EAAGvH,CAAC,CAAC,OAAOuH,CAAE,EAAEA,EACtW,SAASC,GAAG1H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAsH,GAAG,EAAE,QAAQ,SAASrH,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAwB,IAAtBE,EAAEb,EAAE,EAAES,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEtB,EAAE,EAAEqB,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEtB,EAAE,EAAEqB,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAASwH,GAAG3H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEsH,GAAG,EAAEjI,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEb,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAASyH,EAAG5H,EAAE,CAAC,OAAOuB,EAAE+C,EAAE,GAAG,EAAEtE,CAAC,EAAE,EAAE,CAAC,SAAS6H,GAAG7H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAC/c,SAAS2H,GAAG9H,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmB,EAAE+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAI2H,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGhI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO+C,EAAE,GAAG,EAAEtE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEf,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEM,GAAEhB,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,EAAEtB,EAAE,EAAEmB,EAAEE,IAAI,CAAC,EAAEE,GAAEqH,GAAG/H,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAMiC,EAAG,GAAGmC,GAAG1D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAhB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAI6H,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGnI,EAAE,CAAC,IAAIC,EAAE,MAAMuF,GAAGxF,CAAC,EAAE,CAAC,EAAE,OAAAyF,GAAGzF,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACjf,IAAImI,GAAG,CAACpI,EAAEC,IAAI,CAAClB,EAAE,EAAE,IAAIiB,EAAEC,IAAI,CAAC,CAAC,EAC/B,SAASoI,GAAGrI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE8C,GAAE,CAAC,IAAI/C,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAE+C,GAAE,CAAC,EAAE/C,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS8C,GAAEyE,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1E,GAAE/C,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDwH,GAAE1E,GAAE/C,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCwH,GAAE1E,GAAE/C,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUwH,EAAC,CAAC,SAAShI,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI8C,GAAE/C,EAAE,SAAS,EAAEyH,IAAG9B,GAAE3F,EAAE,YAAY,CAAC,EAAEmH,GAAGC,IAAIrE,EAAC,EAAE,GAAG9C,GAAEwH,GAAEzH,EAAE,QAAQ,EAAEC,IAAGwH,GAAEzH,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAG+C,GAAE/C,EAAE,SAAS+C,GAAE,CAAC,GAAG/C,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA8C,GAAE,IAAI,KAAK/C,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAE+C,GAAEtD,GAAEsD,EAAC,EAAS,GAAGvD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEuD,GAAE/C,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAEpB,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGd,EAAE,EAAEc,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEmD,GAAEnD,CAAC,EAAE,EAAE,EAAEP,EAAE0D,GAAE1D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WACxf,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GACzfF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE8C,GAAE,EAAEA,IAAG/C,EAAE,GAAG,EAAEC,KAAI0F,GAAE3F,EAAE,GAAG,IAAI,EAAEmH,GAAGC,IAAIrE,IAAG,EAAE,CAAC,OAAOxD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GACnf,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ8C,IAAG/C,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAK+C,IAAH,GAASA,IAAH,GAAM4C,GAAE3F,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI8C,IAAG/C,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAM+C,IAAH,GAASA,IAAH,GAAM4C,GAAE3F,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,EAAEP,EAAE,SAASQ,EAAC,IACrgBR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAEyH,GAAGjI,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEmI,GAAG1H,GAAEV,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS8H,GAAGxI,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACmC,GAAEnC,CAAC,CAAC,CAAC,CAAC,SAASwI,GAAGzI,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACsI,GAAG,KAAKvI,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQmC,KAAImG,GAAG,IAAI,IAAIvI,GAAGiC,GAAE,EAAEvB,IAAO8H,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAE9F,IAAI,EAAE2F,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAExI,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI0I,GAAE,EAAE9H,GAAE,KAAKgI,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC7e,SAASlI,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACgJ,GAAG,CAAC,QAAQjJ,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASkJ,IAAI,CAAC,IAAInJ,EAAE+G,GAAG,KAAK,EAAE9G,EAAED,EAAE,GAAGT,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEC,EAAEV,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAEyI,GAAG,CAAC,EAAE,IAAIxI,EAAE4I,GAAG7I,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE8I,KAAKF,GAAG7I,CAAC,EAAEC,EAAE6I,GAAG7I,CAAC,EAAED,GAAGA,EAAEC,EAAEb,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAASoJ,IAAI,CAAC,IAAIpJ,EAAEX,EAAE,EAAEwB,GAAE,GAAG,IAAI,CAAC,EAAE,OAAAb,EAAEqC,EAAE0G,GAAG/I,CAAC,CAAC,EAAE,EAAE6C,GAAU7C,EAAE,CAAC,CACtS,SAASqJ,GAAGrJ,EAAE,CAAC,GAAG,CAACuC,GAAE,CAAC,GAAOoG,KAAJ,EAAM,CAAC,IAAI1I,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACoC,KAAIsG,GAAG1I,EAAEF,EAAE,GAAGC,GAAG,CAACyI,GAAE,EAAEH,GAAG,IAAIc,GAAGzI,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEgJ,GAAG,CAAC,OAAO7I,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE2I,GAAG3I,IAAI2I,GAAG,MAAM9I,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI0I,GAAE,EAAE9H,GAAEsI,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIe,GAAG1I,EAAC,CAAC,EAAE,MAAU8H,KAAJ,GAAOA,GAAE,EAAEH,GAAGgB,EAAE,EAAEC,GAAG5I,EAAC,EAAEA,GAAE,KAAKqI,GAAG,QAAQ/I,GAAGmG,GAAGnG,CAAC,CAAC,GAAGiC,GAAE,kBAAkBuG,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC/d,SAASa,GAAG1J,EAAE,CAAC,OAAOqJ,GAAGpJ,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAACgE,GAAE,GAAG,EAChD,IAAI0F,GAAG,CAAC,KAAKtF,GAAGG,GAAGY,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGO,EAAGC,EAAGa,GAAGC,GAAGC,EAAGC,GAAGC,GAAGE,EAAE,EAAE4B,GAAG,CAAC,EAAE,SAAS5J,EAAEC,EAAEC,EAAE,CAAC,OAAOwJ,GAAG,SAAS,CAAC,MAAM7J,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIiF,GAAGjF,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEgF,GAAGlF,EAAEmF,KAAWD,EAAG,EAAE,EAAE,SAASlF,EAAE,CAAC6J,GAAG7J,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE6C,GAAE,GAAG,CAAC,EAAE,EAAE,SAASjE,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,EAAEgE,GAAGhE,CAAC,CAAC,EAAE,EAAEqF,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAE,IAAI,GAAG,EAAE,SAASrG,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAI0E,GAAG,CAAC,EAAEpD,EAAE,YAAY,CAAC,aAAavB,EAC5f,IAAI,cAAc,CAAC,GAAGA,EAAEiE,GAAE,GAAGjE,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,EAAE,EAAE,EAAEuG,GAAG,EAAE,SAASvG,EAAE,CAACsB,GAAG2C,GAAE,GAAGjE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAC3f,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEC,GAAGwG,GAAEzG,EAAE,YAAY,CAAC,EAAE0G,GAAGC,IAAI3G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAED,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EACrf,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGC,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAClf,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGd,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGuG,GAAExG,EAAE,YAAY,CAAC,EAAEyG,GAAGC,IAAI1G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEE,EAAEb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAW6J,IAAIpG,GAAE1D,EAAE,GAAG,CAAC,KAAK,IAAI0D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE1D,IAAI,CAAC,EAAE,EAAE4G,EAAG,EAAEC,EACpf,EAAE,SAAS7G,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEE,EAAE,KAAK,IAAIJ,EAAEG,EAAC,EAAEhB,EAAE,EAAES,GAAG,IAAI,CAAC,EAAE,GAAGQ,EAAEnB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE8G,EAAG9G,CAAC,EAAEC,EAAE6G,EAAG7G,CAAC,EAAEM,GAAEH,GAAGb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEF,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAED,IAAIV,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAED,EAAEV,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACoC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASpC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEgH,EAAGhH,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EACtfC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEgH,EAAGhH,IAAI,EAAEC,IAAI,CAAC,EAASyD,GAAG3D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAA4C,IAAI,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,UAAU,CAAC,OAAOvB,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,mBAAmB,EAAE,EAAE,SAAStB,EAAEC,EAAEC,EAAEC,EAAE,CAAmC,IAAlC8D,GAAE,GAAGhE,IAAI,EAAEqH,GAAG,OAAOpH,EAAED,EAAEE,IAAI,GAAG,EAAMA,EAAE,EAAEA,EAAED,EAAEC,IAAImH,GAAGnH,CAAC,EAAER,EAAG,EAAEM,EAAEE,IAAI,CAAC,EAAE,OAAO,EAAEH,EAAE2D,GAAG,CAAC3D,EAAE,CAAC,EAAE2J,GAAG3J,CAAC,GAAG,MAAM,KAAKsH,EAAE,CAAC,EAAE,EAAE,SAAStH,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEd,EAAE,EAAE,OAAO,GAAGa,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EACxf,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAEnB,GAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,GAAE,KAAKoB,CAAC,EAAElB,GAAE,EAAE,IAAImB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAEqH,GAAG,EAAEC,GAAG,EAAEpD,GAAG,EAAEqD,EAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEE,GAAG,EAAEhJ,IAAGa,EAAE,WAAW,EAAEwI,GAAG,EAAE,SAASrI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOkI,GAAGrI,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GACrW,UAAU,CAAC,SAASH,EAAEE,EAAEC,EAAE,CAAC,OAAAD,EAAEA,EAAE,QAAQA,EAAEuI,GAAGvI,CAAC,EAAEmC,EAAEnC,EAAE6J,GAAG7J,CAAC,EAAE+D,GAAE,GAAG,KAAK5B,EAAE,EAAE,EAAEM,GAAG,QAAQN,EAAE,CAAC,EAAEC,GAAGnC,EAAEgD,GAAG,EAASjD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE2J,EAAE,EAAO,GAAL1G,GAAG,EAAKrD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC,EAAE,sDAAsDA,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAuD,GAAGxD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,SAASA,EAAE,MAAM,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAAEF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASwC,EAAE,GAAGrC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBwC,EAAE,GAAGrC,EAAEC,CAAC,EAC7ZJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,KAAKZ,EAAE,yBAAyBwC,EAAE,GAAGrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAC7dL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBwC,EAAE,IAAIrC,CAAC,EAC5dH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAewC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBwC,EAAE,IAAIrC,CAAC,EACxeH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYwC,EAAE,IAAIrC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBwC,EAAE,IAAIrC,CAAC,EAAE,IAAI0E,GAAG7E,EAAE,cAAc,KAAK6E,GAAG7E,EAAE,cAAcwC,EAAE,IAAI,EAAE0E,GAAGlH,EAAE,QAAQG,IAAI+G,GAAGlH,EAAE,QAAQwC,EAAE,IAAIrC,CAAC,EAAEyJ,GAAG5J,EAAE,MAAMG,IAAIyJ,GAAG5J,EAAE,MAAMwC,EAAE,IAAIrC,CAAC,EAAEH,EAAE,sBAAsB,KAAKA,EAAE,sBAAsBwC,EAAE,IAAI,EAC7d,IAAIwH,GAAGhK,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwJ,GAAGhK,EAAE,yBAAyBwC,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,4BAA4B,KAAKA,EAAE,4BAA4BwC,EAAE,IAAI,EAC1K,IAAIgF,GAAG,CAACrH,EAAEC,EAAEC,EAAEC,KAAKkH,GAAGhF,EAAE,IAAIrC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsE,GAAGzE,IAAIyE,GAAGpC,EAAE,IAAIrC,CAAC,EAAEgF,GAAGnF,EAAE,yBAAyBG,IAAIgF,GAAGnF,EAAE,yBAAyBwC,EAAE,IAAIrC,CAAC,EAAEwG,GAAG3G,EAAE,2BAA2B,KAAK2G,GAAG3G,EAAE,2BAA2BwC,EAAE,IAAI,EAAEyH,GAAG9J,IAAI8J,GAAGzH,EAAE,IAAIrC,CAAC,EAAE6E,GAAG,CAAC7E,EAAEC,KAAK4E,GAAGxC,EAAE,IAAIrC,EAAEC,CAAC,EAAEkH,GAAG,KAAKA,GAAG9E,EAAE,IAAI,EAAEyC,GAAG9E,IAAI8E,GAAGzC,EAAE,IAAIrC,CAAC,EAAEoH,GAAGpH,IAAIoH,GAAG/E,EAAE,IAAIrC,CAAC,EAAE+E,GAAGlF,EAAE,WAAW,CAACG,EAAEC,KAAK8E,GAAGlF,EAAE,WAAWwC,EAAE,IAAIrC,EAAEC,CAAC,EAAEsJ,GAAGvJ,IAAIuJ,GAAGlH,EAAE,IAAIrC,CAAC,EAAE4I,GAAG,KAAKA,GAAGvG,EAAE,IAAI,EAAEiH,GAAGtJ,IAAIsJ,GAAGjH,EAAE,IAAIrC,CAAC,EAAEwJ,GAAG,KAAKA,GAAGnH,EAAE,IAAI,EAAExC,EAAE,eAAe,QAAQA,EAAE,cAAc,QAC3d,SAASkK,GAAG/J,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,aAAaC,EAAED,EAAE,YAAY,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,iBAAiBiD,GAAGjD,EAAE,WAAWb,GAAEa,EAAE,WAAWuH,GAAGvH,EAAE,UAAUsH,GAAGtH,EAAE,aAAaiF,GAAGjF,EAAE,aAAa+D,GAAE/D,EAAE,aAAa6F,GAAG7F,EAAE,gBAAgB2F,GAAG3F,EAAE,WAAWiE,GAAGjE,EAAE,QAAQoE,GAAE,IAAI+F,GAAG/G,GAAE,SAASgH,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAK/G,GAAEgH,EAAG,EAC/b,SAASC,IAAI,CAAC,SAASlK,GAAG,CAAC,GAAG,CAACgK,KAAKA,GAAG,GAAGnK,EAAE,UAAU,GAAG,CAAC0C,MAAIhB,GAAGqD,GAAGjC,EAAE,EAAE7C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAK,CAAC0B,GAAE,CAAC,GAAG1B,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAE+C,GAAG,QAAQ3C,CAAC,CAAC,CAAC2E,GAAGhC,EAAE,CAAC,CAAE,CAAC,GAAG,EAAE,EAAEG,IAAG,GAAGxB,EAAEzB,EAAGD,CAAC,EAAE0B,GAAGqD,GAAGjC,EAAE,EAAE,YAAY9C,CAAC,MAAM,CAAC,GAAGA,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQ6C,GAAG,QAAQ7C,EAAE,OAAO,MAAM,CAAC,EAAE+E,GAAGlC,EAAE,EAAE,EAAEK,KAAIlD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EACpiB,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAAC,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAqK,GAAG,EAGzHpL,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC9FlC,IAAAuL,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,0/ECAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA8GAC,GAxMbC,GAAAC,EAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA6ErC,GA1EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EACrC,GAAI,OAAO,KAAS,IAClBc,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC9MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,EAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,EAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GA+EOC,GArIbC,GAAAC,EAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,WAAY,CAC5B,IAAIM,EAAaN,EAAa,YAE1B,OAAOM,GAAc,UAAY,CAAC,OAAO,UAAUA,CAAU,GAAKA,EAAa,KACjFA,EAAa,GAEf,IAAML,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBI,EAAW,SAAS,EAAGR,CAAM,EACjEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMY,EAAgBZ,EACtB,GAAIY,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAMN,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBK,EAAc,gBAAiBT,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDE,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCR,CAAM,EAAE,CACjE,CAEA,IAAMS,EAAmBN,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBY,CAAgB,IAAM,GACxFH,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMgB,EAAOL,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBY,EAAkDjB,GAAW,CAAC,EACpET,GAAqB0B,CAAc,EAEnC,GAAI,CACF,IAAMnB,EAAyBT,GAAyB4B,EAAe,wBAA0B,KAAK,EAChGlB,EAAgBT,GAAiB2B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWR,GAAgBQ,EAAe,MAAOZ,CAAM,EAAI,EAEzFc,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFR,GAAgBQ,EAAe,uBAAwBZ,CAAM,EAC7D,EAcJ,GAZAF,EAAuBa,EAAK,yBACxBlB,EAAwB,CAAC,CAACmB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBlB,EAC/F,CAAC,CAACkB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BlB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CK,EAAe,oBACjBzB,GAAsBW,EAAsBc,EAAe,mBAAoBZ,CAAM,EAGnFY,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAaf,GAAgBa,EAAMjB,CAAM,EAC3CW,EAAK,6BAA6Bb,EAAsBqB,EAAYD,CAAK,IAAM,GACjFX,GAAe,wCAAwCU,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMf,EAAgBC,GAAgBiB,EAAKrB,CAAM,EAC3CK,EAAkBD,GAAgBc,EAAOlB,CAAM,EAEjDW,EAAK,0BAA0Bb,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCc,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACpB,EAAsBE,CAAM,CACtC,OAASsB,EAAG,CACV,MAAIxB,IAAyB,GAC3Ba,EAAK,0BAA0Bb,CAAoB,EAErDE,EAAO,QAAQuB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IC/MA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,EAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,EAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,EAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,EAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,EAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,EAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,MACR,KAAK,IACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,GACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,EAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASC,EAAIN,EAAW,EAAI,EAAGM,GAAKH,EAAOG,IAAK,CAC9C,IAAMC,EAAON,EAAQK,EAAI,EAAI,EAAIR,EAAMG,EAAQK,CAAC,EAC1CE,EAAON,EAAQI,EAAI,EAAI,EAAIP,EAAMG,EAAQI,CAAC,EAEhD,GAAIC,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFJ,EAAMD,EAAQG,CAAC,EAAI,KAAK,IAAIC,EAAMC,CAAI,CACxC,CAEA,OAAOJ,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASN,EAAI,EAAGA,GAAKK,EAAWL,IAC9B,GAAIG,EAAME,EAAYL,CAAC,IAAM,GAAKG,EAAME,EAAYL,CAAC,IAAMI,EAAWE,EAAYN,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGajB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASZ,EAAIU,EAAOV,EAAIW,EAAKX,IAAK,CAGhC,GAAIQ,EAAKR,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHY,GAAQJ,EAAKR,CAAC,CAChB,CACA,OAAOY,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASb,EAAIa,EAAO,EAAGb,GAAK,EAAG,EAAEA,EAC/Bc,EAAQd,CAAC,EAAIc,EAAQd,EAAI,CAAC,EAAIQ,EAAKR,EAAI,CAAC,EAE1C,OAAOc,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGnB,IAAMmB,EAAIC,EAAIpB,CAAC,EAAIoB,EAAIpB,EAAIa,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGnB,IAAMmB,IAAMG,EAAOtB,CAAC,CAAC,CAC/C,CACF,EAEahB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAqMPC,GAoCOC,GAUAC,GAOAC,GAiBAC,GAcAC,GAgBAC,GAsBPC,GAuSOC,EAaAC,EA4DPC,GAuFOC,GAYAC,GAeAC,GAlzBbC,GAAAC,EAAA,kBAGAC,KACAC,KAaalB,GAAiB,GAqMxBC,GAAoB,CAACkB,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEajB,GAA8B,CAACiB,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAapB,GAAkBkB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAOalB,GAA8BmB,GACvCA,EAAK,SAAW,EAAI,CAAC,EAAI,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAMrGlB,GAAoBoB,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASInB,GAAa,CAACoB,EAAW,MAAOL,EAAqBM,EAAQ,MACpE,CAACN,GAAcA,IAAe,EACzB,GAAGK,CAAQ,IAAIC,CAAK,IAGtB,MAAMN,CAAU,IAAIK,CAAQ,KAAKC,CAAK,IASlCpB,GAAY,CAACmB,EAAkBL,EAAoBM,IAC1DD,IAAa,MACRC,EAELN,IAAe,EACV,OAAOM,CAAK,IAGd,MAAMN,CAAU,KAAKM,CAAK,IAQtBnB,GAAY,CAACoB,EAAcP,IAClCA,IAAe,EACV,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,MAClBP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EAaHnB,GACF,CAACmB,EAAcC,EAAoBC,EAAuCC,EACzEV,IAAuC,CACtC,IAAMW,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFX,EAAapB,GAAkB2B,EAAYR,CAAU,EACrDe,EAAY,OAAOd,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEe,EAAc,OAAOf,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASe,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,GAA+B,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGb,CAAI,SAC/Be,EAAU,GAAGF,CAAa,GAAGb,CAAI,WACnCgB,EAAa,GACjB,QAASC,EAAI,EAAGA,EAAIZ,EAAO,EAAGY,IAC5BD,GAAc;AAAA,aACTC,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC5BA,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC7BA,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,oBAAoBR,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzBwB,CAAU;AAAA;AAAA,KAIJG,EAAmBC,IACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,EAAY,OAAOpB,CAAI,IAAIoB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,EAAIZ,EAAO,EAAGY,GAAK,EAAGA,IAC7BI,EAAQ,KAAK,GAAGN,CAAO,IAAIE,CAAC,gBAAgBA,CAAC,IAAI,EAIrD,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,aAAaR,EAAK,OAAO;AAAA,aAC3B6B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,IACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,EAAa,OAAOxB,CAAI,IAAIwB,CAAU,KAGpDC,EAAU,IAAIC,IAChBrB,IAAS,EAAI,KAAO,GAAGb,EAAK,OAAO,IAAIkC,EAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,EAAa,CAACH,EAAoBI,KAClCvB,EAAO,EACF,GAAGmB,CAAU,GAEb,GAAGA,CAAU,IAAII,EAAG,IAIzBC,GAAa,CAACL,EAAoBI,GAAoB7B,KACtDM,EAAO,EACF,GAAGmB,CAAU,IAAIzB,EAAK,IAEtB,GAAGyB,CAAU,IAAII,EAAG,KAAK7B,EAAK,IAInC+B,EAAoE,CAAC,EACrEC,EAA6B,CAACP,EAAoBQ,KAA0B,CAChFpB,EAAmB,2BAA6B,GAChD,IAAMqB,GAAU,GAAGD,GAAO,IAAI,uBAAuBhC,CAAI,SACzD,GAAIiC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIT,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMI,GAAO,WAAW,gBAAiBf,GAAIe,GAAO,KAAO3B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,EAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,EAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAa,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,GAAO,KAAK,OAAO;AAAA,sBACzCX,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGY,EAAO,IAAIT,CAAU,GACjC,EAEMU,GAAc,CAACC,EAAuBpC,MAAmB,IAAM,CACnE,GAAIP,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,KAAKpC,EAAK,IAC7B,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,8BAA8BA,EAAK,UAC9E,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,UAC3C,GAAIP,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,8DAA8DpC,EAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CP,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG4C,GAAeD,IAA2B,IAAM,CACpD,GAAI3C,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,IACnB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBQ,CAAI,IAAImC,CAAM,oBAAoBnC,CAAI,IAAImC,CAAM,sBAAsBnC,CAAI,IAChGmC,CAAM,wBAAwBnC,CAAI,IAAImC,CAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6C3C,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG6C,GAA6BhC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,QAAQgB,CAAS;AAAA,aACrD4B,GAAY,OAAOpC,CAAI,WAAW,CAAC;AAAA,KAGpCsC,EAAoBjC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,QAAQ/B,CAAS;AAAA,iBACjCR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIhB,IAA0C,CACxD,GAAIA,EAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMqC,GAAoBjB,EAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJ+B,GAAY,IAAI,EACd/B,IAAS,EACX+B,GAAYM,GAAkB,CAAC,CAAC,GAEvC9B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,IAE3C,EAEMC,GAAgBnB,GAChBnB,EAAO,EACF+B,GAAYZ,CAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAIvCoB,GAA6BvC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,YAAYgB,CAAS;AAAA,MAChE0B,GAAY,OAAOlC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC6C,GAAoBxC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,YAAY/B,CAAS;AAAA,UAC5CR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAExC,GAAG,EAiEH,MAAO,CACL,KA/BW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACf,OAAK1C,IACH0C,EAAM,KAAK,SAAShC,CAAK,MAAMtB,EAAK,OAAO,IAAIU,EAAY,KAAK,GAAG,CAAC,IAAI,EACxE4C,EAAM,KAAK,SAAS/B,CAAO,MAAMvB,EAAK,OAAO,IAAII,EAAU,eAAeM,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,GAElGU,EAAmB,iBACrBkC,EAAM,KAAK5B,CAA6B,EAEtCN,EAAmB,iBACrBkC,EAAM,KAAKxB,CAA6B,EAEtCV,EAAmB,4BACrB,OAAO,OAAOkB,CAAwC,EAAE,QAAQiB,IAAQD,EAAM,KAAKC,EAAI,CAAC,EAEtFnC,EAAmB,KACrBkC,EAAM,KAAKD,EAAiB,EAE1BjC,EAAmB,cACrBkC,EAAM,KAAKF,EAA0B,EAEnChC,EAAmB,KACrBkC,EAAM,KAAKR,CAAiB,EAE1B1B,EAAmB,cACrBkC,EAAM,KAAKT,EAA0B,EAEhCS,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAtD,EACA,gBAAA2B,EACA,gBAAAI,EACA,2BAAAQ,EACA,QAAAN,EACA,WAAAE,EACA,WAAAE,GACA,IAxEU,IAAImB,IAAkD,CAChE,GAAIA,EAAgB,SAAW3C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMN,GAAQiD,EAAgB3C,CAAI,EAClC,GAAI,OAAON,IAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM2C,GAAoBM,EAAgB,MAAM,EAAG3C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ6B,GAAY,KAAMnC,EAAK,EACrBM,IAAS,EACX6B,GAAYQ,GAAkB,CAAC,EAAG3C,EAAK,GAE9Ca,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,KAAK3C,EAAK,IAErD,EAoDE,YAAAmC,GACA,aAnDmB,CAACV,EAAoBzB,KACpCM,EAAO,EACF6B,GAAYV,EAAYzB,EAAK,GAEpCa,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAAKzB,EAAK,MA8CrD,IAAA0C,GACA,YAAAL,GACA,aAAAO,GAEA,MAAOxC,EAAU,QAAU,SAC3B,KAAAH,EACA,QAAAe,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWSvB,EACT,CAACkB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAMT,CAAU,EAWxDV,EACT,CAACiB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAOT,CAAU,EA0DhET,GAAN,KAA+C,CAC7C,YAAoBiE,EAAmD,CAAnD,6BAAAA,EA4DpB,KAAQ,eAAkC,CAAC,EAC3C,KAAQ,SAA8B,CAAC,EAevC,KAAQ,cAAgB,CA5EgD,CAExE,sCAAsCpD,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUqD,EAAiD7E,GAAgB,CACzE,IAAM8E,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA,wDAEA;AAAA;AAAA,yDAGnCE,EAAsBF,EACxB,gCACA;AAAA,mEAEIH,EAAiBC,EAAiBC,CAAc,mBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,gBAAgBC,EAAyBC,EAA8B,CAC7E,KAAK,eAAe,KAAKD,CAAQ,EAC7BA,EAAS,OAAS,IAChBA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAE7FA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,GAGrG,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/ChD,EAAcgD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWhD,CAAW,IAC3G,CAEA,oBAAoBmD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEA,gBAAgB7D,EAAcR,EAA4B,CACxD,YAAK,SAAS,KAAK,CAAC,KAAAQ,EAAM,KAAAR,CAAI,CAAC,EACxB,IACT,CAEA,iBAAiBsE,EAAqD,CACpE,YAAK,SAAW,KAAK,SAAS,OAAOA,CAAkB,EAChD,IACT,CAIQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMC,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAA/D,EAAM,KAAAR,CAAI,IAAK,KAAK,SAC9BuE,EAAgB,KAAK,GAAG/D,CAAI,IAAIR,CAAI,EAAE,EAGxC,MAAO;AAAA,0BACeuE,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,eAAe,IAAI9C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACrF,CACF,EAEahC,GAAsB+E,GAA4C,IAAIhF,GAAiBgF,CAAa,EAYpG9E,GAAmB,CAAC+E,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjBtE,EAAiB,CAAC,EACxB,QAASsB,EAAI,EAAGA,EAAIkD,EAAQlD,IAAK,CAC/B,IAAMN,EAAMwD,EAAS,EAAIlD,EACnBmD,EAAIH,EAAQtD,CAAG,GAAK,GAChBuD,EAASA,EAAS,OAAS,EAAIjD,CAAC,GAAK,GACvC,GAAKmD,IAAM,GACjBzE,EAAK,QAAQgB,CAAG,CAEpB,CACA,OAAOhB,CACT,EAGaR,GAAwBkB,GAA0BA,GAAQ,IClzBvE,IAcMgE,GAMAC,GAGAC,GAGAC,GAWOC,GA+CAC,GAKAC,GAzFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GAA6B,CAACkB,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BT,EAAYS,EAAY,KAAK,OAC7BR,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CE,EAAoBC,GAAqBb,CAAS,EAClDc,EAAczB,GAAeoB,EAAY,KAAMR,CAAI,EACnDc,EAAiBH,EAAoBE,EAAY,OAASA,EAC1DE,EAAgBJ,EAAoBZ,EAAYS,EAAY,KAC5DH,EAASW,EAAe,SAAUN,EAAeI,CAAc,EAC/DV,EAAQa,EAAc,IAAKP,EAAeK,CAAa,EAEvDG,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBf,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDc,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5Dd,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEpE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmBE,EAAoB,CAAC,MAAM,EAAI,CAAC,MAAM,CAAC,EAC7F,WAAab,GAAW,CACtB,IAAMsB,EAAalB,EAAU,KAAKW,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUf,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,EAClE,gBAAiBT,EACb,CACE,CAAC,KAAM,SAAU,KAAMS,CAAU,EACjC,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGuB,GAA2BR,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAMO,CAAU,CACnC,CACN,CACF,EACA,gBAAAF,CACF,CACF,EAEa3B,GAAY,CAAC+B,EAAyBC,IAA0C,CAC3FrC,GAAeoC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQhC,GAA2BgC,EAAQ,OAAO,CAAC,EAAGC,EAAW,IAAI,CAAC,CAChF,EAEa/B,GAA4B+B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,IC1FnE,IAYME,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GA0EPC,GAkCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAvQbC,GAAAC,EAAA,kBAKAC,KAGAC,KACAC,KACAC,KAEM1B,GAAqC,CACzC,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA2C,CAC/C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA4C,CAChD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAA8C,CAClD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACuB,EAAsBC,IAA2B,CACzE,IAAMC,EAAM,CAAC,EACb,QAASC,EAAIF,EAAOD,EAAcG,EAAIF,EAAM,EAAEE,EAC5CD,EAAI,KAAKC,CAAC,EAEZ,OAAOD,CACT,EAEMxB,GAA4B,CAAC0B,EAA0BC,IAAkD,CAC7G,IAAMC,EAAc,CAAC,EACfL,EAAOG,EAAM,OACnB,QAASG,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,IACxBD,EAAY,KAAKF,EAAMG,CAAG,CAAC,EAG/B,IAAMC,EAAcH,EAAK,IAAIE,GAAOH,EAAMG,CAAG,CAAC,EAC9C,MAAO,CAACD,EAAaE,CAAW,CAClC,EAEM7B,GAAuB,CAACyB,EAAiBC,IAA6B,CAC1E,IAAMJ,EAAOG,EAAM,OAASC,EAAK,OAC3BI,EAAc,CAAC,EACjBC,EAAW,EACf,QAASH,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,GACxBE,EAAY,KAAKL,EAAMM,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEM7B,GAAuB,CAACyB,EAAgBJ,IAA0B,CACtE,QAASE,EAAI,EAAGA,EAAIE,EAAK,OAAQ,EAAEF,EACjC,GAAIE,EAAKA,EAAK,OAASF,EAAI,CAAC,IAAMF,EAAO,EAAIE,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMtB,GAAqB,CAACwB,EAAgBJ,IAA2B,CACrE,IAAMC,EAAM,CAAC,EACb,GAAI,CAACtB,GAAqByB,EAAMJ,CAAI,EAAG,CACrC,QAASE,EAAI,EAAGA,EAAIF,EAAM,EAAEE,EACtBE,EAAK,QAAQF,CAAC,IAAM,IACtBD,EAAI,KAAKC,CAAC,EAGdE,EAAK,QAAQM,GAAQT,EAAI,KAAKS,CAAI,CAAC,CACrC,CACA,OAAOT,CACT,EAEapB,GACT,CAAC8B,EAAcC,EAAqCC,EAA+BC,EAClFC,EAA0BV,EAAuBE,IAAuC,CACvF,IAAMS,EAAaH,EAAO,CAAC,EAAE,KAEvBI,EAAaC,EAAU,KAAKb,CAAW,EACvCc,EAAaD,EAAU,KAAKX,CAAW,EAEvCa,EAAQC,EAAc,KAAMR,EAAO,CAAC,EAAE,SAAUG,CAAU,EAC1DM,EAASC,EAAe,SAAUR,EAAgBV,CAAW,EAE7DmB,EAAgB,GAEhBC,EAAsB;AAAA,+CACaH,EAAO,KAAK,OAAO,KAAKE,CAAa;AAAA,SAgD9E,MAAO,CACL,KAAAb,EACA,YAAAC,EACA,gBAhDuBc,GAA+B;AAAA,UACpDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBN,EAAOE,CAAM,CAAC;AAAA,UACjFG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBC,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA,2CAGLA,CAAa;AAAA;AAAA;AAAA,4BAG5BF,EAAO,KAAK,OAAO,IAAIhD,GAAiBwC,CAAU,CAAC;AAAA;AAAA,wDAEvBU,CAAa;AAAA,6BACxCF,EAAO,KAAK,OAAO,IAAIF,EAAM,YAAY,YAAY,CAAC;AAAA,yBAC1DhD,GAAU0C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKNU,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BnD,GAAgByC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS3CQ,EAAO,YACH,cACA,GACIR,IAAe,OAAS,eAAeQ,EAAO,KAAK,OAAO,wBAClC,GAAG/C,GAAmBuC,CAAU,CAAC,EAAE,EAAE,CAAC;AAAA;AAAA,WASxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUU,CAAc,CAAC,EACvD,cAAe,CAAC,EAAGE,CAAU,EAC7B,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,CACtD,EACF,CACF,EAEErC,GACF,CAAC6C,EAAyBhB,EAAciB,EACvCd,IAAiG,CAChG,IAAMe,EACFF,EAAQ,OAAO,SAAW,EAAIC,EAAaE,GAAiCH,EAAQ,OAAQC,CAAU,EAEtGG,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAAcJ,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACK,EAAM9B,IAAMA,CAAC,GAEzD,IAAM+B,EAAgBf,EAAU,cAAca,EAAaJ,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFvB,EAAO6B,EACPb,EAAQO,EAAQ,OAAO,CAAC,EACtBO,EAAetD,GAAmBwB,EAAMuB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEO,EAAa,OAAS,IACxBd,EAAQO,EAAQ,QACZQ,GAA2BR,EAAQ,OAAO,CAAC,EAAGO,CAAY,EAAG,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAChG9B,EAAO5B,GAAiB4B,EAAK,OAAQgB,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACf,EAAaE,CAAW,EAAI9B,GAA0B2C,EAAM,KAAMhB,CAAI,EACzEgC,EAAmB/B,EACnBwB,EAAkB,WACpBO,EAAmB1D,GAAqB2B,EAAa4B,CAAa,GAGpEN,EAAQ,QACJ9C,GACI8B,EAAM,CAAC,KAAMkB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACT,CAAK,EAAGN,EAChFa,EAAQ,OAAO,CAAC,EAAE,SAAUS,EAAkB7B,CAAW,EAC7D,CAAC,OAAQ,CAACa,CAAK,CAAC,CAAC,CACvB,EAESrC,GAAmB,CAAC4C,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEa5C,GAAiB,CAAC2C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa3C,GAAiB,CAAC0C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa1C,GAAwB,CAACyC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEazC,GAAkB,CAACwC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEaxC,GAAkB,CAACuC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEavC,GAAmB,CAACsC,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEatC,GAAkB,CAACqC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEarC,GAAwB,CAACoC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEapC,GAAqB,CAACmC,EAAyBC,IAAuC,CACjG9C,GAAa6C,EAAS,qBAAsBC,EAAY,QAAQ,CAClE,ICzQA,IAYMS,GAoBAC,GACOC,GA4EAC,GAUPC,GAeAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAsBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAtXbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KACAC,KAEMhC,GAAkBiC,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYMhC,GAAkBiC,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,YAAY,aAAa,CAAC,IAAK,EAAE,EACpFhC,GACT,CAACiC,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KAEvBW,EAAOC,EAAU,cAAcP,EAAWL,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/Da,EAAkB,CAACL,GAAqBG,EAAK,SAAW,EAC9DD,EAAW,QAAQ,CAACI,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCR,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKK,CAAC,CAEtB,CAAC,EAED,IAAME,EAAoB,CAAC,EAErBf,EAAQgB,EAAc,KAAMjB,EAAO,CAAC,EAAE,SAAUU,CAAU,EAC1DQ,EAASC,EAAe,SAAUb,EAAgBG,CAAW,EAC7DW,EAAMhB,EAASH,EAAOiB,EAAQP,CAAI,EAClCU,EAAwB,iBAAiBpB,EAAM,gBAAgB,cAAc,CAAC,IAC9EqB,EAAqB,OAAOD,CAAqB,IACjDE,EAAqB,OAAOF,CAAqB,IACjDG,EAAmBJ,EAAI,CAAC,IAAM,GAAM,GAAKG,EAC3CE,GAAcL,EAAI,CAAC,IAAM,GAAME,EAAqBD,GAAyB;AAAA,EAAOD,EAAI,CAAC,EAE7F,QAASM,EAAI,EAAGC,EAAI,EAAGD,EAAI1B,EAAO,CAAC,EAAE,KAAK,OAAQ0B,IAE5Cb,GAAmBF,EAAK,QAAQe,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAM1B,EAAO,CAAC,EAAE,KAAK0B,CAAC,CAAC,MAAMA,CAAC;AAAA,kBAC/DN,EAAI,CAAC,EAAE,SAAS,WAAW,EAAI,oBAAoBM,CAAC,IAAM,EAAE;AAAA,kBAC5DzB,EAAM,WAAW,eAAgByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,kBAC5CD,CAAS;AAAA,mBAGjBT,EAAQ,KAAK,GAAGf,EAAM,WAAW,eAAgByB,EAAGR,EAAO,WAAW,gBAAiBS,CAAC,CAAC,CAAC,GAAG,EAC7FA,KAIJ,IAAMC,EAAahB,EAAU,KAAKH,CAAW,EAkB7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBApBuB0B,GAA+B;AAAA,UACpDA,EAAa,iBAAiB5B,EAAOiB,CAAM,CAAC;AAAA;AAAA,UAE5CW,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCD,CAAU,CAAC;AAAA,8BAC5C3B,EAAM,KAAK,OAAO;AAAA,gCAChBiB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNI,CAAe;AAAA,YACfJ,EAAI,CAAC,CAAC;AAAA,YACNK,CAAS;AAAA,YACTL,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,WAO1F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMX,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAES1D,GACT,CAAC8B,EAA+B8B,IAAmD,CACjF,IAAMnB,EAAiB,CAAC,EACxB,OAAIX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ+B,GAAKpB,EAAK,KAAK,OAAOoB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAArB,EAAM,SAAUmB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEE3D,GACF,CAAC8D,EAAyB/B,EAAc4B,EAA8B1B,IAA6B,CACjG,IAAMJ,EAASiC,EAAQ,OACjBC,EACFlC,EAAO,SAAW,EAAI8B,EAAa5D,GAAiC8B,EAAQ8B,CAAU,EAE1FG,EAAQ,QACJhE,GACIiC,EAAM,CAAC,KAAMgC,EAAkB,QAAQ,EAAG,CAAClC,EAAO,CAAC,CAAC,EACpDkC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIlE,GAAOoC,EACpF8B,EAAkB,KAAMlC,EAAO,CAAC,EAAE,SAAUkC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEE9D,GAAoB,CAAC6D,EAAyBH,IAAuC,CACzF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,eAAgBH,EANf,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,qBACL,CAC8D,CAChE,EAEM5B,GAAgB,CAAC4D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,EACL,CAC0D,CAC5D,EAEM3B,GAAgB,CAAC2D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,sBACvC,sBACL,CAC0D,CAC5D,EAEM1B,GAAuB,CAAC0D,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,qBACL,CACiE,CACnE,EAEMzB,GAAiB,CAACyD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAKnC,EAAM,WAAW,eAAgByB,EAAG,CAAC,CAAC,EAIvD,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMxB,GAAkB,CAACwD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAiB7B9D,GAAiB8D,EAAS,aAAcH,EAhBb,CAAC7B,EAAOiB,EAAQP,IAAS,CAClD,IAAI0B,EAAO,EACX,QAASX,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,KAE1C0B,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKP,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,YAAY,aAAa,CAAC,KAC9C,eAAeiB,EAAO,KAAK,KAAK,UAAUmB,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEM3D,GAAiB,CAACuD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAK,gBAAgBV,CAAC,QAAQ,EAI1C,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMtB,GAAkB,CAACsD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,aAAcH,EANb,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC4D,CAC9D,EAEMrB,GAAiB,CAACqD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,YAAaH,EANZ,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC2D,CAC7D,EAEMpB,GAAuB,CAACoD,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,oBACvC,EACL,CACiE,CACnE,EAEMnB,GACF,CAACwD,EAA0B3B,EAAyBH,IAAwC,CAC1F,GAAIG,EAAK,SAAW,EAClB,MAAO,EAAAH,EAGT,IAAIoB,EAAa,EACbW,EAAa,EACjB,QAASC,EAAM,EAAGA,EAAM7B,EAAK,OAAQ6B,IAC/B7B,EAAK,QAAQ6B,CAAG,IAAM,GACxBZ,GAAcU,EAAME,CAAG,EAEvBD,GAAcD,EAAME,CAAG,EAO3B,OAAOD,EAAa,IAAMX,EAAa,IACzC,EAES7C,GAAa,CAACkD,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FrD,GAAgBwD,EAASH,CAAU,EAEnCW,GAAiBR,EAASH,CAAU,CAExC,EAEa9C,GAAW,CAACiD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FzD,GAAc4D,EAASH,CAAU,EAEjCY,GAAeT,EAASH,CAAU,CAEtC,EAEa7C,GAAW,CAACgD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FxD,GAAc2D,EAASH,CAAU,EAEjCa,GAAeV,EAASH,CAAU,CAEtC,EAEa5C,GAAkB,CAAC+C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FvD,GAAqB0D,EAASH,CAAU,EAExCc,GAAsBX,EAASH,CAAU,CAE7C,EAEa3C,GAAY,CAAC8C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FtD,GAAeyD,EAASH,CAAU,EAElCe,GAAgBZ,EAASH,CAAU,CAEvC,EAEa1C,GAAY,CAAC6C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FpD,GAAeuD,EAASH,CAAU,EAElCgB,GAAgBb,EAASH,CAAU,CAEvC,EAEazC,GAAa,CAAC4C,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FnD,GAAgBsD,EAASH,CAAU,EAEnCiB,GAAiBd,EAASH,CAAU,CAExC,EAEaxC,GAAY,CAAC2C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FlD,GAAeqD,EAASH,CAAU,EAElCkB,GAAgBf,EAASH,CAAU,CAEvC,EAEavC,GAAkB,CAAC0C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FjD,GAAqBoD,EAASH,CAAU,EAExCmB,GAAsBhB,EAASH,CAAU,CAE7C,EAEatC,GAAe,CAACyC,EAAyBH,IAAuC,CACvFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5F1D,GAAkB6D,EAASH,CAAU,EAErCoB,GAAmBjB,EAASH,CAAU,CAE1C,EAEarC,GAAyBqC,GAClCE,GAA4BF,CAAiE,ICvXjG,IAcMqB,GAeOC,GA0BAC,GA0BAC,GAjFbC,GAAAC,EAAA,kBAOAC,KAEAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQaR,GAAS,CAACS,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEE,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,QAAQ,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EAAa,CAACD,EAAW,IAAI,IACzFA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaT,GAAS,CAACQ,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEE,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,QAAQ,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EAAa,CAACD,EAAW,IAAI,IACzFA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaR,GAA4BQ,GACrCQ,GAA4BR,CAAoE,IClFpG,IAmEMS,GAsKOC,GAGAC,GAkFPC,GAwGAC,GAiFOC,GASPC,GAmHOC,GAnnBbC,GAAAC,EAAA,kBAIAC,KACAC,KAEAC,KA4DMZ,GAA0B,CAACa,EAA+BC,IAAoD,CAmClH,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAUH,EAAO,CAAC,EAClBI,EAAOJ,EAAO,CAAC,EACfK,EAAYL,EAAO,CAAC,EACpBM,EAAON,EAAO,CAAC,EACfO,EAAuBP,EAAO,CAAC,EAErC,GAAIM,GAAQC,EACV,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIL,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAMM,EAAYN,EAAM,KAAK,CAAC,EACxBO,EAAiBP,EAAM,KAAK,CAAC,EAC7BQ,EAAkBR,EAAM,KAAK,CAAC,EAEpC,GAAIE,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIA,EAAQ,KAAK,CAAC,IAAMO,EACtB,MAAM,IAAI,MAAM,uEAAuE,EAGzF,GAAIN,EAAK,KAAK,CAAC,IAAMD,EAAQ,KAAK,CAAC,EACjC,MAAM,IAAI,MAAM,oFAAoF,EAGtG,IAAIQ,EAAcP,EAAK,KAAK,CAAC,EAAI,EAC7BQ,EAAcD,EACdE,EAAcD,EAClB,GAAIX,EAAW,eAAe,OAAS,EAAG,CACxC,GAAIA,EAAW,eAAe,SAAW,EACvC,MAAM,IAAI,MAAM,mDAAmD,EAErE,QAAWa,KAAMb,EAAW,eAC1B,GAAIa,EAAKb,EAAW,WAAa,EAC/B,MAAM,IAAI,MAAM,mDAAmD,EAIvEU,EAAcV,EAAW,eAAe,CAAC,EACzCW,EAAcX,EAAW,eAAe,CAAC,EACzCY,EAAcZ,EAAW,eAAe,CAAC,CAC3C,CAEA,IAAMc,EAAmBN,EAEzB,GAAIE,IAAgBC,EAClB,MAAM,IAAI,MAAM,6DAA6D,EAG/E,GAAIR,EAAK,KAAK,CAAC,IAAMO,EAAcC,EAAcC,EAC/C,MAAM,IAAI,MAAM,+EAA+E,EAGjG,IAAIG,EAAqB,EACzB,GAAIV,EAAM,CACR,GAAIM,IAAgBC,EAClB,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GAAIP,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,qCAAqC,EAEvD,GAAIA,EAAK,KAAK,CAAC,IAAM,EACnB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAK,KAAK,CAAC,IAAME,EACnB,MAAM,IAAI,MAAM,kDAAkD,EAEpE,GAAIF,EAAK,KAAK,CAAC,IAAML,EAAW,SAC9B,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAIK,EAAK,KAAK,CAAC,IAAMM,EAAcX,EAAW,SAC5C,MAAM,IAAI,MAAM,gEAAgE,EAG7EA,EAAW,yBACde,EAAqBV,EAAK,KAAK,CAAC,EAGpC,CAEA,IAAMW,EAAsBF,EAAmBC,EACzCE,EAAoB,GAEpBC,EAAW,EACjB,GAAId,EAGF,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAIC,EACF,MAAM,IAAI,MAAM,uBAAuB,EAEzC,GAAIC,EACF,MAAM,IAAI,MAAM,uCAAuC,EAGzD,MAAO,CACL,UAAAC,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAAAE,EACA,kBAAAC,EACA,gBAAAR,EACA,WAAYC,EACZ,YAAAE,EACA,SAAU,KAAK,MAAMF,EAAcV,EAAW,QAAQ,EACtD,UAAW,KAAK,MAAMY,EAAcZ,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAqB,GACrB,aAAc,GACd,UAAW,CACb,CACF,EAEab,GAA4Ba,GACrCmB,GAA4B,CAAC,GAAGnB,CAAU,CAAC,EAElCZ,GAAwB,CAACgC,EAAyBnB,EAAmBoB,EAAWC,IAAc,CACzG,IAAMC,EAAaC,GAAiBF,CAAC,EAC/BG,EAAcC,EAAe,IAAKzB,EAAM,SAAUA,EAAM,KAAMsB,CAAU,EAE1EI,EAAiB,kBACjBJ,IAAe,EACjBI,EAAiB,4CACRJ,IAAe,IACxBI,EAAiB,6FAEnB,IAAMC,EAAWC,GAA4B5B,EAAM,QAAQ,EACvD6B,EAAK,GACHC,EAAQT,EAAIC,EACdQ,EAAQD,EACVA,EAAK,EACIC,EAAQ,EAAI,KACrBD,EAAK,KAAK,KAAKC,EAAQ,CAAC,GAE1B,IAAMC,EAAgB,KAAK,KAAKV,EAAIC,EAAaO,CAAE,EAE7CG,EAAmBC,GAA+B;AAAA,gBAC1CN,CAAQ,UAAUN,CAAC;AAAA,kBACjBA,EAAIC,CAAU;AAAA,qCACKO,CAAE;AAAA,qCACFA,CAAE;AAAA;AAAA,IAEnCI,EAAa,iBAAiBT,CAAW,CAAC;AAAA,6BACjBK,CAAE;AAAA;AAAA;AAAA,sCAGOE,CAAa;AAAA;AAAA;AAAA,4BAGvBG,GAAW,MAAOZ,EAAY,gBAAgB,CAAC;AAAA,+BAC5CS,CAAa;AAAA,8BACdI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA;AAAA,2BAEnDI,CAAc;AAAA;AAAA;AAAA;AAAA,2BAIdG,CAAE;AAAA;AAAA;AAAA;AAAA,sBAIPK,GAAW,MAAOZ,EAAY,GAAG,CAAC;AAAA,+BACzBS,CAAa;AAAA,yBACnBI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA;AAAA,2BAE9Cc,GAAU,YAAad,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,2BAIlCO,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA,iCAKIE,CAAa;AAAA,0BACpBG,GAAWP,EAAUL,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA,iCAGjCS,CAAa;AAAA,yBACrBI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA,0BAC/CE,EAAY,KAAK,KAAK;AAAA;AAAA;AAAA,KAK9CL,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGE,CAAC,EAAE,EAC1B,gBAAAW,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,EACV,cAAe,CAAC,EAAGZ,CAAC,CACtB,EACF,EACA,CAAC,OAAQ,CAACpB,CAAK,EAAG,QAAS,CAAC,CAAC,CAAC,CACpC,EAEMZ,GACF,CAAC+B,EAAyBkB,EAAeC,EAAiBC,EACzDC,EAAiCzC,IAA+B,CAC/D,IAAM0C,EAAa,CACjBD,EAAW,UAAWA,EAAW,SAAUA,EAAW,eACtDA,EAAW,iBAAmBA,EAAW,kBAC3C,EAGME,EAAQ3C,EAAW,QAAU,EAAI,EAAM,KAAK,KAAKyC,EAAW,QAAQ,EAAIzC,EAAW,MAEnF4B,EAAWC,GAA4BS,EAAE,QAAQ,EAEjDf,EAAaC,GAAiBiB,EAAW,QAAQ,EACjDG,EAASC,EAAc,IAAKP,EAAE,SAAUA,EAAE,KAAMf,CAAU,EAC1DuB,EAASD,EAAc,MAAON,EAAI,SAAUA,EAAI,KAAMhB,CAAU,EAChEwB,EAASrB,EAAe,SAAUY,EAAE,SAAUI,CAAU,EAExDM,EAAqBP,EAAW,SAAWlB,EAC3C0B,EAAIR,EAAW,eACfS,EAAIT,EAAW,oBACfU,EAAIH,EAEJI,EAAY,GAEZC,EAAW,CACf,EAAG,KAAK,KAAKZ,EAAW,oBAAsBW,CAAS,EACvD,EAAG,KAAK,KAAKX,EAAW,eAAiBW,CAAS,EAClD,EAAGX,EAAW,UAAYA,EAAW,QACvC,EAEM1C,EAAS,CAACuC,EAAGC,CAAG,EAChBN,EAAmBC,GAA+B;AAAA,mBAC3Ce,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,iBACHvB,CAAQ,MAAMe,CAAK;AAAA,gBACpBf,CAAQ;AAAA,sBACFwB,CAAS;AAAA;AAAA,gCAECR,EAAO,KAAK,OAAO,KAAKQ,EAAYA,CAAS;AAAA,gCAC7CR,EAAO,KAAK,OAAO,KAAKQ,EAAYA,CAAS;AAAA;AAAA,IAEzElB,EAAa,iBAAiBU,EAAQE,EAAQC,CAAM,CAAC;AAAA;AAAA,6BAE5BK,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBASjEX,EAAW,eAAiBO,CAAkB;AAAA,oBAC9CP,EAAW,iBAAmBO,CAAkB;AAAA;AAAA,kBAElDb,GAAWP,EAAUL,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAoBtBc,GAAU,QAASd,CAAU,CAAC;AAAA;AAAA,KAI9C+B,EAAQlC,EAAQ,QAClB,CACE,KAAM,iBACN,YAAa,CAAC,KAAM,KAAK,UAAUqB,CAAU,CAAC,EAC9C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAY,SAAUJ,EAAE,SAAU,aAAgC,CAAC,EACpF,cAAee,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAAlC,EAAQ,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAE9B,OAAAX,GACIgC,EAASkC,EAAOb,EAAW,UAAYA,EAAW,SAAWA,EAAW,eACxEA,EAAW,mBAAmB,EAE3Ba,CACT,EAEEhE,GACF,CAAC8B,EAAyBkC,EAAmBC,EAAeC,IAAgC,CAC1F,IAAMC,EAAc,CAACD,EAAO,UAAWA,EAAO,eAAgBA,EAAO,WAAW,EAE1EE,EAAcb,EAAc,QAASS,EAAM,SAAUA,EAAM,IAAI,EAC/DK,EAAUd,EAAc,IAAKU,EAAE,SAAUA,EAAE,IAAI,EAC/CR,EAASrB,EAAe,SAAU4B,EAAM,SAAUG,CAAW,EAE7D7B,EAAWC,GAA4ByB,EAAM,QAAQ,EAErDF,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKG,EAAO,UAAYJ,CAAS,EACzC,EAAG,KAAK,KAAKI,EAAO,eAAiBJ,CAAS,EAC9C,EAAGI,EAAO,UAAYA,EAAO,QAC/B,EAEMvB,EAAmBC,GAA+B;AAAA,mBAC3CsB,EAAO,cAAc;AAAA,mBACrBA,EAAO,SAAS;AAAA,mBAChBA,EAAO,mBAAmB;AAAA,0BACnBA,EAAO,QAAQ;AAAA,sBACnBJ,CAAS;AAAA;AAAA,gCAECM,EAAY,KAAK,OAAO,KAAKN,EAAYA,CAAS;AAAA,gCAClDM,EAAY,KAAK,OAAO,KAAKN,EAAYA,CAAS;AAAA;AAAA,IAE9ElB,EAAa,iBAAiBwB,EAAaC,EAASZ,CAAM,CAAC;AAAA;AAAA,6BAElCK,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBASpExB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAgBY4B,EAAO,QAAQ;AAAA,mDACDA,EAAO,QAAQ;AAAA,sCAC5BA,EAAO,QAAQ,gCAAgCA,EAAO,SAAS;AAAA;AAAA,kCAEnEA,EAAO,eAAiBA,EAAO,WAAW,UAAUA,EAAO,WAAW;AAAA,oCACpEA,EAAO,SAAS;AAAA;AAAA;AAAA,KAK9C,OAAOpC,EAAQ,QACX,CACE,KAAM,iBACN,YAAa,CAAC,KAAM,KAAK,UAAUoC,CAAM,CAAC,EAC1C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAM,SAAU,aAAgC,CAAC,EACzF,cAAeD,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAQ,CAACqB,EAAOC,CAAC,EAAG,QAAS,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAC3C,EAEShE,GACT,CAAC6B,EAAyBkB,EAAesB,EAAeL,EAAeM,EACtEC,EAA6BC,EAAgCC,EAC7D1D,EAA4CmC,EAAiCzC,IAA+B,CAC3G,IAAMsD,EAAQjE,GAAsB+B,EAASkB,EAAGsB,EAAGtD,EAAsBmC,EAAYzC,CAAU,EAE/FV,GAAwB8B,EAASkC,EAAOC,EAAGd,CAAU,CACvD,EAEEjD,GAAU,CAAC4B,EAAyBqB,IAAoC,CAC5E,IAAMgB,EAAc,CAClBhB,EAAW,UACXA,EAAW,SACXA,EAAW,eACXA,EAAW,QACb,EAEMb,EAAWC,GAA4BT,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAEjE6B,EAAIR,EAAW,eACfU,EAAIV,EAAW,gBACfS,EAAIT,EAAW,SAEfW,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKZ,EAAW,SAAWW,CAAS,EAC5C,EAAG,KAAK,KAAKX,EAAW,eAAiBW,CAAS,EAClD,EAAGX,EAAW,UAAYA,EAAW,QACvC,EAEMR,EAAkB,IAAM;AAAA,mBACbgB,CAAC;AAAA,mBACDE,CAAC;AAAA,mBACDD,CAAC;AAAA,0BACMT,EAAW,QAAQ;AAAA,gBAC7BA,EAAW,WAAaA,EAAW,WAAaA,EAAW,WAAW;AAAA,sBAChEW,CAAS;AAAA;AAAA,oCAEKxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAChCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAClCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAClCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA;AAAA,0DAEdxB,CAAQ;AAAA,2DACPA,CAAQ;AAAA,yDACVA,CAAQ;AAAA,kEACCA,CAAQ;AAAA,kEACRA,CAAQ;AAAA,kEACRA,CAAQ;AAAA;AAAA,6BAE7CwB,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA,wCAE7CX,EAAW,QAAQ;AAAA,wCACnBA,EAAW,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,qCAKtBA,EAAW,QAAQ;AAAA,wBAChCA,EAAW,UAAU;AAAA,wBACrBA,EAAW,UAAU;AAAA;AAAA,mBAE1Bb,CAAQ;AAAA,mBACRA,CAAQ;AAAA,mBACRA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAuBUa,EAAW,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAchD1C,EAAS,CAACqB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,CAAC,EAEvE,OAAOA,EAAQ,QACX,CACE,KAAM,mBACN,YAAa,CAAC,KAAM,KAAK,UAAUqB,CAAU,CAAC,EAC9C,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMgB,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMqC,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMqC,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,CAC5F,EACA,cAAeiC,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAAlC,EAAQ,QAAS,CAAC,GAAI,GAAI,EAAE,CAAC,CAAC,CACrC,EAEaN,GAAY,CAAC2B,EAAyBpB,IAAqC,CACtF,IAAMwD,EAAStE,GAAwBkC,EAAQ,OAAQpB,CAAU,EAE3D,CAACsC,EAAGsB,EAAGL,CAAC,EAAI/D,GAAQ4B,EAASoC,CAAM,EAEzC,OAAOjE,GACH6B,EAASkB,EAAGsB,EAAGL,EAAGnC,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAAWA,EAAQ,OAAO,CAAC,EAAGoC,EAAQxD,CAAU,CACjH,IC1nBA,IASMiE,GAkBAC,GAkCOC,GA7DbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,EAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,EAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,EAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,EAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAiBOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BPC,GAMOC,GAaAC,GAIAC,GAIAC,GAQAC,GAGAC,GAeAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAMAC,GAIAC,GAIAC,GAIAC,GAKAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAOAC,GA5QbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMzC,GACF,CAAC0C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,EAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,EAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,QACLN,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAEnFL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA;AAAA,cAE/DQ,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEhD,GACF,CAACiD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,EAAU,kBAAmB,CAAC,MAAM,CAAC,EACzD,gBAAiBb,GAAgB1C,GAC7B0C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,EACpG,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKD,EAAU,KAAKN,EAAM,IAAI,EAAI,CAAC,CAAC,CAClE,CACF,EACF,GAEShD,GAAOwD,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEavD,GAAQuD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEatD,GAASsD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEarD,GAAQqD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEapD,GAASoD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEanD,GAAQmD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACalD,GAASkD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOajD,GAAuBkD,GAChCC,GAA4BD,CAA0B,EAG7CjD,GAAO,CAACgD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOMhD,GAAoCmD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GAC9DC,EAAOH,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GACpE,OAAON,GAA4B,CAAC,IAAAG,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEarD,GAAO,CAAC8C,EAAyBS,IAAyC,CACrF,IAAMR,EAAaD,EAAQ,OAAO,SAAW,EAAIS,EAAiBxD,GAAiC+C,EAAQ,MAAM,EAC3GU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QACJzD,GACIyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,SAASA,CAAC,0BAA2B;AAAA,4BACnDF,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,4BAC9CS,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjFD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,YAAYA,CAAC,IAAK;AAAA,gCACvBX,EAAW,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAS1CA,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAACkD,EAAkBG,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFH,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5BjD,GAAOuC,GAAkC,CACpD,IAAMU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,YAAYA,CAAC,IAAKpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEahD,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjEpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEa7C,GAAY,CAACmC,EAAyBC,IAAsC,CACvFD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,YAAaY,GAAK,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,sBAChF,sCAAsCX,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACtF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa7C,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa5C,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,aAAcY,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEa3C,GAAQ+B,GAAkC,CACrDA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,oBAAoB,CAAC,CAC5F,EAEa1C,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,UAAWY,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEazC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,KACvDD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,kBAAmBY,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,8BAC5E,wDAAwDX,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC/F,GAGIxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,IC9QA,IAUMc,GAkBAC,GAwCOC,GApEbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,EAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,EAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,EAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAsBjD,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBE,GAA+B;AAAA;AAAA,yBAEjCT,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CS,EAAa,iBAAiBP,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDK,GAAQ,OAAO,CAAC;AAAA;AAAA,IAEhBD,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBiB,GAAkC,CAC9DnB,GAAemB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlB,GAA+BkB,EAAQ,MAAM,CAAC,CAChE,ICvEA,IAiBMC,GAyGAC,GA6EAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GA7QbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAAsCC,EAChFC,EAAeC,EAAeC,EAAoBC,EAClDC,IAAsC,CACrC,IAAIC,EACAC,EACA,OAAOP,GAAa,SACtBM,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGT,CAAQ,KAAKQ,CAAC,MAAMC,CAAC,KAC/D,OAAOT,GAAa,WAC7BM,EAAmBC,EAAmBP,GAEtCM,EAAmBN,EAAS,OAC5BO,EAAmBP,EAAS,QAG9B,IAAMU,EAAoBN,EAAoBV,EAAM,OAASA,EACvDiB,EAAoBP,EAAoBT,EAAM,OAASA,EACvDiB,EAAoBR,EAAoBR,EAAW,OAASA,EAC5DiB,EAASC,EAAe,aAAcX,EAAYS,EAAmB,CAAC,EACtEJ,EAAIO,EAAc,QAASd,EAAOS,EAAmB,CAAC,EACtDD,EAAIM,EAAc,QAASb,EAAOS,EAAmB,CAAC,EAExDK,EACJ,GAAInB,EACF,GAAIC,EAAa,CACf,IAAMmB,EAAgBC,EAAU,KAAKxB,CAAK,IAAM,EAC1CyB,EAAgBD,EAAU,KAAKvB,CAAK,IAAM,EAC1CyB,EAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC3E2B,EAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC7EsB,GAAiBE,EACnBH,EAAaH,EAAO,YAChB,aACAN,EACIU,EAAgB,GAAGT,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFW,EAAgB,GAAGV,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGO,EAAa;AAAA,kCACSH,EAAO,gBAAgB,iBAAiB,CAAC;AAAA,4BAC/CL,EAAE,2BAA2B,gBAAiBK,CAAM,CAAC;AAAA,4BACrDJ,EAAE,2BAA2B,gBAAiBI,CAAM,CAAC;AAAA,cAEjEA,EAAO,YACH,aACAN,EACIR,GAA+BqB,EAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,kBACpDT,GAA+BsB,EAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,iBAAiB,CAAC,CAAC;AAAA,WAGvF,MACEO,EAAaH,EAAO,YAChB,aAAcN,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACX,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAMwB,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,GAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMX,EAAO,gBAAgB,qBAAqBW,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMhB,EAAE,2BAA2B,gBAAgBgB,CAAC,GAAIX,CAAM,CAAC;AAAA,yBAChEW,CAAC,MAAMf,EAAE,2BAA2B,gBAAgBe,CAAC,GAAIX,CAAM,CAAC;AAAA,wBACjEW,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAInB,EAAiBoB,GAAaC,CAAW,CAAC;AAAA,WAE9E,EACIxB,IAAe,EACjBa,EAAa;AAAA;AAAA,cAETM,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCN,EAAa;AAAA,cACTM,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH7B,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBe,EAAGC,EAAGI,CAAM,CAAC;AAAA;AAAA,UAE9ER,GAA4B,EAAE;AAAA;AAAA,UAE9BZ,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvEuB,CAAU;AAAA,QAEhB,EAEExC,GACF,CAACoD,EAAcC,EAAkBrB,EAAeC,EAAeT,EAC9DK,EAAmCyB,EAAyBtB,EAAE,WAA0B,CACvF,IAAMuB,EAAc,CAACb,EAAU,SAASV,EAAE,KAAMC,EAAE,IAAI,EAClDuB,EAAcxB,EAAE,KAChByB,EAAaf,EAAU,KAAKV,EAAE,IAAI,EAElCX,EAAY,GACZE,EAA8B,GAG5BmC,EAAc,CAACH,CAAW,EAChC,GAAIA,EAAa,CACf,IAAMI,EAAkBC,GAAc,UAAU5B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAAC0B,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjEH,EAAcG,EACdF,EAAaf,EAAU,KAAKc,CAAW,EACvC,IAAMf,EAAgBC,EAAU,KAAKV,EAAE,IAAI,IAAM,EAC3CW,EAAgBD,EAAU,KAAKT,EAAE,IAAI,IAAM,EAC3CW,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EAC9Ea,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EACpFyB,EAAY,KAAKjB,CAAa,EAC9BiB,EAAY,KAAKf,CAAa,EAC9Be,EAAY,KAAKd,CAAoB,EACrCc,EAAY,KAAKb,CAAoB,EAErC,IAAIgB,EAAkB,EACtB,QAASC,EAAI,EAAGA,EAAIN,EAAY,OAAQM,IAAK,CAC3C,IAAMC,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS8B,CAAC,GAAK,EACpCE,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS6B,CAAC,GAAK,EAC1C,GAAIC,IAASC,EACXH,GAAmBE,MAEnB,MAEJ,CACIF,EAAkB,IAAM,GAC1BtC,EAA8B,GAC9BF,EAAY,KACHoB,GAAiBE,GAAiBC,GAAwBC,KACnExB,EAAY,GAEhB,MAEEA,EAAY,GAEdqC,EAAY,KAAKrC,CAAS,EAC1B,IAAMO,EAAoBqC,GAAqBjC,EAAE,KAAK,MAAM,GAAKiC,GAAqBhC,EAAE,KAAK,MAAM,GAC/FgC,GAAqBT,EAAY,MAAM,EAC3C,MAAO,CACL,KAAAJ,EACA,YAAa,CACX,KAAMC,EAAWK,EAAY,IAAKV,GAAMA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,EAC9D,kBAAmBpB,EAAoB,CAAC,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CAC3E,EACA,gBAAkBX,GAAiBlB,GAC/BkB,EAAce,EAAE,KAAMC,EAAE,KAAMuB,EAAanC,EAAWkC,EAAahC,EAA6BC,EAChGQ,EAAE,SAAUC,EAAE,SAAUqB,EAAgB1B,EAAmBC,CAAwB,EACvF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM2B,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,GAA0B,CAAsB,CAAC,EAC3F,gBAAiB7B,EACb,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKc,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,EACjE,GAAGU,GAA2BlC,EAAE,IAAI,EACpC,GAAGkC,GAA2BjC,EAAE,IAAI,EACpC,GAAGiC,GAA2BV,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKd,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,CACnE,CACN,EACF,CACF,EAEEvD,GACF,CAACkE,EAAyBf,EAAc5B,EAA8BK,EACrEwB,EAAmBC,IAAkC,CACpDa,EAAQ,QAAQnE,GACZoD,EAAMC,GAAY,GAAIc,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG3C,EAAUK,EACtEyB,CAAc,CAAC,CACrB,EAESpD,GAAOiE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa9B,GAAOgE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa7B,GAAS+D,GAAkC,CACtDlE,GACIkE,EAAS,QAAU,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa5B,GAAO8D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa3B,GAAO6D,GAAkC,CACpD,IAAMC,EAAO7B,EAAc,QAAS4B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7FlE,GACIkE,EAAS,MAAQ,CAAC,OAAQ,CAAC,EAAGlC,IAAM,cAAc,CAAC,IAAIA,CAAC,IAAK,OAAQ,CAAC,EAAGA,IAAM,qBAAqB,CAAC,IAAIA,CAAC,GAAG,EAC7G;AAAA,wBACkBmC,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa7D,GAAO4D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEazB,GAAW2D,GAAkC,CACxDlE,GACIkE,EAAS,UAAY,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEaxB,GAAQ0D,GAAkC,CACrDlE,GACIkE,EAAS,OAAS,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEavB,GAAkByD,GAAkC,CAC/DlE,GACIkE,EAAS,iBAAmB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEatB,GAAewD,GAAkC,CAC5DlE,GACIkE,EAAS,cAAgB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,ICjRA,IAcMoC,GAqBAC,GAWAC,GAmBAC,GAkGOC,GAKAC,GAxKbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA0B,CAACc,EAAyBC,IAAwC;AAAA;AAAA,wCAE1DD,CAAe,MAAMC,CAAmB;AAAA,gCAChDD,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCM,IAA0B,CACpF,IAAMF,EAAkBJ,EAAO,OAEzBO,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIJ,EAAiB,EAAEI,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcN,EAAOQ,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFJ,IAAoB,EACtBG,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMJ,EAAkB,EACjCG,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMf,GAA0B,CAACQ,EAA+BU,IAA8B,CAC5F,IAAMC,EAAaX,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIU,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IAAK,CACtC,IAAMM,EAAad,EAAOQ,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAclB,EAAO,MAAM,EAClDmB,EAAY,IAAI,MAAqBnB,EAAO,MAAM,EAClDoB,EAAWpB,EAAO,CAAC,EAAE,SAEvBqB,EAAc,EACZC,EAAwD,CAAC,EACzDC,EAAoB,CAAC,EACrBC,EAA4B,CAAC,EAC7BC,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMT,CAAU,CAAC,EAC7E,QAASR,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EACnCa,GAAerB,EAAOQ,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EACtBG,EAA0B,KAAKE,GAAqB1B,EAAOQ,CAAC,EAAE,KAAK,MAAM,CAAC,EAC1Ee,EAAkB,KAAKC,EAA0BhB,CAAC,EAAIR,EAAOQ,CAAC,EAAE,KAAK,OAASR,EAAOQ,CAAC,EAAE,IAAI,EAC5FW,EAAUX,CAAC,EAAImB,EAAc,QAAQnB,CAAC,GAAIY,EAAUG,EAAkBf,CAAC,CAAC,EACxEc,EAAkB,KAAKE,EAA0BhB,CAAC,EAAI,OAAS,MAAM,EACrEiB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMP,EAAiBV,CAAC,CAAC,CAAC,EAElE,QAASA,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EAC/BgB,EAA0BhB,CAAC,GAC7BiB,EAAgB,KAAK,GAAGG,GAA2B5B,EAAOQ,CAAC,EAAE,IAAI,CAAC,EAItE,IAAMqB,EAA6BH,GAAqBb,EAAY,MAAM,EACtEgB,GACFJ,EAAgB,KAAK,GAAGG,GAA2Bf,CAAW,CAAC,EAGjE,IAAMiB,EAAoBD,EAA6BhB,EAAY,OAASA,EACtEP,EAASyB,EAAe,SAAUX,EAAUU,CAAiB,EAE7DE,EAAc1B,EAAO,WAAW,UAAWM,CAAY,EACvDP,EACF,MAAM,KAAK,MAAMa,EAAiB,MAAM,EAAE,KAAK,CAAC,EAAE,IAAIV,GAAK,4BAA4BA,CAAC,EAAE,EAAE,KAAK,GAAG,EAClGyB,EAAmBC,GAA+B;AAAA;AAAA,KAErD,IAAM,CACPA,EAAa,gBAAgB,aAAc,KAAK,EAChD,QAAS1B,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IACjC0B,EAAa,gBAAgB,mBAAmB1B,CAAC,GAAI,KAAK,EAE5D,OAAO0B,EAAa,iBAAiB,GAAGf,EAAWb,CAAM,CAC3D,GAAG,CAAC;AAAA;AAAA,IAEFhB,GAAwB4B,EAAiB,OAAQb,CAAmB,CAAC;AAAA;AAAA,IAErE6B,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3D5B,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEb0B,CAAW;AAAA;AAAA,0CAEZd,EAAiB,MAAM,MAAMb,CAAmB;AAAA,QAClF2B,CAAW;AAAA;AAAA;AAAA,MAGbzC,GAAiB4B,EAAWb,CAAM,CAAC;AAAA,KAGvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,GAAI,kBAAAY,CAAiB,EAChD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAa,EAAuB,CAAC,EAClE,gBAAAS,CACF,GACA,gBAAAQ,CACF,CACF,EAEaxC,GAAS,CAAC0C,EAAyBC,IAAuC,CACrF/C,GAAe8C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ3C,GAAwB2C,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEa1C,GAAyB0C,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,ICzKjE,IAYaE,GAsBAC,GAlCbC,GAAAC,EAAA,kBAGAC,KASaJ,GAAuB,CAACK,EAA0CC,IAClB,CACvD,OAAQD,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sBAAsBC,CAAS,SAAS,EAC3F,IAAK,UACH,MAAO,CACL,mBAAoB,GACpB,gBAAiB,YAAYA,CAAS,YAAYA,CAAS,wBAC7D,EACF,IAAK,OACH,MAAO,CACL,mBAAoB,mBAAmBA,CAAS,IAAID,EAAW,OAAQ,qBAAqBC,CAAS,IACjGD,EAAW,OAAQ,KACvB,gBAAiB,6CACnB,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAESJ,GACRI,GAAgF,CAC/E,IAAME,EAAaF,GAAY,YAAwB,GAEvD,GAAIE,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIJ,GAAY,mBAAyC,CAACK,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,IC3CJ,IAqBaK,GAeAC,GApCbC,GAAAC,EAAA,kBAqBaH,GAAc,CAACI,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaH,GAAeK,GAA6B;AAAA,QACjDA,EAAU,iDAAmD,EAAE;UCrCvE,IAqBaC,GArBbC,GAAAC,EAAA,kBAqBaF,GAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ICrB7B,IA6BMG,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GAmFOC,GAvabC,GAAAC,EAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,iBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,mBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,IAAMC,EAAcF,EAAY,CAAC,EAC3BG,EAAcH,EAAY,CAAC,EAC3BI,EAAaJ,EAAY,CAAC,EAC1BK,EAAgBN,EAAU,CAAC,EAC3BO,EAAYP,EAAU,CAAC,EACvBQ,EAAYR,EAAU,CAAC,EACvBS,EAAiBT,EAAU,CAAC,EAC5BU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5F/C,EAAYsD,EAAc,YAAaT,EAAO,CAAC,EAAE,SAAUQ,CAAS,EACpEhC,EAAY,CAACrB,CAAS,EACtBsB,EAAc,CAAC6B,EAAYC,EAAYC,CAAS,EAChDE,EAAYC,EAAU,KAAKH,CAAS,EAEpCI,EAAYR,EAAOA,EAAO,OAAS,CAAC,EACpCS,EAAWT,EAAOA,EAAO,OAAS,CAAC,EACnCU,EAAYT,EAAOA,EAAO,OAAS,CAAC,EACpCU,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EAGjDE,EAAoBJ,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDrD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD0D,EAAW,CACf,KAAK,KAAKH,EAAYvD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKJ,EAAYrD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYnD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,CAC/D,EAEM3B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDkB,EAAaH,EAAS,EAAI,EAC1BI,EAAIV,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGM,EAAYM,EAAWC,EAAWK,CAAU,EAAGA,CAAU,EACxGE,EAAIX,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGO,EAAYM,EAAUC,EAAYI,CAAU,EAAGA,CAAU,EACxGG,EACFpC,EAAe,SAAUe,EAAO,CAAC,EAAE,SAAU,CAACU,EAAWE,EAAWE,EAAYI,CAAU,EAAGA,CAAU,EAC3G1C,EAAU,KAAK2C,CAAC,EAChB3C,EAAU,KAAK4C,CAAC,EAChB5C,EAAU,KAAK6C,CAAM,EACrB,IAAMC,GAAiB,CAACH,EAAGC,CAAC,EACtB9C,EAAU0B,EAAO,OAAS,EAC1B,CAAC,mBAAAuB,EAAoB,gBAAAhD,EAAe,EAAIiD,GAAqBvB,EAAsBoB,EAAO,KAAK,KAAK,EACpGI,GACF/E,GAAwBwE,EAAY5C,EAASC,GAAiBC,EAAWC,EAAaC,CAAc,EACxG,GAAIJ,EAAS,CACX,IAAMoD,EAAiBhD,EAAiBwC,EAAa,EACrDI,GAAe,KAAKb,EAAc,OAAQT,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,CAAc,CAAC,CAC/F,CACA,IAAMC,GAAmBC,GAA+B;AAAA,2BACnChB,CAAS;AAAA,2BACTE,CAAS;AAAA,0BACVD,CAAQ;AAAA,IAC9Be,EAAa,iBAAiB,GAAGN,GAAgBD,CAAM,CAAC;AAAA,IACxDE,CAAkB;AAAA,IAClBE,EAAgB;AAAA,IAEVV,EAASzE,GAA2B0E,EAAmBzD,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuBuE,EAAmBzD,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAC3EA,EAAU,KAAK,CAAC,GAC/B,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM8C,EAAqB,kBAAkB,EAC3D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAAU,EACF,CACF,IC1eJ,IAiCME,GA6HOC,GA9JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAEAC,KAEAC,KAEAC,KACAC,KACAC,KAEMV,GACF,CAACW,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAA4BC,EAAoB,EAAGC,EAAoB,EAAGC,EAAmB,EAC7FC,EAAW,QAAkB,CAC5B,IAAMC,EAAeF,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,CAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,qCACT,IAAK,GACH,MAAO,yCACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBZ,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCa,EAAkBb,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCc,EAAUd,EAAiB,YAAc,YACzCe,EAASf,EAAiB,YAAc,YACxCgB,EAAMhB,EAAiB,MAAQ,MAC/BiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAe;AAAA;AAAA,qBAENlB,EAAiB,cAAgB,aAAa;AAAA,mBAChDgB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUpB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCG,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbN,GAAYD,EAAY;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFvB,EAAiBmB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFxB,EAAiBmB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EACjG,CAAC,mBAAAgB,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBtB,EAAYiB,CAAO,EAuBtF,MAtBiB;AAAA,MACjBG,CAAkB;AAAA,yDACiCF,CAAK;AAAA,QACtDvB,EAAiBoB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBR,EAAiB,cAAgB,aAAa;AAAA,QAC7Da,CAAe;AAAA,QACfe,GAAYxB,CAAO,CAAC;AAAA,QACpBsB,CAAe;AAAA;AAAA;AAAA,MAKnB,EAESpC,GACT,CAACuC,EAA+BxB,EAA4ByB,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiBK,EAAW,SAAW,OACvC+B,EAAapC,EAAiB6B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMtC,EAAmBiC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAKS,EAAkB,CAAC,EAElGG,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAIpC,EAAkBoC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,EAAY8B,EAAYiB,IAAe,EACvC9C,GAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAACjC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D4C,EAAIC,GAA4BxB,EAAO,CAAC,EAAE,QAAQ,EAElDyB,GAAgB,CACpB,qDAAqDb,GAAUjC,IAAqB,EAAI,QAAQ4C,CAAC,IAAMA,CAAC,KACxG,qDAAqDX,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAChF,EACIG,GAAmB;AAAA,qDACwBd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,8BAChDX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,OAAIP,IACFoB,GAAc,KAAK,wDAAwDb,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAAI,EACxGG,IAAoB;AAAA,0DAC8Bd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,YAIlE,CACL,KAAM,eACN,YAAa,CAAC,KAAMpC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMyB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBU,EAAa;AAAA;AAAA;AAAA;AAAA,UAIbF,GAAc,KAAK,EAAE,CAAC;AAAA,6BACHA,GAAc,MAAM,4CACrCb,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACNE,GAAc,OAAS,CAAC;AAAA;AAAA,+CAERzB,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBC,EAAY,KAAK,GAAG,CAAC;AAAA,wDACd2B,EAAU,eAAe3B,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChEzB,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClE0B,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BsB,EAAgB;AAAA,UAEdlE,GACIW,EAAgBC,EAAWC,EAAWC,GAAU+B,EAAS7B,EAAY8C,EAAa,CAAC,EAAGA,EAAa,CAAC,EACpGA,EAAa,CAAC,EAAGC,CAAC,CAAC;AAAA,cAEvBX,EACIiB,GAA2Bb,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGS,GACId,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,IChQJ,IAeayB,GAfbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhDO,EAAgBP,EAAW,SAAW,OACtCQ,EAAcC,GAChBL,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASO,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUS,CAAW,EACjE,CAAC,mBAAAM,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYY,EAAO,KAAK,KAAK,EAC1FK,EAAIC,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDe,EAAID,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDe,EAAY,CAACH,EAAGE,CAAC,EACnBjB,GACFkB,EAAU,KAAKF,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMsB,EAAmBC,GAA+B;AAAA,oCAC1BtB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEsB,EAAa,iBAAiB,GAAGF,EAAWR,CAAM,CAAC;AAAA;AAAA,IAEnDE,CAAkB;AAAA;AAAA,IAElBQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYD,CAAsB;AAAA;AAAA,iBAEhDM,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPP,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBF,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgBU,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnDA,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDE,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3EhB,CAAW;AAAA,MACXY,CAAe;AAAA,MACfH,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BO,CAAW,EAAIA,EAC7E,SAAUT,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKW,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,IChGJ,IAcaE,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAsGAC,GA0BOC,GAnQbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KAEahB,GACT,CAACiB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAAC,EAAGU,IAAM,GAAK,EAAI,IAAMT,EAAUS,CAAC,EAAI,EAAE,EAEtFC,EAD2BL,EAAkB,IAAI,CAAC,EAAGI,IAAM,EAAIR,EAAWQ,CAAC,EAAIR,EAAWQ,EAAIH,CAAW,CAAC,EAEnF,IAAI,CAAC,EAAGG,IAAM,KAAK,OAAO,EAAID,EAAmBC,CAAC,EAAIP,EAAQO,CAAC,GAAKP,EAAQO,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGN,CAAS,EAClCM,EAAY,OAAOP,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDG,CACT,EAcE5B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC4B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAML,EAAcK,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWN,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIM,EAAW,QAAQ,SAAWN,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIM,EAAW,KAAK,SAAWN,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIM,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM3B,GAA4B,CAA2B4B,EAAeD,IAAqC,CAC/G,IAAMZ,EAAca,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCV,EAAYU,EAAI,CAAC,IAAM,IACzBV,EAAYU,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWb,EAAagB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAlB,EAAa,KAAAgB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEahC,GAAuB2B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFZ,EAAYY,EAAW,UACvBU,EAAQV,EAAW,MACnBb,EAAca,EAAW,aACzBG,EAAOH,EAAW,KAClBV,EAAUU,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAApB,EAAW,MAAAsB,EAAO,YAAAvB,EAAa,KAAAgB,EAAM,QAAAb,EAAS,SAAAqB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMhC,GAAS,CAACuC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB1C,GAA0B4B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc7B,GAChB8B,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CrB,EAAcG,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,EACpBC,GAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG7B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC8B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAE5BN,EAAU,CACZ,IAAMQ,EAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,CAAS,CAAC,EACnDL,EAAYG,EAAiB,QAAQ,CAAC,EAAGE,EAAWtC,CAAW,CAAC,EAChEkC,EAAoB,CAAC,EAAGH,EAAO/B,CAAW,CAC5C,MACEgC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,EAAiB,QAAQ,CAAC,EAAGX,EAAezB,CAAW,CAAC,EACpEkC,EAAoB,CAACH,EAAOH,EAAYC,EAAU7B,CAAW,EAE/DmC,GAAa,KAAKH,CAAS,EAC3BG,GAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGJ,EAAayB,CAAa,CAAC,EAC7DS,EAAoB,CAACH,EAAO/B,EAAa4B,EAAYC,CAAQ,EAC7DM,GAAa,KAAKF,CAAS,EAC3BE,GAAa,KAAKH,CAAS,EAEzBV,GACFa,GAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7Bc,EAAQ,QACJqB,GAAwBJ,GAAchB,EAAoBhB,EAAa+B,EAAmBb,CAAc,EACxG,CAAC,OAAQc,EAAY,CAAC,EAC1B,MACF,CAIA,IAAMK,EAAgE,GAGhEJ,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG7B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC8B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMK,EAAa,CAACrC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFmB,EAAW,KAAKrC,EAAO,CAAC,CAAC,EAI3B,IAAMsC,EAAYrB,EAAiBO,EAAYC,EAAW7B,EACpD2C,EAAYtB,EAAiBrB,EAAc4B,EAAYC,EACvDe,EAAWlB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ2B,GACIJ,EAAYtB,EAAoBhB,EAAauC,EAAWC,EAAWC,EAAUtB,EAC7EkB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEM7D,GAAS,CAACsC,EAAyBb,IAAqC,CAE5E,IAAMT,EAAgBS,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdtB,EAEI,CAACsB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDV,EAAU,CAAC,CAAC,EAAE,OAAOU,EAAW,OAAO,EACvCZ,EAAY,CAAC,CAAC,EAAE,OAAOY,EAAW,SAAS,EAC3Cb,EAAc,CAAC,CAAC,EAAE,OAAOa,EAAW,WAAW,EAC/Cc,EAAqB1C,GAA0B,CAAC,GAAG4B,EAAY,KAAAG,EAAM,QAAAb,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGY,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeP,EAAgB,CAACO,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEatB,GAAO,CAACqC,EAAyBb,IAAqC,CACjF7B,GAAe0C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCtC,GAAOsC,EAASb,CAAU,EAE1B1B,GAAOuC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,IC1QA,IAgCMyC,GA4HOC,GA5JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAGAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAU,GAAOC,EAAqCC,EAAmB,IAAc,CAC/G,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,iDACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBP,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCQ,EAAkBR,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCS,EAAUT,EAAiB,iBAAmB,iBAC9CU,EAASV,EAAiB,iBAAmB,iBAC7CW,EAAMX,EAAiB,MAAQ,MAC/BY,EAAMZ,EAAiB,MAAQ,MAE/Ba,EAAe;AAAA,yBACFb,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,cAAgB,aAAa;AAAA,qBAChDW,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,qDACgCJ,CAAgB,KAEzDW,EAAUd,EAAiB;AAAA,0BACbG,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBH,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,oCACA,mCAAmC;AAAA;AAAA;AAAA,UAGpDM,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAGP,CAAC,mBAAAY,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYE,CAAI,EAsBnF,MArBiB;AAAA,QACfY,CAAkB;AAAA,uDAC6BZ,CAAI;AAAA,MACrDJ,EAAiBc,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDJ,EAAiBe,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBH,EAAiB,cAAgB,aAAa;AAAA,QAC7DQ,CAAe;AAAA,QACfW,GAAYlB,CAAO,CAAC;AAAA,QACpBgB,CAAe;AAAA,sDAC+Bd,CAAgB;AAAA;AAAA,IAIlE,EAESZ,GACT,CAAC6B,EAA+BlB,EAAqCmB,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBE,EAAW,SAAW,OACvCyB,EAAa3B,EAAiBoB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMlC,EAAmB6B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAIhC,EAAkBgC,EAAc,CAAC,CAAC,EAG1EK,EAAgB,CACpB,qDAAqDR,EAAS,YAAc,KAAK,KACjF,yDACF,EACIS,EAAmB,GACvB,OAAIhB,IACFe,EAAc,KAAK,wDAAwDR,EAAS,YAAc,KAAK,IAAI,EAC3GS,GAAoB;AAAA,0DAC8BT,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,YAGlE,CACL,KAAM,wBACN,YAAa,CAAC,KAAM9B,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMmB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBK,EAAa;AAAA,UACbF,EAAc,KAAK;AAAA,CAAI,CAAC;AAAA,6BACLA,EAAc,MAAM,4CACrCR,EAAS,YAAc,KAAK;AAAA,oDACYZ,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CAC7BA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBC,EAAY,KAAK,GAAG,CAAC;AAAA,wDACdsB,EAAU,eAAetB,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChEnB,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC,KACrFE,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CE,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEoB,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BiB,CAAgB;AAAA,UAChBnD,GAA6BU,EAAgByB,EAASvB,EAAYC,CAAgB,CAAC;AAAA,UAEjF6B,EAASY,GACIR,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFM,GACIT,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,ICvPJ,IA0BMoB,GAsNOC,GAhPbC,GAAAC,EAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,EAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,EAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,KAAK;AAAA,YACtDqB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,EAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAQ1CX,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,KAAK;AAAA,YAClDqB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,CAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAmDAC,GA6COC,GA/SbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAG,IAAMA,EAAI,EAAG,CAAC,IAAM,EAAG,CAClGhB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMQ,EAAiBH,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOiB,EAAiB,EAAI,EAAG,EAAGF,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAG,IAAMA,EAAI,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMT,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAG,IAAMA,EAAI,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMT,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASc,EACzFZ,EAAeC,CAAW,EAG9B,IAAMY,EAAmB,OAAO,OAAO,CAAC,EAAGJ,CAAU,EAC/CK,EAAWL,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOiB,EAAe,CAAC,YAAAlB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAgB,CAAQ,CAAC,EACnGD,CACT,EAES5C,GAAgCwC,GAAiE,CAC5G,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBS,EAAYT,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOU,GAA4B,CACjC,QAAA9B,EACA,OAAA4B,EACA,UAAArB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAoB,EACA,GAAGH,CACL,CAAC,CACH,EAEM7C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMU,EAAcV,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFW,EAAkBX,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIU,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcZ,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMY,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMpB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGY,IAAMZ,EAAIY,EAAG,CAAC,EAAI,GAEnDd,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGY,IAAMZ,EAAIY,EAAG,CAAC,EAAI,GAEjDd,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGY,IAAMZ,EAAIY,EAAG,CAAC,EAAI,GAC9Cd,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGY,IAAMZ,EAAIY,EAAG,CAAC,EAAI,GACrDd,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EE,EAAiBH,EAAW,SAAW,OACvCiB,EAAUhB,EAAO,SAAW,EAClC,GAAIe,EAAmB,QAAU,EAAG,CAClCD,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMxB,EAAcwB,EAAmB,YACjCG,EAAY3B,EAAYW,EAAiB,EAAI,CAAC,EAC9CiB,EAAW5B,EAAYW,EAAiB,EAAI,CAAC,EAC7CN,EAAcL,EAAYW,EAAiB,EAAI,CAAC,EAChDkB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC9BsB,EAAgBtB,EAAO,CAAC,EAAE,KAAKE,EAAiB,EAAI,CAAC,EAErDqB,EAAYrB,EAAiBgB,EAAYC,EAAWvB,EACpD4B,EAAYtB,EAAiBN,EAAcsB,EAAYC,EACvDM,EAAWL,EAAeC,EAAcC,EAExCI,EAAgE,GAIhEC,EAAoBb,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJc,GAA2B5B,EAAO,CAAC,EAAGvC,EAAmB,EACzD,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKa,GAIhC,IAAME,EAAsB,CAAC7B,EAAO,CAAC,EAAG2B,CAAgB,EACpDX,IACE,CAACd,GAAkBF,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C6B,EAAoB,KAAK7B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE6B,EAAoB,KAAK7B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACID,EAAqBd,EAAoBxB,EAAagC,EAAWC,EAAWC,EAAUT,EACtFU,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEElE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICtTA,IAqBMgC,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GA4FOC,GAKAC,GApRbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAaMd,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYU,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMZ,GAAN,KAAqB,CACnB,YAAYa,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOjB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBiB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOrB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMuB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOrB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdqB,EAAI,MAAM,OAAOtB,GAAe,GAAG,CAAC,GAC3C,QAASgB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAM,KAAK,UAAU,CACxD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO3B,EAAe,CAAC,GAAM,CAAC4B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO7B,GAAe,GAAG,CAAC,EACpDyB,EAAa,IAAIpB,GAAWY,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIoB,CAAC,EACxDX,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,CAAC,EAC9B,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMlB,GAA0B,CAACY,EAA+BoB,IAAgD,CAC9G,IAAMC,EAAWrB,EAAO,CAAC,EAAE,SACrBsB,EAAY,IAAI,MAAqBtB,EAAO,MAAM,EACxD,QAASiB,EAAI,EAAGA,EAAIjB,EAAO,OAAQ,EAAEiB,EACnCK,EAAUL,CAAC,EAAIM,EAAc,QAAQN,CAAC,GAAII,EAAUrB,EAAOiB,CAAC,EAAE,IAAI,EAEpE,IAAMO,EAAcJ,EAAe,WAC7BK,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAASC,EAAe,SAAUP,EAAUG,CAAW,EACvDK,EAAoB,CAAC,EACrBC,EAAa,MAAM,KAAKV,EAAe,IAAI,gBAAgB,KAAK,CAAC,EACjEW,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBlB,EAAe,aAAa,OAASU,EAAW,OAC/EV,EAAe,aAAa,QAAQ,CAACZ,EAAMX,IAAW,CACpD,GAAIiC,EAAW,SAASjC,CAAM,EAAG,CAC/B,IAAM0C,EAAcT,EAAW,QAAQjC,CAAM,EAC7CuB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzB+B,EAAQ,KAAK,GACTP,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO6B,EAAO,WAAW,gBAAiBY,CAAW,CAAC,CAAC,EAAE,CAC3G,CAAC,CACH,CACF,CAAC,CACH,MACEnB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,IAAMT,EAAOY,EAAe,aAAa,IAAIvB,CAAM,EACnD,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,sBAAsB,EAExC,GAAIA,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzBoC,EAAoB,KAAK,GAAGZ,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO,GAAGD,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDwC,EAAgB,KAAK,WAAWf,EAAUL,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACDkB,EAAqB,KAAK,WAAWtC,CAAM,cAAcA,CAAM,MAC3DuB,EAAe,aAAa,IAAIvB,CAAM,GAAG,QAAQ,KAAKA,CAAM,OAAO,EACvEuC,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGT,EACH,aAAaP,EAAU,IAAI,CAACoB,EAAUzB,IAAMyB,EAAS,aAAa,QAAQzB,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGY,EACHG,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACEO,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB,GAAGtB,EAAWK,CAAM,CAAC;AAAA;AAAA,QAEnDiB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCnB,CAAU,CAAC;AAAA,8BAC1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDL,EAAU,IAAI,CAACuB,EAAM5B,IAAM,YAAYA,CAAC,YAAYK,EAAUL,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAC5FwB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,UACpBd,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,SAE/C,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMP,EAAe,QAAQ,EAC3C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMI,EAAa,SAAUxB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAkB,CACF,CACF,EAEatD,GAAS,CAACyD,EAAyBC,IAAuC,CACrF,IAAM3B,EAAiB,IAAIjC,GAAe2D,EAAQ,OAAQC,EAAW,QAAQ,EAC7ED,EAAQ,QAAQ1D,GAAwB0D,EAAQ,OAAQ1B,CAAc,CAAC,CACzE,EAEa9B,GAAyByD,GAA0D,CAC9F,IAAM9C,EAAY8C,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOC,GAA4B,CAAC,SAAA/C,CAAQ,CAAC,CAC/C,ICvRA,IASMgD,GAiBAC,GAYAC,GAIAC,GAuCOC,GAjFbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMZ,GAAmB,CAACa,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMT,GAAuB,CAACQ,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUV,GAAiBS,EAAYC,CAAK,EAAIV,GAAiBU,EAAOD,CAAU,EAG3GP,GAA2BM,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBhB,GAAqBQ,EAAYC,CAAK,EAC9DQ,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWZ,EAAO,CAAC,EAAE,SACrBa,EAAQC,EAAc,QAASF,EAAUX,CAAU,EACnDc,EAASC,EAAe,SAAUJ,EAAUH,CAAW,EAEvDQ,EAAmBC,GAA+B;AAAA,uBACnCL,EAAM,QAAQ,GAAGZ,CAAU,CAAC;AAAA,IAC/CiB,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,IAC5CG,EAAa,UAAU,CAAC;AAAA,IACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,0BACxCK,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBACtCF,EAAM,KAAK,OAAO;AAAA,0BAChBZ,EAAW,MAAM;AAAA,YAC/BY,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA,UACrCA,EAAM,WAAW,eAAgB,IAAK,CAAC,CAAC;AAAA;AAAA,UAG5CA,EAAM,WACF,eAAgB,IAAKE,EAAO,WAAW,gBAAiB,OAAON,EAAY,OAASR,EAAW,MAAM,EAAE,CAAC,CAAC;AAAA;AAAA;AAAA,MAG7Gc,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,KAExE,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGJ,CAAW,EAAE,EACpC,gBAAAQ,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEaf,GAAUwB,GAAkC,CACvD5B,GAAe4B,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzB,GAAwByB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,ICpFA,IAcMC,GAMAC,GA8FOC,GAGAC,GArHbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMR,GAA0B,CAACQ,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaH,EAAU,KAAKC,CAAW,EAEvCG,EAA4BC,GAAqBX,EAAO,CAAC,EAAE,KAAK,MAAM,EACtEY,EAAmBF,EAA4BV,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACjFa,EAA8BF,GAAqBX,EAAO,CAAC,EAAE,KAAK,MAAM,EACxEc,EAAqBD,EAA8Bb,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACrFe,EAA6BJ,GAAqBJ,EAAY,MAAM,EACpES,EAAoBD,EAA6BR,EAAY,OAASA,EAEtEU,EAAOC,EAAc,OAAQlB,EAAO,CAAC,EAAE,SAAUY,CAAgB,EACjEO,EAAUD,EAAc,eAAgBlB,EAAO,CAAC,EAAE,SAAUc,CAAkB,EAC9EM,EAASC,EAAe,SAAUrB,EAAO,CAAC,EAAE,SAAUgB,CAAiB,EAEvEM,EACF,CAAC,CAAC,KAAM,SAAU,KAAMb,CAAU,EAAG,CAAC,KAAM,QAAS,KAAMD,CAAY,EAAG,CAAC,KAAM,SAAU,KAAMH,CAAI,CAAC,EACtGK,GACFY,EAAgB,KAAK,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEa,GACFS,EAAgB,KAAK,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEe,GACFO,EAAgB,KAAK,GAAGC,GAA2BhB,CAAW,CAAC,EAGjE,IAAMiB,EAAwD,CAAC,EAC/DA,EAAkB,KAAKd,EAA4B,OAAS,MAAM,EAClEc,EAAkB,KAAKX,EAA8B,OAAS,MAAM,EAEpE,IAAMY,EAAkB,IAAc,CACpC,IAAMC,EAAcvB,EAAa,OAC7BwB,EAAU,yBAAyBR,EAAQ,KAAK,OAAO,OAC3D,QAASS,EAAI,EAAGA,EAAIF,EAAaE,IAC/BD,GAAW,GAAGD,EAAc,EAAI,kBAAkBE,CAAC,IAAM,gBAAgB,MACrErB,EAAY,OAAS,EAAI,iCAAiCqB,CAAC,IAAM,eAAe,IAEtFD,GAAW;AAAA,oBACKR,EAAQ,aAAa,gBAAgB,CAAC;AAAA;AAAA;AAAA;AAAA,4BAI9BF,EAAK,KAAK,OAAO;AAAA,QAEzC,QAASW,EAAI,EAAGC,EAAI,EAAGD,EAAIxB,EAAWwB,IAChCA,IAAMvB,GACRsB,GAAW,GAAGvB,EAAY,EAAI,eAAewB,CAAC,IAAM,aAAa,eACjEC,GAAKH,IAELC,GAAW,GAAGvB,EAAY,EAAI,eAAewB,CAAC,IAAM,aAAa,MAC7DrB,EAAY,OAAS,EAAI,iBAAiBsB,CAAC,IAAM,eAAe,IACpEA,KAGJ,OAAOF,CACT,EAEMG,EAAmBC,GAA+B;AAAA,QAEpDA,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBd,EAAME,EAASC,CAAM,CAAC;AAAA,QAC1CW,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,8BACrDX,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDK,EAAgB,CAAC;AAAA,sBACLR,EAAK,aAAa,aAAa,CAAC;AAAA,UAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,SAEjD,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMnB,EAAW,SAAU,kBAAAuB,CAAiB,EAC1D,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMjB,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAC,EAClE,gBAAAa,CACF,GACA,gBAAAQ,CACF,CACF,EAEarC,GAAyBQ,GAClC+B,GAA4B,CAAC,KAAM/B,EAAW,IAAc,CAAC,EAEpDP,GAAS,CAACuC,EAAyBhC,IAAuC,CACrF,IAAMD,EAASiC,EAAQ,OACvB1C,GAAeS,CAAM,EACrBiC,EAAQ,QAAQzC,GAAwByC,EAAQ,OAAQhC,CAAU,CAAC,CACrE,ICzHA,IAcMiC,GAeAC,GAqEOC,GAGAC,GArGbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OACvBG,EAAeC,EAAU,eAAeJ,CAAU,EAClDK,EAAYD,EAAU,KAAKJ,CAAU,EAErCM,EAAeR,EAAO,CAAC,EAAE,KACzBS,EAAkBT,EAAO,CAAC,EAAE,SAC5BU,EAAcJ,EAAU,KAAKE,CAAY,EAEzCG,EAAOL,EAAU,cAAcL,EAAW,KAAMG,CAAS,EACzDQ,EAAeV,EAAWS,CAAI,EAE9BE,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaR,EAAU,KAAKO,CAAW,EAEvCE,EAAQC,EAAc,QAASb,EAAqBD,CAAU,EAC9De,EAAUD,EAAc,UAAWP,EAAiB,CAACC,CAAW,CAAC,EACjEQ,EAASC,EAAe,SAAUhB,EAAqBU,CAAW,EAMlEO,EAAmBC,GAA+B;AAAA,wCACtBhB,EAAa,MAAM,KAAKA,EAAa,IAAIiB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,QAChGD,EAAa,iBAAiBN,EAAOE,EAASC,CAAM,CAAC;AAAA,QACrDG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCP,CAAU,CAAC;AAAA;AAAA,4BAE1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA,sBAE7BL,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKNV,EAAW,MAAM;AAAA,mBAC1BS,CAAI;AAAA;AAAA;AAAA,yBAGEO,EAAO,WAAW,gBAAiB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAMtBX,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,KAO7C,MAAO,CACL,KAAM,iBACN,YAAa,CAAC,KAAMN,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMY,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAM,CACF,CACF,EAES3B,GAAiCQ,GAC1CsB,GAA4B,CAAC,KAAMtB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC8B,EAAyBvB,IAA+C,CACrG,IAAMD,EAASwB,EAAQ,OACvBjC,GAAeS,CAAM,EACrBwB,EAAQ,QAAQhC,GAAgCgC,EAAQ,OAAQvB,CAAU,CAAC,CAC7E,ICzGA,IAUMwB,GA0BAC,GAmBAC,GAoEOC,GAKAC,GAhIbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMT,GAAU,CAACU,EAAWC,EAAWC,IAAoC,CACzE,GAAIA,EAAK,SAAW,EAClB,MAAO,KAGT,IAAMC,EAAcD,EAAK,SAAW,GAAKF,IAAM,GAAOE,EAAK,SAAW,GAAKA,EAAK,CAAC,IAAMF,EACjFI,EAAaF,EAAKA,EAAK,OAAS,CAAC,IAAMD,EAEzCI,EAAS,KACb,OAAKF,IACHE,GAAU,SAASH,EAAKA,EAAK,OAAS,CAAC,CAAC,KAErCE,IACHC,GAAU,MAGLA,CACT,EAEMd,GAAwB,CAACQ,EAA+BO,IAA4C,CACxG,IAAMC,EAASR,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BS,EAAST,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACU,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQP,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGc,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACzCG,EAAO,GACPV,EAAW,QAAUA,EAAW,OAClCU,EAAO,wCACEV,EAAW,QAAU,CAACA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAUA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAU,CAACA,EAAW,SAC3CU,EAAO,yCAGT,IAAMC,EAAWC,GAA4BnB,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAiBb,EAAW,QAAU,EAAI,GAAK,kBAC/Cc,EAAarB,EAAO,SAAW,EAAI,qBAAqBT,GAAQmB,EAAGC,EAAGX,EAAO,CAAC,EAAE,IAAI,CAAC,KAAO,GAC5FsB,EAAkC,CACtC,sDAAsDJ,CAAQ,KAC9D,sDAAsDA,CAAQ,IAChE,EACIlB,EAAO,SAAW,GACpBsB,EAAgC,KAAK,sDAAsDJ,CAAQ,IAAI,EAEzG,IAAMK,EAAmBC,GAA+B;AAAA,mBACvCd,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,kBACFM,CAAQ,IAAIX,EAAW,KAAK;AAAA,iBAC7BW,CAAQ,IAAIX,EAAW,IAAI;AAAA;AAAA,IAExCe,EAAgC,KAAK;AAAA,CAAI,CAAC;AAAA,uBACvBtB,EAAO,MAAM,6CAA6CkB,CAAQ;AAAA;AAAA,IAErFM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAKlDG,CAAQ;AAAA,8BACIN,CAAC;AAAA,QACvBK,CAAI;AAAA;AAAA;AAAA,MAGNG,CAAc;AAAA,MACdC,CAAU;AAAA;AAAA;AAAA,KAId,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAMd,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMO,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,EAEa9B,GAAO,CAACgC,EAAyBlB,IAAqC,CACjFjB,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAsBiC,EAAQ,OAAQlB,CAAU,CAAC,CACnE,EAEab,GAAuBa,GAChCmB,GAA4BnB,CAA+D,ICjI/F,IAgBMoB,GAIAC,GA8FAC,GA2GAC,GAgDOC,GAGAC,GAhRbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMX,GAAW,CACf,KAAM,uBACR,EAEMC,GACF,CAACW,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KAEnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAIN,EAAO,CAAC,EACZO,EAAIC,EAAc,IAAKV,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EAC3EI,EAAQD,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEY,EAAOF,EAAc,OAAQV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/Da,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EACtFQ,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAgB,GAChBC,EAAmBC,GAA+B;AAAA;AAAA,mBAE3CX,CAAC;AAAA,0BACMD,CAAQ;AAAA,yBACTN,EAAW,OAAO;AAAA,gCACXe,CAAQ;AAAA,uCACDA,CAAQ;AAAA,2CACJA,CAAQ,KAAKC,CAAa;AAAA,0BAC3CA,CAAa;AAAA,IACnCE,EAAa,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IAC3CI,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAOtBD,CAAQ;AAAA;AAAA,4BAECP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAahBO,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOzBP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAkBJO,CAAQ;AAAA,qCACtBL,EAAM,YAAY,SAAS,CAAC;AAAA,yBACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEhCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA,QAC1CI,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,KAG9C,MAAO,CACL,GAAGzB,GACH,YAAa,CAAC,KAAMa,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,CAC9B,GACA,gBAAAa,CACF,CACF,EAEE5B,GACF,CAAC8B,EAAyBC,EAAmBV,EAAmBC,EAAkB,EAAWU,EAAWC,EACvGC,IAAoB,CACnB,IAAMC,EAAaC,GAAiBH,CAAC,EAC/BI,EAAcjB,EAAc,QAASW,EAAM,SAAUA,EAAM,KAAMI,CAAU,EAC3EG,EAAclB,EAAc,QAASC,EAAM,SAAUA,EAAM,KAAMc,CAAU,EAC3EI,EAAanB,EAAc,OAAQE,EAAK,SAAUA,EAAK,KAAMa,CAAU,EAEvEK,EAAK,GAGLC,EAAaN,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC5DO,EAAcP,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACzDQ,EAAiB,CAACC,EAAcC,IAAiB,GAAGJ,CAAU,IAAIG,CAAI,KAAKC,CAAI,IAC/EC,EAAc,EAAIb,EAAIE,EACtBY,EAAS,KAAK,KAAKf,EAAIQ,CAAE,EAEzBQ,EAAuBnB,GAA+B;AAAA,mBAC/CG,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNH,EAAIC,EAAIE,CAAU;AAAA;AAAA,IAEzCN,EAAa,iBAAiBQ,CAAW,CAAC;AAAA,kEACoBI,CAAU;AAAA;AAAA,IAExEZ,EAAa,UAAUW,CAAE,CAAC;AAAA,4CACcA,CAAE;AAAA,+CACCA,CAAE;AAAA,8BACnBA,CAAE;AAAA,4BACJO,CAAM;AAAA;AAAA;AAAA;AAAA,iCAIDA,CAAM;AAAA;AAAA;AAAA,gBAGvBE,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA;AAAA,sBAE9BO,CAAW;AAAA;AAAA;AAAA;AAAA,2BAINC,EAAe,MAAO,YAAY,CAAC;AAAA,KAGlDO,EAAapB,EAAQ,QACvB,CACE,KAAM,0BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAK,EAAY,EAAG,EAAAH,EAAG,EAAAC,CAAC,CAAC,CAAC,EACzD,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGA,EAAGO,EAAI,CAAC,EAAG,UAAwB,CAChD,EACA,cAAe,CAAC,EAAG,EAAIP,EAAIE,CAAU,CACvC,GACA,gBAAiBa,CACnB,EACA,CAAC,OAAQ,CAACjB,CAAK,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EACjCH,EAAmBC,GAA+B;AAAA,mBAC3CG,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNK,EAAKP,EAAIE,CAAU;AAAA,yBACrBD,CAAO;AAAA;AAAA,2DAE2BO,CAAU;AAAA,2DACVH,EAAY,KAAK,OAAO;AAAA,0DACzBC,EAAW,KAAK,OAAO;AAAA,kEACfE,CAAU;AAAA;AAAA,IAExEZ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCiB,CAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKrDG,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA,+BACrBK,CAAE;AAAA,gEAC+BA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAO7BE,CAAW;AAAA,yBACvBA,CAAW;AAAA;AAAA,2BAETC,EAAe,eAAgB,cAAc,CAAC;AAAA,KAGnE,OAAOb,EAAQ,QACX,CACE,KAAM,uCACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAK,EAAY,EAAG,EAAAH,EAAG,EAAAC,EAAG,QAAAC,CAAO,CAAC,CAAC,EAClE,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGD,EAAG,CAAC,EAAG,UAAwB,CAC5C,EACA,cAAe,CAAC,EAAG,KAAK,KAAKa,EAAc,EAAuB,CAAC,CACrE,GACA,gBAAAlB,CACF,EACA,CAAC,OAAQ,CAACsB,EAAY7B,EAAOC,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC3D,EAEErB,GACF,CAAC6B,EAAyBpB,EAA+BC,IAAuC,CAC9F,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACduC,EAAIvC,EAAO,CAAC,EACZM,EAAIN,EAAOA,EAAO,OAAS,CAAC,EAC5BwC,EAAIpC,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIM,EAE7CiB,EAAaC,GAAiBlB,CAAC,EAC/BmC,EAAarC,EAAU,KAAKH,CAAW,EAAIsB,EAC3CE,EAAcjB,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMyB,CAAU,EACnFmB,EAAe9B,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUG,EAAasB,CAAU,EAEnFT,EAAW6B,GAA4B7C,EAAO,CAAC,EAAE,QAAQ,EACzD8C,EAAYrB,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC3DsB,EAAgBtB,IAAe,EAAIT,EAAW,MAAMS,CAAU,IAAIT,CAAQ,IAE1EgC,EAAoB1D,GAAY8B,EAASpB,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGyC,EAAGC,EAAGlC,EAAGP,EAAW,OAAO,EAErGiB,EAAmBC,GAA+B;AAAA,mBAC3CuB,CAAC;AAAA,mBACDlC,EAAIiB,CAAU;AAAA;AAAA,2DAE0BE,EAAY,KAAK,OAAO;AAAA,gEACnBmB,CAAS;AAAA,kEACPF,EAAa,KAAK,OAAO;AAAA;AAAA,IAEvFzB,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsB4B,CAAa,eAAeA,CAAa;AAAA,KAErF3B,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGnB,EAAW,QAAQ,EAAE,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAK2C,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAzB,CACF,EACA,CAAC,OAAQ,CAAClB,EAAO,CAAC,EAAGgD,CAAiB,CAAC,CAAC,CAC9C,EAESxD,GAA+BS,GACxCgD,GAA4B,CAAC,QAAShD,EAAW,QAAS,OAAQA,EAAW,MAAM,CAAC,EAE3ER,GAAe,CAAC2B,EAAyBnB,IAA6C,CAC7FA,EAAW,SAAW,OACxBV,GAAkC6B,EAASA,EAAQ,OAAQnB,CAAU,EAErEmB,EAAQ,QAAQ/B,GAA8B+B,EAAQ,OAAQnB,CAAU,CAAC,CAE7E,ICtRA,IAgBMiD,GAMAC,GAiGOC,GAGAC,GA1HbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEMT,GACF,CAACS,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAOC,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DM,EAAYD,EAAU,gBAAgBL,EAAQI,CAAI,EAClDG,EAAWF,EAAU,kBAAkBL,EAAQI,CAAI,EAEnDI,EAAYH,EAAU,KAAKJ,EAAM,IAAI,EACrCQ,EAAWP,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIM,IAAcD,GAAaL,GAAQO,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAAmB,CAAC,EAC1B,QAASC,EAAI,EAAGA,EAAIX,EAAO,OAAQ,EAAEW,EAC/BA,EAAIP,EACNM,EAAiB,KAAKV,EAAOW,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAI3B,IAAME,EAAaC,GAAiBN,CAAQ,EACtCO,EAAWC,GAA4BlB,EAAO,CAAC,EAAE,QAAQ,EACzDmB,EAAY,CAChBC,EAAc,IAAKpB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAU,EACjEK,EAAc,QAAShB,EAAM,SAAUA,EAAM,KAAMW,CAAU,CAC/D,EACIV,GACFc,EAAU,KAAKC,EAAc,OAAQf,EAAK,SAAUA,EAAK,KAAMU,CAAU,CAAC,EAE5EI,EAAU,KAAKE,EAAe,SAAUrB,EAAO,CAAC,EAAE,SAAUM,EAAaS,CAAU,CAAC,EAEpF,IAAMO,EAAoBpB,EAAc,EAClCqB,EAAkBrB,EAAc,EAElCoB,GACFH,EAAU,KAAKE,EAAe,mBAAkCR,CAAgB,CAAC,EAE/EU,GACFJ,EAAU,KAAKE,EAAe,iBAAgCR,CAAgB,CAAC,EAGjF,IAAMW,EAAmBC,GAA+B;AAAA,0BACpCf,CAAQ;AAAA,oCACEA,EAAWK,CAAU;AAAA,yBAChCd,EAAW,OAAO;AAAA;AAAA,IAEvCwB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA,IAC3CM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,uBAE5CiB,GAAW,MAAOX,CAAU,CAAC;AAAA,6BACvBW,GAAW,MAAOX,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGtCY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDa,GAAU,aAAcb,CAAU,CAAC;AAAA,4BACxBa,GAAU,mBAAoBb,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI9CY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA,uBAChDY,GAAUV,EAAUF,EAAY,UAAU,CAAC;AAAA,6BACrCI,EAAU,CAAC,EAAE,KAAK,KAAK;AAAA,UAC1Cd,EAAO,KAAKsB,GAAUV,EAAUF,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEO,EAAoB,oCAAsC,EAAE;AAAA,MAC5DC,EAAkB,4CAA8C,EAAE;AAAA,KAE5DM,EAAU,CAAC,CAAC,KAAMvB,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIsB,GACFO,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAE7DU,GACFM,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAG1D,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGZ,EAAW,QAAQ,IAAIC,CAAW,IAAIF,EAAO,MAAM,EAAE,EAC5E,WAAY,KAAO,CAAC,QAAA6B,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKpB,EAAY,EAAuB,CAAC,CAAC,GAC/F,gBAAAe,CACF,CACF,EAEShC,GAA4BS,GACrC6B,GAA4B,CAAC,KAAM7B,EAAW,KAAM,QAASA,EAAW,OAAO,CAAC,EAEvER,GAAY,CAACsC,EAAyB9B,IAA0C,CAC3FX,GAAeyC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQxC,GAA2BwC,EAAQ,OAAQ9B,EAAY8B,EAAQ,WAAW,CAAC,CAC7F,IC7HA,IASMC,GAUOC,GAnBbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEML,GAAkBM,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaL,GAAUM,GAAkC,CACvDP,GAAeO,EAAQ,MAAM,EAC7B,IAAMC,EAAcC,GAAc,UAAUF,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1DD,EAAQ,QAAQG,GAAwBH,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGC,CAAW,CAAC,CAChH,IC1BA,IAYMG,GA2NOC,GAGPC,GAEAC,GAmCAC,GA2BOC,GA1SbC,GAAAC,EAAA,kBAIAC,KACAC,KACAC,KAEAC,KACAC,KACAC,KAEMb,GAAiB,CAACc,EAA+BC,IAAoD,CACzG,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAMH,EAAO,CAAC,EACdI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EACfM,EAAiBN,EAAO,CAAC,EACzBO,EAAuBP,EAAO,CAAC,EAC/BQ,EAAUR,EAAO,CAAC,EAClBS,EAAYT,EAAO,CAAC,EAoC1B,GAAIE,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMQ,EAAe,GACfC,EAAYT,EAAM,KAAK,CAAC,EACxBU,EAAiBV,EAAM,KAAK,CAAC,EAC7BW,EAAaX,EAAM,KAAK,SAAW,EAAKQ,EAAeR,EAAM,KAAK,CAAC,EAAI,EAAIA,EAAM,KAAK,CAAC,EAChDD,EAAW,SAAWC,EAAM,KAAK,CAAC,EAC3EY,EAAmBF,EAEnBG,EAAqB,EACrBC,EAAoB,EAClBC,EAAW,KAAK,MAAMJ,EAAaZ,EAAW,QAAQ,EAC5D,GAAIO,GAAWC,EAAW,CACxB,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,mDAAmD,EAErE,GAAIC,EAAU,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,qDAAqD,EAEvEM,EAAqBP,EAAQ,KAAK,CAAC,EACnCQ,EAAoBR,EAAQ,KAAK,CAAC,CACpC,SAAWA,GAAWC,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAIS,EACJ,GAAIf,EAAK,CACP,GAAID,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAIC,EAAI,KAAK,OAAS,GAAKA,EAAI,KAAK,OAAS,EAC3C,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAID,EAAM,KAAK,CAAC,IAAMC,EAAI,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIA,EAAI,KAAK,SAAW,EAAG,CACzB,GAAIA,EAAI,KAAK,CAAC,IAAMD,EAAM,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,6DAA6D,EAE/EgB,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,SAAWA,EAAI,KAAK,SAAW,EAAG,CAChC,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAM,GAAKA,EAAI,KAAK,CAAC,IAAMc,EAC9E,MAAM,IAAI,MAAM,4FAA4F,EAE9G,GAAIb,EACF,MAAM,IAAI,MAAM,yDAAyD,EAE3Ec,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,KAAO,CACL,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAMc,EACzD,MAAM,IAAI,MAAM,wFAAwF,EAG1GC,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,CACF,KAAO,CACL,GAAID,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,uEAAuE,EAEzF,GAAIA,EAAM,KAAK,SAAW,IAAMA,EAAM,KAAK,CAAC,IAAMD,EAAW,UAAYC,EAAM,KAAK,CAAC,IAAM,GACzF,MAAM,IAAI,MAAM,8FAA8F,EAGhHgB,EAAY,CACd,CAEA,GAAIb,EAAM,CACR,GAAIA,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,8CAA8C,EAGhE,GAAID,GACEF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,CAAC,IAAM,EAC/C,MAAM,IAAI,MAAM,oCAAoC,CAG1D,CAEA,IAAIiB,IACJ,GAAIb,EAAgB,CAClBa,EAAW,EACX,IAAMC,EAAWd,EAAe,KAUhC,MATIc,EAAS,SAAW,EAClBA,EAAS,CAAC,IAAMT,EAClBQ,EAAW,EACFC,EAAS,CAAC,IAAM,EAAIT,EAAY,IACzCQ,EAAW,GAEJC,EAAS,SAAW,GAAKA,EAAS,CAAC,IAAMT,GAAaS,EAAS,CAAC,IAAMN,IAC/EK,EAAW,GAETA,IAAa,EACT,IAAI,MAAM,0FAA0F,EAEtG,IAAI,MAAM,oBAAoB,CACtC,CAEA,IAAIE,EAAe,GACfC,EAAcT,EAClB,GAAIT,EAAO,CACT,GAAIA,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAIF,EAAM,KAAK,CAAC,IAAME,EAAM,KAAK,CAAC,EAChC,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIA,EAAM,KAAK,SAAW,EAAG,CAC3B,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1FkB,EAAclB,EAAM,KAAK,CAAC,CAC5B,KAAO,CACL,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,kFAAkF,EAEpGkB,EAAclB,EAAM,KAAK,CAAC,EAAIA,EAAM,KAAK,CAAC,EAC1CiB,EAAe,EACjB,CACF,CAEA,IAAME,EAAsBR,EAAqBD,EAC3CU,EAAsB,GAO5B,GAAIlB,EACF,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIC,EACF,MAAM,IAAI,MAAM,6BAA6B,EAE/C,GAAIC,EACF,MAAM,IAAI,MAAM,0BAA0B,EAE5C,GAAIC,EACF,MAAM,IAAI,MAAM,4BAA4B,EAG9C,MAAO,CACL,UAAAE,EACA,eAAAC,EACA,mBAAAG,EACA,iBAAAD,EACA,oBAAAS,EACA,kBAAAP,EACA,gBAAiB,EACjB,WAAAH,EACA,YAAAS,EACA,SAAAL,EACA,UAAW,KAAK,MAAMK,EAAcrB,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAAuB,EACA,aAAAH,EACA,UAAAH,CACF,CACF,EAGa/B,GAAqCc,GAC9CwB,GAA4B,CAAC,GAAGxB,CAAU,CAAC,EAEzCb,GAAgDqC,GAA4B,CAAC,KAAM,CAAC,EAAG,EAAG,EAAG,CAAC,CAAC,CAAC,EAEhGpC,GACF,CAACqC,EAAyBC,EAAiBtB,EAAkBM,EAAmBC,EAC/EC,EAAoBe,IAAuB,CAC1C,IAAMC,EAAc,CAAClB,EAAWC,EAAgBC,CAAU,EACpDiB,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWC,GAA4BN,EAAI,QAAQ,EACnDO,EAAmBC,GAA+B;AAAA,uBACvCP,CAAU;AAAA,uBACVf,CAAU;AAAA;AAAA,wDAEuBmB,CAAQ;AAAA,yDACPA,CAAQ;AAAA,wEACOA,CAAQ;AAAA;AAAA,IAE5EG,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,KAM9D,OAAOJ,EAAQ,QACX,CACE,KAAM,4BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,UAAAf,EAAW,eAAAC,EAAgB,WAAAC,EAAY,WAAAe,CAAU,CAAC,CAAC,EACvF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAI,SAAU,aAAgC,CAAC,EACvF,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAI,CACF,EACA,CAAC,OAAQ,CAACP,EAAKtB,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC7C,EAEEf,GACF,CAACoC,EAAyBf,EAAmByB,EAAkBxB,EAAwBK,EACtFoB,EAAmBhC,EAAmBuB,IAAwB,CAG7D,IAAIU,EAAgBD,EACpB,GAAKhC,EAOE,CACL,GAAIO,IAAmB,EACrB,MAAM,IAAI,MAAM,mFAAmF,EAEnG,OAAA0B,EACIjD,GAAiBqC,EAASW,EAAOhC,EAAMM,EAAWC,EAAgBwB,EAAWnB,EAAUW,CAAW,EACtGU,EAAgBA,EAAc,QAAQ,CAAC3B,EAAWC,EAAgBwB,EAAUnB,CAAQ,CAAC,EAC9ES,EAAQ,QACXa,GAA2BD,EAAelD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACkD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAEnD,KAjBE,QAAID,EAAM,KAAK,SAAW,IACxBC,EAAgBD,EAAM,QAAQ,CAAC1B,EAAWC,EAAgBwB,EAAUnB,CAAQ,CAAC,GAExES,EAAQ,QACXa,GAA2BD,EAAelD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACkD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAanD,EAES/C,GAAqB,CAACmC,EAAyBzB,IAAqC,CAC/F,IAAMuC,EAAStD,GAAewC,EAAQ,OAAQzB,CAAU,EAExD,GAAIyB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpC,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAQ,OAAO,CAAC,GAAG,KAAK,SAAW,EACrC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAMe,EAASf,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,GACvFA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAEhCgB,EAAIpD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,eAAgBA,EAAO,SAAUd,EAAQ,OAAO,CAAC,EACpGA,EAAQ,OAAO,CAAC,EAAG,CAAC,EAExB,GAAIe,EACF,OAAOE,GACHjB,EAASgB,EAAGhB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAC3FA,EAAQ,OAAO,CAAC,EAAGc,EAAQvC,CAAU,EAG3C,IAAM2C,EAAItD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,SAAUd,EAAQ,OAAO,CAAC,EACtGA,EAAQ,OAAO,CAAC,EAAGc,EAAO,UAAU,EAElCK,EAAIvD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,UAAWd,EAAQ,OAAO,CAAC,EACvGA,EAAQ,OAAO,CAAC,EAAG,EAAIc,EAAO,UAAU,EAE5CG,GACIjB,EAASgB,EAAGE,EAAGC,EAAGnB,EAAQ,OAAO,CAAC,EAAG,OAAWA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGc,EACzGvC,CAAU,CAChB,IC9UA,IAkBM6C,GAmBAC,GA8BAC,GA8BAC,GA0BAC,GA0BAC,GAiBAC,GA0BAC,GAaAC,GA0BOC,GAMAC,GA7ObC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KASMhB,GAAkBiB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMjB,GACF,CAACkB,EAAuBC,EAA8BC,EAAiCC,EACtFC,EAAkBC,IAAkC,CACnD,IAAMC,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACKP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI5CP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA,4BAGPN,EAAaM,CAAC,CAAC;AAAA,UAIrC,MAAO;AAAA,oBACOJ,CAAQ,IAAIC,CAAa;AAAA;AAAA;AAAA;AAAA,cAI/BE,CAAK;AAAA;AAAA;AAAA,OAIf,EAEExB,GACF,CAACiB,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKvC,GAAKP,EAAUO,CAAC,EAAI,EAAE;AAAA;AAAA,4BAE1BP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,gCAIRN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEvB,GACF,CAACgB,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI5CP,EAAUO,CAAC,CAAC;AAAA,wBACfP,EAAUO,CAAC,EAAI,CAAC;AAAA;AAAA,gCAERN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEtB,GACF,CAACe,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA,yBAE9CP,EAAUO,CAAC,CAAC;AAAA;AAAA,2BAEVP,EAAUO,CAAC,CAAC;AAAA,yBACdP,EAAUO,CAAC,CAAC;AAAA;AAAA,gCAELN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEErB,GACF,CAACc,EAAuBC,EAA8BC,EAAiCO,EACtFL,IAA6B,CAC5B,OAAQK,EAAW,KAAM,CACvB,IAAK,GACH,OAAO3B,GAAekB,EAAQC,EAAWC,EAAcO,EAAW,KAAML,EAAUK,EAAW,KAAK,EACpG,IAAK,GACH,OAAO1B,GAAciB,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACvE,IAAK,GACH,OAAOzB,GAAWgB,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACpE,IAAK,GACH,OAAOxB,GAAWe,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACpE,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEEtB,GACF,CAACuB,EAA4BZ,EAA+BW,EAA2BL,IACzE,CACR,IAAMH,EAAYH,EAAO,CAAC,EAAE,KACtBa,EAAaC,EAAU,SAASX,EAAU,MAAM,EAAGQ,EAAW,IAAI,EAClEI,EAAaD,EAAU,KAAKD,CAAU,EACtCT,EAAeU,EAAU,eAAeX,CAAS,EAEjDD,EAASc,EAAe,SAAUhB,EAAO,CAAC,EAAE,SAAUa,CAAU,EAChEI,EAAQC,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUG,CAAS,EAExDgB,EAAa/B,GAAcc,EAAQC,EAAWC,EAAcO,EAAYL,CAAQ,EAYtF,MAXgB;AAAA,gBACVM,EAAa,iBAAiBK,EAAOf,CAAM,CAAC;AAAA,gBAC5CU,EAAa,UAAU,CAAC;AAAA,gBACxBA,EAAa,sCAAsCG,CAAU,CAAC;AAAA;AAAA,8BAEhDb,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEtCI,CAAQ;AAAA,gBACpBa,CAAU;AAAA;AAAA,YAIlB,EAEF7B,GAAuB,CAACU,EAA+BW,IAA2C,CACtG,IAAMS,EAAcN,EAAU,SAASd,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGW,EAAW,IAAI,EAC9E,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAMA,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMS,EAAa,SAAUpB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAU,KAAKM,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBR,GAAgBvB,GAAgBuB,EAAcZ,EAAQW,EAAY,KAAK,CAC1F,CACF,EAEMpB,GAAgC,CAACS,EAA+BW,IAA6C,CACjH,GAAIX,EAAO,OAAS,EAAG,CACrB,IAAMqB,EAAerB,EAAO,CAAC,EAAE,iBAAiB,EAC1CsB,EAAStB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFQ,EAAYR,EAAO,CAAC,EAAE,KAAK,OAC3BuB,EAAa,IAAI,WAAW,EAAIf,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIR,EAAO,QAAU,EAAG,CACtB,IAAMwB,EAAOxB,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAASU,EAAI,EAAGA,EAAIc,EAAK,OAAQd,IAC/Ba,EAAW,OAAOC,EAAKd,CAAC,CAAC,CAAC,EAAI,OAAOW,EAAaX,CAAC,CAAC,EACpDa,EAAW,OAAOC,EAAKd,CAAC,CAAC,EAAIF,CAAS,EAAI,OAAOa,EAAaX,EAAIc,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAGf,IAAMa,EAAW,OAAOb,CAAC,CAAC,EAAK,OAAOe,CAAC,CAAE,EAGpE,IAAMpB,EAAiB,CAAC,EACxB,OAAAkB,EAAW,QAAQE,GAAKpB,EAAK,KAAKoB,CAAC,CAAC,EAE7BC,GAA4B,CAAC,KAAMf,EAAW,KAAM,MAAAW,EAAO,KAAAjB,CAAI,CAAC,CACzE,KACE,QAAOM,CAEX,EAEanB,GAAM,CAACmC,EAAyBhB,IAAoC,CAC/E5B,GAAe4C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBrC,GAA8BoC,EAAQ,OAAQhB,CAAU,EAClFgB,EAAQ,QAAQrC,GAAqBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,EAEanC,GAAsBkB,GAAuD,CACxF,IAAMkB,EAAOlB,EAAW,KAClBW,EAAQX,EAAW,MACnBN,EAAOM,EAAW,KACxB,OAAOe,GAA4B,CAAC,KAAAG,EAAM,MAAAP,EAAO,KAAAjB,CAAI,CAAC,CACxD,IClPA,IAgBMyB,GASAC,GA4BAC,GAwKAC,GAaAC,GA4BOC,GAYAC,GAKPC,GAYOC,GAKAC,GAUPC,GAqBOC,GAKAC,GAgBAC,GAKAC,GAjWbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMnB,GAAkBoB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,4BAA4B,EAE9C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMnB,GAA0C,CAC5CoB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EAA2BJ,EAAM,KAAK,MAAM,EAC9CG,GACFC,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAC9CI,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAE1F,IAAMY,EAA2BF,EAA0B,MAAM,EACjE,OAAAE,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAACD,EAAeT,EAAiBU,EAA2BF,CAAyB,CAC9F,EAEM9B,GAAsB,CACxBiC,EAA4BC,EAAkBC,EAA2BC,EACzEhB,EAA2BiB,EAAaC,EAAaC,IAA0B,CACjF,IAAMjB,EAAiBF,EAAW,SAAW,OACvCoB,EAAYL,EACZM,EAAWP,EAAE,KAAK,MAClBQ,EAAOF,EAAU,OACjBG,EAAaC,EAAU,KAAKR,CAAW,EACvCS,EAASC,EAAe,SAAUZ,EAAE,KAAK,OAAQE,CAAW,EAElE,GAAIhB,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM2B,EAAK3B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D4B,EAAK5B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD6B,EAAU7B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD8B,EAAQ9B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClD+B,EAAUT,GAAQpB,EAAiB,EAAI,GACzC8B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GAqBf,GApBIL,EAAUC,IAAU,EACtBE,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQX,EAAUW,CAAO,CAAC;AAAA;AAAA;AAAA;AAAA,kCAI5DjB,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAGjBe,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kCAC9Cf,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAIfjB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMmC,EAAKnC,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DoC,EAAKpC,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDqC,EAAUrC,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDsC,GAAQtC,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDuC,EAAUjB,GAAQpB,EAAiB,EAAI,GACvCsC,EAAOpB,EAAUmB,CAAO,EAC1BF,EAAUC,KAAU,EACtBL,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQC,CAAI;AAAA,4BACpDb,CAAE;AAAA;AAAA;AAAA,gBAKtBM,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kBAG1EH,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVrB,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,cAExCZ,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2BAExCJ,CAAQ,MAAMA,CAAQ,IAAIF,CAAK;AAAA;AAAA,gBAE1Cc,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRhB,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIhB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMuC,EAAajB,EAAU,KAAKxB,EAAW,WAAW,EAClD0C,EAAgBlB,EAAU,eAAexB,EAAW,WAAW,EAC/D2C,EAAcD,EAAc,OAC5BE,EAAW5C,EAAW,KAAK,OAC3B6C,EAAU7C,EAAW,KAAK,OAAO,CAAC8C,EAAKC,IAAQD,EAAMC,CAAG,EAC1DC,EAAU,GACd,OAAIH,EACFG,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBlC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGf+B,EAAU;AAAA;AAAA,8BAEclC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,sCAEhBmB,CAAQ,KAAK5C,EAAW,KAAK,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,2CACnD3B,CAAI,KAAKF,EAAU,IAAI6B,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+CAC1CN,CAAW,KAAKD,EAAc,IAAIO,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC/DN,CAAW,KAAK3C,EAAW,QAAQ,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,cAEzFpC,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BkB,CAAW;AAAA;AAAA,4BAEvBlB,EAAO,KAAK,KAAK,IAAIN,CAAK;AAAA;AAAA;AAAA;AAAA,0CAIZsB,CAAU;AAAA;AAAA,uCAEbE,EAAc,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI5BA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVrB,EAAOqB,CAAW,UAAUrB,CAAI;AAAA,2DACJA,EAAOqB,CAAW;AAAA,oCACzCrB,EAAOqB,CAAW;AAAA,oBAClCK,CAAO;AAAA;AAAA,gBAEX9B,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMrC,GAA6BmB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMlB,GACF,CAACoE,EAAcnD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEwC,EAAajB,EAAU,KAAK2B,EAAmB,WAAW,EAE1DrC,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACjDsB,EAAWP,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACV,OAAIiC,EAAmB,gBACrBjC,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,KAEzCvB,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,WAEpC,CACL,KAAAS,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,KAAK,CACvG,CACF,EAESnC,GAA8BiB,GAA+D,CACxG,IAAMqD,EAAmBrD,EAAW,oBAAiC,EAE/DsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAIsD,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,OAAOC,GAA4B,CAAC,gBAAAF,EAAiB,GAAGC,CAAI,CAAC,CAC/D,EAEatE,GAAc,CAACwE,EAAyBxD,IAA4C,CAC/FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,cAAe0E,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CACnG,EAEMf,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,EACZ,SAAU,EACZ,EAEaC,GAAoCc,GAA+D,CAC9G,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEatE,GAAoB,CAACqE,EAAyBxD,IAA4C,CACrGtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,oBAAqB0E,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CACxG,EAOMZ,GACF,CAAC8D,EAAcnD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEgB,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACvD,MAAO,CACL,KAAAmD,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,MAAM,CACxG,CACF,EAES7B,GAAU,CAACmE,EAAyBxD,IAAwC,CACvFtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,UAAWoE,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CAC3F,EAEaV,GAA0BU,GAA2D,CAChG,IAAM0D,EAAe1D,EAAW,cAC1BO,EAAYP,EAAW,UAEvBsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAI0D,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAGtF,OAAOC,GAA4B,CAAC,aAAAG,EAAc,UAAAnD,EAAW,GAAG+C,CAAI,CAAC,CACvE,EAEa/D,GAAgCS,GAA2D,CACtG,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEajE,GAAgB,CAACgE,EAAyBxD,IAAwC,CAC7FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,gBAAiBoE,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CAChG,ICpWA,IAUM2D,GAUAC,GAwBOC,GA5CbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EAEbG,EAASC,EAAe,SAAUL,EAAUE,CAAW,EACvDI,EAAWF,EAAO,KAAK,QAEvBG,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,iBAAiBJ,CAAM,CAAC;AAAA,UACrCI,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,+BACzCG,CAAQ,IAAIZ,CAAK,OAAOY,CAAQ,kBAAkBA,CAAQ,IAAIV,CAAK;AAAA,SAEhG,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,CAACF,EAAOC,EAAOC,CAAK,EAAE,IAAIa,GAAKA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,CAAC,EAC1E,gBAAAF,EACA,WAAY,KACR,CAAC,QAAS,CAAC,CAAC,KAAML,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CAAC,EAC1E,CACF,EAEaf,GAASsB,GAAkC,CACtD,IAAIhB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRc,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACbzB,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3Cc,EAAQ,QAAQvB,GAAuBO,EAAOC,EAAOC,EAAOc,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC9DA,IAgCME,GAoBAC,GASAC,GA8CAC,GA0CAC,GAkCAC,GAaAC,GAwBAC,GAyBAC,GAsBAC,GAkCAC,GAYAC,GAiDAC,GAwEAC,GA2FAC,GAOOC,GAUAC,GA9hBbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAuBMrB,GAAiB,CAACsB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,gEAAgE,UAEzEC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMrB,GAAe,CAACqB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEMzB,GACF,CAAC2B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGvB,GAAesB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BtB,GAAaqB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEvB,GAA8CiC,GAChD,+JAEC,IAAM,CACL,OAAQA,EAAwB,CAC9B,IAAK,aACH,MAAO,4BACT,IAAK,qBACH,MAAO,sKAKT,IAAK,uBACH,MAAO,oCACT,IAAK,gBACH,MAAO,6LAKT,IAAK,qBACH,MAAO,gUAMT,IAAK,uBACH,MAAO,CACL,8CAA+C,kDAC/C,qCAAsC,4CACtC,oDACF,EAAE,KAAK;AAAA,CAAI,EACb,IAAK,aACH,MAAO,4CACT,QACE,MAAM,IAAI,MAAM,6BAA6BA,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACH,IAEEhC,GAA8B,CAACiC,EAA0BP,IAC3D,+EAAiF,IAAM,CACrF,OAAQO,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIP,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBO,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEhC,GAAY,CAAC2B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMY,EAAS,IAAI,MAAMZ,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Da,EAAWP,EAAI,SAAW,EAAIM,EAASN,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACe,EAAGC,IAAM,CACrBH,EAAOE,CAAC,EAAID,EAASE,CAAC,EACtBH,EAAOG,EAAIf,CAAI,EAAIa,EAASd,EAAK,OAASgB,CAAC,CAC7C,CAAC,EACMH,GAEFC,CACT,EAEMjC,GACF,CAACoC,EAA+BpB,EAA2BS,EAA0BN,IACrE,CACV,IAAIkB,EAAwB,CAAC,EAC7B,GAAIZ,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAiB,EAAW,QAASF,GAAMG,EAAY,KAAKH,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGf,CAAI,EAAIiB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExCjB,EAAK,QAAQ,CAACe,EAAGC,IAAME,EAAYH,CAAC,EAAIT,EAAMU,CAAC,CAAC,CAClD,MACEV,EAAM,QAASS,GAAMG,EAAY,KAAKH,CAAC,CAAC,MAErC,CACL,GAAIlB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDqB,EAAcD,EAAW,IAAI,CAAClB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOe,CACT,EAEFpC,GAAoB,CAACmC,EAA+BpB,EAAkBC,IAA2C,CACrH,IAAMqB,GAAiB,IAAM,CAC3B,OAAQrB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMuB,EAAsBH,EAAW,MAAM,EAC7C,OAAInB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASiB,GAAMlB,EAAOkB,CAAC,EAAII,CAAa,EACxDrB,EAAW,KAAK,QAASiB,GAAMK,EAAoBL,CAAC,EAAI,KAAK,MAAME,EAAWF,CAAC,EAAIlB,EAAOkB,CAAC,CAAC,CAAC,IAE7FlB,EAAO,KAAKsB,EAAe,EAAGtB,EAAO,MAAM,EAC3CuB,EAAoB,QAAQ,CAACL,EAAGC,IAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMD,EAAIlB,EAAOmB,CAAC,CAAC,CAAC,GAEnFI,CACT,EAEMrC,GACF,CAACsC,EAAuBJ,EAA+BC,EAAgCrB,EACtFU,IAAmC;AAAA,kEAC0Bc,EAAO,KAAK,OAAO,mBAC7EH,EAAY,MAAM;AAAA,sCACYD,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,uCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+BACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCACrCE,EAAY,MAAM;AAAA,gCAC1BA,EAAY,MAAM;AAAA,4BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,2EAKhBD,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,OAMtFjC,GACF,CAACsC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBgB,IAAsC;AAAA,+DAC/BF,EAAO,KAAK,OAAO,QAAQC,EAAM,KAAK,OAAO;AAAA,wCACpEL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,iCACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,4BACnDM,EAAM,KAAK,OAAO;AAAA,kCACZJ,EAAY,MAAM;AAAA,8BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+EAMdD,EAAW,MAAM;AAAA,mBAC7EM,CAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAYvBD,EAAM,WAAW,eAAgB,IAAK,YAAY,CAAC;AAAA;AAAA;AAAA,OAKzDrC,GAAoB,CAACqC,EAAsBL,IAA0C;AAAA,yCAClDK,EAAM,KAAK,OAAO;AAAA,sCACrBL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,gCAClEC,EAAW,MAAM;AAAA,2BACtBA,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQjF/B,GACF,CAACoC,EAAsBD,EAAuBJ,EAA+BpB,EAC5E0B,EAA2BC,IAAuC,CACjE,GAAM,CAACC,EAAUC,EAAWC,EAAUC,CAAU,EAC5CX,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAKpB,EAAO,CAAC,IAAM,EAAM,CAAC,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,EAC9F,MAAO;AAAA;AAAA,0BAEayB,EAAM,KAAK,OAAO;AAAA,qBACvBI,CAAS,uBAAuBT,EAAWS,CAAS,CAAC;AAAA,qBACrDC,CAAQ,uBAAuBV,EAAWU,CAAQ,CAAC;AAAA,YAC5DV,EAAW,MAAM;AAAA,uBACNW,CAAU;AAAA,uBACVH,CAAQ;AAAA;AAAA,qBAEVH,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,8CAGZD,EAAO,KAAK,OAAO;AAAA;AAAA,sCAE3BK,CAAS;AAAA,sCACTC,CAAQ;AAAA,YAClCJ,CAAgB,0BAA0BN,EAAWS,CAAS,CAAC,6BACjET,EAAWU,CAAQ,CAAC;AAAA,iBACbH,CAAkB;AAAA;AAAA,8BAELP,EAAWS,CAAS,CAAC;AAAA,8BACrBT,EAAWU,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOtCV,EAAW,OAAS,CAAC;AAAA,wCACOW,CAAU;AAAA,sCACZH,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAY1C,EAEEtC,GACF,CAACmC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBsB,EAAqBN,EACxEC,EAA4BM,IAAoC,CAC/D,GAAM,CAACJ,EAAWC,CAAQ,EAAIV,EAAW,SAAW,EAAI,CAAC,EAAG,CAAC,EAAKpB,EAAO,CAAC,IAAM,EAAO,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAE/FkC,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQN,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJO,CAAS,oCAAoCX,EAAM,KAAK,OAAO,oBAC9DD,EAAO,KAAK,OAAO;AAAA,4BACHH,EAAY,SAAW,EAAI,gBAAkB,iBAAiBc,CAAG,GAAG;AAAA,8FACFnC,EAAOmC,CAAG,CAAC;AAAA,cAC3Fd,EAAYc,CAAG,CAAC,UAAUf,EAAWe,CAAG,CAAC,MAAMzB,EAAIyB,CAAG,CAAC,KAAKzB,EAAIyB,CAAG,CAAC,MAAMf,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,cAI3FM,CAAgB,0CAA0CN,EAAWe,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA;AAAA;AAAA,gBAIrBS,CAAS;AAAA,gBACTA,CAAS,WAAWA,CAAS,OAAOhB,EAAWe,CAAG,CAAC;AAAA,kBACjDF,CAAc;AAAA;AAAA;AAAA,yBAGPP,CAAgB;AAAA,uBAClBC,CAAkB;AAAA;AAAA,gBAEzBS,CAAS,iBAAiBA,CAAS,KAAKhB,EAAWe,CAAG,CAAC;AAAA;AAAA;AAAA,kCAGrCV,EAAM,KAAK,OAAO;AAAA,6BACvBU,CAAG,WAAWC,CAAS;AAAA,0BAC1BD,IAAQN,EAAY,SAASJ,EAAM,gBAAgB,kBAAkB,CAAC,KAAO;AAAA,uGACA;AAAA;AAAA;AAAA,QAIjG,EAEA,MAAO;AAAA,MACPS,EAAiCL,CAAS,CAAC;AAAA,MAC3CK,EAAiCJ,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAO5BE,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CASfR,EAAO,KAAK,OAAO;AAAA,wBACtCC,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAItC,EAEElC,GACF,CAAC8C,EAAyBpC,EAA8BO,EAAsB8B,EAC7E7B,EAA0B8B,IAA6C,CACtE,IAAMnB,EAAaiB,EAAY,KACzB3B,EAAM3B,GAAUwD,EAAUtC,EAAW,KAAMmB,EAAW,MAAM,EAE9DC,EAAcrC,GAAgBoC,EAAYkB,EAAa7B,EAAOR,EAAW,IAAI,EAC7ED,EAASsC,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzBtC,EAASoB,EAAW,IAAI,CAAClB,EAAOI,IAAUJ,IAAU,EAAI,EAAMmB,EAAYf,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCoB,EAAcpC,GAAkBmC,EAAYpB,EAAQC,CAAU,IAGlE,IAAMuB,EAASgB,EAAe,SAAUH,EAAY,SAAUhB,CAAW,EACnEI,EAAQgB,EAAc,QAASJ,EAAY,SAAUjB,CAAU,EAC/DsB,EAAaC,EAAU,KAAKtB,CAAW,EACvCuB,EAAUxB,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAACyB,EAAG1B,IAAM0B,IAAMxB,EAAYF,CAAC,CAAC,EACrGO,EAAmBzB,EAAW,0BAA4B,qBAC1D6C,EAAmBC,GAA+B;AAAA,QACtDH,EAAU,GAAK;AAAA,QACf/D,GAA2CoB,EAAW,uBAAuB,CAAC;AAAA,SAC7E,IAAM,CACP,OAAQA,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHb,GAAkBqC,EAAOL,CAAU,CAAC;AAAA,gBACpCtC,GAA4BmB,EAAW,YAAaO,CAAY,CAAC;AAAA,gBAEjErB,GACIsC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKgB,CAAgB,CAAC;AAAA,gBAEhF,IAAK,SACH,MAAO;AAAA,gBACHxC,GAA0CsC,EAAQJ,EAAYC,EAAarB,EAAQU,CAAG,CAAC;AAAA,gBAEvFrB,GACIoC,EAAOD,EAAQJ,EAAYpB,EAAQ0B,EAAkBzB,EAAW,kBAAkB,CAAC;AAAA,gBAE7F,IAAK,QACH,MAAO;AAAA,cAEHX,GACImC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKT,EAAW,YAAayB,EAC7EzB,EAAW,mBAAoBA,EAAW,cAAc,CAAC;AAAA,cAEnE,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,OACH;AAAA,QACC8C,EAAa,iBAAiBtB,EAAOD,CAAM,CAAC;AAAA,QAC5CuB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,UAC9DE,EAAU,0CAA4C;AAAA,8BAClCpB,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACtCC,EAAM,KAAK,OAAO;AAAA,WACnC,IAAM,CACT,OAAQxB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,+CAE4BwB,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA,yCAE3CxB,EAAW,kBAAkB;AAAA,mBAE5D,IAAK,SACH,MAAO,6DACT,IAAK,QACH,MAAO,4DACT,QACE,MAAM,MAAM,4BAA4BA,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA,SACD;AAAA,SAGH,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,IAAImC,CAAO,EAC9C,EACA,gBAAAE,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMzB,EAAa,SAAUgB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEElD,GAAuCwD,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEaxD,GAAS,CAACuD,EAAyB/C,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoCwD,CAAO,EAChEpE,GAAeoE,EAAQ,OAAQ/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EsC,EAAQ,QACJzD,GAAwByD,EAAQ,OAAO,CAAC,EAAG/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAMiD,EAAYjD,EAAW,UACvBE,EAAOF,EAAW,KAClBkD,EACFlD,EAAW,wBACT+B,EAAc/B,EAAW,YACzBgC,EAAiBhC,EAAW,iBAA6B,EACzD0B,EAAqB1B,EAAW,mBAChCmD,EAA+CnD,EAAW,sBAC1DoD,EAAapD,EAAW,KAExBc,EAA4Bd,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOqD,GAA4B,CACjC,UAAAJ,EACA,KAAA/C,EACA,wBAAAgD,EACA,YAAAnB,EACA,eAAAC,EACA,mBAAAN,EACA,sBAAAyB,EACA,KAAAC,EACA,YAAAtC,CACF,CAAC,CACH,ICrjBA,IAeMwC,GAyDAC,GAyFOC,GAoBAC,GArLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EAAqBC,IACvE,CACb,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAgBT,GAAcD,EAAc,EAC5CW,EAAqBV,GAAcD,EAAc,EACjDY,EAA4BZ,EAAc,EAE1Ca,EAAaC,GAAiBnB,CAAU,EACxCoB,EAAY,CAChBC,EAAc,IAAKzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACjEG,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACpEG,EAAc,QAASzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CACvE,EACIL,GACFO,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAElFJ,GACFM,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAEtFE,EAAU,KAAKE,EAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAChFH,GACFK,EAAU,KAAKE,EAAe,eAA8BV,CAAgB,CAAC,EAE3EI,GACFI,EAAU,KAAKE,EAAe,iBAAgCV,CAAgB,CAAC,EAE7EK,GACFG,EAAU,KAAKE,EAAe,mBAAoB1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAEhG,IAAMK,EAAWC,GAA4B5B,EAAO,CAAC,EAAE,QAAQ,EACzD6B,EAAmBC,GAA+B;AAAA,gCAClC1B,CAAU;AAAA,0CACAA,EAAakB,CAAU;AAAA,6BACpCd,EAAW,OAAO;AAAA;AAAA,QAEvCsB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA;AAAA,QAE3CM,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCf,EAAaX,CAAU,CAAC;AAAA;AAAA,oBAEjE2B,GAAW,MAAOT,CAAU,CAAC;AAAA,0BACvBS,GAAW,MAAOT,CAAU,CAAC;AAAA;AAAA;AAAA,4BAG3BJ,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDG,EAA4B,wCAA0C,EAAE;AAAA;AAAA,2BAEzDW,GAAUL,EAAUL,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA,qBAI9CW,GAAU,MAAOX,CAAU,CAAC;AAAA,8BACnBW,GAAU,YAAaX,CAAU,CAAC;AAAA,UACtDH,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,uDAEzBO,CAAQ,aAAaA,CAAQ;AAAA,eACrEV,EAAe,UAAY,KAAK;AAAA;AAAA,SAG/BiB,EAAU,CAAC,CAAC,KAAMpB,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMvB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAqB,EACA,WAAY,KAAO,CAAC,QAAAK,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKnB,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAEKZ,GAAgB,CAAC2C,EAAyB3B,IAA8C,CAGnGlB,GAAe6C,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJ5C,GAA+B4C,EAAQ,OAAQ3B,EAAY2B,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEazC,GAAgCe,GAAiE,CAC5G,IAAM4B,EAAU5B,EAAW,QAC3B,OAAO6B,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICxLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GA2BAC,GAyGOC,GAYAC,GA9NbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,EAA+BI,EAC5EC,IACG,2CAA2CF,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,8BAClEA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAEvBQ,EAAW,MAAM;AAAA,kCAE9BK,EAA2B,uBAAuBL,EAAW,OAAS,EAAI,MAAQ,EAAE,GAAK,eAAe;AAAA,6BAExGK,EAA2B,iBAAiBL,EAAW,OAAS,EAAI,MAAQ,EAAE,GAAK,UAAU;AAAA,6BAE7FK,EAA2B,iBAAiBL,EAAW,OAAS,EAAI,MAAQ,EAAE,GAAK,UAAU;AAAA,8BAE7FK,EAA2B,kBAAkBL,EAAW,OAAS,EAAI,MAAQ,EAAE,GAAK,WAAW;AAAA,gCAC3EI,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAOjFJ,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA,SAKpErB,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBkB,EAAYC,EAAU,KAAKP,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKkB,EAAU,cAAclB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASO,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBP,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACoB,EAAOC,IAAMjC,GAAkBgC,EAAOC,EAAGV,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACsB,EAAKD,IAAMjC,GAAkBkC,EAAKD,EAAGV,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWF,EAAO,QAAUE,EAAK,SAAWD,EAAK,OACxD,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIC,EAAK,SAAWI,EAAW,OAC7B,QAASU,EAAI,EAAGA,EAAIV,EAAW,OAAQ,EAAEU,EAClCd,EAAK,SAASc,CAAC,IAClBhB,EAAO,OAAOgB,EAAG,EAAG,CAAC,EACrBf,EAAK,OAAOe,EAAG,EAAGV,EAAWU,CAAC,CAAC,EAC/BT,EAAM,OAAOS,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQX,EAAM,IAAIO,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CP,EAAM,QAAQ,CAACO,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYnB,EAAKe,CAAC,EAAIhB,EAAOgB,CAAC,GAAKF,EACnCO,EAASrB,EAAOgB,CAAC,EACjBM,EAAWD,EAASD,EAAWb,EAAMS,CAAC,EAC5ChB,EAAOgB,CAAC,EAAIM,EACZrB,EAAKe,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMS,EAAsBC,GAAqB9B,EAAO,CAAC,EAAE,KAAK,MAAM,EAChE+B,EAAmBF,EAAsB7B,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KAE3EgB,EAAcJ,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACwB,EAAM9B,IAAM,CACxBc,EAAYgB,CAAI,EAAI,KAAK,MAAMzB,EAAKyB,CAAI,EAAI1B,EAAO0B,CAAI,GAAKnB,EAAMmB,CAAI,CAAC,CACzE,CAAC,EACD,IAAMC,EAAoBJ,EAAsBb,EAAY,OAASA,EAE/DkB,EAA+B,CAAC,KAAMlB,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASoB,EAAe,SAAUnC,EAAO,CAAC,EAAE,SAAUiC,CAAiB,EACvE7B,EAAQgC,EAAc,QAASpC,EAAO,CAAC,EAAE,SAAU+B,CAAgB,EACnEM,EAAalB,EAAU,KAAKH,CAAW,EACvCsB,EAAoC,CAAC,EACrCC,EAA8B,CAAC,EACjCV,IACFU,EAAS,KAAK,CAAC,KAAM,SAAU,KAAMjC,EAAO,OAAS,EAAI,MAAMA,EAAO,MAAM,QAAU,KAAK,CAAC,EAC5FiC,EAAS,KAAK,CAAC,KAAM,QAAS,KAAMf,EAAM,OAAS,EAAI,MAAMA,EAAM,MAAM,QAAU,KAAK,CAAC,EACzFe,EAAS,KAAK,CAAC,KAAM,QAAS,KAAM1B,EAAM,OAAS,EAAI,MAAMA,EAAM,MAAM,QAAU,KAAK,CAAC,EACzFyB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMhC,CAAM,CAAC,EACnDgC,EAAgB,KAAK,CAAC,KAAM,QAAS,KAAMd,CAAK,CAAC,EACjDc,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMzB,CAAK,CAAC,GAEpD0B,EAAS,KAAK,CAAC,KAAM,aAAc,KAAM,KAAK,CAAC,EAC/CD,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMD,CAAU,CAAC,EACnDR,IACFS,EAAgB,KAAK,GAAGE,GAA2BxC,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEsC,EAAgB,KAAK,GAAGE,GAA2BxB,CAAW,CAAC,GAGjE,IAAMyB,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBH,CAAQ,EAAE,iBAAiBnC,EAAOW,CAAM,CAAC;AAAA,UACrEc,EAAsB,GAAK,CACjC,4BAA4BL,EAAM,MAAM,KAAKA,EAAM,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,KAC9E,6BAA6BhB,EAAO,MAAM,KAAKA,EAAO,IAAIgB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,KACjF,4BAA4BT,EAAM,MAAM,KAAKA,EAAM,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,KAC9E,iCAAiCV,EAAW,MAAM,KAAKA,EAAW,IAAIU,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,IAC/F,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA;AAAA,UAEJhC,GAA0Bc,EAAOW,EAAQH,EAAYI,EAAaa,CAAmB,CAAC;AAAA,UACtFa,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,gCACrD3B,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDA,EAAO,YAAY,aAAcX,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,SAE9E,MAAO,CACL,KAAM,QACN,YAAa,CACX,KAAMyB,EAAsB,GAAGL,EAAM,MAAM,IAAIlB,EAAO,MAAM,IAAIO,EAAM,MAAM,GAChD,GAAGZ,EAAW,QAAQ,MAAMD,EAAO,CAAC,GAAG,MAAQ,EAAE,GAC7E,kBAAmB,CAAC6B,EAAsB,OAAS,MAAM,CAC3D,EACA,gBAAAY,EACA,WAAY,KAAO,CACjB,QAAS,CAACP,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKhB,EAAY,EAAuB,CAAC,EACjE,gBAAAoB,CACF,EACF,CACF,EAEa9C,GAAQ,CAACmD,EAAyB1C,IAAsC,CACnFf,GAAeyD,EAAQ,OAAQ1C,CAAU,EACzC,IAAM2C,EAAoBxD,GAAgCuD,EAAQ,OAAQ1C,CAAU,EACpF0C,EAAQ,QAAQpD,GAAuBoD,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEanD,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,ICnOA,IAcMqC,GAUAC,GAwHOC,GAKAC,GArJbC,GAAAC,EAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAQF,EAAM,KACdG,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOL,EAAW,KAItB,GAHIK,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EACpBE,EAAaC,GAAiBH,CAAI,EAClCI,EAAaJ,EAAOE,EAEpBG,EAAY,CAACC,EAAcJ,IAC3BA,IAAe,EACV,WAAWI,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDJ,IAAe,EACjB,OAAOI,CAAI,OAAOA,CAAI,MACpBJ,IAAe,EACjB,WAAWI,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAEHC,EAAIC,EAAc,IAAKf,EAAM,SAAUA,EAAM,KAAMS,CAAU,EAC7DO,EAASC,EAAe,SAAUjB,EAAM,SAAUA,EAAM,KAAMS,CAAU,EACxES,EAAYJ,EAAE,KAAK,MAEnBK,EAAgBC,GAA4BpB,EAAM,QAAQ,IAAM,MAClE,mBAAmBkB,CAAS,oBAC5B,mBAAmBA,CAAS,eAC1BG,EAAmBC,GAA+B;AAAA,sCACpBJ,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKb,CAAE;AAAA;AAAA,4DAEAa,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA,QAIjEI,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBR,EAAGE,CAAM,CAAC;AAAA,QAC7EM,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA,qBAGXjB,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAMbc,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBID,CAAS,IAAIN,EAAU,kBAAmBH,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDS,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIK,GAAU,kBAAmBd,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAU9E,MAAO,CACL,KAAM,UACN,YAAa,CAAC,KAAM,GAAGA,CAAU,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAChE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMP,EAAO,SAAUF,EAAM,QAAQ,CAAC,EACjD,cAAe,CAAC,EAAGQ,CAAI,EACvB,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAMG,CAAU,CAAC,CACtD,GACA,gBAAAU,CACF,CACF,EAEa7B,GAAU,CAACgC,EAAyBvB,IAAwC,CACvFX,GAAekC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAyBiC,EAAQ,OAAO,CAAC,EAAGvB,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCwB,GAA4B,CAAC,KAAMxB,EAAW,IAAc,CAAC,ICtJjE,IAgBMyB,GAMAC,GAWAC,GASAC,GAqBAC,GAkDOC,GAOAC,GAxHbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,GAEtBf,GAAuBgB,GAAsC,CACjE,IAAMD,EAAkBC,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,uBAAuBC,CAAC,QAAQC,CAAa,IAAI,EACvDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,4BAA4BC,CAAC,OAAOC,CAAa,IAAI,CAExE,CACA,MAAO;AAAA,uDAC8CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACpEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMhB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMU,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWd,EAAO,CAAC,EAAE,SACrBe,EAAOJ,EAAW,OAClBK,EAAOf,EAAW,KAClBgB,EAAgBD,EAAO,EAAKL,EAAW,OAASK,EAAOA,EACvDT,EAAU,IAAI,MAAqBN,EAAW,UAAU,EACxDiB,EAAQC,EAAc,QAASL,EAAUH,CAAU,EACnDS,EAAmB,IAAI,MAAcnB,EAAW,UAAU,EAC1DoB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EAClB,QAASd,EAAI,EAAGA,EAAIR,EAAW,WAAYQ,IAAK,CAC9Cc,GAAetB,EAAW,WAAWQ,CAAC,EACtCW,EAAiBX,CAAC,EAAIc,EACtB,IAAMC,EAAcb,EAAW,MAAM,EACrCa,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWQ,CAAC,EACtDa,EAAa,KAAKE,CAAW,EAC7BjB,EAAQE,CAAC,EAAIgB,EAAe,SAAShB,CAAC,GAAIK,EAAUQ,EAAab,CAAC,CAAC,EACnEY,EAAkB,KAAK,CAAC,KAAMC,EAAab,CAAC,EAAG,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACA,IAAM0B,EAAcX,EAAO,EAAI,UAAY,WAAWE,CAAY,IAC5DU,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiBV,EAAO,GAAGX,CAAO,CAAC;AAAA,wCACZa,EAAiB,MAAM,KAAKA,EAAiB,IAAIX,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GnB,GAAyB8B,EAAiB,MAAM,CAAC;AAAA,IACjD7B,GAAoBgB,CAAO,CAAC;AAAA;AAAA,IAE5BqB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,oBAE/CM,EAAM,gBAAgB,YAAY,CAAC;AAAA,8CACTQ,CAAW;AAAA;AAAA,UAE/CA,CAAW;AAAA;AAAA;AAAA,KAInB,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASN,EACT,cAAe,CAAC,EAAG,KAAK,KAAKT,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEanB,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,IChIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAoCAC,GArFbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,EAAc,QAASF,EAAUN,CAAU,EACnDS,EAASC,EAAe,SAAUJ,EAAUJ,CAAW,EAEvDS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAC5CG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,4BAC1CK,EAAO,gBAAgB,YAAY,CAAC;AAAA,0BACtCF,EAAM,KAAK,OAAO;AAAA,4BAChBP,EAAW,MAAM;AAAA,8BACfS,EAAO,WAAW,gBAAiB,GAAG,CAAC,OAAOF,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA;AAAA,UAErGA,EAAM,WAAW,eAAgB,IAAK,eAAe,CAAC;AAAA;AAAA,QAExDE,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,OAG1E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,EAAE,EAChC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAO,CACF,CACF,EAEanB,GAAQqB,GAAkC,CACrDxB,GAAewB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAsBsB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,ICxFA,IAUMC,GA8DAC,GA+BOC,GAvGbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAU,KAAK,KAAKF,EAAa,CAAC,EAElCG,EAASC,EAAe,aAAcL,EAAYF,EAAY,CAAC,EAC/DQ,EAAIC,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEW,EAAID,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEY,EAAIF,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAElEa,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACV,EACHW,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IAE9CI,EAAc,oBAAoBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC5E,MAAO;AAAA,+BACcA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMR,EAAE,2BAA2B,gBAAgBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAMN,EAAE,2BAA2B,gBAAgBM,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAML,EAAE,2BAA2B,gBAAgBK,CAAC,GAAIV,CAAM,CAAC;AAAA,wBACjEU,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIlB,IAAe,EACjBU,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCF,EAAa;AAAA,cACTE,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACHhB,EAAa,iBAAiBa,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UAC9CR,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCO,CAAO,CAAC;AAAA,UAC3DO,CAAU;AAAA,QAEhB,EAEErB,GAA4BQ,GAA+C,CAC/E,IAAMsB,EAAQtB,EAAO,CAAC,EAAE,KAClBuB,EAAQvB,EAAO,CAAC,EAAE,KAClBwB,EAAQxB,EAAO,CAAC,EAAE,KAClByB,EAAiBzB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEG,EAAU,SAASiB,EAAOC,CAAK,GAAKlB,EAAU,SAASkB,EAAOC,CAAK,GACrFE,EAAcJ,EACdlB,EAAaC,EAAU,KAAKiB,CAAK,EAGrC,GAAIpB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUN,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhED,EAAcC,EACdvB,EAAaC,EAAU,KAAKqB,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,gBAAkB3B,GACdR,GAA2BQ,EAAcC,EAAQ0B,EAAaxB,EAAauB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKrB,EAAa,GAA0B,CAAgB,CAAC,CACvF,EACF,CACF,EAEaX,GAASoC,GAAkC,CACtDA,EAAQ,QAAQrC,GAAyBqC,EAAQ,MAAM,CAAC,CAC1D,ICzGA,IAuCaC,GAvCbC,GAAAC,EAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOahC,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAUiC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EAEnD,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACf,GAAMC,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACe,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,GAAcC,EAA2B,CAAC,EACrE,CAAC,qBAAsB,CAACC,GAAWC,EAAwB,CAAC,EAC5D,CAAC,YAAa,CAAUC,GAAoBvB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWwB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,qBAAsB,CAACC,GAAoBC,EAAiC,CAAC,EAC9E,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,GAAKC,EAAkB,CAAC,EACjC,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,GAAWC,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACC,GAAYD,EAAqB,CAAC,EAClD,CAAC,YAAa,CAACE,GAAWF,EAAqB,CAAC,EAChD,CAAC,YAAa,CAACG,GAAWH,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACI,GAAYJ,EAAqB,CAAC,EAClD,CAAC,WAAY,CAACK,GAAUL,EAAqB,CAAC,EAC9C,CAAC,WAAY,CAACM,GAAUN,EAAqB,CAAC,EAC9C,CAAC,eAAgB,CAACO,GAAcP,EAAqB,CAAC,EACtD,CAAC,kBAAmB,CAACQ,GAAiBR,EAAqB,CAAC,EAC5D,CAAC,kBAAmB,CAACS,GAAiBT,EAAqB,CAAC,EAC5D,CAAC,OAAQ,CAAUU,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BrE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACsE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,IC5HD,IAoBaC,GApBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAYaL,GAAN,KAAqB,CAI1B,YAAoBM,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5D,IAAMC,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9DA,EAAmB,YAAYR,EAAc,eAAe,EAC5D,IAAMS,EAAU,CAAC,EACjB,QAAWC,KAASP,EAClBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUP,EACnBK,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEL,GACFG,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUH,CAAoB,CAAC,EAExE,IAAMM,EAAYL,EAAO,gBACrB,CAAC,OAAQP,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAS,EAAS,MAAOT,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAQ,EAAmB,aAAa,EAAGI,CAAS,EAE5CJ,EAAmB,mBAAmB,GAAGH,CAAa,EAEtD,KAAK,QAAQ,wBAET,KAAK,QAAQ,eAAe,EAAG,CAC7B,OAAO,KAAK,QAAQ,UAAc,MACpC,KAAK,QAAQ,UAAY,KAAK,QAAQ,eAAe,OAEjD,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,aAAa,GAE5F,IAAMQ,EAAW,KAAK,QAAQ,eAAe,OAEzC,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,QAAQ,EAErF,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAAgB,KAAK,QAAQ,SAAW,EAAG,EAAG,KAAK,QAAQ,UAAU,OAAQ,CAAC,EAC/G,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,UAAU,OAAQ,EAAGA,EAAS,OAAQ,EAAG,KAAK,QAAQ,cAAgB,CAAC,EACxF,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAC9CE,EAAa,IAAID,EAAW,CAAC,CAAC,KAAKA,EAAW,CAAC,CAAC,GAEjDF,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACxD,IAAMI,EAAa,IAAI,eAAeJ,EAAS,OAAO,eAAe,CAAC,EAChEK,EAAeD,EAAW,CAAC,EAC3BE,EAAaF,EAAW,CAAC,EAE/BJ,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,cAAkB,MACxC,KAAK,QAAQ,cAAgBK,GAG/B,IAAME,EAAY,OAAOF,EAAe,KAAK,QAAQ,aAAa,EAC5DG,EAAU,OAAOF,EAAa,KAAK,QAAQ,aAAa,EAE9D,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,KAAK,QAAQ,eAAe,QAAQR,EAAS,EAAE,EAC/C,IAAIS,EAAc,GAClBrB,EAAiB,QAAQ,CAACsB,EAAOC,IAAM,CACrCF,GAAe,SAASE,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIG,EAAe,GACnBxB,EAAkB,QAAQ,CAACqB,EAAOC,IAAM,CACtCE,GAAgB,UAAUF,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIE,CAAU,KAAKM,CAAW,GAAGI,CAAY,mBACpFL,EAAUD,CAAS,KAAK,CAC9B,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,CAEvB,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/F,IAAMrB,EAAS,KAAK,QAAQ,OACtBsB,EAAuB,CAAC,EAC1BtB,EAAO,SAAS,IAAI,YAAY,GAClCsB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe3B,EAAO,mBAAmB,CAAC,KAAA0B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,YAAYR,EAAY,IAAI,iBAAiBM,CAAI,EAAE,EAE9E,IAAMG,EAAkB7B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ2B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,MAAO,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2B/B,EACE,CAC3B,IAAMgC,EAAI,OAAOhC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEiC,EAAI,OAAOjC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEkC,EAAI,OAAOlC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEmC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IC9JA,IAYMC,GA4CAC,GAqBOC,GA7EbC,GAAAC,EAAA,kBAKAC,KACAC,KACAC,KACAC,KACAC,KAGMT,GACF,CAACU,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEX,GACF,CAACgB,EAA0BP,EAAqCQ,IAA0C,CAGxG,IAAIC,EAAMF,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BE,GAAO,IAAMF,EAAY,YAAY,KAAO,KAE9CE,GAAO,IAAMD,EACT,IACOlB,GACIU,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GAC1FS,CACT,EAMSjB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,KAAQ,eAAyC,KACjD,KAAQ,mBAAiD,KACzD,2BAAwB,EAIxB,mBAAgB,EAQhB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAIkB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAyB,CACxC,GAAI,CAAC,UAAU,IAEb,MAAM,IAAI,MAAM,yCAAyC,EAG3D,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAEID,EAAQ,SAAS,IAAI,iBAAiB,GACxCC,EAAiB,KAAK,iBAAiB,EAErCD,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMC,EAAkD,CAAC,EACrD,KAAK,eAAe,IAClB,OAAO,KAAK,SAAa,MAC3B,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,aACd,CAAC,GAEHA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,EAC3B,oBAAqB,CACvB,GAGF,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiBA,CAAqB,CAC3F,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAEA,gBAA0B,CACxB,MAAI,QAAK,OAAO,SAAS,IAAI,iBAAiB,GAAK,KAAK,IAAI,OAAO,gBAAkB,UAKvF,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CAErG,IAAMC,EAAwB,CAAC,EAC/B,QAAStB,EAAI,EAAGA,EAAIkB,EAAiB,OAAQ,EAAElB,EAAG,CAChD,IAAMuB,EAAU,KAAK,eAAe,IAAIL,EAAiBlB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACuB,EACH,MAAM,IAAI,MAAM,0BAA0BL,EAAiBlB,CAAC,EAAE,IAAI,EAAE,EAEtEsB,EAAWtB,CAAC,EAAIuB,CAClB,CAEA,GAAM,CAAC,QAAAC,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIT,EAAQ,WAAWC,CAAgB,EAG/ES,EAAyBR,EAAc,SAAW,EAAIK,EAAQ,IAAI,CAACI,EAAG5B,IAAMA,CAAC,EAAImB,EACvF,GAAIQ,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS9B,EAAI,EAAGA,EAAIwB,EAAQ,OAAQ,EAAExB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU2B,EAAuB3B,CAAC,CAAC,GAAK2B,EAAuB3B,CAAC,EAAI,IAC5E2B,EAAuB3B,CAAC,GAAKwB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB3B,CAAC,CAAC,EAAE,EAEtE,GAAI2B,EAAuB3B,CAAC,IAAM,GAChC,SAEF,IAAM+B,EAAcJ,EAAuB3B,CAAC,IAAM,GAC5CgC,EAAeL,EAAuB3B,CAAC,IAAM,GAC7CiC,EAAcF,GAAeC,EAC/BX,EAAyBG,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAC7DoB,EAAmBO,EAAuB3B,CAAC,EAAGwB,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAChFuB,EAAU,KAAK,eAAe,IAAIU,EAAW,IAAI,EACvD,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,2BAA2BU,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKR,CAAO,EAE7BS,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKX,CAAO,CAC7B,CACAM,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKP,CAAO,CAC1B,CAMA,IAAIY,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EAChBC,EAAY,EACVC,EAAoB,CAAC,EACvBC,EAAsB,EAC1Bb,EAAgB,QAAQc,GAAK,CAC3B,IAAMjC,EAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAIjC,EAAK,SAAW,EAClB,OAGF,IAAIkC,GACJ,OAAQlC,EAAK,OAAQ,CACnB,IAAK,GACHkC,GAAgB,EAChB,MACF,IAAK,GACHA,GAAgB,EAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,QACE,MAAM,IAAI,MAAM,4BAA4BlC,EAAK,MAAM,EAAE,CAC7D,EAEI8B,IAAc,GAAKA,IAAc,KACnCI,GAAgB,IAEdA,GAAgBF,IAClBA,EAAsBE,IAExBL,EAAgB,KAAK,KAAKA,EAAgBK,EAAa,EAAIA,GAC3DJ,EAAY9B,EAAK,OACjB+B,EAAQ,KAAKF,CAAa,EAC1BA,GAAiB7B,EAAK,OAAS,CACjC,CAAC,EAED6B,EAAgB,KAAK,KAAKA,EAAgBG,CAAmB,EAAIA,EACjE,IAAMG,EAAc,IAAI,YAAYN,CAAa,EACjDV,EAAgB,QAAQ,CAACc,EAAGxC,IAAM,CAChC,IAAM2C,GAASL,EAAQtC,CAAC,EAClBO,EAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWE,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAChDiC,EAAE,OAAS,SACpB,IAAI,YAAYE,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAE1D,IAAI,aAAamC,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,CAE/D,CAAC,EAED,IAAMqC,EAEF,KAAK,eAAe,OAAOR,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYQ,EAAkB,OAAQ,EAAGF,EAAa,EAAGN,CAAa,EACxF,KAAK,eAAe,QAAQQ,EAAkB,EAAE,EAChDT,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQQ,EAAkB,MAAM,CAC1F,CAEA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BpB,CAAa,EACtFpB,EAAuBwC,EAAwB,CAAC,IAAM,GAAKA,EAAwB,CAAC,IAAM,EAE1FvC,EAAMlB,GAAwB6B,EAASC,EAAkBb,CAAoB,EAC/EyC,EAAW,KAAK,eAAe,YAAYxC,CAAG,EAClD,OAAKwC,IACHA,EAAW,KAAK,eAAe,MAAM7B,EAAS4B,CAAuB,EACrE,KAAK,eAAe,YAAYvC,EAAKwC,CAAQ,GAG/CC,GACI,OACA,IAAM,yBAAyB9B,EAAQ,IAAI,UAAUX,CAAG,UAAUuC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBC,EAAU5B,EAAkBW,EAAmBP,EAAYQ,EAAae,EACxEV,CAAoB,EAEjBN,CACT,CAEA,OAAOmB,EAAmBzC,EAAwB,CAChD,KAAK,eAAe,OAAOyC,EAAWzC,CAAI,CAC5C,CAEA,OAAO0C,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMrB,EAAiB,KAAK,qBAAqB,IAAIqB,CAAQ,EAC7D,GAAIrB,EAAgB,CAClB,QAAW3B,KAAQ2B,EACjB,KAAK,eAAe,QAAQ3B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAOgD,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBjB,GAAU,OAAQ,IAAM,kCAAkCO,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW5D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe6D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMzB,EAAU,KAAK,eAAe,IAAIyB,CAAS,EACjD,GAAI,CAACzB,EACH,MAAM,IAAI,MAAM,2BAA2ByB,CAAS,EAAE,EAExD,OAAOzB,EAAQ,MACjB,CACA,iBAAiBoD,EAAsBvB,EAAcnD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMM,EAAO,MAAMqE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWtE,EAAK,OAAQN,CAAI,CACrC,CACF,CAEF,ICziBA,IAAA6E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA6EOF,GApIbG,GAAAC,EAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,GAAqB,EACtC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIF,EAAYE,IAAK,CACnC,IAAMZ,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BI,EAAML,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASY,EAAI,EAAGA,EAAID,EAAKC,IACvBZ,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQI,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIJ,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFM,EAAgBF,GAAsB,SAAW,CAAC,EAClDG,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIa,EAASE,EAAcC,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAASU,EAAI,EAAGA,EAAIV,EAAK,OAAQU,IAC/B,KAAK,OAAO,QAAQc,GAAQ,EAAIxB,EAAKU,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBQ,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAEapC,GAAO,MAAMU,EAAuB6B,IAA4B,CAC3E,IAAMvC,EAAOU,EAAO,SACpB,GAAIV,GAAQ,UAAU,IAAK,CACzB,GAAI,CAACuC,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,mGAAmG,EAEzG,IAAMtB,EAAU,IAAIuB,GACpB,MAAMvB,EAAQ,WAAWsB,CAAG,EAE5BvC,EAEIiB,EAGCwB,GAAiBxB,EAAQ,MAAMwB,CAAI,EAGnCC,GAAgBzB,EAAQ,KAAKyB,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5FxB,EAAQ,OAAO0B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM7B,EAAOF,EAAO,OAAO,SAASiC,EAAKA,EAAMF,CAAI,EACnDxB,EAAQ,OAAO2B,EAAKhC,CAAI,CAC1B,CACF,EAGA,MAAMmC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAMxB,EAAQ,SAAS8B,EAAW,IAAMrC,EAAO,OAAO,SAASsC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBlC,EAAQ,aAC1DgC,EAAMC,EAAQC,EACdZ,EAAI,OAASA,EAAI,OAAO,gBAAkB,UAAY7B,EAAO,aAAaA,EAAO,iBAAiBwC,CAAM,CAAC,EACnD,GAAGA,CAAM,EAAE,EAGpEA,GAAmBjC,EAAQ,cAAciC,CAAM,EAGhD,CAACA,EAAgBhC,EAA2BkC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpEhC,CAAiB,EAAE,EAC3B,IAAMoC,EAAU,IAAIpD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAciC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,CACF,ICjMA,IAYIE,GAOEC,GAoBAC,GAWOC,GA+CPC,GAEOC,GAMAC,GAgBAC,GA+FAC,GAMAC,GAoBAC,GAqEAC,GA6NAC,GAgBAC,GApiBbC,GAAAC,EAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAEIpB,GAAoB,GAOlBC,GAA8BoB,GAA4C,CAC9E,IAAMC,EAAOC,GAAY,EACnBC,EAAQF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMG,EAAaH,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeI,EAAYA,EAAa,CAAC,IACtE,GAChBC,GAAe,uCAAwC,EAElD,CAACJ,EAAK,OAAOG,EAAa,CAAC,EAAGH,EAAK,OAAOG,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAH,EAAK,aAAaE,CAAK,CACzB,CACF,EAOMtB,GAAU,CAACyB,EAAoBC,IAA+B,CAChDL,GAAY,EAAE,SAASI,EAAYC,CAAY,IAC/C,GAChBF,GAAe,+BAAgC,CAEnD,EAMavB,GAAc,MAAM0B,GAA4B,CAE3D3B,GAAQ2B,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,EAEhC,CAI9B,IAAME,EAAW,cAAuB,KACxC,MAAMA,EAASR,GAAY,EAAGM,CAAG,CACnC,CAEA7B,GAAoB,EACtB,EAkCMI,GAAiB,IAAI,IAEdC,GAAsB,IAAeL,GAMrCM,GAAyB0B,GAAwC,CAC5E,IAAMV,EAAOC,GAAY,EACnBU,EAAkBX,EAAK,QAAQU,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAV,EAAK,OAAO,IAAIU,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAQazB,GACT,CAAC2B,EAAkCC,IAA2E,CAC5G,IAAMb,EAAOC,GAAY,EAErBF,EAAgB,EAChBe,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBN,CAAO,EAE1Dd,EAAgBC,EAAK,kBAAkBY,EAAU,CAAC,EAAGA,EAAU,CAAC,EAAGE,CAAoB,EACnFf,IAAkB,GACpBK,GAAe,yBAA0B,EAG3C,GAAM,CAACgB,EAAYC,CAAW,EAAI1C,GAA2BoB,CAAa,EAEpEuB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAO1B,EAAK,iBAAiBD,EAAe0B,CAAC,EAC/CC,IAAS,GACXtB,GAAe,0BAA2B,EAE5Ca,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKtB,EAAK,aAAa0B,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAO1B,EAAK,kBAAkBD,EAAe0B,CAAC,EAChDC,IAAS,GACXtB,GAAe,2BAA4B,EAE7Cc,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAa3B,EAAK,aAAa0B,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOf,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Bc,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBf,EAAK,kBAAkBD,CAAa,EAClDgB,IAAoB,GACtBX,GAAe,0BAA2B,EAG5CyB,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGFhD,GAAe,IAAIiB,EAAe,CAACA,EAAekB,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAAC9B,EAAeuB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EAEpDlB,IAAoB,GACtBf,EAAK,mBAAmBe,CAAe,EAGrChB,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjCiC,CACR,QAAE,CACAhC,EAAK,MAAMY,EAAU,CAAC,CAAC,EACnBE,IAAyB,GAC3Bd,EAAK,0BAA0Bc,CAAoB,EAErDE,EAAO,QAAQkB,GAASlC,EAAK,MAAMkC,CAAK,CAAC,CAC3C,CACF,EAOShD,GACT,CAACwB,EAAmBG,IAA2E,CAC7F,IAAMD,EAAmC5B,GAAsB0B,CAAK,EACpE,OAAOzB,GAAsB2B,EAAWC,CAAO,CACjD,EAES1B,GAAkBgD,GAA4B,CACzD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACFrC,EAAK,mBAAmBqC,EAAe,MAAM,EAG/CrC,EAAK,wBAAwBmC,CAAS,EAEtClB,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACxDjC,EAAK,mBAAmBD,CAAa,EACrCjB,GAAe,OAAOqD,CAAS,CACjC,EAEa/C,GACT,CAACkD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMvC,EAAOC,GAAY,EAEnBwC,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAU3C,EAAK,mBAAmBmC,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEzB,EAAK,QAAQoD,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB3C,EAAK,OAAO,IAAI,IAAI,WAAWmD,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMzC,EAAQF,EAAK,UAAU,EACvBsD,EAAatD,EAAK,WAAW,EAAI0C,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKxD,EAAK,OAAOuD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAStC,EAAK,iBAChBgD,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACblC,GAAe,iDAAiD+B,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAtC,EAAK,aAAaE,CAAK,CACzB,CACF,EAKKb,GAAM,MACf8C,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2C/C,IAAoE,CACjH,IAAMb,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBlE,EAAK,UAAU,EAChCmE,EAAoBnE,EAAK,WAAWoB,EAAa,CAAC,EAClDgD,EAAmBpE,EAAK,WAAWoB,EAAa,CAAC,EACjDiD,EAAqBrE,EAAK,WAAWqB,EAAc,CAAC,EACpDiD,EAAoBtE,EAAK,WAAWqB,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc1D,CAAO,EAG5D,QAASY,GAAI,EAAGA,GAAIL,EAAYK,KAC9BrC,GAAyBsE,EAAajC,EAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,EAAC,CAAC,EAI7G,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BrC,GACIwE,EAAcnC,EAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,EAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,EAAkBL,EAAmB,EACrCM,GAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,GAAI,EAAGA,GAAIL,EAAYK,KAC9BzB,EAAK,QAAQwE,GAAkB,EAAIT,EAAmBtC,EAAC,EACvDzB,EAAK,QAAQyE,GAAiB,EAAIxD,EAAsBwC,EAAahC,EAAC,CAAC,EAEzE,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BzB,EAAK,QAAQ0E,IAAmB,EAAIV,EAAoBvC,EAAC,EACzDzB,EAAK,QAAQ2E,GAAkB,EAAIzD,EAAuByC,EAAclC,EAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,GAAQ,yBAAApD,GAA0B,gCAAAqD,CAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMzB,EAAK,cAAc4E,GAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChBrB,GAAe,oBAAoBqB,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBzB,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChBrB,GAAe,mCAAmCqB,EAAC,iBAAiBU,CAAS,GAAG,EAK9EnC,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,EAAgCrC,EAAK,CAAC,IACtF,GAChBpC,GAAe,qBAAqBqB,EAAC,QAAQD,GAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,EAE8BzC,EAChCyC,EAAY,MAAM9E,EAAK,mBACnBD,EAAesC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,EAAY,MAAM9E,EAAK,QACnBD,EAAeqE,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,IAAc,GAChB1E,GAAe,0BAA0B,EAG3C,IAAM2E,GAA2B,CAAC,EAElC,QAAStD,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMa,GAAStC,EAAK,QAAQqE,EAAqB,EAAI5C,EAAC,EACtD,GAAIa,KAAW0B,EAAoBvC,EAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,EAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,EAA2BhF,EAAK,UAAU,EAE1CiF,GAAmBjF,EAAK,WAAW,EAAI,CAAC,EAE1CkF,GAAmB,GACnBC,GAA6BhF,GAAa,EAC9C,GAAI,CACgBH,EAAK,kBACnBsC,GAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChB7E,GAAe,4CAA4CqB,EAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWzC,EAAK,QAAQoF,IAAiB,EAC/CjF,GAAaH,EAAK,QAAQoF,IAAiB,EAC3C,IAAM9B,EAAatD,EAAK,QAAQoF,IAAiB,EAC3CC,GAAarF,EAAK,QAAQoF,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,GAAY5D,KAC9BiB,GAAK,KAAK1C,EAAK,QAAQsD,EAAa,EAAI7B,EAAC,CAAC,EAE5CzB,EAAK,SAASsD,CAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,EAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAYjD,GAAa,EAC7B,QAASsB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAAS1F,EAAK,QAAQoD,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYtF,EAAK,QAAQoD,EAAS,EAAIsC,GAC9ED,GAAW,KAAKzF,EAAK,aAAa0F,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAY7C,EAAK,cAAcG,EAAU,EACzCyF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAU7C,EAAK,qBAAqB6C,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACbnF,EAAK,kBAAkBsC,EAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAInD,EAAK,OAAO,SAASG,GAAYA,GAAagD,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAnD,EAAK,aAAagF,CAAwB,EACtCG,KAAS,UAAYhF,IACvBH,EAAK,MAAMG,EAAU,EAElB+E,IACHlF,EAAK,kBAAkBsC,EAAM,CAEjC,CACF,CAEA,OAAID,GACFrC,EAAK,sBAAsBqC,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACA/E,EAAK,aAAakE,CAAc,EAEhCH,EAAmB,QAAQiC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,EAExCpC,IAAqB,GACvB7D,EAAK,sBAAsB6D,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,CAC7C,CACF,EAKa3G,GAAgB6C,GAA4B,CACvD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMrC,EAAgBqC,EAAQ,CAAC,EAGzB8D,EAAkBlG,EAAK,iBAAiBD,CAAa,EACvDmG,IAAoB,GACtB9F,GAAe,iCAAkC,EAEnDJ,EAAK,SAASkG,CAAe,CAC/B,EAEa3G,GAA8B4G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,IC7iBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,8h9QCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAKAC,GACAC,GACEC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GAEAC,GAMAC,GAwEAC,GAEOC,GA6CAC,GAaAC,GAaAC,GAcAC,GAkBAC,GAaAC,GAyBAC,GAaAC,GAtQbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAEM9B,GAAU,IAAe,CAAC,CAAC+B,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnE7B,GAAe,GACfC,GAAc,GACdC,GAAU,GAORG,GAAiF,CAAC,EAClFC,GAAuF,CAAC,EACxFC,GAA+E,CAAC,EAChFC,GAAyD,CAAC,EAC1DC,GAAsE,CAAC,EACvEC,GAAuD,CAAC,EACxDC,GAAiE,CAAC,EAElEC,GAAe,IAAY,CAC/B,GAAIZ,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMc,GAAwBiB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH9B,GAAe,GACX8B,EAAG,KAAK,KACV5B,GAAU,GACVC,GAAkB,CAAC,EAAE2B,EAAG,KAAK,GAAG,IAEhC7B,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,WACC2B,EAAG,KAAK,IACV1B,GAAiB,CAAC,EAAE0B,EAAG,KAAK,GAAG,EAE/B1B,GAAiB,CAAC,EAAE,EAEtB,MACF,IAAK,kBACC0B,EAAG,KAAK,IACVzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAG,EAEtDzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,kBACCA,EAAG,KAAK,IACVxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAG,EAEtDxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,SACCA,EAAG,KAAK,IACVvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAG,EAE9CvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAI,EAEjD,MACF,IAAK,UACCA,EAAG,KAAK,IACVtB,GAAwB,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAG,EAE/CtB,GAAwB,MAAM,EAAG,CAAC,EAAE,EAEtC,MACF,IAAK,MACCsB,EAAG,KAAK,IACVrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAG,EAEpCrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAI,EAEvC,MACF,IAAK,gBACCA,EAAG,KAAK,IACVpB,GAAsB,MAAM,EAAG,CAAC,EAAEoB,EAAG,KAAK,GAAG,EAE7CpB,GAAsB,MAAM,EAAG,CAAC,EAAE,EAEpC,MACF,IAAK,yBACCoB,EAAG,KAAK,IACVnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAG,EAEpDnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAI,EAEvD,MACF,QACF,CACF,EAEMhB,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAgC,SAA0B,CACrE,GAAsCjB,GAAQ,EAAG,CAC/C,GAAIG,GACF,OAEF,GAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAG3D,OAAAF,GAAe,GAGX6B,GAAI,KAAK,YAAc,QACrBf,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Ce,GAAI,KAAK,UAAYf,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACiB,EAASC,IAAW,CAC5CjC,IAAa,UAAU,EAEvB,IAAMkC,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9BlC,GAAc,IAAI,OAAOkC,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnElC,GAAY,QAAW+B,GAAmBE,EAAOF,CAAE,EACnD/B,GAAY,UAAYc,GACxB,IAAI,gBAAgBoB,CAAS,EAC7B9B,GAAoB,CAAC4B,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKL,GAAI,IAAI,EACjE9B,GAAY,YAAYmC,CAAO,CACjC,CAAC,CAEH,KACE,QAAOC,GAAsBN,GAAI,IAAI,CAEzC,EAEab,GAAoB,MAAMa,GAA4B,CACjE,GAAsC/B,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5C5B,GAAmB,CAAC2B,EAASC,CAAM,EACnC,IAAME,EAA0B,CAAC,KAAM,WAAY,GAAKL,CAAG,EAC3D9B,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAED,MAAWE,GAAYP,CAAG,CAE9B,EAEaZ,GAAwB,MAAMoB,GACHvC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAA+B,CAACmB,EAASC,IAAW,CAC7D3B,GAA+B,KAAK,CAAC0B,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,MAAAG,CAAK,CAAC,EACtEtC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,GAEWpB,GAAsBoB,CAAK,EAI9BnB,GAAwB,MAAMoB,EAAkCC,IAEjCzC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnE1B,GAA+B,KAAK,CAACyB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,UAAAI,EAAW,QAAAC,CAAO,CAAC,EACnFxC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWhB,GAAsBoB,EAAWC,CAAO,EAI/CpB,GACT,MAAMkB,EAAmBE,IAAoF,CAC/G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAIyC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA3B,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnEzB,GAAuB,KAAK,CAACwB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAG,EAAO,QAAAE,CAAO,CAAC,EACtExC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,CACH,KACE,QAAYlB,GAAckB,EAAOE,CAAO,CAE5C,EAEanB,GAAiB,MAAMoB,GAAqC,CACvE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CxB,GAAwB,KAAK,CAACuB,EAASC,CAAM,CAAC,EAC9C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKM,CAAS,EAChEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEId,GAAeoB,CAAS,CAEjC,EAEanB,GAAM,MACfmB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCL,IAAoE,CAC3G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAI4C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAjC,GAAa,EACN,IAAI,QAAsC,CAACmB,EAASC,IAAW,CACpEvB,GAAa,KAAK,CAACsB,EAASC,CAAM,CAAC,EACnC,IAAMc,EAAqBJ,EACrBR,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAM,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAJ,CAAO,CAAC,EACpGxC,GAAa,YAAYmC,EAAca,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYzB,GAAImB,EAAWC,EAAcC,EAAQC,EAAeC,EAASL,CAAO,CAEpF,EAEajB,GAAe,MAAMkB,GAAqC,CACrE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CtB,GAAsB,KAAK,CAACqB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKM,CAAS,EACtEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEIZ,GAAakB,CAAS,CAE/B,EAEajB,GAAsB,SACKzB,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAiB,CAACmB,EAASC,IAAW,CAC/CrB,GAA6B,KAAK,CAACoB,EAASC,CAAM,CAAC,EACnD,IAAME,EAA0B,CAAC,KAAM,wBAAwB,EAC/DnC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWX,GAAoB,IC/QpC,IAUIyB,GAESC,GAWAC,GAiBAC,GAxCbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAIaP,GAAuB,CAACQ,EAAgBC,IAA0C,CAC7F,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaR,GAAwBO,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,sBAAsBc,EAA8C,CAGxE,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAsB,IAAI,WAAWD,CAAW,CAAC,CAC1D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CASzG,GARM,MAAMC,GAAoB,IACzBvB,KACHA,GAA+BwB,GAAkBC,EAAG,GAEtD,MAAMzB,GACNA,GAA+B,QAG7B,OAAOqB,GAAiB,SAC1B,GAAI,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAAM,CAE/E,IAAMK,EAAQ,KAAM,SAASL,CAAY,EACzC,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMM,GAAcD,EAAOJ,CAAO,CAC1F,KAAO,CAGL,IAAMM,EAAmC,MAAM,KAAK,sBAAsBP,CAAY,EAEtF,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMQ,GAAsBD,EAAWN,CAAO,CACtG,KAEA,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMK,GAAcN,EAAcC,CAAO,CAEnG,CAEA,MAAM,SAAyB,CAC7B,OAAOQ,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCV,EACzC,CACrC,IAAMW,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKxB,CAAM,EACtByB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK7B,CAAM,EACvB8B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMzC,GAAqBwC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIxC,GAAqBwC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASrB,CAAO,EAEzFwB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKxC,GAAqB0C,EAAQF,CAAC,CAAC,EAEnG,OAAOI,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,ICxIA,IAeaC,GAmBAC,GAlCbC,GAAAC,EAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAazC,IAZI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAC5D,MAAM,MAAsB,CAE1BD,GAAgB,EAGhB,MAAMS,GAA8B,CACtC,CAKA,MAAM,8BAA8BC,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICpDA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,EAAA,kBAGAC,KACaH,GAAc,IAAII,KCJ/B,IAAAC,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,WAAAC,GAAA,oBAAAC,GAAA,YAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAQAC,KACAA,KAGAA,KCNO,IAAMC,GAAU,SDIvB,IAAOC,GAAQC,GAUe,CAC5B,IAAMC,EAA4C,cAAoC,YAEpD,OAAO,UAAc,KAAe,UAAU,KAC9EC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,EACzCC,GAAgB,QAASD,EAAa,CAAC,CAE3C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "B", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "noBackendErrMsg", "TrainingSession", "init_training_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_TrainingSession", "handler", "trainingOptions", "sessionOptions", "evalModel", "optimizerModel", "options", "backendHints", "i", "backend", "resolveBackend", "feeds", "arg1", "arg2", "fetches", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "_array", "_trainableOnly", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "esm_exports", "__export", "InferenceSession", "Tensor", "TrainingSession", "env", "registerBackend", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "d", "aa", "h", "a", "b", "c", "e", "f", "k", "l", "r", "m", "p", "n", "u", "w", "t", "g", "q", "ba", "ca", "x", "y", "da", "z", "ea", "A", "B", "C", "D", "fs", "fa", "ha", "E", "F", "noExitRuntime", "H", "I", "J", "K", "L", "M", "N", "O", "P", "ia", "ja", "ka", "la", "ma", "na", "oa", "Q", "pa", "R", "qa", "S", "ra", "sa", "ta", "ua", "va", "T", "wa", "U", "v", "xa", "ya", "za", "Aa", "Ba", "Ca", "Da", "Ea", "Fa", "V", "Ga", "Ha", "Ja", "Ia", "Ka", "La", "Na", "Pa", "Oa", "Qa", "Ra", "Sa", "Ta", "Ua", "Ma", "G", "W", "Va", "X", "Y", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "kb", "jb", "lb", "mb", "nb", "ob", "Z", "pb", "qb", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "d", "l", "p", "u", "v", "aa", "z", "ba", "A", "ca", "da", "ea", "fa", "ha", "B", "ia", "C", "a", "b", "c", "e", "f", "h", "k", "q", "m", "n", "r", "w", "y", "D", "g", "t", "ja", "ka", "la", "E", "ma", "F", "G", "H", "I", "na", "oa", "J", "pa", "fs", "qa", "ra", "sa", "ta", "L", "noExitRuntime", "M", "N", "ua", "P", "Q", "va", "wa", "xa", "ya", "za", "Aa", "R", "Ba", "S", "Ca", "Da", "Ea", "T", "Fa", "Ga", "Ha", "Ia", "U", "Ja", "V", "x", "Ka", "La", "Ma", "W", "Na", "Oa", "Pa", "Qa", "X", "Sa", "Ra", "Ta", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "Y", "yb", "zb", "Ab", "Bb", "Db", "Cb", "Eb", "Fb", "Hb", "Gb", "Ib", "Jb", "Kb", "Lb", "Nb", "Mb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Vb", "Wb", "Xb", "Yb", "Zb", "$b", "Ub", "O", "ac", "bc", "cc", "Z", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "sc", "vc", "tc", "uc", "wc", "xc", "yc", "zc", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "numThreads", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "i", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "createTensorShapeVariables", "getMaxComponents", "fillVector", "castToF32", "sumVector", "createIndicesHelper", "inputVariable", "outputVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "enableShapesUniforms", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "size", "dataType", "value", "name", "tensorType", "shapeOrRank", "isInput", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "impl", "indicesAndValue", "normalizedDispatchGroup", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "additionalUniforms", "uniformSnippets", "dispatchGroup", "inShape", "outShape", "inRank", "a", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputTensor", "permAttr", "inputDataType", "useShapesUniforms", "enableShapesUniforms", "outputShape", "outShapeOrRank", "inShapeOrRank", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "reduceOps", "reduceSharedOps", "reduceInitValues", "reduceOutputValues", "getInnerMostAxes", "computeOutAndReduceShapes", "expandShapeToKeepDim", "areAxesInnerMostDims", "getAxesPermutation", "createReduceSharedProgramInfo", "reduceCommon", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "init_reduce_shared", "__esmMin", "init_util", "init_common", "init_reduce", "init_transpose", "numInnerAxes", "rank", "res", "i", "shape", "axes", "outputShape", "dim", "reduceShape", "expandShape", "shapeIdx", "axis", "name", "shaderCache", "inputs", "reduceType", "outputDataType", "inputShape", "outputSize", "ShapeUtil", "reduceSize", "input", "inputVariable", "output", "outputVariable", "workgroupSize", "sharedMemorySnippet", "shaderHelper", "context", "attributes", "updatedAttributes", "createReduceAttributesFromInputs", "updatedAxes", "_dim", "normalizeAxes", "permutedAxes", "createTransposeProgramInfo", "finalOutputShape", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSumNaive", "reduceL1Naive", "reduceL2Naive", "reduceLogSumExpNaive", "reduceMaxNaive", "reduceMeanNaive", "reduceMinNaive", "reduceProdNaive", "reduceSumNaive", "reduceSumSquareNaive", "useNaiveReduceMethod", "reduceMean", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "reduceLogSum", "parseReduceAttributes", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "init_reduce_shared", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "inputOffsetAssignment", "initinputOffsetLet", "initinputOffsetVar", "initinputOffset", "reduceOps", "k", "l", "outputSize", "shaderHelper", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "shape", "reduceSize", "dim", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "validateInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "context", "attributes", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "createReduceProgramInfo", "createAttributeWithCacheKey", "validateAttentionInputs", "parseAttentionAttributes", "computeInPlaceSoftmax", "computeAttentionProbs", "computeVxAttentionScore", "applyAttention", "prepare", "attention", "init_attention", "__esmMin", "init_attribute_with_cache_key", "init_types", "init_common", "inputs", "attributes", "input", "weights", "bias", "maskIndex", "past", "relativePositionBias", "batchSize", "sequenceLength", "inputHiddenSize", "qHiddenSize", "kHiddenSize", "vHiddenSize", "sz", "kvSequenceLength", "pastSequenceLength", "totalSequenceLength", "maxSequenceLength", "maskType", "createAttributeWithCacheKey", "context", "n", "d", "components", "getMaxComponents", "inputHelper", "outputVariable", "threadMaxValue", "dataType", "tensorTypeToWsglStorageType", "WG", "dComp", "elementsPerWG", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "q", "key", "_bias", "parameters", "probsShape", "alpha", "qInput", "inputVariable", "kInput", "output", "vectorizedHeadSize", "M", "N", "K", "TILE_SIZE", "dispatch", "probs", "v", "params", "outputShape", "probsHelper", "vHelper", "k", "_maskIndex", "_past", "_pastKey", "_pastValue", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "clipAttributes", "dataType", "tensorTypeToWsglStorageType", "a", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "sharedDimensionDivisibleBy4", "funcCall", "typeA", "typeB", "typeOutput", "useShapesUniforms", "additionalImplementation", "expressionScalar", "expressionVector", "a", "b", "inputAShapeOrRank", "inputBShapeOrRank", "outputShapeOrRank", "output", "outputVariable", "inputVariable", "assignment", "isAOneElement", "ShapeUtil", "isBOneElement", "aLastDimDivisibleBy4", "bLastDimDivisibleBy4", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "outputSize", "cacheKeyAux", "calculatedShape", "BroadcastUtil", "sharedDimension", "i", "dimA", "dimB", "enableShapesUniforms", "createTensorShapeVariables", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "sizeInConcatAxisStr", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputDependencies", "inputShapeOrRanks", "enableInputShapesUniforms", "programUniforms", "enableShapesUniforms", "inputVariable", "createTensorShapeVariables", "enableOutputShapesUniforms", "outputShapeOrRank", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "getActivationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "valueType", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "typeSnippet", "biasSnippet", "init_activation_util", "__esmMin", "component", "dataType", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "inputVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "elementsPerThread", "dispatch", "components", "A", "B", "output", "inputVariables", "activationFunction", "getActivationSnippet", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "attributes", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "activationFunction", "applyActivation", "getActivationSnippet", "x", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_util", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "attributes", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "b", "context", "adjustedAttributes", "hasBias", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "inputChannels", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "createConv2DTransposeMatMulProgramInfo", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "einsumEquation", "dataType", "inputVars", "inputVariable", "outputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "idxCopy", "rhsSymbols", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "getShaderSource", "shaderHelper", "_var", "context", "attributes", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "outputSize", "enableInputShapesUniforms", "enableShapesUniforms", "inputShapeOrRank", "enableIndicesShapesUniforms", "indicesShapeOrRank", "enableOutputShapesUniforms", "outputShapeOrRank", "data", "inputVariable", "indices", "output", "outputVariable", "programUniforms", "createTensorShapeVariables", "inputDependencies", "calcDataIndices", "indicesRank", "calcStr", "i", "j", "getShaderSource", "shaderHelper", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "inputStrides", "ShapeUtil", "inputSize", "indicesShape", "indicesDataType", "indicesSize", "axis", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "getShaderSource", "shaderHelper", "i", "createAttributeWithCacheKey", "context", "validateInputs", "offsetC", "createGemmProgramInfo", "gemm", "parseGemmAttributes", "init_gemm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "m", "n", "dims", "broadcastM", "broadcastN", "offset", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "line", "dataType", "tensorTypeToWsglStorageType", "calculateAlpha", "calculateC", "inputStorageBuffersDeclarations", "getShaderSource", "shaderHelper", "context", "createAttributeWithCacheKey", "metadata", "createInstanceNormProgramInfo", "computeMean", "createInstanceNormNHWCProgramInfo", "parseInstanceNormAttributes", "instanceNorm", "init_instance_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "C", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "workgroupSize", "getShaderSource", "shaderHelper", "context", "input", "h", "c", "epsilon", "components", "getMaxComponents", "inputHelper", "scaleHelper", "biasHelper", "WG", "outputType", "sumCastType", "setOutputValue", "var1", "var2", "unitsOfWork", "wgSize", "getMeanShaderSource", "fillVector", "meanValues", "N", "H", "outputSize", "outputHelper", "tensorTypeToWsglStorageType", "scaleType", "scaleCastType", "channelScaleShift", "createAttributeWithCacheKey", "validateInputs", "createLayerNormProgramInfo", "parseLayerNormAttributes", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "axis", "ShapeUtil", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "components", "getMaxComponents", "dataType", "tensorTypeToWsglStorageType", "variables", "inputVariable", "outputVariable", "hasMeanDataOutput", "hasInvStdOutput", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "createAttributeWithCacheKey", "context", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "inputs", "context", "outputShape", "BroadcastUtil", "createMatmulProgramInfo", "validateInputs", "parseMultiHeadAttentionAttributes", "weightTransposeAttribute", "addBiasTranspose", "maybeTransposeToBNSHAndAddBias", "multiHeadAttention", "init_multi_head_attentiion", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_types", "init_attention", "init_common", "init_transpose", "inputs", "attributes", "query", "key", "value", "bias", "keyPaddingMask", "relativePositionBias", "pastKey", "pastValue", "dmmhaPacking", "batchSize", "sequenceLength", "hiddenSize", "kvSequenceLength", "pastSequenceLength", "maxSequenceLength", "headSize", "qkvFormat", "maskType", "maskDims", "passPastInKv", "vHiddenSize", "totalSequenceLength", "broadcastResPosBias", "createAttributeWithCacheKey", "context", "qkv", "biasOffset", "outputShape", "outputSize", "ShapeUtil", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "numHeads", "input", "reshapedInput", "createTransposeProgramInfo", "params", "kvBNSH", "Q", "applyAttention", "K", "V", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "generatePadCode", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "parsePadAttributes", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "validPads", "output", "inputDims", "inputStrides", "pads", "dataType", "constantValue", "inputRank", "block", "i", "attributes", "shaderHelper", "outputDims", "ShapeUtil", "outputSize", "outputVariable", "input", "inputVariable", "padSnippet", "outputShape", "bigInt64Pads", "value", "updatePads", "axes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "mode", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "generatePoolingCode", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "outputShapeAsChannelLast", "shaderHelper", "x", "xShape", "outputShape", "op1", "op2", "start", "inputDims", "dataType", "rank", "outputSize", "ShapeUtil", "output", "outputVariable", "kw", "sw", "pwStart", "pwEnd", "dimIdxW", "codeW", "codeH", "codeHEnd", "kh", "sh", "phStart", "phEnd", "dimIdxH", "dimH", "kernelSize", "kernelStrides", "stridesRank", "padsRank", "hasPads", "sum", "cur", "padCode", "i", "name", "adjustedAttributes", "inputVariable", "countIncludePad", "attr", "createAttributeWithCacheKey", "context", "format", "storageOrder", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "output", "outputVariable", "wgslType", "getShaderSource", "shaderHelper", "x", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "bilinearInterpolation", "bicubicInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "nearestMode", "roiTmp", "roiLocal", "v", "i", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "output", "input", "useExtrapolation", "extrapolationValue", "batchIdx", "heightIdx", "widthIdx", "channelIdx", "cubicCoeffA", "excludeOutside", "createCubicInterpolationFunction", "idx", "direction", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "getShaderSource", "shaderHelper", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "components", "getMaxComponents", "variables", "inputVariable", "outputVariable", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "outputShape", "enableInputShapeUniforms", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "enableShapeUniforms", "enableShapesUniforms", "inputShapeOrRank", "axis", "outputShapeOrRank", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "programUniforms", "uniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "components", "getMaxComponents", "packedCols", "maxVector", "name", "x", "inputVariable", "output", "outputVariable", "valueType", "threadMaxDecl", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "sumVector", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "rank", "axis", "adjustedAxis", "input", "inputVariable", "sizeInConcatAxis", "outputsTensorInfo", "outputShapes", "previousSum", "outputShape", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "outputSize", "ShapeUtil", "vecSize", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "outputShape", "calculatedShape", "BroadcastUtil", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_attention", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_multi_head_attentiion", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "attention", "parseAttentionAttributes", "averagePool", "parseAveragePoolAttributes", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "parseInstanceNormAttributes", "layerNorm", "parseLayerNormAttributes", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "multiHeadAttention", "parseMultiHeadAttentionAttributes", "neg", "not", "pad", "parsePadAttributes", "pow", "range", "reciprocal", "reduceMin", "parseReduceAttributes", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "device", "computePassEncoder", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "kernelName", "mappedData", "startTimeU64", "endTimeU64", "startTime", "endTime", "inputShapes", "value", "i", "tensorDataTypeEnumToString", "outputShapes", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "is1DimensionDispatch", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "computePassDescriptor", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "inputDatas", "gpuData", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "preLength", "offsets", "maxAlignmentOfField", "v", "baseAlignment", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "artifact", "LOG_DEBUG", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "i", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "ortEnvInitialized", "getSessionInputOutputCount", "initOrt", "initRuntime", "activeSessions", "isOrtEnvInitialized", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "sessionHandle", "wasm", "getInstance", "stack", "dataOffset", "checkLastError", "numThreads", "loggingLevel", "env", "logLevelStringToEnum", "initJsep", "model", "modelDataOffset", "modelData", "options", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "initOrtCallbacks", "createSessionAllocateCallbacks", "createSessionFinalizeCallbacks", "createSessionCallbacks", "releaseSessionCallbacks", "runCallbacks", "endProfilingCallbacks", "isOrtEnvInitializedCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyInstance", "initializeRuntime", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "run", "endProfiling", "isOrtEnvInitialized", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "model", "modeldata", "options", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "runtimeInitializationPromise", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler_inference", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "createSessionAllocate", "pathOrBuffer", "options", "isOrtEnvInitialized", "initializeRuntime", "env", "model", "createSession", "modelData", "createSessionFinalize", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler_inference", "env", "numCpuLogicalCores", "initializeWebAssemblyInstance", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "lib_exports", "__export", "InferenceSession", "Tensor", "TrainingSession", "lib_default", "env", "registerBackend", "init_esm", "version", "lib_default", "esm_exports", "wasmBackend", "registerBackend", "env", "version"]
}
